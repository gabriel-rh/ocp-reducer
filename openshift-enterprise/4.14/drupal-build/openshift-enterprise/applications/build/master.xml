<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE book [
<!ENTITY % sgml.features "IGNORE">
<!ENTITY % xml.features "INCLUDE">
<!ENTITY % DOCBOOK_ENTS PUBLIC "-//OASIS//ENTITIES DocBook Character Entities V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/dbcentx.mod">
%DOCBOOK_ENTS;
]>
<?asciidoc-toc?>
<?asciidoc-numbered?>
<book xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0">
<info>
<title>Building applications</title>
<date>2024-02-23</date>
<title>Building applications</title>
<productname>OpenShift Container Platform</productname>
<productnumber>4.14</productnumber>
<subtitle>Enter a short description here.</subtitle>
<abstract>
    <para>A short overview and summary of the book's subject and purpose, traditionally no more than one paragraph long.</para>
</abstract>
<authorgroup>
    <orgname>Red Hat OpenShift Documentation Team</orgname>
</authorgroup>
<xi:include href="Common_Content/Legal_Notice.xml" xmlns:xi="http://www.w3.org/2001/XInclude" />
</info>
<chapter xml:id="building-applications-overview">
<title>Building applications overview</title>
<simpara>Using OpenShift Container Platform, you can create, edit, delete, and manage applications using the web console or command line interface (CLI).</simpara>
<section xml:id="working-on-a-project">
<title>Working on a project</title>
<simpara>Using projects, you can organize and manage applications in isolation. You can manage the entire project lifecycle, including <link linkend="working-with-projects">creating, viewing, and deleting a project</link> in OpenShift Container Platform.</simpara>
<simpara>After you create the project, you can <link linkend="odc-providing-project-permissions-using-developer-perspective_projects">grant or revoke access to a project</link> and <link linkend="odc-customizing-available-cluster-roles-using-developer-perspective_projects">manage cluster roles</link> for the users using the Developer perspective. You can also <link linkend="configuring-project-creation">edit the project configuration resource</link> while creating a project template that is used for automatic provisioning of new projects.</simpara>
<simpara>Using the CLI, you can <link linkend="creating-project-other-user">create a project as a different user</link> by impersonating a request to the OpenShift Container Platform API. When you make a request to create a new project, the OpenShift Container Platform uses an endpoint to provision the project according to a customizable template. As a cluster administrator, you can choose to <link linkend="disabling-project-self-provisioning_configuring-project-creation">prevent an authenticated user group from self-provisioning new projects</link>.</simpara>
</section>
<section xml:id="working-on-application">
<title>Working on an application</title>
<section xml:id="creating-application">
<title>Creating an application</title>
<simpara>To create applications, you must have created a project or have access to a project with the appropriate roles and permissions. You can create an application by using either <link linkend="odc-creating-applications-using-developer-perspective">the Developer perspective in the web console</link>, <link linkend="creating-apps-from-installed-operators">installed Operators</link>, or <link linkend="creating-applications-using-cli">the OpenShift Container Platform CLI</link>. You can source the applications to be added to the project from Git, JAR files, devfiles, or the developer catalog.</simpara>
<simpara>You can also use components that include source or binary code, images, and templates to create an application by using the OpenShift Container Platform CLI. With the OpenShift Container Platform web console, you can create an application from an Operator installed by a cluster administrator.</simpara>
</section>
<section xml:id="maintaining-application">
<title>Maintaining an application</title>
<simpara>After you create the application you can use the web console to <link linkend="odc-monitoring-project-and-application-metrics-using-developer-perspective">monitor your project or application metrics</link>. You can also <link linkend="odc-editing-applications">edit</link> or <link linkend="odc-deleting-applications">delete</link> the application using the web console.
When the application is running, not all applications resources are used. As a cluster administrator, you can choose to <link linkend="idling-applications">idle these scalable resources</link> to reduce resource consumption.</simpara>
</section>
<section xml:id="connecting-application">
<title>Connecting an application to services</title>
<simpara>An application uses backing services to build and connect workloads, which vary according to the service provider. Using the <link linkend="understanding-service-binding-operator">Service Binding Operator</link>, as a developer, you can bind workloads together with Operator-managed backing services, without any manual procedures to configure the binding connection. You can apply service binding also on <link linkend="getting-started-with-service-binding-ibm-power-ibm-z">IBM Power&#174;, IBM Z&#174;, and IBM&#174; LinuxONE environments</link>.</simpara>
</section>
<section xml:id="deploying-application">
<title>Deploying an application</title>
<simpara>You can deploy your application using <link linkend="what-deployments-are"><literal>Deployment</literal> or <literal>DeploymentConfig</literal></link> objects and <link linkend="deployment-operations">manage</link> them from the web console. You can create <link linkend="deployment-strategies">deployment strategies</link> that help reduce downtime during a change or an upgrade to the application.</simpara>
<simpara>You can also use <link linkend="understanding-helm">Helm</link>, a software package manager that simplifies deployment of applications and services to OpenShift Container Platform clusters.</simpara>
</section>
</section>
<section xml:id="redhat-marketplace">
<title>Using the Red Hat Marketplace</title>
<simpara>The <link linkend="red-hat-marketplace">Red Hat Marketplace</link> is an open cloud marketplace where you can discover and access certified software for container-based environments that run on public clouds and on-premises.</simpara>
</section>
</chapter>
<chapter xml:id="_projects">
<title>Projects</title>
<section xml:id="working-with-projects">
<title>Working with projects</title>
<simpara>A <emphasis>project</emphasis> allows a community of users to organize and manage their content in
isolation from other communities.</simpara>
<note>
<simpara>Projects starting with <literal>openshift-</literal> and <literal>kube-</literal> are  <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/authentication_and_authorization/#rbac-default-projects_using-rbac">default projects</link>. These projects host cluster components that run as pods and other infrastructure components. As such, OpenShift Container Platform does not allow you to create projects starting with <literal>openshift-</literal> or <literal>kube-</literal> using the <literal>oc new-project</literal> command. Cluster administrators can create these projects using the <literal>oc adm new-project</literal> command.</simpara>
</note>
<important>
<simpara>Do not run workloads in or share access to default projects. Default projects are reserved for running core cluster components.</simpara>
<simpara>The following default projects are considered highly privileged: <literal>default</literal>, <literal>kube-public</literal>, <literal>kube-system</literal>, <literal>openshift</literal>, <literal>openshift-infra</literal>, <literal>openshift-node</literal>, and other system-created projects that have the <literal>openshift.io/run-level</literal> label set to <literal>0</literal> or <literal>1</literal>. Functionality that relies on admission plugins, such as pod security admission, security context constraints, cluster resource quotas, and image reference resolution, does not work in highly privileged projects.</simpara>
</important>
<section xml:id="creating-a-project-using-the-web-console_projects">
<title>Creating a project using the web console</title>
<simpara>If allowed by your cluster administrator, you can create a new project.</simpara>
<note>
<simpara>Projects starting with <literal>openshift-</literal> and <literal>kube-</literal> are considered critical by OpenShift Container Platform. As such, OpenShift Container Platform does not allow you to create Projects starting with <literal>openshift-</literal> using the web console.</simpara>
</note>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to <emphasis role="strong">Home</emphasis> &#8594; <emphasis role="strong">Projects</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Create Project</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Enter your project details.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Create</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-creating-projects-using-developer-perspective_projects">
<title>Creating a project using the Developer perspective in the web console</title>
<simpara>You can use the <emphasis role="strong">Developer</emphasis> perspective in the OpenShift Container Platform web console to create a project in your cluster.</simpara>
<note>
<simpara>Projects starting with <literal>openshift-</literal> and <literal>kube-</literal> are considered critical by OpenShift Container Platform. As such, OpenShift Container Platform does not allow you to create projects starting with <literal>openshift-</literal> or <literal>kube-</literal> using the <emphasis role="strong">Developer</emphasis> perspective. Cluster administrators can create these projects using the <literal>oc adm new-project</literal> command.</simpara>
</note>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Ensure that you have the appropriate roles and permissions to create projects, applications, and other workloads in OpenShift Container Platform.</simpara>
</listitem>
</itemizedlist>
<formalpara>
<title>Procedure</title>
<para>You can create a project using the <emphasis role="strong">Developer</emphasis> perspective, as follows:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Click the <emphasis role="strong">Project</emphasis> drop-down menu to see a list of all available projects. Select <emphasis role="strong">Create Project</emphasis>.</simpara>
<figure>
<title>Create project</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_create_project.png"/>
</imageobject>
<textobject><phrase>odc create project</phrase></textobject>
</mediaobject>
</figure>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Create Project</emphasis> dialog box, enter a unique name, such as <literal>myproject</literal>, in the <emphasis role="strong">Name</emphasis> field.</simpara>
</listitem>
<listitem>
<simpara>Optional: Add the <emphasis role="strong">Display Name</emphasis> and <emphasis role="strong">Description</emphasis> details for the project.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Create</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Use the left navigation panel to navigate to the <emphasis role="strong">Project</emphasis> view and see the dashboard for your project.</simpara>
</listitem>
<listitem>
<simpara>Optional:</simpara>
<itemizedlist>
<listitem>
<simpara>Use the <emphasis role="strong">Project</emphasis> drop-down menu at the top of the screen and select <emphasis role="strong">all projects</emphasis> to list all of the projects in your cluster.</simpara>
</listitem>
<listitem>
<simpara>Use the <emphasis role="strong">Details</emphasis> tab to see the project details.</simpara>
</listitem>
<listitem>
<simpara>If you have adequate permissions for a project, you can use the <emphasis role="strong">Project Access</emphasis> tab to provide or revoke <emphasis>administrator</emphasis>, <emphasis>edit</emphasis>, and <emphasis>view</emphasis> privileges for the project.</simpara>
</listitem>
</itemizedlist>
</listitem>
</orderedlist>
</section>
<section xml:id="creating-a-project-using-the-CLI_projects">
<title>Creating a project using the CLI</title>
<simpara>If allowed by your cluster administrator, you can create a new project.</simpara>
<note>
<simpara>Projects starting with <literal>openshift-</literal> and <literal>kube-</literal> are considered critical by OpenShift Container Platform. As such, OpenShift Container Platform does not allow you to create Projects starting with <literal>openshift-</literal> or <literal>kube-</literal> using the <literal>oc new-project</literal> command. Cluster administrators can create these Projects using the <literal>oc adm new-project</literal> command.</simpara>
</note>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>Run:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-project &lt;project_name&gt; \
    --description="&lt;description&gt;" --display-name="&lt;display_name&gt;"</programlisting>
<simpara>For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-project hello-openshift \
    --description="This is an example project" \
    --display-name="Hello OpenShift"</programlisting>
</listitem>
</itemizedlist>
<note>
<simpara>The number of projects you are allowed to create
might be limited by the system administrator.
After your limit is reached, you might have to delete an existing project in
order to create a new one.</simpara>
</note>
</section>
<section xml:id="viewing-a-project-using-the-web-console_projects">
<title>Viewing a project using the web console</title>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to <emphasis role="strong">Home</emphasis> &#8594; <emphasis role="strong">Projects</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select a project to view.</simpara>
<simpara>On this page, click <emphasis role="strong">Workloads</emphasis> to see workloads in the project.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="viewing-a-project-using-the-CLI_projects">
<title>Viewing a project using the CLI</title>
<simpara>When viewing projects, you are restricted to seeing only the projects you have
access to view based on the authorization policy.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To view a list of projects, run:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get projects</programlisting>
</listitem>
<listitem>
<simpara>You can change from the current project to a different project for CLI
operations. The specified project is then used in all subsequent operations that
manipulate project-scoped content:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc project &lt;project_name&gt;</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-providing-project-permissions-using-developer-perspective_projects">
<title>Providing access permissions to your project using the Developer perspective</title>
<simpara>You can use the <emphasis role="strong">Project</emphasis> view in the <emphasis role="strong">Developer</emphasis> perspective to grant or revoke access permissions to your project.</simpara>
<formalpara>
<title>Procedure</title>
<para>To add users to your project and provide <emphasis role="strong">Admin</emphasis>, <emphasis role="strong">Edit</emphasis>, or <emphasis role="strong">View</emphasis> access to them:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>In the <emphasis role="strong">Developer</emphasis> perspective, navigate to the <emphasis role="strong">Project</emphasis> view.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Project</emphasis> page, select the <emphasis role="strong">Project Access</emphasis> tab.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Add Access</emphasis> to add a new row of permissions to the default ones.</simpara>
<figure>
<title>Project permissions</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_project_permissions.png"/>
</imageobject>
<textobject><phrase>odc project permissions</phrase></textobject>
</mediaobject>
</figure>
</listitem>
<listitem>
<simpara>Enter the user name, click the <emphasis role="strong">Select a role</emphasis> drop-down list, and select an appropriate role.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Save</emphasis> to add the new permissions.</simpara>
</listitem>
</orderedlist>
<simpara>You can also use:</simpara>
<itemizedlist>
<listitem>
<simpara>The <emphasis role="strong">Select a role</emphasis> drop-down list, to modify the access permissions of an existing user.</simpara>
</listitem>
<listitem>
<simpara>The <emphasis role="strong">Remove Access</emphasis> icon, to completely remove the access permissions of an existing user to the project.</simpara>
</listitem>
</itemizedlist>
<note>
<simpara>Advanced role-based access control is managed in the <emphasis role="strong">Roles</emphasis> and <emphasis role="strong">Roles Binding</emphasis> views in the <emphasis role="strong">Administrator</emphasis> perspective.</simpara>
</note>
</section>
<section xml:id="odc-customizing-available-cluster-roles-using-developer-perspective_projects">
<title>Customizing the available cluster roles using the Developer perspective</title>
<simpara>The users of a project are assigned to a cluster role based on their access control. You can access these cluster roles by navigating to the <emphasis role="strong">Project</emphasis> &#8594; <emphasis role="strong">Project access</emphasis> &#8594; <emphasis role="strong">Role</emphasis>. By default, these roles are <emphasis role="strong">Admin</emphasis>, <emphasis role="strong">Edit</emphasis>, and <emphasis role="strong">View</emphasis>.</simpara>
<simpara>To add or edit the cluster roles for a project, you can customize the YAML code of the cluster.</simpara>
<formalpara>
<title>Procedure</title>
<para>To customize the different cluster roles of a project:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>In the <emphasis role="strong">Search</emphasis> view, use the <emphasis role="strong">Resources</emphasis> drop-down list to search for <literal>Console</literal>.</simpara>
</listitem>
<listitem>
<simpara>From the available options, select the <emphasis role="strong">Console <literal>operator.openshift.io/v1</literal></emphasis>.</simpara>
<figure>
<title>Searching Console resource</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_cluster_console.png"/>
</imageobject>
<textobject><phrase>odc cluster console</phrase></textobject>
</mediaobject>
</figure>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">cluster</emphasis> under the <emphasis role="strong">Name</emphasis> list.</simpara>
</listitem>
<listitem>
<simpara>Navigate to the <emphasis role="strong">YAML</emphasis> tab to view and edit the YAML code.</simpara>
</listitem>
<listitem>
<simpara>In the YAML code under <literal>spec</literal>, add or edit the list of <literal>availableClusterRoles</literal> and save your changes:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">spec:
  customization:
    projectAccess:
      availableClusterRoles:
      - admin
      - edit
      - view</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="adding-to-a-project_projects">
<title>Adding to a project</title>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Select <emphasis role="strong">Developer</emphasis> from the context selector at the top of the web console
navigation menu.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">+Add</emphasis></simpara>
</listitem>
<listitem>
<simpara>At the top of the page, select the name of the project that you want to add to.</simpara>
</listitem>
<listitem>
<simpara>Click a method for adding to your project, and then follow the workflow.</simpara>
</listitem>
</orderedlist>
<note>
<simpara>You can also add components to the topology using quick search.</simpara>
</note>
</section>
<section xml:id="checking-project-status-using-the-web-console_projects">
<title>Checking project status using the web console</title>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to <emphasis role="strong">Home</emphasis> &#8594; <emphasis role="strong">Projects</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select a project to see its status.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="checking-project-status-using-the-CLI_projects">
<title>Checking project status using the CLI</title>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Run:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc status</programlisting>
<simpara>This command provides a high-level overview of the current project, with its
components and their relationships.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="deleting-a-project-using-the-web-console_projects">
<title>Deleting a project using the web console</title>
<simpara>You can delete a project by using the OpenShift Container Platform web console.</simpara>
<note>
<simpara>If you do not have permissions to delete the project, the <emphasis role="strong">Delete Project</emphasis>
option is not available.</simpara>
</note>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to <emphasis role="strong">Home</emphasis> &#8594; <emphasis role="strong">Projects</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Locate the project that you want to delete from the list of projects.</simpara>
</listitem>
<listitem>
<simpara>On the far right side of the project listing, select <emphasis role="strong">Delete Project</emphasis> from the
Options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject>.</simpara>
</listitem>
<listitem>
<simpara>When the <emphasis role="strong">Delete Project</emphasis> pane opens, enter the name of the project that
you want to delete in the field.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Delete</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="deleting-a-project-using-the-CLI_projects">
<title>Deleting a project using the CLI</title>
<simpara>When you delete a project, the server updates the project status to
<emphasis role="strong">Terminating</emphasis> from <emphasis role="strong">Active</emphasis>. Then, the server clears all content from a project
that is in the <emphasis role="strong">Terminating</emphasis> state before finally removing the project. While a
project is in <emphasis role="strong">Terminating</emphasis> status, you cannot add new content to the project.
Projects can be deleted from the CLI or the web console.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Run:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc delete project &lt;project_name&gt;</programlisting>
</listitem>
</orderedlist>
</section>
</section>
<section xml:id="creating-project-other-user">
<title>Creating a project as another user</title>
<simpara>Impersonation allows you to create a project as a different user.</simpara>
<section xml:id="authentication-api-impersonation_creating-project-other-user">
<title>API impersonation</title>
<simpara>You can configure a request to the OpenShift Container Platform API to act as though it originated from another user. For more information, see <link xlink:href="https://kubernetes.io/docs/reference/access-authn-authz/authentication/#user-impersonation">User impersonation</link> in the Kubernetes documentation.</simpara>
</section>
<section xml:id="impersonation-project-creation_creating-project-other-user">
<title>Impersonating a user when you create a project</title>
<simpara>You can impersonate a different user when you create a project request. Because
<literal>system:authenticated:oauth</literal> is the only bootstrap group that can
create project requests, you must impersonate that group.</simpara>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>To create a project request on behalf of a different user:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-project &lt;project&gt; --as=&lt;user&gt; \
    --as-group=system:authenticated --as-group=system:authenticated:oauth</programlisting>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="configuring-project-creation">
<title>Configuring project creation</title>
<simpara>In OpenShift Container Platform, <emphasis>projects</emphasis> are used to group and isolate related objects.
When a request is made to create a new project using the web console or <literal>oc
new-project</literal> command, an endpoint in OpenShift Container Platform is used to provision the
project according to a template, which can be customized.</simpara>
<simpara>As
a cluster administrator, you can allow and configure how developers and service
accounts can create, or <emphasis>self-provision</emphasis>, their own projects.</simpara>
<section xml:id="about-project-creation_configuring-project-creation">
<title>About project creation</title>
<simpara>The OpenShift Container Platform API server automatically provisions new projects based on
the project template that is identified by the <literal>projectRequestTemplate</literal>
parameter in the cluster&#8217;s project configuration resource. If the parameter is
not defined, the API server creates a default template that creates a project
with the requested name, and assigns the requesting user to the <literal>admin</literal> role for
that project.</simpara>
<simpara>When a project request is submitted, the API substitutes the following
parameters into the template:</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Default project template parameters</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="66.6667*"/>
<thead>
<row>
<entry align="left" valign="top">Parameter</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>PROJECT_NAME</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The name of the project. Required.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>PROJECT_DISPLAYNAME</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The display name of the project. May be empty.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>PROJECT_DESCRIPTION</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The description of the project. May be empty.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>PROJECT_ADMIN_USER</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The user name of the administrating user.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>PROJECT_REQUESTING_USER</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The user name of the requesting user.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>Access to the API is granted to developers with the <literal>self-provisioner</literal> role and
the <literal>self-provisioners</literal> cluster role binding. This role is available to all
authenticated developers by default.</simpara>
</section>
<section xml:id="modifying-template-for-new-projects_configuring-project-creation">
<title>Modifying the template for new projects</title>
<simpara>As a cluster administrator, you can modify the default project template so that
new projects are created using your custom requirements.</simpara>
<simpara>To create your own custom project template:</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Log in as a user with <literal>cluster-admin</literal> privileges.</simpara>
</listitem>
<listitem>
<simpara>Generate the default project template:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm create-bootstrap-project-template -o yaml &gt; template.yaml</programlisting>
</listitem>
<listitem>
<simpara>Use a text editor to modify the generated <literal>template.yaml</literal> file by adding
objects or modifying existing objects.</simpara>
</listitem>
<listitem>
<simpara>The project template must be created in the <literal>openshift-config</literal> namespace. Load
your modified template:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create -f template.yaml -n openshift-config</programlisting>
</listitem>
<listitem>
<simpara>Edit the project configuration resource using the web console or CLI.</simpara>
<itemizedlist>
<listitem>
<simpara>Using the web console:</simpara>
<orderedlist numeration="lowerroman">
<listitem>
<simpara>Navigate to the <emphasis role="strong">Administration</emphasis> &#8594; <emphasis role="strong">Cluster Settings</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Configuration</emphasis> to view all configuration resources.</simpara>
</listitem>
<listitem>
<simpara>Find the entry for <emphasis role="strong">Project</emphasis> and click <emphasis role="strong">Edit YAML</emphasis>.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Using the CLI:</simpara>
<orderedlist numeration="lowerroman">
<listitem>
<simpara>Edit the <literal>project.config.openshift.io/cluster</literal> resource:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit project.config.openshift.io/cluster</programlisting>
</listitem>
</orderedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Update the <literal>spec</literal> section to include the <literal>projectRequestTemplate</literal> and <literal>name</literal>
parameters, and set the name of your uploaded project template. The default name
is <literal>project-request</literal>.</simpara>
<formalpara>
<title>Project configuration resource with custom project template</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: config.openshift.io/v1
kind: Project
metadata:
  ...
spec:
  projectRequestTemplate:
    name: &lt;template_name&gt;</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>After you save your changes, create a new project to verify that your changes
were successfully applied.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="disabling-project-self-provisioning_configuring-project-creation">
<title>Disabling project self-provisioning</title>
<simpara>You can prevent an authenticated user group from self-provisioning new projects.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Log in as a user with <literal>cluster-admin</literal> privileges.</simpara>
</listitem>
<listitem>
<simpara>View the <literal>self-provisioners</literal> cluster role binding usage by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc describe clusterrolebinding.rbac self-provisioners</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">Name:		self-provisioners
Labels:		&lt;none&gt;
Annotations:	rbac.authorization.kubernetes.io/autoupdate=true
Role:
  Kind:	ClusterRole
  Name:	self-provisioner
Subjects:
  Kind	Name				Namespace
  ----	----				---------
  Group	system:authenticated:oauth</programlisting>
</para>
</formalpara>
<simpara>Review the subjects in the <literal>self-provisioners</literal> section.</simpara>
</listitem>
<listitem>
<simpara>Remove the <literal>self-provisioner</literal> cluster role from the group <literal>system:authenticated:oauth</literal>.</simpara>
<itemizedlist>
<listitem>
<simpara>If the <literal>self-provisioners</literal> cluster role binding binds only the <literal>self-provisioner</literal> role to the <literal>system:authenticated:oauth</literal> group, run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc patch clusterrolebinding.rbac self-provisioners -p '{"subjects": null}'</programlisting>
</listitem>
<listitem>
<simpara>If the <literal>self-provisioners</literal> cluster role binding binds the <literal>self-provisioner</literal> role to more users, groups, or service accounts than the <literal>system:authenticated:oauth</literal> group, run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm policy \
    remove-cluster-role-from-group self-provisioner \
    system:authenticated:oauth</programlisting>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Edit the <literal>self-provisioners</literal> cluster role binding to prevent automatic updates to the role. Automatic updates reset the cluster roles to the default state.</simpara>
<itemizedlist>
<listitem>
<simpara>To update the role binding using the CLI:</simpara>
<orderedlist numeration="lowerroman">
<listitem>
<simpara>Run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit clusterrolebinding.rbac self-provisioners</programlisting>
</listitem>
<listitem>
<simpara>In the displayed role binding, set the <literal>rbac.authorization.kubernetes.io/autoupdate</literal> parameter value to <literal>false</literal>, as shown in the following example:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: authorization.openshift.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "false"
  ...</programlisting>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>To update the role binding by using a single command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc patch clusterrolebinding.rbac self-provisioners -p '{ "metadata": { "annotations": { "rbac.authorization.kubernetes.io/autoupdate": "false" } } }'</programlisting>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Log in as an authenticated user and verify that it can no longer self-provision a project:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-project test</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">Error from server (Forbidden): You may not request a new project via this API.</programlisting>
</para>
</formalpara>
<simpara>Consider customizing this project request message to provide more helpful instructions specific to your organization.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="customizing-project-request-message_configuring-project-creation">
<title>Customizing the project request message</title>
<simpara>When a developer or a service account that is unable to self-provision projects
makes a project creation request using the web console or CLI, the following
error message is returned by default:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">You may not request a new project via this API.</programlisting>
<simpara>Cluster administrators can customize this message. Consider updating it to
provide further instructions on how to request a new project specific to your
organization. For example:</simpara>
<itemizedlist>
<listitem>
<simpara>To request a project, contact your system administrator at
<literal>projectname@example.com</literal>.</simpara>
</listitem>
<listitem>
<simpara>To request a new project, fill out the project request form located at
<literal>https://internal.example.com/openshift-project-request</literal>.</simpara>
</listitem>
</itemizedlist>
<simpara>To customize the project request message:</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Edit the project configuration resource using the web console or CLI.</simpara>
<itemizedlist>
<listitem>
<simpara>Using the web console:</simpara>
<orderedlist numeration="lowerroman">
<listitem>
<simpara>Navigate to the <emphasis role="strong">Administration</emphasis> &#8594; <emphasis role="strong">Cluster Settings</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Configuration</emphasis> to view all configuration resources.</simpara>
</listitem>
<listitem>
<simpara>Find the entry for <emphasis role="strong">Project</emphasis> and click <emphasis role="strong">Edit YAML</emphasis>.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Using the CLI:</simpara>
<orderedlist numeration="lowerroman">
<listitem>
<simpara>Log in as a user with <literal>cluster-admin</literal> privileges.</simpara>
</listitem>
<listitem>
<simpara>Edit the <literal>project.config.openshift.io/cluster</literal> resource:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit project.config.openshift.io/cluster</programlisting>
</listitem>
</orderedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Update the <literal>spec</literal> section to include the <literal>projectRequestMessage</literal> parameter and
set the value to your custom message:</simpara>
<formalpara>
<title>Project configuration resource with custom project request message</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: config.openshift.io/v1
kind: Project
metadata:
  ...
spec:
  projectRequestMessage: &lt;message_string&gt;</programlisting>
</para>
</formalpara>
<simpara>For example:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: config.openshift.io/v1
kind: Project
metadata:
  ...
spec:
  projectRequestMessage: To request a project, contact your system administrator at projectname@example.com.</programlisting>
</listitem>
<listitem>
<simpara>After you save your changes, attempt to create a new project as a developer or
service account that is unable to self-provision projects to verify that your
changes were successfully applied.</simpara>
</listitem>
</orderedlist>
</section>
</section>
</chapter>
<chapter xml:id="_creating-applications">
<title>Creating applications</title>
<section xml:id="odc-creating-applications-using-developer-perspective">
<title>Creating applications using the Developer perspective</title>
<simpara>The <emphasis role="strong">Developer</emphasis> perspective in the web console provides you the following options from the <emphasis role="strong">+Add</emphasis> view to create applications and associated services and deploy them on OpenShift Container Platform:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Getting started resources</emphasis>: Use these resources to help you get started with Developer Console. You can choose to hide the header using the <emphasis role="strong">Options</emphasis> menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject>.</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Creating applications using samples</emphasis>: Use existing code samples to get started with creating applications on the OpenShift Container Platform.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Build with guided documentation</emphasis>: Follow the guided documentation to build applications and familiarize yourself with key concepts and terminologies.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Explore new developer features</emphasis>: Explore the new features and resources within the <emphasis role="strong">Developer</emphasis> perspective.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara><emphasis role="strong">Developer catalog</emphasis>: Explore the Developer Catalog to select the required applications, services, or source to image builders, and then add it to your project.</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">All Services</emphasis>: Browse the catalog to discover services across OpenShift Container Platform.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Database</emphasis>: Select the required database service and add it to your application.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Operator Backed</emphasis>: Select and deploy the required Operator-managed service.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Helm chart</emphasis>: Select the required Helm chart to simplify deployment of applications and services.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Devfile</emphasis>: Select a devfile from the <emphasis role="strong">Devfile registry</emphasis> to declaratively define a development environment.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Event Source</emphasis>: Select an event source to register interest in a class of events from a particular system.</simpara>
<note>
<simpara>The Managed services option is also available if the RHOAS Operator is installed.</simpara>
</note>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara><emphasis role="strong">Git repository</emphasis>: Import an existing codebase, Devfile, or Dockerfile from your Git repository using the <emphasis role="strong">From Git</emphasis>, <emphasis role="strong">From Devfile</emphasis>, or <emphasis role="strong">From Dockerfile</emphasis> options respectively, to build and deploy an application on OpenShift Container Platform.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Container images</emphasis>: Use existing images from an image stream or registry to deploy it on to the OpenShift Container Platform.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Pipelines</emphasis>: Use Tekton pipeline to create CI/CD pipelines for your software delivery process on the OpenShift Container Platform.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Serverless</emphasis>: Explore the <emphasis role="strong">Serverless</emphasis> options to create, build, and deploy stateless and serverless applications on the OpenShift Container Platform.</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Channel</emphasis>: Create a Knative channel to create an event forwarding and persistence layer with in-memory and reliable implementations.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara><emphasis role="strong">Samples</emphasis>: Explore the available sample applications to create, build, and deploy an application quickly.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Quick Starts</emphasis>: Explore the quick start options to create, import, and run applications with step-by-step instructions and tasks.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">From Local Machine</emphasis>: Explore the <emphasis role="strong">From Local Machine</emphasis> tile to import or upload files on your local machine for building and deploying applications easily.</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Import YAML</emphasis>: Upload a YAML file to create and define resources for building and deploying applications.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Upload JAR file</emphasis>: Upload a JAR file to build and deploy Java applications.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara><emphasis role="strong">Share my Project</emphasis>: Use this option to add or remove users to a project and provide accessibility options to them.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Helm Chart repositories</emphasis>: Use this option to add Helm Chart repositories in a namespace.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Re-ordering of resources</emphasis>: Use these resources to re-order pinned resources added to your navigation pane. The drag-and-drop icon is displayed on the left side of the pinned resource when you hover over it in the navigation pane. The dragged resource can be dropped only in the section where it resides.</simpara>
</listitem>
</itemizedlist>
<simpara>Note that certain options, such as <emphasis role="strong">Pipelines</emphasis>, <emphasis role="strong">Event Source</emphasis>, and <emphasis role="strong">Import Virtual Machines</emphasis>, are displayed only when the <link xlink:href="https://docs.openshift.com/pipelines/latest/install_config/installing-pipelines.html#op-installing-pipelines-operator-in-web-console_installing-pipelines">OpenShift Pipelines Operator</link>, <link xlink:href="https://docs.openshift.com/serverless/1.28/install/install-serverless-operator.html#serverless-install-web-console_install-serverless-operator">OpenShift Serverless Operator</link>, and <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/virtualization/#virt-subscribing-cli_installing-virt">OpenShift Virtualization Operator</link> are installed, respectively.</simpara>
<section xml:id="prerequisites_odc-creating-applications-using-developer-perspective">
<title>Prerequisites</title>
<simpara>To create applications using the <emphasis role="strong">Developer</emphasis> perspective ensure that:</simpara>
<itemizedlist>
<listitem>
<simpara>You have <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/web_console/#web-console">logged in to the web console</link>.</simpara>
</listitem>
<listitem>
<simpara>You have created a project or have access to a project with the appropriate <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/authentication_and_authorization/#default-roles_using-rbac">roles and permissions</link> to create applications and other workloads in OpenShift Container Platform.</simpara>
</listitem>
</itemizedlist>
<simpara>To create serverless applications, in addition to the preceding prerequisites, ensure that:</simpara>
<itemizedlist>
<listitem>
<simpara>You have <link xlink:href="https://docs.openshift.com/serverless/1.28/install/install-serverless-operator.html#install-serverless-operator">installed the OpenShift Serverless Operator</link>.</simpara>
</listitem>
<listitem>
<simpara>You have <link xlink:href="https://docs.openshift.com/serverless/1.28/install/installing-knative-serving.html#installing-knative-serving">created a <literal>KnativeServing</literal> resource in the <literal>knative-serving</literal> namespace</link>.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="odc-creating-sample-applications_odc-creating-applications-using-developer-perspective">
<title>Creating Sample applications</title>
<simpara>You can use the sample applications in the <emphasis role="strong">+Add</emphasis> flow of the <emphasis role="strong">Developer</emphasis> perspective to create, build, and deploy applications quickly.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have logged in to the OpenShift Container Platform web console and are in the <emphasis role="strong">Developer</emphasis> perspective.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the <emphasis role="strong">+Add</emphasis> view, click on the <emphasis role="strong">Samples</emphasis> tile to see the <emphasis role="strong">Samples</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>On the <emphasis role="strong">Samples</emphasis> page, select one of the available sample applications to see the <emphasis role="strong">Create Sample Application</emphasis> form.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Create Sample Application Form</emphasis>:</simpara>
<itemizedlist>
<listitem>
<simpara>In the <emphasis role="strong">Name</emphasis> field, the deployment name is displayed by default. You can modify this name as required.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Builder Image Version</emphasis>, a builder image is selected by default. You can modify this image version by using the <emphasis role="strong">Builder Image Version</emphasis> drop-down list.</simpara>
</listitem>
<listitem>
<simpara>A sample Git repository URL is added by default.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Create</emphasis> to create the sample application. The build status of the sample application is displayed on the <emphasis role="strong">Topology</emphasis> view. After the sample application is created, you can see the deployment added to the application.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-using-quickstarts_odc-creating-applications-using-developer-perspective">
<title>Creating applications using Quick Starts</title>
<simpara>The <emphasis role="strong">Quick Starts</emphasis> page shows you how to create, import, and run applications on OpenShift Container Platform, with step-by-step instructions and tasks.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have logged in to the OpenShift Container Platform web console and are in the <emphasis role="strong">Developer</emphasis> perspective.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the <emphasis role="strong">+Add</emphasis> view, click the <emphasis role="strong">View all quick starts</emphasis> link to view the <emphasis role="strong">Quick Starts</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Quick Starts</emphasis> page, click the tile for the quick start that you want to use.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Start</emphasis> to begin the quick start.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-importing-codebase-from-git-to-create-application_odc-creating-applications-using-developer-perspective">
<title>Importing a codebase from Git to create an application</title>
<simpara role="_abstract">You can use the <emphasis role="strong">Developer</emphasis> perspective to create, build, and deploy an application on OpenShift Container Platform using an existing codebase in GitHub.</simpara>
<simpara>The following procedure walks you through the <emphasis role="strong">From Git</emphasis> option in the <emphasis role="strong">Developer</emphasis> perspective to create an application.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the <emphasis role="strong">+Add</emphasis> view, click <emphasis role="strong">From Git</emphasis> in the <emphasis role="strong">Git Repository</emphasis> tile to see the <emphasis role="strong">Import from git</emphasis> form.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Git</emphasis> section, enter the Git repository URL for the codebase you want to use to create an application. For example, enter the URL of this sample Node.js application <literal>https://github.com/sclorg/nodejs-ex</literal>. The URL is then validated.</simpara>
</listitem>
<listitem>
<simpara>Optional: You can click <emphasis role="strong">Show Advanced Git Options</emphasis>  to add details such as:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Git Reference</emphasis> to point to code in a specific branch, tag, or commit to be used to build the application.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Context Dir</emphasis> to specify the subdirectory for the application source code you want to use to build the application.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Source Secret</emphasis> to create a <emphasis role="strong">Secret Name</emphasis> with credentials for pulling your source code from a private repository.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Optional: You can import a <literal>Devfile</literal>, a <literal>Dockerfile</literal>, <literal>Builder Image</literal>, or a <literal>Serverless Function</literal> through your Git repository to further customize your deployment.</simpara>
<itemizedlist>
<listitem>
<simpara>If your Git repository contains a <literal>Devfile</literal>, a <literal>Dockerfile</literal>, a <literal>Builder Image</literal>, or a <literal>func.yaml</literal>, it is automatically detected and populated on the respective path fields.</simpara>
</listitem>
<listitem>
<simpara>If a <literal>Devfile</literal>, a <literal>Dockerfile</literal>, or a <literal>Builder Image</literal> are detected in the same repository, the <literal>Devfile</literal> is selected by default.</simpara>
</listitem>
<listitem>
<simpara>If <literal>func.yaml</literal> is detected in the Git repository, the <emphasis role="strong">Import Strategy</emphasis> changes to <literal>Serverless Function</literal>.</simpara>
</listitem>
<listitem>
<simpara>Alternatively, you can create a serverless function by clicking <emphasis role="strong">Create Serverless function</emphasis> in the <emphasis role="strong">+Add</emphasis> view using the Git repository URL.</simpara>
</listitem>
<listitem>
<simpara>To edit the file import type and select a different strategy, click <emphasis role="strong">Edit import strategy</emphasis> option.</simpara>
</listitem>
<listitem>
<simpara>If multiple <literal>Devfiles</literal>, a <literal>Dockerfiles</literal>, or a <literal>Builder Images</literal> are detected, to import a specific instance, specify the respective paths relative to the context directory.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>After the Git URL is validated, the recommended builder image is selected and marked with a star. If the builder image is not auto-detected, select a builder image. For the <literal><link xlink:href="https://github.com/sclorg/nodejs-ex">https://github.com/sclorg/nodejs-ex</link></literal> Git URL, by default the Node.js builder image is selected.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Optional: Use the <emphasis role="strong">Builder Image Version</emphasis> drop-down to specify a version.</simpara>
</listitem>
<listitem>
<simpara>Optional: Use the <emphasis role="strong">Edit import strategy</emphasis> to select a different strategy.</simpara>
</listitem>
<listitem>
<simpara>Optional: For the Node.js builder image, use the <emphasis role="strong">Run command</emphasis> field to override the command to run the application.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">General</emphasis> section:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>In the <emphasis role="strong">Application</emphasis> field, enter a unique name for the application grouping, for example, <literal>myapp</literal>. Ensure that the application name is unique in a namespace.</simpara>
</listitem>
<listitem>
<simpara>The <emphasis role="strong">Name</emphasis> field to identify the resources created for this application is automatically populated based on the Git repository URL if there are no existing applications. If there are existing applications, you can choose to deploy the component within an existing application, create a new application, or keep the component unassigned.</simpara>
<note>
<simpara>The resource name must be unique in a namespace. Modify the resource name if you get an error.</simpara>
</note>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Resources</emphasis> section, select:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Deployment</emphasis>, to create an application in plain Kubernetes style.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Deployment Config</emphasis>, to create an OpenShift Container Platform style application.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Serverless Deployment</emphasis>, to create a Knative service.</simpara>
<note>
<simpara>To set the default resource preference for importing an application, go to <emphasis role="strong">User Preferences</emphasis> &#8594; <emphasis role="strong">Applications</emphasis> &#8594; <emphasis role="strong">Resource type</emphasis> field. The <emphasis role="strong">Serverless Deployment</emphasis> option is displayed in the <emphasis role="strong">Import from Git</emphasis> form only if the OpenShift Serverless Operator is installed in your cluster. The <emphasis role="strong">Resources</emphasis> section is not available while creating a serverless function. For further details, refer to the OpenShift Serverless documentation.</simpara>
</note>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Pipelines</emphasis> section, select <emphasis role="strong">Add Pipeline</emphasis>, and then click <emphasis role="strong">Show Pipeline Visualization</emphasis> to see the pipeline for the application. A default pipeline is selected, but you can choose the pipeline you want from the list of available pipelines for the application.</simpara>
<note>
<simpara>The <emphasis role="strong">Add pipeline</emphasis> checkbox is checked and <emphasis role="strong">Configure PAC</emphasis> is selected by default if the following criterias are fulfilled:</simpara>
<itemizedlist>
<listitem>
<simpara>Pipeline operator is installed</simpara>
</listitem>
<listitem>
<simpara><literal>pipelines-as-code</literal> is enabled</simpara>
</listitem>
<listitem>
<simpara><literal>.tekton</literal> directory is detected in the Git repository</simpara>
</listitem>
</itemizedlist>
</note>
</listitem>
<listitem>
<simpara>Add a webhook to your repository. If <emphasis role="strong">Configure PAC</emphasis> is checked and the GitHub App is set up, you can see the <emphasis role="strong">Use GitHub App</emphasis> and <emphasis role="strong">Setup a webhook</emphasis> options. If GitHub App is not set up, you can only see the <emphasis role="strong">Setup a webhook</emphasis> option:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Go to <emphasis role="strong">Settings</emphasis> &#8594; <emphasis role="strong">Webhooks</emphasis> and click <emphasis role="strong">Add webhook</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Set the <emphasis role="strong">Payload URL</emphasis> to the Pipelines as Code controller public URL.</simpara>
</listitem>
<listitem>
<simpara>Select the content type as <emphasis role="strong">application/json</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Add a webhook secret and note it in an alternate location. With <literal>openssl</literal> installed on your local machine, generate a random secret.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Let me select individual events</emphasis> and select these events: <emphasis role="strong">Commit comments</emphasis>, <emphasis role="strong">Issue comments</emphasis>, <emphasis role="strong">Pull request</emphasis>, and <emphasis role="strong">Pushes</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Add webhook</emphasis>.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Optional: In the <emphasis role="strong">Advanced Options</emphasis> section, the <emphasis role="strong">Target port</emphasis> and the <emphasis role="strong">Create a route to the application</emphasis> is selected by default so that you can access your application using a publicly available URL.</simpara>
<simpara>If your application does not expose its data on the default public port, 80, clear the check box, and set the target port number you want to expose.</simpara>
</listitem>
<listitem>
<simpara>Optional: You can use the following advanced options to further customize your application:</simpara>
</listitem>
</orderedlist>
<variablelist>
<varlistentry>
<term>Routing</term>
<listitem>
<simpara>By clicking the <emphasis role="strong">Routing</emphasis> link, you can perform the following actions:</simpara>
<itemizedlist>
<listitem>
<simpara>Customize the hostname for the route.</simpara>
</listitem>
<listitem>
<simpara>Specify the path the router watches.</simpara>
</listitem>
<listitem>
<simpara>Select the target port for the traffic from the drop-down list.</simpara>
</listitem>
<listitem>
<simpara>Secure your route by selecting the <emphasis role="strong">Secure Route</emphasis> check box. Select the required TLS termination type and set a policy for insecure traffic from the respective drop-down lists.</simpara>
<note>
<simpara>For serverless applications, the Knative service manages all the routing options above. However, you can customize the target port for traffic, if required. If the target port is not specified, the default port of <literal>8080</literal> is used.</simpara>
</note>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<variablelist>
<varlistentry>
<term>Domain mapping</term>
<listitem>
<simpara>If you are creating a <emphasis role="strong">Serverless Deployment</emphasis>, you can add a custom domain mapping to the Knative service during creation.</simpara>
<itemizedlist>
<listitem>
<simpara>In the <emphasis role="strong">Advanced options</emphasis> section, click <emphasis role="strong">Show advanced Routing options</emphasis>.</simpara>
<itemizedlist>
<listitem>
<simpara>If the domain mapping CR that you want to map to the service already exists, you can select it from the <emphasis role="strong">Domain mapping</emphasis> drop-down menu.</simpara>
</listitem>
<listitem>
<simpara>If you want to create a new domain mapping CR, type the domain name into the box, and select the <emphasis role="strong">Create</emphasis> option. For example, if you type in <literal>example.com</literal>, the <emphasis role="strong">Create</emphasis> option is <emphasis role="strong">Create "example.com"</emphasis>.</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>Health Checks</term>
<listitem>
<simpara>Click the <emphasis role="strong">Health Checks</emphasis> link to add Readiness, Liveness, and Startup probes to your application. All the probes have prepopulated default data; you can add the probes with the default data or customize it as required.</simpara>
<simpara>To customize the health probes:</simpara>
<itemizedlist>
<listitem>
<simpara>Click <emphasis role="strong">Add Readiness Probe</emphasis>, if required, modify the parameters to check if the container is ready to handle requests, and select the check mark to add the probe.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Add Liveness Probe</emphasis>, if required, modify the parameters to check if a container is still running, and select the check mark to add the probe.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Add Startup Probe</emphasis>, if required, modify the parameters to check if the application within the container has started, and select the check mark to add the probe.</simpara>
<simpara>For each of the probes, you can specify the request type - <emphasis role="strong">HTTP GET</emphasis>, <emphasis role="strong">Container Command</emphasis>, or <emphasis role="strong">TCP Socket</emphasis>,  from the drop-down list. The form changes as per the selected request type. You can then modify the default values for the other parameters, such as the success and failure thresholds for the probe, number of seconds before performing the first probe after the container starts, frequency of the probe, and the timeout value.</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>Build Configuration and Deployment</term>
<listitem>
<simpara>Click the <emphasis role="strong">Build Configuration</emphasis> and <emphasis role="strong">Deployment</emphasis> links to see the respective configuration options. Some options are selected by default; you can customize them further by adding the necessary triggers and environment variables.</simpara>
<simpara>For serverless applications, the <emphasis role="strong">Deployment</emphasis> option is not displayed as the Knative configuration resource maintains the desired state for your deployment instead of a <literal>DeploymentConfig</literal> resource.</simpara>
</listitem>
</varlistentry>
</variablelist>
<variablelist>
<varlistentry>
<term>Scaling</term>
<listitem>
<simpara>Click the <emphasis role="strong">Scaling</emphasis> link to define the number of pods or instances of the application you want to deploy initially.</simpara>
<simpara>If you are creating a serverless deployment, you can also configure the following settings:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Min Pods</emphasis> determines the lower limit for the number of pods that must be running at any given time for a Knative service. This is also known as the <literal>minScale</literal> setting.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Max Pods</emphasis> determines the upper limit for the number of pods that can be running at any given time for a Knative service. This is also known as the <literal>maxScale</literal> setting.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Concurrency target</emphasis> determines the number of concurrent requests desired for each instance of the application at a given time.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Concurrency limit</emphasis> determines the limit for the number of concurrent requests allowed for each instance of the application at a given time.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Concurrency utilization</emphasis> determines the percentage of the concurrent requests limit that must be met before Knative scales up additional pods to handle additional traffic.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Autoscale window</emphasis> defines the time window over which metrics are averaged to provide input for scaling decisions when the autoscaler is not in panic mode. A service is scaled-to-zero if no requests are received during this window. The default duration for the autoscale window is <literal>60s</literal>. This is also known as the stable window.</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>Resource Limit</term>
<listitem>
<simpara>Click the <emphasis role="strong">Resource Limit</emphasis> link to set the amount of <emphasis role="strong">CPU</emphasis> and <emphasis role="strong">Memory</emphasis> resources a container is guaranteed or allowed to use when running.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Labels</term>
<listitem>
<simpara>Click the <emphasis role="strong">Labels</emphasis> link to add custom labels to your application.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Click <emphasis role="strong">Create</emphasis> to create the application and a success notification is displayed. You can see the build status of the application in the <emphasis role="strong">Topology</emphasis> view.</simpara>
</listitem>
</orderedlist>
</listitem>
</varlistentry>
</variablelist>
</section>
<section xml:id="odc-deploying-container-image_odc-creating-applications-using-developer-perspective">
<title>Creating applications by deploying container image</title>
<simpara>You can use an external image registry or an image stream tag from an internal registry to deploy an application on your cluster.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have logged in to the OpenShift Container Platform web console and are in the <emphasis role="strong">Developer</emphasis> perspective.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the <emphasis role="strong">+Add</emphasis> view, click <emphasis role="strong">Container images</emphasis> to view the <emphasis role="strong">Deploy Images</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Image</emphasis> section:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Select <emphasis role="strong">Image name from external registry</emphasis> to deploy an image from a public or a private registry, or select <emphasis role="strong">Image stream tag from internal registry</emphasis> to deploy an image from an internal registry.</simpara>
</listitem>
<listitem>
<simpara>Select an icon for your image in the <emphasis role="strong">Runtime icon</emphasis> tab.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">General</emphasis> section:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>In the <emphasis role="strong">Application name</emphasis> field, enter a unique name for the application grouping.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Name</emphasis> field, enter a unique name to identify the resources created for this component.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Resource type</emphasis> section, select the resource type to generate:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Select <emphasis role="strong">Deployment</emphasis> to enable declarative updates for <literal>Pod</literal> and <literal>ReplicaSet</literal> objects.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">DeploymentConfig</emphasis> to define the template for a <literal>Pod</literal> object, and manage deploying new images and configuration sources.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">Serverless Deployment</emphasis> to enable scaling to zero when idle.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Create</emphasis>. You can view the build status of the application in the <emphasis role="strong">Topology</emphasis> view.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-deploying-java-applications_odc-creating-applications-using-developer-perspective">
<title>Deploying a Java application by uploading a JAR file</title>
<simpara>You can use the web console <emphasis role="strong">Developer</emphasis> perspective to upload a JAR file by using the following options:</simpara>
<itemizedlist>
<listitem>
<simpara>Navigate to the <emphasis role="strong">+Add</emphasis> view of the <emphasis role="strong">Developer</emphasis> perspective, and click <emphasis role="strong">Upload JAR file</emphasis> in the <emphasis role="strong">From Local Machine</emphasis> tile. Browse and select your JAR file, or drag a JAR file to deploy your application.</simpara>
</listitem>
<listitem>
<simpara>Navigate to the <emphasis role="strong">Topology</emphasis> view and use the <emphasis role="strong">Upload JAR file</emphasis> option, or drag a JAR file to deploy your application.</simpara>
</listitem>
<listitem>
<simpara>Use the in-context menu in the <emphasis role="strong">Topology</emphasis> view, and then use the <emphasis role="strong">Upload JAR file</emphasis> option to upload your JAR file to deploy your application.</simpara>
</listitem>
</itemizedlist>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>The Cluster Samples Operator must be installed by a cluster administrator.</simpara>
</listitem>
<listitem>
<simpara>You have access to the OpenShift Container Platform web console and are in the <emphasis role="strong">Developer</emphasis> perspective.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the <emphasis role="strong">Topology</emphasis> view, right-click anywhere to view the <emphasis role="strong">Add to Project</emphasis> menu.</simpara>
</listitem>
<listitem>
<simpara>Hover over the <emphasis role="strong">Add to Project</emphasis> menu to see the menu options, and then select the <emphasis role="strong">Upload JAR file</emphasis> option to see the <emphasis role="strong">Upload JAR file</emphasis> form. Alternatively, you can drag the JAR file into the <emphasis role="strong">Topology</emphasis> view.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">JAR file</emphasis> field, browse for the required JAR file on your local machine and upload it. Alternatively, you can drag the JAR file on to the field. A toast alert is displayed at the top right if an incompatible file type is dragged into the <emphasis role="strong">Topology</emphasis> view. A field error is displayed if an incompatible file type is dropped on the field in the upload form.</simpara>
</listitem>
<listitem>
<simpara>The runtime icon and builder image are selected by default. If a builder image is not auto-detected, select a builder image. If required, you can change the version using the <emphasis role="strong">Builder Image Version</emphasis> drop-down list.</simpara>
</listitem>
<listitem>
<simpara>Optional: In the <emphasis role="strong">Application Name</emphasis> field, enter a unique name for your application to use for resource labelling.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Name</emphasis> field, enter a unique component name for the associated resources.</simpara>
</listitem>
<listitem>
<simpara>Optional: Use the <emphasis role="strong">Resource type</emphasis> drop-down list to change the resource type.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Advanced options</emphasis> menu, click <emphasis role="strong">Create a Route to the Application</emphasis> to configure a public URL for your deployed application.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Create</emphasis> to deploy the application. A toast notification is shown to notify you that the JAR file is being uploaded. The toast notification also includes a link to view the build logs.</simpara>
</listitem>
</orderedlist>
<note>
<simpara>If you attempt to close the browser tab while the build is running, a web alert is displayed.</simpara>
</note>
<simpara>After the JAR file is uploaded and the application is deployed, you can view the application in the <emphasis role="strong">Topology</emphasis> view.</simpara>
</section>
<section xml:id="odc-using-the-devfile-registry_odc-creating-applications-using-developer-perspective">
<title>Using the Devfile registry to access devfiles</title>
<simpara>You can use the devfiles in the <emphasis role="strong">+Add</emphasis> flow of the <emphasis role="strong">Developer</emphasis> perspective to create an application. The <emphasis role="strong">+Add</emphasis> flow provides a complete integration with the <link xlink:href="https://registry.devfile.io/viewer">devfile community registry</link>. A devfile is a portable YAML file that describes your development environment without needing to configure it from scratch. Using the <emphasis role="strong">Devfile registry</emphasis>, you can use a preconfigured devfile to create an application.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to <emphasis role="strong">Developer Perspective</emphasis> &#8594; <emphasis role="strong">+Add</emphasis> &#8594; <emphasis role="strong">Developer Catalog</emphasis> &#8594; <emphasis role="strong">All Services</emphasis>. A list of all the available services in the <emphasis role="strong">Developer Catalog</emphasis> is displayed.</simpara>
</listitem>
<listitem>
<simpara>Under <emphasis role="strong">All Services</emphasis>, select <emphasis role="strong">Devfiles</emphasis> to browse for devfiles that support a particular language or framework. Alternatively, you can use the keyword filter to search for a particular devfile using their name, tag, or description.</simpara>
</listitem>
<listitem>
<simpara>Click the devfile you want to use to create an application. The devfile tile displays the details of the devfile, including the name, description, provider, and the documentation of the devfile.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Create</emphasis> to create an application and view the application in the <emphasis role="strong">Topology</emphasis> view.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-using-the-developer-catalog-to-add-services-or-components_odc-creating-applications-using-developer-perspective">
<title>Using the Developer Catalog to add services or components to your application</title>
<simpara>You use the Developer Catalog to deploy applications and services based on Operator backed services such as Databases, Builder Images, and Helm Charts. The Developer Catalog contains a collection of application components, services, event sources, or source-to-image builders that you can add to your project. Cluster administrators can customize the content made available in the catalog.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the <emphasis role="strong">Developer</emphasis> perspective, navigate to the <emphasis role="strong">+Add</emphasis> view and from the <emphasis role="strong">Developer Catalog</emphasis> tile, click <emphasis role="strong">All Services</emphasis> to view all the available services in the <emphasis role="strong">Developer Catalog</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Under <emphasis role="strong">All Services</emphasis>, select the kind of service or the component you need to add to your project. For this example, select <emphasis role="strong">Databases</emphasis> to list all the database services and then click <emphasis role="strong">MariaDB</emphasis> to see the details for the service.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Instantiate Template</emphasis> to see an automatically populated template with details for the <emphasis role="strong">MariaDB</emphasis> service, and then click <emphasis role="strong">Create</emphasis> to create and view the MariaDB service in the <emphasis role="strong">Topology</emphasis> view.</simpara>
<figure>
<title>MariaDB in Topology</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_devcatalog_toplogy.png"/>
</imageobject>
<textobject><phrase>odc devcatalog toplogy</phrase></textobject>
</mediaobject>
</figure>
</listitem>
</orderedlist>
</section>
<section xml:id="additional-resources_odc-creating-applications-using-developer-perspective" role="_additional-resources">
<title>Additional resources</title>
<itemizedlist>
<listitem>
<simpara>For more information about Knative routing settings for OpenShift Serverless, see <link xlink:href="https://docs.openshift.com/serverless/1.28/knative-serving/external-ingress-routing/routing-overview.html#routing-overview">Routing</link>.</simpara>
</listitem>
<listitem>
<simpara>For more information about domain mapping settings for OpenShift Serverless, see <link xlink:href="https://docs.openshift.com/serverless/1.28/knative-serving/config-custom-domains/serverless-custom-domains.html#serverless-custom-domains">Configuring a custom domain for a Knative service</link>.</simpara>
</listitem>
<listitem>
<simpara>For more information about Knative autoscaling settings for OpenShift Serverless, see <link xlink:href="https://docs.openshift.com/serverless/1.28/knative-serving/autoscaling/serverless-autoscaling-developer.html#serverless-autoscaling-developer">Autoscaling</link>.</simpara>
</listitem>
<listitem>
<simpara>For more information about adding a new user to a project, see <link linkend="odc-providing-project-permissions-using-developer-perspective_projects">Working with projects</link>.</simpara>
</listitem>
<listitem>
<simpara>For more information about creating a Helm Chart repository, see <link linkend="odc-creating-helm-releases-using-developer-perspective_configuring-custom-helm-chart-repositories">Creating Helm Chart repositories</link>.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="creating-apps-from-installed-operators">
<title>Creating applications from installed Operators</title>
<simpara><emphasis>Operators</emphasis> are a method of packaging, deploying, and managing a Kubernetes
application. You can create applications on OpenShift Container Platform using Operators that
have been installed by a cluster administrator.</simpara>
<simpara>This guide walks developers through an example of creating applications from an
installed Operator using the OpenShift Container Platform web console.</simpara>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara>See the
<link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/operators/#olm-what-operators-are">Operators</link>
guide for more on how Operators work and how the Operator Lifecycle Manager is
integrated in OpenShift Container Platform.</simpara>
</listitem>
</itemizedlist>
<section xml:id="olm-creating-etcd-cluster-from-operator_creating-apps-from-installed-operators">
<title>Creating an etcd cluster using an Operator</title>
<simpara>This procedure walks through creating a new etcd cluster using the etcd Operator, managed by Operator Lifecycle Manager (OLM).</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Access to an OpenShift Container Platform 4.14 cluster.</simpara>
</listitem>
<listitem>
<simpara>The etcd Operator already installed cluster-wide by an administrator.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a new project in the OpenShift Container Platform web console for this procedure. This example uses a project called <literal>my-etcd</literal>.</simpara>
</listitem>
<listitem>
<simpara>Navigate to the <emphasis role="strong">Operators &#8594; Installed Operators</emphasis> page. The Operators that have been installed to the cluster by the
cluster administrator
and are available for use are shown here as a list of cluster service versions (CSVs). CSVs are used to launch and manage the software provided by the Operator.</simpara>
<tip>
<simpara>You can get this list from the CLI using:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get csv</programlisting>
</tip>
</listitem>
<listitem>
<simpara>On the <emphasis role="strong">Installed Operators</emphasis> page, click the etcd Operator to view more details and available actions.</simpara>
<simpara>As shown under <emphasis role="strong">Provided APIs</emphasis>, this Operator makes available three new resource types, including one for an <emphasis role="strong">etcd Cluster</emphasis> (the <literal>EtcdCluster</literal> resource). These objects work similar to the built-in native Kubernetes ones, such as <literal>Deployment</literal> or <literal>ReplicaSet</literal>, but contain logic specific to managing etcd.</simpara>
</listitem>
<listitem>
<simpara>Create a new etcd cluster:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>In the <emphasis role="strong">etcd Cluster</emphasis> API box, click <emphasis role="strong">Create instance</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>The next page allows you to make any modifications to the minimal starting template of an <literal>EtcdCluster</literal> object, such as the size of the cluster. For now, click <emphasis role="strong">Create</emphasis> to finalize. This triggers the Operator to start up the pods, services, and other components of the new etcd cluster.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Click the <emphasis role="strong">example</emphasis> etcd cluster, then click the <emphasis role="strong">Resources</emphasis> tab to see that your project now contains a number of resources created and configured automatically by the Operator.</simpara>
<simpara>Verify that a Kubernetes service has been created that allows you to access the database from other pods in your project.</simpara>
</listitem>
<listitem>
<simpara>All users with the <literal>edit</literal> role in a given project can create, manage, and delete application instances (an etcd cluster, in this example) managed by Operators that have already been created in the project, in a self-service manner, just like a cloud service. If you want to enable additional users with this ability, project administrators can add the role using the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc policy add-role-to-user edit &lt;user&gt; -n &lt;target_project&gt;</programlisting>
</listitem>
</orderedlist>
<simpara>You now have an etcd cluster that will react to failures and rebalance data as pods become unhealthy or are migrated between nodes in the cluster. Most importantly,
cluster administrators
or developers with proper access can now easily use the database with their applications.</simpara>
</section>
</section>
<section xml:id="creating-applications-using-cli">
<title>Creating applications using the CLI</title>
<simpara>You can create an OpenShift Container Platform application from components that include
source or binary code, images, and templates by using the OpenShift Container Platform
CLI.</simpara>
<simpara>The set of objects created by <literal>new-app</literal> depends on the artifacts passed as
input: source repositories, images, or templates.</simpara>
<section xml:id="applications-create-using-cli-source-code_creating-applications-using-cli">
<title>Creating an application from source code</title>
<simpara>With the <literal>new-app</literal> command you can create applications from source code in a local or remote Git repository.</simpara>
<simpara>The <literal>new-app</literal> command creates a build configuration, which itself creates a new application image from your source code. The <literal>new-app</literal> command typically also creates a <literal>Deployment</literal> object to deploy the new image, and a service to provide load-balanced access to the deployment running your image.</simpara>
<simpara>OpenShift Container Platform automatically detects whether the pipeline, source, or docker build strategy should be used, and in the case of source build, detects an appropriate language builder image.</simpara>
<section xml:id="local_creating-applications-using-cli">
<title>Local</title>
<simpara>To create an application from a Git repository in a local directory:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app /&lt;path to source code&gt;</programlisting>
<note>
<simpara>If you use a local Git repository, the repository must have a remote named <literal>origin</literal> that points to a URL that is accessible by the OpenShift Container Platform cluster. If there is no recognized remote,  running the <literal>new-app</literal> command will create a binary build.</simpara>
</note>
</section>
<section xml:id="remote_creating-applications-using-cli">
<title>Remote</title>
<simpara>To create an application from a remote Git repository:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app https://github.com/sclorg/cakephp-ex</programlisting>
<simpara>To create an application from a private remote Git repository:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app https://github.com/youruser/yourprivaterepo --source-secret=yoursecret</programlisting>
<note>
<simpara>If you use a private remote Git repository, you can use the <literal>--source-secret</literal> flag to specify an existing source clone secret that will get injected into your build config to access the repository.</simpara>
</note>
<simpara>You can use a subdirectory of your source code repository by specifying a <literal>--context-dir</literal> flag. To create an application from a remote Git repository and a context subdirectory:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app https://github.com/sclorg/s2i-ruby-container.git \
    --context-dir=2.0/test/puma-test-app</programlisting>
<simpara>Also, when specifying a remote URL, you can specify a Git branch to use by appending <literal>#&lt;branch_name&gt;</literal> to the end of the URL:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app https://github.com/openshift/ruby-hello-world.git#beta4</programlisting>
</section>
<section xml:id="build-strategy-detection_creating-applications-using-cli">
<title>Build strategy detection</title>
<simpara>OpenShift Container Platform automatically determines which build strategy to use by detecting certain files:</simpara>
<itemizedlist>
<listitem>
<simpara>If a Jenkins file exists in the root or specified context directory of the source repository when creating a new application, OpenShift Container Platform generates a pipeline build strategy.</simpara>
<note>
<simpara>The <literal>pipeline</literal> build strategy is deprecated; consider using Red Hat OpenShift Pipelines instead.</simpara>
</note>
</listitem>
<listitem>
<simpara>If a Dockerfile exists in the root or specified context directory of the source repository when creating a new application, OpenShift Container Platform generates a docker build strategy.</simpara>
</listitem>
<listitem>
<simpara>If neither a Jenkins file nor a Dockerfile is detected, OpenShift Container Platform generates a source build strategy.</simpara>
</listitem>
</itemizedlist>
<simpara>Override the automatically detected build strategy by setting the <literal>--strategy</literal> flag to <literal>docker</literal>, <literal>pipeline</literal>, or <literal>source</literal>.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app /home/user/code/myapp --strategy=docker</programlisting>
<note>
<simpara>The <literal>oc</literal> command requires that files containing build sources are available in a remote Git repository. For all source builds, you must use <literal>git remote -v</literal>.</simpara>
</note>
</section>
<section xml:id="language-detection_creating-applications-using-cli">
<title>Language detection</title>
<simpara>If you use the source build strategy, <literal>new-app</literal> attempts to determine the language builder to use by the presence of certain files in the root or specified context directory of the repository:</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Languages detected by <literal>new-app</literal></title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="66.6667*"/>
<thead>
<row>
<entry align="left" valign="top">Language</entry>
<entry align="left" valign="top">Files</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>dotnet</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>project.json</literal>, <literal>*.csproj</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>jee</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>pom.xml</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>nodejs</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>app.json</literal>, <literal>package.json</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>perl</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>cpanfile</literal>, <literal>index.pl</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>php</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>composer.json</literal>, <literal>index.php</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>python</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>requirements.txt</literal>, <literal>setup.py</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ruby</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>Gemfile</literal>, <literal>Rakefile</literal>, <literal>config.ru</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>scala</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>build.sbt</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>golang</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>Godeps</literal>, <literal>main.go</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>After a language is detected, <literal>new-app</literal> searches the OpenShift Container Platform server for image stream tags that have a <literal>supports</literal> annotation matching the detected language, or an image stream that matches the name of the detected language. If a match is not found, <literal>new-app</literal> searches the <link xlink:href="https://registry.hub.docker.com">Docker Hub registry</link> for an image that matches the detected language based on name.</simpara>
<simpara>You can override the image the builder uses for a particular source repository by specifying the image, either an image stream or container
specification, and the repository with a <literal>~</literal> as a separator. Note that if this is done, build strategy detection and language detection are not carried out.</simpara>
<simpara>For example, to use the <literal>myproject/my-ruby</literal> imagestream with the source in a remote repository:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app myproject/my-ruby~https://github.com/openshift/ruby-hello-world.git</programlisting>
<simpara>To use the <literal>openshift/ruby-20-centos7:latest</literal> container image stream with the source in a local repository:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app openshift/ruby-20-centos7:latest~/home/user/code/my-ruby-app</programlisting>
<note>
<simpara>Language detection requires the Git client to be locally installed so that your repository can be cloned and inspected. If Git is not available, you can avoid the language detection step by specifying the builder image to use with your repository with the <literal>&lt;image&gt;~&lt;repository&gt;</literal> syntax.</simpara>
<simpara>The <literal>-i &lt;image&gt; &lt;repository&gt;</literal> invocation requires that <literal>new-app</literal> attempt to clone <literal>repository</literal> to determine what type of artifact it is, so this will fail if Git is not available.</simpara>
<simpara>The <literal>-i &lt;image&gt; --code &lt;repository&gt;</literal> invocation requires <literal>new-app</literal> clone <literal>repository</literal> to determine whether <literal>image</literal> should be used as a builder for the source code, or deployed separately, as in the case of a database image.</simpara>
</note>
</section>
</section>
<section xml:id="applications-create-using-cli-image_creating-applications-using-cli">
<title>Creating an application from an image</title>
<simpara>You can deploy an application from an existing image. Images can come from image streams in the OpenShift Container Platform server, images in a specific registry, or images in the local Docker server.</simpara>
<simpara>The <literal>new-app</literal> command attempts to determine the type of image specified in the arguments passed to it. However, you can explicitly tell <literal>new-app</literal> whether the image is a container image using the <literal>--docker-image</literal> argument or an image stream using the <literal>-i|--image-stream</literal> argument.</simpara>
<note>
<simpara>If you specify an image from your local Docker repository, you must ensure that the same image is available to the OpenShift Container Platform cluster nodes.</simpara>
</note>
<section xml:id="_docker-hub-mysql-image">
<title>Docker Hub MySQL image</title>
<simpara>Create an application from the Docker Hub MySQL image, for example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app mysql</programlisting>
</section>
<section xml:id="_image-in-a-private-registry">
<title>Image in a private registry</title>
<simpara>Create an application using an image in a private registry, specify the full container image specification:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app myregistry:5000/example/myimage</programlisting>
</section>
<section xml:id="_existing-image-stream-and-optional-image-stream-tag">
<title>Existing image stream and optional image stream tag</title>
<simpara>Create an application from an existing image stream and optional image stream tag:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app my-stream:v1</programlisting>
</section>
</section>
<section xml:id="applications-create-using-cli-template_creating-applications-using-cli">
<title>Creating an application from a template</title>
<simpara>You can create an application from a previously stored template or from a
template file, by specifying the name of the template as an argument. For
example, you can store a sample application template and use it to create an
application.</simpara>
<simpara>Upload an application template to your current project&#8217;s template library. The following example uploads an application template from a file called <literal>examples/sample-app/application-template-stibuild.json</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create -f examples/sample-app/application-template-stibuild.json</programlisting>
<simpara>Then create a new application by referencing the application template. In this example, the template name is <literal>ruby-helloworld-sample</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app ruby-helloworld-sample</programlisting>
<simpara>To create a new application by referencing a template file in your local file system, without first storing it in OpenShift Container Platform, use the <literal>-f|--file</literal> argument. For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app -f examples/sample-app/application-template-stibuild.json</programlisting>
<section xml:id="_template-parameters">
<title>Template parameters</title>
<simpara>When creating an application based on a template, use the <literal>-p|--param</literal> argument to set parameter values that are defined by the template:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app ruby-helloworld-sample \
    -p ADMIN_USERNAME=admin -p ADMIN_PASSWORD=mypassword</programlisting>
<simpara>You can store your parameters in a file, then use that file with <literal>--param-file</literal> when instantiating a template. If you want to read the parameters from standard input, use <literal>--param-file=-</literal>. The following is an example file called <literal>helloworld.params</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">ADMIN_USERNAME=admin
ADMIN_PASSWORD=mypassword</programlisting>
<simpara>Reference the parameters in the file when instantiating a template:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app ruby-helloworld-sample --param-file=helloworld.params</programlisting>
</section>
</section>
<section xml:id="applications-create-using-cli-modify_creating-applications-using-cli">
<title>Modifying application creation</title>
<simpara>The <literal>new-app</literal> command generates OpenShift Container Platform objects that build, deploy, and run the application that is created. Normally, these objects are created in the current project and assigned names that are derived from the input source repositories or the input images. However, with <literal>new-app</literal> you can modify this behavior.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title><literal>new-app</literal> output objects</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="20*"/>
<colspec colname="col_2" colwidth="80*"/>
<thead>
<row>
<entry align="left" valign="top">Object</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>BuildConfig</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A <literal>BuildConfig</literal> object is created for each source repository that is specified in the command line. The <literal>BuildConfig</literal> object specifies the strategy to use, the source location, and the build output location.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ImageStreams</literal></simpara></entry>
<entry align="left" valign="top"><simpara>For the <literal>BuildConfig</literal> object, two image streams are usually created. One represents the input image. With source builds, this is the builder image.
With <literal>Docker</literal> builds, this is the <emphasis role="strong">FROM</emphasis> image.
The second one represents the output image. If a container image was specified as input to <literal>new-app</literal>, then an image stream is created for that image as well.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>DeploymentConfig</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A <literal>DeploymentConfig</literal> object is created either to deploy the output of a build, or a specified image. The <literal>new-app</literal> command creates <literal>emptyDir</literal> volumes for all Docker volumes that are specified in containers included in the resulting <literal>DeploymentConfig</literal> object .</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>Service</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The <literal>new-app</literal> command attempts to detect exposed ports in input images. It uses the lowest numeric exposed port to generate a service that exposes that port. To expose a different port, after <literal>new-app</literal> has completed, simply use the <literal>oc expose</literal> command to generate additional services.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Other</simpara></entry>
<entry align="left" valign="top"><simpara>Other objects can be generated when instantiating templates, according to the template.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<section xml:id="specifying-environment-variables">
<title>Specifying environment variables</title>
<simpara>When generating applications from a template, source, or an image, you can use the <literal>-e|--env</literal> argument to pass environment variables to the application container at run time:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app openshift/postgresql-92-centos7 \
    -e POSTGRESQL_USER=user \
    -e POSTGRESQL_DATABASE=db \
    -e POSTGRESQL_PASSWORD=password</programlisting>
<simpara>The variables can also be read from file using the <literal>--env-file</literal> argument. The following is an example file called <literal>postgresql.env</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">POSTGRESQL_USER=user
POSTGRESQL_DATABASE=db
POSTGRESQL_PASSWORD=password</programlisting>
<simpara>Read the variables from the file:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app openshift/postgresql-92-centos7 --env-file=postgresql.env</programlisting>
<simpara>Additionally, environment variables can be given on standard input by using <literal>--env-file=-</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ cat postgresql.env | oc new-app openshift/postgresql-92-centos7 --env-file=-</programlisting>
<note>
<simpara>Any <literal>BuildConfig</literal> objects created as part of <literal>new-app</literal> processing are not updated with environment variables passed with the <literal>-e|--env</literal> or <literal>--env-file</literal> argument.</simpara>
</note>
</section>
<section xml:id="specifying-build-environment-variables">
<title>Specifying build environment variables</title>
<simpara>When generating applications from a template, source, or an image, you can use the <literal>--build-env</literal> argument to pass environment variables to the build container at run time:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app openshift/ruby-23-centos7 \
    --build-env HTTP_PROXY=http://myproxy.net:1337/ \
    --build-env GEM_HOME=~/.gem</programlisting>
<simpara>The variables can also be read from a file using the <literal>--build-env-file</literal> argument. The following is an example file called <literal>ruby.env</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">HTTP_PROXY=http://myproxy.net:1337/
GEM_HOME=~/.gem</programlisting>
<simpara>Read the variables from the file:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app openshift/ruby-23-centos7 --build-env-file=ruby.env</programlisting>
<simpara>Additionally, environment variables can be given on standard input by using <literal>--build-env-file=-</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ cat ruby.env | oc new-app openshift/ruby-23-centos7 --build-env-file=-</programlisting>
</section>
<section xml:id="specifying-labels">
<title>Specifying labels</title>
<simpara>When generating applications from source, images, or templates, you can use the <literal>-l|--label</literal> argument to add labels to the created objects. Labels make it easy to collectively select, configure, and delete objects associated with the application.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app https://github.com/openshift/ruby-hello-world -l name=hello-world</programlisting>
</section>
<section xml:id="viewing-output-without-creation">
<title>Viewing the output without creation</title>
<simpara>To see a dry-run of running the <literal>new-app</literal> command, you can use the <literal>-o|--output</literal> argument with a <literal>yaml</literal> or <literal>json</literal> value. You can then use the output to preview the objects that are created or redirect it to a file that you can edit. After you are satisfied, you can use <literal>oc create</literal> to create the OpenShift Container Platform objects.</simpara>
<simpara>To output <literal>new-app</literal> artifacts to a file, run the following:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app https://github.com/openshift/ruby-hello-world \
    -o yaml &gt; myapp.yaml</programlisting>
<simpara>Edit the file:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ vi myapp.yaml</programlisting>
<simpara>Create a new application by referencing the file:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create -f myapp.yaml</programlisting>
</section>
<section xml:id="creating-objects-different-names">
<title>Creating objects with different names</title>
<simpara>Objects created by <literal>new-app</literal> are normally named after the source repository, or the image used to generate them. You can set the name of the objects produced by adding a <literal>--name</literal> flag to the command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app https://github.com/openshift/ruby-hello-world --name=myapp</programlisting>
</section>
<section xml:id="creating-objects-different-project">
<title>Creating objects in a different project</title>
<simpara>Normally, <literal>new-app</literal> creates objects in the current project. However, you can create objects in a different project by using the <literal>-n|--namespace</literal> argument:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app https://github.com/openshift/ruby-hello-world -n myproject</programlisting>
</section>
<section xml:id="creating-multiple-objects">
<title>Creating multiple objects</title>
<simpara>The <literal>new-app</literal> command allows creating multiple applications specifying multiple parameters to <literal>new-app</literal>. Labels specified in the command line apply to all objects created by the single command. Environment variables apply to all components created from source or images.</simpara>
<simpara>To create an application from a source repository and a Docker Hub image:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app https://github.com/openshift/ruby-hello-world mysql</programlisting>
<note>
<simpara>If a source code repository and a builder image are specified as separate arguments, <literal>new-app</literal> uses the builder image as the builder for the source code repository. If this is not the intent, specify the required builder image for the source using the <literal>~</literal> separator.</simpara>
</note>
</section>
<section xml:id="grouping-images-source-single-pod">
<title>Grouping images and source in a single pod</title>
<simpara>The <literal>new-app</literal> command allows deploying multiple images together in a single pod. To specify which images to group together, use the <literal>+</literal> separator. The <literal>--group</literal> command line argument can also be used to specify the images that should be grouped together. To group the image built from a source repository with other images, specify its builder image in the group:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app ruby+mysql</programlisting>
<simpara>To deploy an image built from source and an external image together:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app \
    ruby~https://github.com/openshift/ruby-hello-world \
    mysql \
    --group=ruby+mysql</programlisting>
</section>
<section xml:id="searching-for-images-templates-other-inputs">
<title>Searching for images, templates, and other inputs</title>
<simpara>To search for images, templates, and other inputs for the <literal>oc new-app</literal> command, add the <literal>--search</literal> and <literal>--list</literal> flags. For example, to find all of the images or templates that include PHP:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app --search php</programlisting>
</section>
<section xml:id="setting-the-import-mode">
<title>Setting the import mode</title>
<simpara>To set the import mode when using <literal>oc new-app</literal>, add the <literal>--import-mode</literal> flag. This flag can be appended with <literal>Legacy</literal> or <literal>PreserveOriginal</literal>, which provides users the option to create image streams using a single sub-manifest, or all manifests, respectively.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app --image=registry.redhat.io/ubi8/httpd-24:latest  --import-mode=Legacy --name=test</programlisting>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app --image=registry.redhat.io/ubi8/httpd-24:latest  --import-mode=PreserveOriginal --name=test</programlisting>
</section>
</section>
</section>
</chapter>
<chapter xml:id="odc-viewing-application-composition-using-topology-view">
<title>Viewing application composition using the Topology view</title>
<simpara>The <emphasis role="strong">Topology</emphasis> view in the <emphasis role="strong">Developer</emphasis> perspective of the web console provides a visual representation of all the applications within a project, their build status, and the components and services associated with them.</simpara>
<section xml:id="_prerequisites">
<title>Prerequisites</title>
<simpara>To view your applications in the <emphasis role="strong">Topology</emphasis> view and interact with them, ensure that:</simpara>
<itemizedlist>
<listitem>
<simpara>You have <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/web_console/#web-console">logged in to the web console</link>.</simpara>
</listitem>
<listitem>
<simpara>You have the appropriate <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/authentication_and_authorization/#default-roles_using-rbac">roles and permissions</link> in a project to create applications and other workloads in OpenShift Container Platform.</simpara>
</listitem>
<listitem>
<simpara>You have <link linkend="odc-creating-applications-using-developer-perspective">created and deployed an application on OpenShift Container Platform using the <emphasis role="strong">Developer</emphasis> perspective</link>.</simpara>
</listitem>
<listitem>
<simpara>You are in <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/web_console/#about-developer-perspective_web-console-overview">the <emphasis role="strong">Developer</emphasis> perspective</link>.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="odc-viewing-application-topology_viewing-application-composition-using-topology-view">
<title>Viewing the topology of your application</title>
<simpara>You can navigate to the <emphasis role="strong">Topology</emphasis> view using the left navigation panel in the <emphasis role="strong">Developer</emphasis> perspective. After you deploy an application, you are directed automatically to the <emphasis role="strong">Graph view</emphasis> where you can see the status of the application pods, quickly access the application on a public URL, access the source code to modify it, and see the status of your last build. You can zoom in and out to see more details for a particular application.</simpara>
<simpara>The <emphasis role="strong">Topology</emphasis> view provides you the option to monitor your applications using the <emphasis role="strong">List</emphasis> view. Use the <emphasis role="strong">List view</emphasis> icon (<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_list_view_icon.png"/>
</imageobject>
<textobject><phrase>odc list view icon</phrase></textobject>
</inlinemediaobject>) to see a list of all your applications and use the <emphasis role="strong">Graph view</emphasis> icon (<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_topology_view_icon.png"/>
</imageobject>
<textobject><phrase>odc topology view icon</phrase></textobject>
</inlinemediaobject>) to switch back to the graph view.</simpara>
<simpara>You can customize the views as required using the following:</simpara>
<itemizedlist>
<listitem>
<simpara>Use the <emphasis role="strong">Find by name</emphasis> field to find the required components. Search results may appear outside of the visible area; click <emphasis role="strong">Fit to Screen</emphasis> from the lower-left toolbar to resize the <emphasis role="strong">Topology</emphasis> view to show all components.</simpara>
</listitem>
<listitem>
<simpara>Use the <emphasis role="strong">Display Options</emphasis> drop-down list to configure the <emphasis role="strong">Topology</emphasis> view of the various application groupings. The options are available depending on the types of components deployed in the project:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Mode</emphasis> (<emphasis role="strong">Connectivity</emphasis> or <emphasis role="strong">Consumption</emphasis>)</simpara>
<itemizedlist>
<listitem>
<simpara>Connectivity: Select to show all the connections between the different nodes in the topology.</simpara>
</listitem>
<listitem>
<simpara>Consumption: Select to show the resource consumption for all nodes in the topology.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara><emphasis role="strong">Expand</emphasis> group</simpara>
<itemizedlist>
<listitem>
<simpara>Virtual Machines: Toggle to show or hide the virtual machines.</simpara>
</listitem>
<listitem>
<simpara>Application Groupings: Clear to condense the application groups into cards with an overview of an application group and alerts associated with it.</simpara>
</listitem>
<listitem>
<simpara>Helm Releases: Clear to condense the components deployed as Helm Release into cards with an overview of a given release.</simpara>
</listitem>
<listitem>
<simpara>Knative Services: Clear to condense the Knative Service components into cards with an overview of a given component.</simpara>
</listitem>
<listitem>
<simpara>Operator Groupings: Clear to condense the components deployed with an Operator into cards with an overview of the given group.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara><emphasis role="strong">Show</emphasis> elements based on <emphasis role="strong">Pod Count</emphasis> or <emphasis role="strong">Labels</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>Pod Count: Select to show the number of pods of a component in the component icon.</simpara>
</listitem>
<listitem>
<simpara>Labels: Toggle to show or hide the component labels.</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
<simpara>The <emphasis role="strong">Topology</emphasis> view also provides you the <emphasis role="strong">Export application</emphasis> option to download your application in the ZIP file format. You can then import the downloaded application to another project or cluster. For more details, see <emphasis>Exporting an application to another project or cluster</emphasis> in the <emphasis>Additional resources</emphasis> section.</simpara>
</section>
<section xml:id="odc-interacting-with-applications-and-components_viewing-application-composition-using-topology-view">
<title>Interacting with applications and components</title>
<simpara>The <emphasis role="strong">Topology</emphasis> view in the <emphasis role="strong">Developer</emphasis> perspective of the web console provides the following options to interact with applications and components:</simpara>
<itemizedlist>
<listitem>
<simpara>Click <emphasis role="strong">Open URL</emphasis> (<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_open_url.png"/>
</imageobject>
<textobject><phrase>odc open url</phrase></textobject>
</inlinemediaobject>) to see your application exposed by the route on a public URL.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Edit Source code</emphasis> to access your source code and modify it.</simpara>
<note>
<simpara>This feature is available only when you create applications using the <emphasis role="strong">From Git</emphasis>, <emphasis role="strong">From Catalog</emphasis>, and the <emphasis role="strong">From Dockerfile</emphasis> options.</simpara>
</note>
</listitem>
<listitem>
<simpara>Hover your cursor over the lower left icon on the pod to see the name of the latest build and its status. The status of the application build is indicated as <emphasis role="strong">New</emphasis> (<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_build_new.png"/>
</imageobject>
<textobject><phrase>odc build new</phrase></textobject>
</inlinemediaobject>), <emphasis role="strong">Pending</emphasis> (<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_build_pending.png"/>
</imageobject>
<textobject><phrase>odc build pending</phrase></textobject>
</inlinemediaobject>), <emphasis role="strong">Running</emphasis> (<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_build_running.png"/>
</imageobject>
<textobject><phrase>odc build running</phrase></textobject>
</inlinemediaobject>), <emphasis role="strong">Completed</emphasis> (<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_build_completed.png"/>
</imageobject>
<textobject><phrase>odc build completed</phrase></textobject>
</inlinemediaobject>), <emphasis role="strong">Failed</emphasis> (<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_build_failed.png"/>
</imageobject>
<textobject><phrase>odc build failed</phrase></textobject>
</inlinemediaobject>), and <emphasis role="strong">Canceled</emphasis> (<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_build_canceled.png"/>
</imageobject>
<textobject><phrase>odc build canceled</phrase></textobject>
</inlinemediaobject>).</simpara>
</listitem>
<listitem>
<simpara>The status or phase of the pod is indicated by different colors and tooltips as:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Running</emphasis> (<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_pod_running.png"/>
</imageobject>
<textobject><phrase>odc pod running</phrase></textobject>
</inlinemediaobject>): The pod is bound to a node and all of the containers are created. At least one container is still running or is in the process of starting or restarting.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Not Ready</emphasis> (<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_pod_not_ready.png"/>
</imageobject>
<textobject><phrase>odc pod not ready</phrase></textobject>
</inlinemediaobject>): The pods which are running multiple containers, not all containers are ready.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Warning</emphasis>(<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_pod_warning.png"/>
</imageobject>
<textobject><phrase>odc pod warning</phrase></textobject>
</inlinemediaobject>): Containers in pods are being terminated, however termination did not succeed. Some containers may be other states.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Failed</emphasis>(<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_pod_failed.png"/>
</imageobject>
<textobject><phrase>odc pod failed</phrase></textobject>
</inlinemediaobject>): All containers in the pod terminated but least one container has terminated in failure. That is, the container either exited with non-zero status or was terminated by the system.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Pending</emphasis>(<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_pod_pending.png"/>
</imageobject>
<textobject><phrase>odc pod pending</phrase></textobject>
</inlinemediaobject>): The pod is accepted by the Kubernetes cluster, but one or more of the containers has not been set up and made ready to run. This includes time a pod spends waiting to be scheduled as well as the time spent downloading container images over the network.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Succeeded</emphasis>(<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_pod_succeeded.png"/>
</imageobject>
<textobject><phrase>odc pod succeeded</phrase></textobject>
</inlinemediaobject>): All containers in the pod terminated successfully and will not be restarted.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Terminating</emphasis>(<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_pod_terminating.png"/>
</imageobject>
<textobject><phrase>odc pod terminating</phrase></textobject>
</inlinemediaobject>): When a pod is being deleted, it is shown as <emphasis role="strong">Terminating</emphasis> by some kubectl commands. <emphasis role="strong">Terminating</emphasis> status is not one of the pod phases. A pod is granted a graceful termination period, which defaults to 30 seconds.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Unknown</emphasis>(<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_pod_unknown.png"/>
</imageobject>
<textobject><phrase>odc pod unknown</phrase></textobject>
</inlinemediaobject>): The state of the pod could not be obtained. This phase typically occurs due to an error in communicating with the node where the pod should be running.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>After you create an application and an image is deployed, the status is shown as <emphasis role="strong">Pending</emphasis>. After the application is built, it is displayed as <emphasis role="strong">Running</emphasis>.</simpara>
<figure>
<title>Application topology</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_application_topology.png"/>
</imageobject>
<textobject><phrase>odc application topology</phrase></textobject>
</mediaobject>
</figure>
<simpara>The application resource name is appended with indicators for the different types of resource objects as follows:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">CJ</emphasis>: <literal>CronJob</literal></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">D</emphasis>: <literal>Deployment</literal></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">DC</emphasis>: <literal>DeploymentConfig</literal></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">DS</emphasis>: <literal>DaemonSet</literal></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">J</emphasis>: <literal>Job</literal></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">P</emphasis>: <literal>Pod</literal></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">SS</emphasis>: <literal>StatefulSet</literal></simpara>
</listitem>
<listitem>
<simpara><inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_serverless_app.png"/>
</imageobject>
<textobject><phrase>odc serverless app</phrase></textobject>
</inlinemediaobject> (Knative): A serverless application</simpara>
<note>
<simpara>Serverless applications take some time to load and display on the <emphasis role="strong">Graph view</emphasis>. When you deploy a serverless application, it first creates a service resource and then a revision. After that, it is deployed and displayed on the <emphasis role="strong">Graph view</emphasis>. If it is the only workload, you might be redirected to the <emphasis role="strong">Add</emphasis> page. After the revision is deployed, the serverless application is displayed on the <emphasis role="strong">Graph view</emphasis>.</simpara>
</note>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>
<section xml:id="odc-scaling-application-pods-and-checking-builds-and-routes_viewing-application-composition-using-topology-view">
<title>Scaling application pods and checking builds and routes</title>
<simpara>The <emphasis role="strong">Topology</emphasis> view provides the details of the deployed components in the <emphasis role="strong">Overview</emphasis> panel. You can use the <emphasis role="strong">Overview</emphasis> and <emphasis role="strong">Resources</emphasis> tabs to scale the application pods, check build status, services, and routes as follows:</simpara>
<itemizedlist>
<listitem>
<simpara>Click on the component node to see the <emphasis role="strong">Overview</emphasis> panel to the right. Use the <emphasis role="strong">Overview</emphasis> tab to:</simpara>
<itemizedlist>
<listitem>
<simpara>Scale your pods using the up and down arrows to increase or decrease the number of instances of the application manually. For serverless applications, the pods are automatically scaled down to zero when idle and scaled up depending on the channel traffic.</simpara>
</listitem>
<listitem>
<simpara>Check the <emphasis role="strong">Labels</emphasis>, <emphasis role="strong">Annotations</emphasis>, and <emphasis role="strong">Status</emphasis> of the application.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Click the <emphasis role="strong">Resources</emphasis> tab to:</simpara>
<itemizedlist>
<listitem>
<simpara>See the list of all the pods, view their status, access logs, and click on the pod to see the pod details.</simpara>
</listitem>
<listitem>
<simpara>See the builds, their status, access logs, and start a new build if needed.</simpara>
</listitem>
<listitem>
<simpara>See the services and routes used by the component.</simpara>
</listitem>
</itemizedlist>
<simpara>For serverless applications, the <emphasis role="strong">Resources</emphasis> tab provides information on the revision, routes, and the configurations used for that component.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="odc-adding-components-to-an-existing-project_viewing-application-composition-using-topology-view">
<title>Adding components to an existing project</title>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Click <emphasis role="strong">Add to Project</emphasis> (<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_add_to_project.png"/>
</imageobject>
<textobject><phrase>odc add to project</phrase></textobject>
</inlinemediaobject>) next to left navigation pane or press <keycombo><keycap>Ctrl</keycap><keycap>Space</keycap></keycombo></simpara>
</listitem>
<listitem>
<simpara>Search for the component and select <emphasis role="strong">Create</emphasis> or press <keycap>Enter</keycap> to add the component to the project and see it in the topology <emphasis role="strong">Graph view</emphasis>.</simpara>
</listitem>
</orderedlist>
<figure>
<title>Adding component via quick search</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_quick_search.png"/>
</imageobject>
<textobject><phrase>odc quick search</phrase></textobject>
</mediaobject>
</figure>
<simpara>Alternatively, you can also use the <emphasis role="strong">Import from Git</emphasis>, <emphasis role="strong">Container Image</emphasis>, <emphasis role="strong">Database</emphasis>, <emphasis role="strong">From Catalog</emphasis>, <emphasis role="strong">Operator Backed</emphasis>, <emphasis role="strong">Helm Charts</emphasis>, <emphasis role="strong">Samples</emphasis>, or <emphasis role="strong">Upload JAR file</emphasis>  options in the context menu by right-clicking in the topology <emphasis role="strong">Graph view</emphasis> to add a component to your project.</simpara>
<figure>
<title>Context menu to add services</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_context_project.png"/>
</imageobject>
<textobject><phrase>odc context project</phrase></textobject>
</mediaobject>
</figure>
</section>
<section xml:id="odc-grouping-multiple-components_viewing-application-composition-using-topology-view">
<title>Grouping multiple components within an application</title>
<simpara>You can use the <emphasis role="strong">+Add</emphasis> view to add multiple components or services to your project and use the topology <emphasis role="strong">Graph view</emphasis> to group applications and resources within an application group.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have created and deployed minimum two or more components on OpenShift Container Platform using the <emphasis role="strong">Developer</emphasis> perspective.</simpara>
</listitem>
</itemizedlist>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>To add a service to the existing application group, press <keycap>Shift</keycap>+ drag it to the existing application group. Dragging a component and adding it to an application group adds the required labels to the component.</simpara>
<figure>
<title>Application grouping</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_app_grouping_label.png"/>
</imageobject>
<textobject><phrase>odc app grouping label</phrase></textobject>
</mediaobject>
</figure>
</listitem>
</itemizedlist>
<simpara>Alternatively, you can also add the component to an application as follows:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Click the service pod to see the <emphasis role="strong">Overview</emphasis> panel to the right.</simpara>
</listitem>
<listitem>
<simpara>Click the <emphasis role="strong">Actions</emphasis> drop-down menu and select <emphasis role="strong">Edit Application Grouping</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Edit Application Grouping</emphasis> dialog box, click the <emphasis role="strong">Application</emphasis> drop-down list, and select an appropriate application group.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Save</emphasis> to add the service to the application group.</simpara>
</listitem>
</orderedlist>
<simpara>You can remove a component from an application group by selecting the component and using <keycap>Shift</keycap>+ drag to drag it out of the application group.</simpara>
</section>
<section xml:id="odc-adding-services-to-your-application_viewing-application-composition-using-topology-view">
<title>Adding services to your application</title>
<simpara>To add a service to your application use the <emphasis role="strong">+Add</emphasis> actions using the context menu in the topology <emphasis role="strong">Graph view</emphasis>.</simpara>
<note>
<simpara>In addition to the context menu, you can add services by using the sidebar or hovering and dragging the dangling arrow from the application group.</simpara>
</note>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Right-click an application group in the topology <emphasis role="strong">Graph view</emphasis> to display the context menu.</simpara>
<figure>
<title>Add resource context menu</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_context_menu.png"/>
</imageobject>
<textobject><phrase>odc context menu</phrase></textobject>
</mediaobject>
</figure>
</listitem>
<listitem>
<simpara>Use <emphasis role="strong">Add to Application</emphasis> to select a method for adding a service to the application group, such as <emphasis role="strong">From Git</emphasis>, <emphasis role="strong">Container Image</emphasis>, <emphasis role="strong">From Dockerfile</emphasis>, <emphasis role="strong">From Devfile</emphasis>, <emphasis role="strong">Upload JAR file</emphasis>, <emphasis role="strong">Event Source</emphasis>, <emphasis role="strong">Channel</emphasis>, or <emphasis role="strong">Broker</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Complete the form for the method you choose and click <emphasis role="strong">Create</emphasis>. For example, to add a service based on the source code in your Git repository, choose the <emphasis role="strong">From Git</emphasis> method, fill in the <emphasis role="strong">Import from Git</emphasis> form, and click <emphasis role="strong">Create</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-removing-services-from-your-application_viewing-application-composition-using-topology-view">
<title>Removing services from your application</title>
<simpara>In the topology <emphasis role="strong">Graph view</emphasis> remove a service from your application using the context menu.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Right-click on a service in an application group in the topology <emphasis role="strong">Graph view</emphasis> to display the context menu.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">Delete Deployment</emphasis> to delete the service.</simpara>
<figure>
<title>Deleting deployment option</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_deleting_deployment.png"/>
</imageobject>
<textobject><phrase>odc deleting deployment</phrase></textobject>
</mediaobject>
</figure>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-labels-and-annotations-used-for-topology-view_viewing-application-composition-using-topology-view">
<title>Labels and annotations used for the Topology view</title>
<simpara>The <emphasis role="strong">Topology</emphasis> view uses the following labels and annotations:</simpara>
<variablelist>
<varlistentry>
<term>Icon displayed in the node</term>
<listitem>
<simpara>Icons in the node are defined by looking for matching icons using the <literal>app.openshift.io/runtime</literal> label, followed by the <literal>app.kubernetes.io/name</literal> label. This matching is done using a predefined set of icons.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Link to the source code editor or the source</term>
<listitem>
<simpara>The <literal>app.openshift.io/vcs-uri</literal> annotation is used to create links to the source code editor.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Node Connector</term>
<listitem>
<simpara>The <literal>app.openshift.io/connects-to</literal> annotation is used to connect the nodes.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>App grouping</term>
<listitem>
<simpara>The <literal>app.kubernetes.io/part-of=&lt;appname&gt;</literal> label is used to group the applications, services, and components.</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>For detailed information on the labels and annotations OpenShift Container Platform applications must use, see <link xlink:href="https://github.com/redhat-developer/app-labels/blob/master/labels-annotation-for-openshift.adoc">Guidelines for labels and annotations for OpenShift applications</link>.</simpara>
</section>
<section xml:id="_additional-resources" role="_additional-resources">
<title>Additional resources</title>
<itemizedlist>
<listitem>
<simpara>See <link linkend="odc-importing-codebase-from-git-to-create-application_odc-creating-applications-using-developer-perspective">Importing a codebase from Git to create an application</link> for more information on creating an application from Git.</simpara>
</listitem>
<listitem>
<simpara>See <link linkend="odc-connecting-an-application-to-a-service-using-the-developer-perspective">Connecting an application to a service using the Developer perspective</link>.</simpara>
</listitem>
<listitem>
<simpara>See <link linkend="odc-exporting-applications">Exporting applications</link></simpara>
</listitem>
</itemizedlist>
</section>
</chapter>
<chapter xml:id="odc-exporting-applications">
<title>Exporting applications</title>
<simpara>As a developer, you can export your application in the ZIP file format. Based on your needs, import the exported application to another project in the same cluster or a different cluster by using the <emphasis role="strong">Import YAML</emphasis> option in the <emphasis role="strong">+Add</emphasis> view. Exporting your application helps you to reuse your application resources and saves your time.</simpara>
<section xml:id="prerequisites_odc-exporting-applications">
<title>Prerequisites</title>
<itemizedlist>
<listitem>
<simpara>You have installed the gitops-primer Operator from the OperatorHub.</simpara>
<note>
<simpara>The <emphasis role="strong">Export application</emphasis> option is disabled in the <emphasis role="strong">Topology</emphasis> view even after installing the gitops-primer Operator.</simpara>
</note>
</listitem>
<listitem>
<simpara>You have created an application in the <emphasis role="strong">Topology</emphasis> view to enable <emphasis role="strong">Export application</emphasis>.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="odc-exporting-applications-procedure">
<title>Procedure</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>In the developer perspective, perform one of the following steps:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Navigate to the <emphasis role="strong">+Add</emphasis> view and click <emphasis role="strong">Export application</emphasis> in the <emphasis role="strong">Application portability</emphasis> tile.</simpara>
</listitem>
<listitem>
<simpara>Navigate to the <emphasis role="strong">Topology</emphasis> view and click <emphasis role="strong">Export application</emphasis>.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">OK</emphasis> in the <emphasis role="strong">Export Application</emphasis> dialog box. A notification opens to confirm that the export of resources from your project has started.</simpara>
</listitem>
<listitem>
<simpara>Optional steps that you might need to perform in the following scenarios:</simpara>
<itemizedlist>
<listitem>
<simpara>If you have started exporting an incorrect application, click  <emphasis role="strong">Export application</emphasis> &#8594; <emphasis role="strong">Cancel Export</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>If your export is already in progress and you want to start a fresh export, click  <emphasis role="strong">Export application</emphasis> &#8594; <emphasis role="strong">Restart Export</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>If you want to view logs associated with exporting an application, click  <emphasis role="strong">Export application</emphasis> and the <emphasis role="strong">View Logs</emphasis> link.</simpara>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="images/export-application-dialog-box.png"/>
</imageobject>
<textobject><phrase>export application dialog box</phrase></textobject>
</mediaobject>
</informalfigure>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>After a successful export, click <emphasis role="strong">Download</emphasis> in the dialog box to download application resources in ZIP format onto your machine.</simpara>
</listitem>
</orderedlist>
</section>
</chapter>
<chapter xml:id="_connecting-applications-to-services">
<title>Connecting applications to services</title>
<section xml:id="servicebinding-release-notes">
<title>Release notes for {servicebinding-title}</title>
<simpara>The Service Binding Operator consists of a controller and an accompanying custom resource definition (CRD) for service binding. It manages the data plane for workloads and backing services. The Service Binding Controller reads the data made available by the control plane of backing services. Then, it projects this data to workloads according to the rules specified through the <literal>ServiceBinding</literal> resource.</simpara>
<simpara>With Service Binding Operator, you can:</simpara>
<itemizedlist>
<listitem>
<simpara>Bind your workloads together with Operator-managed backing services.</simpara>
</listitem>
<listitem>
<simpara>Automate configuration of binding data.</simpara>
</listitem>
<listitem>
<simpara>Provide service operators a low-touch administrative experience to provision and manage access to services.</simpara>
</listitem>
<listitem>
<simpara>Enrich development lifecycle with a consistent and declarative service binding method that eliminates discrepancies in cluster environments.</simpara>
</listitem>
</itemizedlist>
<simpara>The custom resource definition (CRD) of the Service Binding Operator supports the following APIs:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Service Binding</emphasis> with the <literal>binding.operators.coreos.com</literal> API group.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Service Binding (Spec API)</emphasis> with the <literal>servicebinding.io</literal> API group.</simpara>
</listitem>
</itemizedlist>
<section xml:id="support-matrix">
<title>Support matrix</title>
<simpara>Some features in the following table are in <link xlink:href="https://access.redhat.com/support/offerings/techpreview">Technology Preview</link>. These experimental features are not intended for production use.</simpara>
<simpara>In the table, features are marked with the following statuses:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">TP</emphasis>: <emphasis>Technology Preview</emphasis></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">GA</emphasis>: <emphasis>General Availability</emphasis></simpara>
</listitem>
</itemizedlist>
<simpara>Note the following scope of support on the Red Hat Customer Portal for these features:</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Support matrix</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"><emphasis role="strong">Service Binding Operator</emphasis></entry>
<entry align="left" valign="top" namest="col_2" nameend="col_3"><emphasis role="strong">API Group and Support Status</emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong">OpenShift Versions</emphasis></entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Version</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong"><literal>binding.operators.coreos.com</literal></emphasis></simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong"><literal>servicebinding.io</literal></emphasis></simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>1.3.3</simpara></entry>
<entry align="left" valign="top"><simpara>GA</simpara></entry>
<entry align="left" valign="top"><simpara>GA</simpara></entry>
<entry align="left" valign="top"><simpara>4.9-4.12</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>1.3.1</simpara></entry>
<entry align="left" valign="top"><simpara>GA</simpara></entry>
<entry align="left" valign="top"><simpara>GA</simpara></entry>
<entry align="left" valign="top"><simpara>4.9-4.11</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>1.3</simpara></entry>
<entry align="left" valign="top"><simpara>GA</simpara></entry>
<entry align="left" valign="top"><simpara>GA</simpara></entry>
<entry align="left" valign="top"><simpara>4.9-4.11</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>1.2</simpara></entry>
<entry align="left" valign="top"><simpara>GA</simpara></entry>
<entry align="left" valign="top"><simpara>GA</simpara></entry>
<entry align="left" valign="top"><simpara>4.7-4.11</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>1.1.1</simpara></entry>
<entry align="left" valign="top"><simpara>GA</simpara></entry>
<entry align="left" valign="top"><simpara>TP</simpara></entry>
<entry align="left" valign="top"><simpara>4.7-4.10</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>1.1</simpara></entry>
<entry align="left" valign="top"><simpara>GA</simpara></entry>
<entry align="left" valign="top"><simpara>TP</simpara></entry>
<entry align="left" valign="top"><simpara>4.7-4.10</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>1.0.1</simpara></entry>
<entry align="left" valign="top"><simpara>GA</simpara></entry>
<entry align="left" valign="top"><simpara>TP</simpara></entry>
<entry align="left" valign="top"><simpara>4.7-4.9</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>1.0</simpara></entry>
<entry align="left" valign="top"><simpara>GA</simpara></entry>
<entry align="left" valign="top"><simpara>TP</simpara></entry>
<entry align="left" valign="top"><simpara>4.7-4.9</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section xml:id="servicebinding-inclusive-language">
<title>Making open source more inclusive</title>
<simpara>Red Hat is committed to replacing problematic language in our code, documentation, and web properties. We are beginning with these four terms: master, slave, blacklist, and whitelist. Because of the enormity of this endeavor, these changes will be implemented gradually over several upcoming releases. For more details, see <link xlink:href="https://www.redhat.com/en/blog/making-open-source-more-inclusive-eradicating-problematic-language">Red Hat CTO Chris Wright&#8217;s message</link>.</simpara>
</section>
<section xml:id="sbo-release-notes-1-3-3_servicebinding-release-notes">
<title>Release notes for Service Binding Operator 1.3.3</title>
<simpara>Service Binding Operator 1.3.3 is now available on OpenShift Container Platform 4.9, 4.10, 4.11 and 4.12.</simpara>
<section xml:id="fixed-issues-1-3-3_servicebinding-release-notes">
<title>Fixed issues</title>
<itemizedlist>
<listitem>
<simpara>Before this update, a security vulnerability <literal>CVE-2022-41717</literal> was noted for Service Binding Operator. This update fixes the <literal>CVE-2022-41717</literal> error and updates the <literal>golang.org/x/net</literal> package from v0.0.0-20220906165146-f3363e06e74c to v0.4.0. <link xlink:href="https://issues.redhat.com/browse/APPSVC-1256">APPSVC-1256</link></simpara>
</listitem>
<listitem>
<simpara>Before this update, Provisioned Services were only detected if the respective resource had the "servicebinding.io/provisioned-service: true" annotation set while other Provisioned Services were missed. With this update, the detection mechanism identifies all Provisioned Services correctly based on the "status.binding.name" attribute. <link xlink:href="https://issues.redhat.com/browse/APPSVC-1204">APPSVC-1204</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="sbo-release-notes-1-3-1_servicebinding-release-notes">
<title>Release notes for Service Binding Operator 1.3.1</title>
<simpara>Service Binding Operator 1.3.1 is now available on OpenShift Container Platform 4.9, 4.10, and 4.11.</simpara>
<section xml:id="fixed-issues-1-3-1_servicebinding-release-notes">
<title>Fixed issues</title>
<itemizedlist>
<listitem>
<simpara>Before this update, a security vulnerability <literal>CVE-2022-32149</literal> was noted for Service Binding Operator. This update fixes the <literal>CVE-2022-32149</literal> error and updates the <literal>golang.org/x/text</literal> package from v0.3.7 to v0.3.8. <link xlink:href="https://issues.redhat.com/browse/APPSVC-1220">APPSVC-1220</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="sbo-release-notes-1-3_servicebinding-release-notes">
<title>Release notes for Service Binding Operator 1.3</title>
<simpara>Service Binding Operator 1.3 is now available on OpenShift Container Platform 4.9, 4.10, and 4.11.</simpara>
<section xml:id="removal-notice-1-3_servicebinding-release-notes">
<title>Removed functionality</title>
<itemizedlist>
<listitem>
<simpara>In Service Binding Operator 1.3, the Operator Lifecycle Manager (OLM) descriptor feature has been removed to improve resource utilization. As an alternative to OLM descriptors, you can use CRD annotations to declare binding data.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="sbo-release-notes-1-2_servicebinding-release-notes">
<title>Release notes for Service Binding Operator 1.2</title>
<simpara>Service Binding Operator 1.2 is now available on OpenShift Container Platform 4.7, 4.8, 4.9, 4.10, and 4.11.</simpara>
<section xml:id="new-features-1-2_servicebinding-release-notes">
<title>New features</title>
<simpara>This section highlights what is new in Service Binding Operator 1.2:</simpara>
<itemizedlist>
<listitem>
<simpara>Enable Service Binding Operator to consider optional fields in the annotations by setting the <literal>optional</literal> flag value to <literal>true</literal>.</simpara>
</listitem>
<listitem>
<simpara>Support for <literal>servicebinding.io/v1beta1</literal> resources.</simpara>
</listitem>
<listitem>
<simpara>Improvements to the discoverability of bindable services by exposing the relevant binding secret without requiring a workload to be present.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="known-issues-1-2_servicebinding-release-notes">
<title>Known issues</title>
<itemizedlist>
<listitem>
<simpara>Currently, when you install Service Binding Operator on OpenShift Container Platform 4.11, the memory footprint of Service Binding Operator increases beyond expected limits. With low usage, however, the memory footprint stays within the expected ranges of your environment or scenarios. In comparison with OpenShift Container Platform 4.10, under stress, both the average and maximum memory footprint increase considerably. This issue is evident in the previous versions of Service Binding Operator as well. There is currently no workaround for this issue. <link xlink:href="https://issues.redhat.com/browse/APPSVC-1200">APPSVC-1200</link></simpara>
</listitem>
<listitem>
<simpara>By default, the projected files get their permissions set to 0644. Service Binding Operator cannot set specific permissions due to a bug in Kubernetes that causes issues if the service expects specific permissions such as, <literal>0600</literal>. As a workaround, you can modify the code of the program or the application that is running inside a workload resource to copy the file to the <literal>/tmp</literal> directory and set the appropriate permissions. <link xlink:href="https://issues.redhat.com/browse/APPSVC-1127">APPSVC-1127</link></simpara>
</listitem>
<listitem>
<simpara>There is currently a known issue with installing Service Binding Operator in a single namespace installation mode. The absence of an appropriate namespace-scoped role-based access control (RBAC) rule prevents the successful binding of an application to a few known Operator-backed services that the Service Binding Operator can automatically detect and bind to. When this happens, it generates an error message similar to the following example:</simpara>
<formalpara>
<title>Example error message</title>
<para>
<programlisting language="text" linenumbering="unnumbered">`postgresclusters.postgres-operator.crunchydata.com "hippo" is forbidden:
        User "system:serviceaccount:my-petclinic:service-binding-operator" cannot
        get resource "postgresclusters" in API group "postgres-operator.crunchydata.com"
        in the namespace "my-petclinic"`</programlisting>
</para>
</formalpara>
<simpara>Workaround 1: Install the Service Binding Operator in the <literal>all namespaces</literal> installation mode. As a result, the appropriate cluster-scoped RBAC rule now exists and the binding succeeds.</simpara>
<simpara>Workaround 2: If you cannot install the Service Binding Operator in the <literal>all namespaces</literal> installation mode, install the following role binding into the namespace where the Service Binding Operator is installed:</simpara>
<formalpara>
<title>Example: Role binding for Crunchy Postgres Operator</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: service-binding-crunchy-postgres-viewer
subjects:
  - kind: ServiceAccount
    name: service-binding-operator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: service-binding-crunchy-postgres-viewer-role</programlisting>
</para>
</formalpara>
<simpara><link xlink:href="https://issues.redhat.com/browse/APPSVC-1062">APPSVC-1062</link></simpara>
</listitem>
<listitem>
<simpara>According to the specification, when you change the <literal>ClusterWorkloadResourceMapping</literal> resources, Service Binding Operator must use the previous version of the <literal>ClusterWorkloadResourceMapping</literal> resource to remove the binding data that was being projected until now. Currently, when you change the <literal>ClusterWorkloadResourceMapping</literal> resources, the Service Binding Operator uses the latest version of the <literal>ClusterWorkloadResourceMapping</literal> resource to remove the binding data. As a result, {the servicebinding-title} might remove the binding data incorrectly. As a workaround, perform the following steps:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Delete any <literal>ServiceBinding</literal> resources that use the corresponding <literal>ClusterWorkloadResourceMapping</literal> resource.</simpara>
</listitem>
<listitem>
<simpara>Modify the <literal>ClusterWorkloadResourceMapping</literal> resource.</simpara>
</listitem>
<listitem>
<simpara>Re-apply the <literal>ServiceBinding</literal> resources that you previously removed in step 1.</simpara>
</listitem>
</orderedlist>
<simpara><link xlink:href="https://issues.redhat.com/browse/APPSVC-1102">APPSVC-1102</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="sbo-release-notes-1-1-1_servicebinding-release-notes">
<title>Release notes for Service Binding Operator 1.1.1</title>
<simpara>Service Binding Operator 1.1.1 is now available on OpenShift Container Platform 4.7, 4.8, 4.9, and 4.10.</simpara>
<section xml:id="fixed-issues-1-1-1_servicebinding-release-notes">
<title>Fixed issues</title>
<itemizedlist>
<listitem>
<simpara>Before this update, a security vulnerability <literal>CVE-2021-38561</literal> was noted for Service Binding Operator Helm chart. This update fixes the <literal>CVE-2021-38561</literal> error and updates the <literal>golang.org/x/text</literal> package from v0.3.6 to v0.3.7. <link xlink:href="https://issues.redhat.com/browse/APPSVC-1124">APPSVC-1124</link></simpara>
</listitem>
<listitem>
<simpara>Before this update, users of the Developer Sandbox did not have sufficient permissions to read <literal>ClusterWorkloadResourceMapping</literal> resources. As a result, Service Binding Operator prevented all service bindings from being successful. With this update, the Service Binding Operator now includes the appropriate role-based access control (RBAC) rules for any authenticated subject including the Developer Sandbox users. These RBAC rules allow the Service Binding Operator to <literal>get</literal>, <literal>list</literal>, and <literal>watch</literal> the <literal>ClusterWorkloadResourceMapping</literal> resources for the Developer Sandbox users and to process service bindings successfully. <link xlink:href="https://issues.redhat.com/browse/APPSVC-1135">APPSVC-1135</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="known-issues-1-1-1_servicebinding-release-notes">
<title>Known issues</title>
<itemizedlist>
<listitem>
<simpara>There is currently a known issue with installing Service Binding Operator in a single namespace installation mode. The absence of an appropriate namespace-scoped role-based access control (RBAC) rule prevents the successful binding of an application to a few known Operator-backed services that the Service Binding Operator can automatically detect and bind to. When this happens, it generates an error message similar to the following example:</simpara>
<formalpara>
<title>Example error message</title>
<para>
<programlisting language="text" linenumbering="unnumbered">`postgresclusters.postgres-operator.crunchydata.com "hippo" is forbidden:
        User "system:serviceaccount:my-petclinic:service-binding-operator" cannot
        get resource "postgresclusters" in API group "postgres-operator.crunchydata.com"
        in the namespace "my-petclinic"`</programlisting>
</para>
</formalpara>
<simpara>Workaround 1: Install the Service Binding Operator in the <literal>all namespaces</literal> installation mode. As a result, the appropriate cluster-scoped RBAC rule now exists and the binding succeeds.</simpara>
<simpara>Workaround 2: If you cannot install the Service Binding Operator in the <literal>all namespaces</literal> installation mode, install the following role binding into the namespace where the Service Binding Operator is installed:</simpara>
<formalpara>
<title>Example: Role binding for Crunchy Postgres Operator</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: service-binding-crunchy-postgres-viewer
subjects:
  - kind: ServiceAccount
    name: service-binding-operator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: service-binding-crunchy-postgres-viewer-role</programlisting>
</para>
</formalpara>
<simpara><link xlink:href="https://issues.redhat.com/browse/APPSVC-1062">APPSVC-1062</link></simpara>
</listitem>
<listitem>
<simpara>Currently, when you modify the <literal>ClusterWorkloadResourceMapping</literal> resources, the Service Binding Operator does not implement correct behavior. As a workaround, perform the following steps:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Delete any <literal>ServiceBinding</literal> resources that use the corresponding <literal>ClusterWorkloadResourceMapping</literal> resource.</simpara>
</listitem>
<listitem>
<simpara>Modify the <literal>ClusterWorkloadResourceMapping</literal> resource.</simpara>
</listitem>
<listitem>
<simpara>Re-apply the <literal>ServiceBinding</literal> resources that you previously removed in step 1.</simpara>
</listitem>
</orderedlist>
<simpara><link xlink:href="https://issues.redhat.com/browse/APPSVC-1102">APPSVC-1102</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="sbo-release-notes-1-1_servicebinding-release-notes">
<title>Release notes for Service Binding Operator 1.1</title>
<simpara>Service Binding Operator is now available on OpenShift Container Platform 4.7, 4.8, 4.9, and 4.10.</simpara>
<section xml:id="new-features-1-1_servicebinding-release-notes">
<title>New features</title>
<simpara>This section highlights what is new in Service Binding Operator 1.1:</simpara>
<itemizedlist>
<listitem>
<simpara>Service Binding Options</simpara>
<itemizedlist>
<listitem>
<simpara>Workload resource mapping: Define exactly where binding data needs to be projected for the secondary workloads.</simpara>
</listitem>
<listitem>
<simpara>Bind new workloads using a label selector.</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>
<section xml:id="fixed-issues-1-1_servicebinding-release-notes">
<title>Fixed issues</title>
<itemizedlist>
<listitem>
<simpara>Before this update, service bindings that used label selectors to pick up workloads did not project service binding data into the new workloads that matched the given label selectors. As a result, the Service Binding Operator could not periodically bind such new workloads. With this update, service bindings now project service binding data into the new workloads that match the given label selector. The Service Binding Operator now periodically attempts to find and bind such new workloads. <link xlink:href="https://issues.redhat.com/browse/APPSVC-1083">APPSVC-1083</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="known-issues-1-1_servicebinding-release-notes">
<title>Known issues</title>
<itemizedlist>
<listitem>
<simpara>There is currently a known issue with installing Service Binding Operator in a single namespace installation mode. The absence of an appropriate namespace-scoped role-based access control (RBAC) rule prevents the successful binding of an application to a few known Operator-backed services that the Service Binding Operator can automatically detect and bind to. When this happens, it generates an error message similar to the following example:</simpara>
<formalpara>
<title>Example error message</title>
<para>
<programlisting language="text" linenumbering="unnumbered">`postgresclusters.postgres-operator.crunchydata.com "hippo" is forbidden:
        User "system:serviceaccount:my-petclinic:service-binding-operator" cannot
        get resource "postgresclusters" in API group "postgres-operator.crunchydata.com"
        in the namespace "my-petclinic"`</programlisting>
</para>
</formalpara>
<simpara>Workaround 1: Install the Service Binding Operator in the <literal>all namespaces</literal> installation mode. As a result, the appropriate cluster-scoped RBAC rule now exists and the binding succeeds.</simpara>
<simpara>Workaround 2: If you cannot install the Service Binding Operator in the <literal>all namespaces</literal> installation mode, install the following role binding into the namespace where the Service Binding Operator is installed:</simpara>
<formalpara>
<title>Example: Role binding for Crunchy Postgres Operator</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: service-binding-crunchy-postgres-viewer
subjects:
  - kind: ServiceAccount
    name: service-binding-operator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: service-binding-crunchy-postgres-viewer-role</programlisting>
</para>
</formalpara>
<simpara><link xlink:href="https://issues.redhat.com/browse/APPSVC-1062">APPSVC-1062</link></simpara>
</listitem>
<listitem>
<simpara>Currently, when you modify the <literal>ClusterWorkloadResourceMapping</literal> resources, the Service Binding Operator does not implement correct behavior. As a workaround, perform the following steps:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Delete any <literal>ServiceBinding</literal> resources that use the corresponding <literal>ClusterWorkloadResourceMapping</literal> resource.</simpara>
</listitem>
<listitem>
<simpara>Modify the <literal>ClusterWorkloadResourceMapping</literal> resource.</simpara>
</listitem>
<listitem>
<simpara>Re-apply the <literal>ServiceBinding</literal> resources that you previously removed in step 1.</simpara>
</listitem>
</orderedlist>
<simpara><link xlink:href="https://issues.redhat.com/browse/APPSVC-1102">APPSVC-1102</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="sbo-release-notes-1-0-1_servicebinding-release-notes">
<title>Release notes for Service Binding Operator 1.0.1</title>
<simpara>Service Binding Operator is now available on OpenShift Container Platform 4.7, 4.8 and 4.9.</simpara>
<simpara>Service Binding Operator 1.0.1 supports OpenShift Container Platform 4.9 and later running on:</simpara>
<itemizedlist>
<listitem>
<simpara>IBM Power Systems</simpara>
</listitem>
<listitem>
<simpara>IBM Z and LinuxONE</simpara>
</listitem>
</itemizedlist>
<simpara>The custom resource definition (CRD) of the Service Binding Operator 1.0.1 supports the following APIs:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Service Binding</emphasis> with the <literal>binding.operators.coreos.com</literal> API group.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Service Binding (Spec API Tech Preview)</emphasis> with the <literal>servicebinding.io</literal> API group.</simpara>
<important>
<simpara><emphasis role="strong">Service Binding (Spec API Tech Preview)</emphasis> with the <literal>servicebinding.io</literal> API group is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.</simpara>
<simpara>For more information about the support scope of Red Hat Technology Preview features, see <link xlink:href="https://access.redhat.com/support/offerings/techpreview/">Technology Preview Features Support Scope</link>.</simpara>
</important>
</listitem>
</itemizedlist>
<section xml:id="support-matrix-1-0-1_servicebinding-release-notes">
<title>Support matrix</title>
<simpara>Some features in this release are currently in Technology Preview. These experimental features are not intended for production use.</simpara>
<simpara><link xlink:href="https://access.redhat.com/support/offerings/techpreview">Technology Preview Features Support Scope</link></simpara>
<simpara>In the table below, features are marked with the following statuses:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">TP</emphasis>: <emphasis>Technology Preview</emphasis></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">GA</emphasis>: <emphasis>General Availability</emphasis></simpara>
</listitem>
</itemizedlist>
<simpara>Note the following scope of support on the Red Hat Customer Portal for these features:</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Support matrix</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Feature</entry>
<entry align="left" valign="top">Service Binding Operator 1.0.1</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>binding.operators.coreos.com</literal> API group</simpara></entry>
<entry align="left" valign="top"><simpara>GA</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>servicebinding.io</literal> API group</simpara></entry>
<entry align="left" valign="top"><simpara>TP</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section xml:id="fixed-issues-1-0-1_servicebinding-release-notes">
<title>Fixed issues</title>
<itemizedlist>
<listitem>
<simpara>Before this update, binding the data values from a <literal>Cluster</literal> custom resource (CR) of the <literal>postgresql.k8s.enterpriesedb.io/v1</literal> API collected the <literal>host</literal> binding value from the <literal>.metadata.name</literal> field of the CR. The collected binding value is an incorrect hostname and the correct hostname is available at the <literal>.status.writeService</literal> field. With this update, the annotations that the Service Binding Operator uses to expose the binding data values from the backing service CR are now modified to collect the <literal>host</literal> binding value from the <literal>.status.writeService</literal> field. The Service Binding Operator uses these modified annotations to project the correct hostname in the <literal>host</literal> and <literal>provider</literal> bindings. <link xlink:href="https://issues.redhat.com/browse/APPSVC-1040">APPSVC-1040</link></simpara>
</listitem>
<listitem>
<simpara>Before this update, when you would bind a <literal>PostgresCluster</literal> CR of the <literal>postgres-operator.crunchydata.com/v1beta1</literal> API, the binding data values did not include the values for the database certificates. As a result, the application failed to connect to the database. With this update, modifications to the annotations that the Service Binding Operator uses to expose the binding data from the backing service CR now include the database certificates. The Service Binding Operator uses these modified annotations to project the correct <literal>ca.crt</literal>, <literal>tls.crt</literal>, and <literal>tls.key</literal> certificate files. <link xlink:href="https://issues.redhat.com/browse/APPSVC-1045">APPSVC-1045</link></simpara>
</listitem>
<listitem>
<simpara>Before this update, when you would bind a <literal>PerconaXtraDBCluster</literal> custom resource (CR) of the <literal>pxc.percona.com</literal> API, the binding data values did not include the <literal>port</literal> and <literal>database</literal> values. These binding values along with the others already projected are necessary for an application to successfully connect to the database service. With this update, the annotations that the Service Binding Operator uses to expose the binding data values from the backing service CR are now modified to project the additional <literal>port</literal> and <literal>database</literal> binding values. The Service Binding Operator uses these modified annotations to project the complete set of binding values that the application can use to successfully connect to the database service. <link xlink:href="https://issues.redhat.com/browse/APPSVC-1073">APPSVC-1073</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="known-issues-1-0-1_servicebinding-release-notes">
<title>Known issues</title>
<itemizedlist>
<listitem>
<simpara>Currently, when you install the Service Binding Operator in the single namespace installation mode, the absence of an appropriate namespace-scoped role-based access control (RBAC) rule prevents the successful binding of an application to a few known Operator-backed services that the Service Binding Operator can automatically detect and bind to. In addition, the following error message is generated:</simpara>
<formalpara>
<title>Example error message</title>
<para>
<screen>`postgresclusters.postgres-operator.crunchydata.com "hippo" is forbidden:
        User "system:serviceaccount:my-petclinic:service-binding-operator" cannot
        get resource "postgresclusters" in API group "postgres-operator.crunchydata.com"
        in the namespace "my-petclinic"`</screen>
</para>
</formalpara>
<simpara>Workaround 1: Install the Service Binding Operator in the <literal>all namespaces</literal> installation mode. As a result, the appropriate cluster-scoped RBAC rule now exists and the binding succeeds.</simpara>
<simpara>Workaround 2: If you cannot install the Service Binding Operator in the <literal>all namespaces</literal> installation mode, install the following role binding into the namespace where the Service Binding Operator is installed:</simpara>
<formalpara>
<title>Example: Role binding for Crunchy Postgres Operator</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: service-binding-crunchy-postgres-viewer
subjects:
  - kind: ServiceAccount
    name: service-binding-operator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: service-binding-crunchy-postgres-viewer-role</programlisting>
</para>
</formalpara>
<simpara><link xlink:href="https://issues.redhat.com/browse/APPSVC-1062">APPSVC-1062</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="sbo-release-notes-1-0_servicebinding-release-notes">
<title>Release notes for Service Binding Operator 1.0</title>
<simpara>Service Binding Operator is now available on OpenShift Container Platform 4.7, 4.8 and 4.9.</simpara>
<simpara>The custom resource definition (CRD) of the Service Binding Operator 1.0 supports the following APIs:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Service Binding</emphasis> with the <literal>binding.operators.coreos.com</literal> API group.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Service Binding (Spec API Tech Preview)</emphasis> with the <literal>servicebinding.io</literal> API group.</simpara>
<important>
<simpara><emphasis role="strong">Service Binding (Spec API Tech Preview)</emphasis> with the <literal>servicebinding.io</literal> API group is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.</simpara>
<simpara>For more information about the support scope of Red Hat Technology Preview features, see <link xlink:href="https://access.redhat.com/support/offerings/techpreview/">Technology Preview Features Support Scope</link>.</simpara>
</important>
</listitem>
</itemizedlist>
<section xml:id="support-matrix-1-0_servicebinding-release-notes">
<title>Support matrix</title>
<simpara>Some features in this release are currently in Technology Preview. These experimental features are not intended for production use.</simpara>
<simpara><link xlink:href="https://access.redhat.com/support/offerings/techpreview">Technology Preview Features Support Scope</link></simpara>
<simpara>In the table below, features are marked with the following statuses:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">TP</emphasis>: <emphasis>Technology Preview</emphasis></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">GA</emphasis>: <emphasis>General Availability</emphasis></simpara>
</listitem>
</itemizedlist>
<simpara>Note the following scope of support on the Red Hat Customer Portal for these features:</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Support matrix</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Feature</entry>
<entry align="left" valign="top">Service Binding Operator 1.0</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>binding.operators.coreos.com</literal> API group</simpara></entry>
<entry align="left" valign="top"><simpara>GA</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>servicebinding.io</literal> API group</simpara></entry>
<entry align="left" valign="top"><simpara>TP</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section xml:id="new-features-1-0_servicebinding-release-notes">
<title>New features</title>
<simpara>Service Binding Operator 1.0 supports OpenShift Container Platform 4.9 and later running on:</simpara>
<itemizedlist>
<listitem>
<simpara>IBM Power Systems</simpara>
</listitem>
<listitem>
<simpara>IBM Z and LinuxONE</simpara>
</listitem>
</itemizedlist>
<simpara>This section highlights what is new in Service Binding Operator 1.0:</simpara>
<itemizedlist>
<listitem>
<simpara>Exposal of binding data from services</simpara>
<itemizedlist>
<listitem>
<simpara>Based on annotations present in CRD, custom resources (CRs), or resources.</simpara>
</listitem>
<listitem>
<simpara>Based on descriptors present in Operator Lifecycle Manager (OLM) descriptors.</simpara>
</listitem>
<listitem>
<simpara>Support for provisioned services</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Workload projection</simpara>
<itemizedlist>
<listitem>
<simpara>Projection of binding data as files, with volume mounts.</simpara>
</listitem>
<listitem>
<simpara>Projection of binding data as environment variables.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Service Binding Options</simpara>
<itemizedlist>
<listitem>
<simpara>Bind backing services in a namespace that is different from the workload namespace.</simpara>
</listitem>
<listitem>
<simpara>Project binding data into the specific container workloads.</simpara>
</listitem>
<listitem>
<simpara>Auto-detection of the binding data from resources owned by the backing service CR.</simpara>
</listitem>
<listitem>
<simpara>Compose custom binding data from the exposed binding data.</simpara>
</listitem>
<listitem>
<simpara>Support for non-<literal>PodSpec</literal> compliant workload resources.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Security</simpara>
<itemizedlist>
<listitem>
<simpara>Support for role-based access control (RBAC).</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="additional-resources_release-notes-sbo" role="_additional-resources">
<title>Additional resources</title>
<itemizedlist>
<listitem>
<simpara><link linkend="understanding-service-binding-operator">Understanding Service Binding Operator</link>.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="understanding-service-binding-operator">
<title>Understanding Service Binding Operator</title>
<simpara role="_abstract">Application developers need access to backing services to build and connect workloads. Connecting workloads to backing services is always a challenge because each service provider suggests a different way to access their secrets and consume them in a workload. In addition, manual configuration and maintenance of this binding together of workloads and backing services make the process tedious, inefficient, and error-prone.</simpara>
<simpara>The Service Binding Operator enables application developers to easily bind workloads together with Operator-managed backing services, without any manual procedures to configure the binding connection.</simpara>
<section xml:id="sbo-service-binding-terminology_understanding-service-binding-operator">
<title>Service Binding terminology</title>
<simpara>This section summarizes the basic terms used in Service Binding.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Service binding</simpara>
</entry>
<entry>
<simpara>The representation of the action of providing information about a service to a workload. Examples include establishing the exchange of credentials between a Java application and a database that it requires.</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Backing service</simpara>
</entry>
<entry>
<simpara>Any service or software that the application consumes over the network as part of its normal operation. Examples include a database, a message broker, an application with REST endpoints, an event stream, an Application Performance Monitor (APM), or a Hardware Security Module (HSM).</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Workload (application)</simpara>
</entry>
<entry>
<simpara>Any process running within a container. Examples include a Spring Boot application, a NodeJS Express application, or a Ruby on Rails application.</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Binding data</simpara>
</entry>
<entry>
<simpara>Information about a service that you use to configure the behavior of other resources within the cluster. Examples include credentials, connection details, volume mounts, or secrets.</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Binding connection</simpara>
</entry>
<entry>
<simpara>Any connection that establishes an interaction between the connected components, such as a bindable backing service and an application requiring that backing service.</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="sbo-about-service-binding-operator_understanding-service-binding-operator">
<title>About Service Binding Operator</title>
<simpara>The Service Binding Operator consists of a controller and an accompanying custom resource definition (CRD) for service binding. It manages the data plane for workloads and backing services. The Service Binding Controller reads the data made available by the control plane of backing services. Then, it projects this data to workloads according to the rules specified through the <literal>ServiceBinding</literal> resource.</simpara>
<simpara>As a result, the Service Binding Operator enables workloads to use backing services or external services by automatically collecting and sharing binding data with the workloads. The process involves making the backing service bindable and binding the workload and the service together.</simpara>
<section xml:id="making-an-operator-managed-backing-service-bindable_understanding-service-binding-operator">
<title>Making an Operator-managed backing service bindable</title>
<simpara>To make a service bindable, as an Operator provider, you need to expose the binding data required by workloads to bind with the services provided by the Operator. You can provide the binding data either as annotations or as descriptors in the CRD of the Operator that manages the backing service.</simpara>
</section>
<section xml:id="binding-a-workload-together-with-a-backing-service_understanding-service-binding-operator">
<title>Binding a workload together with a backing service</title>
<simpara>By using the Service Binding Operator, as an application developer, you need to declare the intent of establishing a binding connection. You must create a <literal>ServiceBinding</literal> CR  that references the backing service. This action triggers the Service Binding Operator to project the exposed binding data into the workload. The Service Binding Operator receives the declared intent and binds the workload together with the backing service.</simpara>
<simpara>The CRD of the Service Binding Operator supports the following APIs:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Service Binding</emphasis> with the <literal>binding.operators.coreos.com</literal> API group.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Service Binding (Spec API)</emphasis> with the <literal>servicebinding.io</literal> API group.</simpara>
</listitem>
</itemizedlist>
<simpara>With Service Binding Operator, you can:</simpara>
<itemizedlist>
<listitem>
<simpara>Bind your workloads to Operator-managed backing services.</simpara>
</listitem>
<listitem>
<simpara>Automate configuration of binding data.</simpara>
</listitem>
<listitem>
<simpara>Provide service operators with a low-touch administrative experience to provision and manage access to services.</simpara>
</listitem>
<listitem>
<simpara>Enrich the development lifecycle with a consistent and declarative service binding method that eliminates discrepancies in cluster environments.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="sbo-key-features_understanding-service-binding-operator">
<title>Key features</title>
<itemizedlist>
<listitem>
<simpara>Exposal of binding data from services</simpara>
<itemizedlist>
<listitem>
<simpara>Based on annotations present in CRD, custom resources (CRs), or resources.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Workload projection</simpara>
<itemizedlist>
<listitem>
<simpara>Projection of binding data as files, with volume mounts.</simpara>
</listitem>
<listitem>
<simpara>Projection of binding data as environment variables.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Service Binding Options</simpara>
<itemizedlist>
<listitem>
<simpara>Bind backing services in a namespace that is different from the workload namespace.</simpara>
</listitem>
<listitem>
<simpara>Project binding data into the specific container workloads.</simpara>
</listitem>
<listitem>
<simpara>Auto-detection of the binding data from resources owned by the backing service CR.</simpara>
</listitem>
<listitem>
<simpara>Compose custom binding data from the exposed binding data.</simpara>
</listitem>
<listitem>
<simpara>Support for non-<literal>PodSpec</literal> compliant workload resources.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Security</simpara>
<itemizedlist>
<listitem>
<simpara>Support for role-based access control (RBAC).</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>
<section xml:id="sbo-api-differences_understanding-service-binding-operator">
<title>API differences</title>
<simpara>The CRD of the Service Binding Operator supports the following APIs:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Service Binding</emphasis> with the <literal>binding.operators.coreos.com</literal> API group.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Service Binding (Spec API)</emphasis> with the <literal>servicebinding.io</literal> API group.</simpara>
</listitem>
</itemizedlist>
<simpara>Both of these API groups have similar features, but they are not completely identical. Here is the complete list of differences between these API groups:</simpara>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top">Feature</entry>
<entry align="left" valign="top">Supported by the <literal>binding.operators.coreos.com</literal> API group</entry>
<entry align="left" valign="top">Supported by the <literal>servicebinding.io</literal> API group</entry>
<entry align="left" valign="top">Notes</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Binding to provisioned services</simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Not applicable (N/A)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Direct secret projection</simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Not applicable (N/A)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Bind as files</simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><itemizedlist>
<listitem>
<simpara>Default behavior for the service bindings of the <literal>servicebinding.io</literal> API group</simpara>
</listitem>
<listitem>
<simpara>Opt-in functionality for the service bindings of the <literal>binding.operators.coreos.com</literal> API group</simpara>
</listitem>
</itemizedlist></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Bind as environment variables</simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><itemizedlist>
<listitem>
<simpara>Default behavior for the service bindings of the <literal>binding.operators.coreos.com</literal> API group.</simpara>
</listitem>
<listitem>
<simpara>Opt-in functionality for the service bindings of the <literal>servicebinding.io</literal> API group: Environment variables are created alongside files.</simpara>
</listitem>
</itemizedlist></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Selecting workload with a label selector</simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Not applicable (N/A)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Detecting binding resources (<literal>.spec.detectBindingResources</literal>)</simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>The <literal>servicebinding.io</literal> API group has no equivalent feature.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Naming strategies</simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>There is no current mechanism within the <literal>servicebinding.io</literal> API group to interpret the templates that naming strategies use.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Container path</simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Partial</simpara></entry>
<entry align="left" valign="top"><simpara>Because a service binding of the <literal>binding.operators.coreos.com</literal> API group can specify mapping behavior within the <literal>ServiceBinding</literal> resource, the <literal>servicebinding.io</literal> API group cannot fully support an equivalent behavior without more information about the workload.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Container name filtering</simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>The <literal>binding.operators.coreos.com</literal> API group has no equivalent feature.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Secret path</simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>The <literal>servicebinding.io</literal> API group has no equivalent feature.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Alternative binding sources (for example, binding data from annotations)</simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Allowed by Service Binding Operator</simpara></entry>
<entry align="left" valign="top"><simpara>The specification requires support for getting binding data from provisioned services and secrets. However, a strict reading of the specification suggests that support for other binding data sources is allowed. Using this fact, Service Binding Operator can pull the binding data from various sources (for example, pulling binding data from annotations). Service Binding Operator supports these sources on both the API groups.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="additional-resources_understanding-sbo" role="_additional-resources">
<title>Additional resources</title>
<itemizedlist>
<listitem>
<simpara><link linkend="getting-started-with-service-binding">Getting started with service binding</link>.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="installing-sbo">
<title>Installing Service Binding Operator</title>
<simpara role="_abstract">This guide walks cluster administrators through the process of installing the Service Binding Operator to an OpenShift Container Platform cluster.</simpara>
<simpara>You can install Service Binding Operator on OpenShift Container Platform 4.7 and later.</simpara>
<bridgehead xml:id="_prerequisites-2" renderas="sect3">Prerequisites</bridgehead>
<itemizedlist>
<listitem>
<simpara>You have access to an OpenShift Container Platform cluster using an account with <literal>cluster-admin</literal> permissions.</simpara>
</listitem>
<listitem>
<simpara>Your cluster has the <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/postinstallation_configuration/#enabling-cluster-capabilities">Marketplace capability</link> enabled or the Red Hat Operator catalog source configured manually.</simpara>
</listitem>
</itemizedlist>
<section xml:id="op-installing-sbo-operator-using-the-web-console_installing-sbo">
<title>Installing the Service Binding Operator using the web console</title>
<simpara>You can install Service Binding Operator using the OpenShift Container Platform OperatorHub. When you install the Service Binding Operator, the custom resources (CRs) required for the service binding configuration are automatically installed along with the Operator.</simpara>
<orderedlist numeration="discrete">
<title>Procedure</title>
<listitem>
<simpara>In the <emphasis role="strong">Administrator</emphasis> perspective of the web console, navigate to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">OperatorHub</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Use the <emphasis role="strong">Filter by keyword</emphasis> box to search for <literal>Service Binding Operator</literal> in the catalog. Click the <emphasis role="strong">Service Binding Operator</emphasis> tile.</simpara>
</listitem>
<listitem>
<simpara>Read the brief description about the Operator on the <emphasis role="strong">Service Binding Operator</emphasis> page. Click <emphasis role="strong">Install</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>On the <emphasis role="strong">Install Operator</emphasis> page:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Select <emphasis role="strong">All namespaces on the cluster (default)</emphasis> for the <emphasis role="strong">Installation Mode</emphasis>. This mode installs the Operator in the default <literal>openshift-operators</literal> namespace, which enables the Operator to watch and be made available to all namespaces in the cluster.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">Automatic</emphasis> for the <emphasis role="strong">Approval Strategy</emphasis>. This ensures that the future upgrades to the Operator are handled automatically by the Operator Lifecycle Manager (OLM). If you select the <emphasis role="strong">Manual</emphasis> approval strategy, OLM creates an update request. As a cluster administrator, you must then manually approve the OLM update request to update the Operator to the new version.</simpara>
</listitem>
<listitem>
<simpara>Select an <emphasis role="strong">Update Channel</emphasis>.</simpara>
<itemizedlist>
<listitem>
<simpara>By default, the <emphasis role="strong">stable</emphasis> channel enables installation of the latest stable and supported release of the Service Binding Operator.</simpara>
</listitem>
</itemizedlist>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Install</emphasis>.</simpara>
<note>
<simpara>The Operator is installed automatically into the <literal>openshift-operators</literal> namespace.</simpara>
</note>
</listitem>
<listitem>
<simpara>On the <emphasis role="strong">Installed Operator&#8201;&#8212;&#8201;ready for use</emphasis> pane, click <emphasis role="strong">View Operator</emphasis>. You will see the Operator listed on the <emphasis role="strong">Installed Operators</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Verify that the <emphasis role="strong">Status</emphasis> is set to <emphasis role="strong">Succeeded</emphasis>  to confirm successful installation of Service Binding Operator.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="_additional-resources-2">
<title>Additional Resources</title>
<itemizedlist>
<listitem>
<simpara><link linkend="getting-started-with-service-binding">Getting started with service binding</link>.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="getting-started-with-service-binding">
<title>Getting started with service binding</title>
<simpara role="_abstract">The Service Binding Operator manages the data plane for workloads and backing services. This guide provides instructions with examples to help you create a database instance, deploy an application, and use the Service Binding Operator to create a binding connection between the application and the database service.</simpara>
<bridgehead xml:id="_prerequisites-3" renderas="sect3">Prerequisites</bridgehead>
<itemizedlist>
<listitem>
<simpara>You have access to an OpenShift Container Platform cluster using an account with <literal>cluster-admin</literal> permissions.</simpara>
</listitem>
<listitem>
<simpara>You have installed the <literal>oc</literal> CLI.</simpara>
</listitem>
<listitem>
<simpara>You have installed Service Binding Operator from OperatorHub.</simpara>
</listitem>
<listitem>
<simpara>You have installed the 5.1.2 version of the Crunchy Postgres for Kubernetes Operator from OperatorHub using the <emphasis role="strong">v5</emphasis> Update channel. The installed Operator is available in an appropriate namespace, such as the <literal>my-petclinic</literal> namespace.</simpara>
<note>
<simpara>You can create the namespace using the <literal>oc create namespace my-petclinic</literal> command.</simpara>
</note>
</listitem>
</itemizedlist>
<section xml:id="sbo-creating-a-postgresql-database-instance_getting-started-with-service-binding">
<title>Creating a PostgreSQL database instance</title>
<simpara>To create a PostgreSQL database instance, you must create a <literal>PostgresCluster</literal> custom resource (CR) and configure the database.</simpara>
<orderedlist numeration="discrete">
<title>Procedure</title>
<listitem>
<simpara>Create the <literal>PostgresCluster</literal> CR in the <literal>my-petclinic</literal> namespace by running the following command in shell:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -n my-petclinic -f - &lt;&lt; EOD
---
apiVersion: postgres-operator.crunchydata.com/v1beta1
kind: PostgresCluster
metadata:
  name: hippo
spec:
  image: registry.developers.crunchydata.com/crunchydata/crunchy-postgres:ubi8-14.4-0
  postgresVersion: 14
  instances:
    - name: instance1
      dataVolumeClaimSpec:
        accessModes:
        - "ReadWriteOnce"
        resources:
          requests:
            storage: 1Gi
  backups:
    pgbackrest:
      image: registry.developers.crunchydata.com/crunchydata/crunchy-pgbackrest:ubi8-2.38-0
      repos:
      - name: repo1
        volume:
          volumeClaimSpec:
            accessModes:
            - "ReadWriteOnce"
            resources:
              requests:
                storage: 1Gi
EOD</programlisting>
<simpara>The annotations added in this <literal>PostgresCluster</literal> CR enable the service binding connection and trigger the Operator reconciliation.</simpara>
<simpara>The output verifies that the database instance is created:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">postgrescluster.postgres-operator.crunchydata.com/hippo created</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>After you have created the database instance, ensure that all the pods in the <literal>my-petclinic</literal> namespace are running:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods -n my-petclinic</programlisting>
<simpara>The output, which takes a few minutes to display, verifies that the database is created and configured:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                                     READY    STATUS      RESTARTS   AGE
hippo-backup-9rxm-88rzq                   0/1     Completed   0          2m2s
hippo-instance1-6psd-0                    4/4     Running     0          3m28s
hippo-repo-host-0                         2/2     Running     0          3m28s</programlisting>
</para>
</formalpara>
<simpara>After the database is configured, you can deploy the sample application and connect it to the database service.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="sbo-deploying-the-spring-petclinic-sample-application_getting-started-with-service-binding">
<title>Deploying the Spring PetClinic sample application</title>
<simpara>To deploy the Spring PetClinic sample application on an OpenShift Container Platform cluster, you must use a deployment configuration and configure your local environment to be able to test the application.</simpara>
<orderedlist numeration="discrete">
<title>Procedure</title>
<listitem>
<simpara>Deploy the <literal>spring-petclinic</literal> application with the <literal>PostgresCluster</literal> custom resource (CR) by running the following command in shell:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -n my-petclinic -f - &lt;&lt; EOD
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spring-petclinic
  labels:
    app: spring-petclinic
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spring-petclinic
  template:
    metadata:
      labels:
        app: spring-petclinic
    spec:
      containers:
        - name: app
          image: quay.io/service-binding/spring-petclinic:latest
          imagePullPolicy: Always
          env:
          - name: SPRING_PROFILES_ACTIVE
            value: postgres
          ports:
          - name: http
            containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: spring-petclinic
  name: spring-petclinic
spec:
  type: NodePort
  ports:
    - port: 80
      protocol: TCP
      targetPort: 8080
  selector:
    app: spring-petclinic
EOD</programlisting>
<simpara>The output verifies that the Spring PetClinic sample application is created and deployed:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">deployment.apps/spring-petclinic created
service/spring-petclinic created</programlisting>
</para>
</formalpara>
<note>
<simpara>If you are deploying the application using <emphasis role="strong">Container images</emphasis> in the <emphasis role="strong">Developer</emphasis> perspective of the web console, you must enter the following environment variables under the <emphasis role="strong">Deployment</emphasis> section of the <emphasis role="strong">Advanced options</emphasis>:</simpara>
<itemizedlist>
<listitem>
<simpara>Name: SPRING_PROFILES_ACTIVE</simpara>
</listitem>
<listitem>
<simpara>Value: postgres</simpara>
</listitem>
</itemizedlist>
</note>
</listitem>
<listitem>
<simpara>Verify that the application is not yet connected to the database service by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods -n my-petclinic</programlisting>
<simpara>The output takes a few minutes to display the <literal>CrashLoopBackOff</literal> status:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                                READY   STATUS             RESTARTS      AGE
spring-petclinic-5b4c7999d4-wzdtz   0/1     CrashLoopBackOff   4 (13s ago)   2m25s</programlisting>
</para>
</formalpara>
<simpara>At this stage, the pod fails to start. If you try to interact with the application, it returns errors.</simpara>
</listitem>
<listitem>
<simpara>Expose the service to create a route for your application:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc expose service spring-petclinic -n my-petclinic</programlisting>
<simpara>The output verifies that the <literal>spring-petclinic</literal> service is exposed and a route for the Spring PetClinic sample application is created:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">route.route.openshift.io/spring-petclinic exposed</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
<simpara>You can now use the Service Binding Operator to connect the application to the database service.</simpara>
</section>
<section xml:id="_connecting-the-spring-petclinic-sample-application-to-the-postgresql-database-service">
<title>Connecting the Spring PetClinic sample application to the PostgreSQL database service</title>
<simpara xml:id="sbo-connecting-spring-petclinic-sample-app-to-postgresql-database-service_getting-started-with-service-binding">To connect the sample application to the database service, you must create a <literal>ServiceBinding</literal> custom resource (CR) that triggers the Service Binding Operator to project the binding data into the application.</simpara>
<orderedlist numeration="discrete">
<title>Procedure</title>
<listitem>
<simpara>Create a <literal>ServiceBinding</literal> CR to project the binding data:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -n my-petclinic -f - &lt;&lt; EOD
---
apiVersion: binding.operators.coreos.com/v1alpha1
kind: ServiceBinding
metadata:
  name: spring-petclinic-pgcluster
spec:
  services: <co xml:id="CO1-1"/>
    - group: postgres-operator.crunchydata.com
      version: v1beta1
      kind: PostgresCluster <co xml:id="CO1-2"/>
      name: hippo
  application: <co xml:id="CO1-3"/>
    name: spring-petclinic
    group: apps
    version: v1
    resource: deployments
EOD</programlisting>
<calloutlist>
<callout arearefs="CO1-1">
<para>Specifies a list of service resources.</para>
</callout>
<callout arearefs="CO1-2">
<para>The CR of the database.</para>
</callout>
<callout arearefs="CO1-3">
<para>The sample application that points to a Deployment or any other similar resource with an embedded PodSpec.</para>
</callout>
</calloutlist>
<simpara>The output verifies that the <literal>ServiceBinding</literal> CR is created to project the binding data into the sample application.</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">servicebinding.binding.operators.coreos.com/spring-petclinic created</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Verify that the request for service binding is successful:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get servicebindings -n my-petclinic</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                         READY   REASON              AGE
spring-petclinic-pgcluster   True    ApplicationsBound   7s</programlisting>
</para>
</formalpara>
<simpara>By default, the values from the binding data of the database service are projected as files into the workload container that runs the sample application. For example, all the values from the Secret resource are projected into the <literal>bindings/spring-petclinic-pgcluster</literal> directory.</simpara>
<note>
<simpara>Optionally, you can also verify that the files in the application contain the projected binding data, by printing out the directory contents:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ for i in username password host port type; do oc exec -it deploy/spring-petclinic -n my-petclinic -- /bin/bash -c 'cd /tmp; find /bindings/*/'$i' -exec echo -n {}:" " \; -exec cat {} \;'; echo; done</programlisting>
<formalpara>
<title>Example output: With all the values from the secret resource</title>
<para>
<programlisting language="text" linenumbering="unnumbered">/bindings/spring-petclinic-pgcluster/username: &lt;username&gt;
/bindings/spring-petclinic-pgcluster/password: &lt;password&gt;
/bindings/spring-petclinic-pgcluster/host: hippo-primary.my-petclinic.svc
/bindings/spring-petclinic-pgcluster/port: 5432
/bindings/spring-petclinic-pgcluster/type: postgresql</programlisting>
</para>
</formalpara>
</note>
</listitem>
<listitem>
<simpara>Set up the port forwarding from the application port to access the sample application from your local environment:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc port-forward --address 0.0.0.0 svc/spring-petclinic 8080:80 -n my-petclinic</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">Forwarding from 0.0.0.0:8080 -&gt; 8080
Handling connection for 8080</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Access <link xlink:href="http://localhost:8080/petclinic">http://localhost:8080/petclinic</link>.</simpara>
<simpara>You can now remotely access the Spring PetClinic sample application at localhost:8080 and see that the application is now connected to the database service.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="additional-resources_getting-started-sbo" role="_additional-resources">
<title>Additional Resources</title>
<itemizedlist>
<listitem>
<simpara><link linkend="installing-sbo">Installing Service Binding Operator</link>.</simpara>
</listitem>
<listitem>
<simpara><link linkend="odc-creating-applications-using-developer-perspective">Creating applications using the Developer perspective</link>.</simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/operators/#managing-resources-from-crds">Managing resources from custom resource definitions</link>.</simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://github.com/redhat-developer/service-binding-operator#known-bindable-operators">Known bindable Operators</link>.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="getting-started-with-service-binding-ibm-power-ibm-z">
<title>Getting started with service binding on IBM Power, IBM Z, and IBM LinuxONE</title>
<simpara role="_abstract">The Service Binding Operator manages the data plane for workloads and backing services. This guide provides instructions with examples to help you create a database instance, deploy an application, and use the Service Binding Operator to create a binding connection between the application and the database service.</simpara>
<bridgehead xml:id="_prerequisites-4" renderas="sect3">Prerequisites</bridgehead>
<itemizedlist>
<listitem>
<simpara>You have access to an OpenShift Container Platform cluster using an account with <literal>cluster-admin</literal> permissions.</simpara>
</listitem>
<listitem>
<simpara>You have installed the <literal>oc</literal> CLI.</simpara>
</listitem>
<listitem>
<simpara>You have installed the Service Binding Operator from OperatorHub.</simpara>
</listitem>
</itemizedlist>
<section xml:id="sbo-deploying-a-postgresql-operator-instance-power-z_getting-started-with-service-binding-ibm-power-ibm-z">
<title>Deploying a PostgreSQL Operator</title>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To deploy the Dev4Devs PostgreSQL Operator in the <literal>my-petclinic</literal> namespace run the following command in shell:</simpara>
</listitem>
</orderedlist>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f - &lt;&lt; EOD
---
apiVersion: v1
kind: Namespace
metadata:
  name: my-petclinic
---
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: postgres-operator-group
  namespace: my-petclinic
---
apiVersion: operators.coreos.com/v1alpha1
kind: CatalogSource
metadata:
  name: ibm-multiarch-catalog
  namespace: openshift-marketplace
spec:
  sourceType: grpc
  image: quay.io/ibm/operator-registry-&lt;architecture&gt; <co xml:id="CO2-1"/>
  imagePullPolicy: IfNotPresent
  displayName: ibm-multiarch-catalog
  updateStrategy:
    registryPoll:
      interval: 30m
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: postgresql-operator-dev4devs-com
  namespace: openshift-operators
spec:
  channel: alpha
  installPlanApproval: Automatic
  name: postgresql-operator-dev4devs-com
  source: ibm-multiarch-catalog
  sourceNamespace: openshift-marketplace
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: database-view
  labels:
    servicebinding.io/controller: "true"
rules:
  - apiGroups:
      - postgresql.dev4devs.com
    resources:
      - databases
    verbs:
      - get
      - list
EOD</programlisting>
<calloutlist>
<callout arearefs="CO2-1">
<para>The Operator image.</para>
<itemizedlist>
<listitem>
<simpara>For IBM Power&#174;: <literal>quay.io/ibm/operator-registry-ppc64le:release-4.9</literal></simpara>
</listitem>
<listitem>
<simpara>For IBM Z&#174; and IBM&#174; LinuxONE: <literal>quay.io/ibm/operator-registry-s390x:release-4.8</literal></simpara>
</listitem>
</itemizedlist>
</callout>
</calloutlist>
<orderedlist numeration="arabic">
<title>Verification</title>
<listitem>
<simpara>After the operator is installed, list the operator subscriptions in the <literal>openshift-operators</literal> namespace:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get subs -n openshift-operators</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                               PACKAGE                            SOURCE                  CHANNEL
postgresql-operator-dev4devs-com   postgresql-operator-dev4devs-com   ibm-multiarch-catalog   alpha
rh-service-binding-operator        rh-service-binding-operator        redhat-operators        stable</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</section>
<section xml:id="sbo-creating-a-postgresql-database-instance-power-z_getting-started-with-service-binding-ibm-power-ibm-z">
<title>Creating a PostgreSQL database instance</title>
<simpara role="_abstract">To create a PostgreSQL database instance, you must create a <literal>Database</literal> custom resource (CR) and configure the database.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create the <literal>Database</literal> CR in the <literal>my-petclinic</literal> namespace by running the following command in shell:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f - &lt;&lt; EOD
apiVersion: postgresql.dev4devs.com/v1alpha1
kind: Database
metadata:
  name: sampledatabase
  namespace: my-petclinic
  annotations:
    host: sampledatabase
    type: postgresql
    port: "5432"
    service.binding/database: 'path={.spec.databaseName}'
    service.binding/port: 'path={.metadata.annotations.port}'
    service.binding/password: 'path={.spec.databasePassword}'
    service.binding/username: 'path={.spec.databaseUser}'
    service.binding/type: 'path={.metadata.annotations.type}'
    service.binding/host: 'path={.metadata.annotations.host}'
spec:
  databaseCpu: 30m
  databaseCpuLimit: 60m
  databaseMemoryLimit: 512Mi
  databaseMemoryRequest: 128Mi
  databaseName: "sampledb"
  databaseNameKeyEnvVar: POSTGRESQL_DATABASE
  databasePassword: "samplepwd"
  databasePasswordKeyEnvVar: POSTGRESQL_PASSWORD
  databaseStorageRequest: 1Gi
  databaseUser: "sampleuser"
  databaseUserKeyEnvVar: POSTGRESQL_USER
  image: registry.redhat.io/rhel8/postgresql-13:latest
  databaseStorageClassName: nfs-storage-provisioner
  size: 1
EOD</programlisting>
<simpara>The annotations added in this <literal>Database</literal> CR enable the service binding connection and trigger the Operator reconciliation.</simpara>
<simpara>The output verifies that the database instance is created:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">database.postgresql.dev4devs.com/sampledatabase created</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>After you have created the database instance, ensure that all the pods in the <literal>my-petclinic</literal> namespace are running:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods -n my-petclinic</programlisting>
<simpara>The output, which takes a few minutes to display, verifies that the database is created and configured:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                                     READY    STATUS      RESTARTS   AGE
sampledatabase-cbc655488-74kss            0/1     Running        0       32s</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
<simpara>After the database is configured, you can deploy the sample application and connect it to the database service.</simpara>
</section>
<section xml:id="sbo-deploying-the-spring-petclinic-sample-application-ibm-power-z_getting-started-with-service-binding-ibm-power-ibm-z">
<title>Deploying the Spring PetClinic sample application</title>
<simpara role="_abstract">To deploy the Spring PetClinic sample application on an OpenShift Container Platform cluster, you must use a deployment configuration and configure your local environment to be able to test the application.</simpara>
<orderedlist numeration="discrete">
<title>Procedure</title>
<listitem>
<simpara>Deploy the <literal>spring-petclinic</literal> application with the <literal>PostgresCluster</literal> custom resource (CR) by running the following command in shell:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -n my-petclinic -f - &lt;&lt; EOD
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spring-petclinic
  labels:
    app: spring-petclinic
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spring-petclinic
  template:
    metadata:
      labels:
        app: spring-petclinic
    spec:
      containers:
        - name: app
          image: quay.io/service-binding/spring-petclinic:latest
          imagePullPolicy: Always
          env:
          - name: SPRING_PROFILES_ACTIVE
            value: postgres
          - name: org.springframework.cloud.bindings.boot.enable
            value: "true"
          ports:
          - name: http
            containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: spring-petclinic
  name: spring-petclinic
spec:
  type: NodePort
  ports:
    - port: 80
      protocol: TCP
      targetPort: 8080
  selector:
    app: spring-petclinic
EOD</programlisting>
<simpara>The output verifies that the Spring PetClinic sample application is created and deployed:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">deployment.apps/spring-petclinic created
service/spring-petclinic created</programlisting>
</para>
</formalpara>
<note>
<simpara>If you are deploying the application using <emphasis role="strong">Container images</emphasis> in the <emphasis role="strong">Developer</emphasis> perspective of the web console, you must enter the following environment variables under the <emphasis role="strong">Deployment</emphasis> section of the <emphasis role="strong">Advanced options</emphasis>:</simpara>
<itemizedlist>
<listitem>
<simpara>Name: SPRING_PROFILES_ACTIVE</simpara>
</listitem>
<listitem>
<simpara>Value: postgres</simpara>
</listitem>
</itemizedlist>
</note>
</listitem>
<listitem>
<simpara>Verify that the application is not yet connected to the database service by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods -n my-petclinic</programlisting>
<simpara>It takes take a few minutes until the <literal>CrashLoopBackOff</literal> status is displayed:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                                READY   STATUS             RESTARTS      AGE
spring-petclinic-5b4c7999d4-wzdtz   0/1     CrashLoopBackOff   4 (13s ago)   2m25s</programlisting>
</para>
</formalpara>
<simpara>At this stage, the pod fails to start. If you try to interact with the application, it returns errors.</simpara>
</listitem>
</orderedlist>
<simpara>You can now use the Service Binding Operator to connect the application to the database service.</simpara>
</section>
<section xml:id="sbo-connecting-spring-petclinic-sample-app-to-postgresql-database-service-ibm-power-z_getting-started-with-service-binding-ibm-power-ibm-z">
<title>Connecting the Spring PetClinic sample application to the PostgreSQL database service</title>
<simpara role="_abstract">To connect the sample application to the database service, you must create a <literal>ServiceBinding</literal> custom resource (CR) that triggers the Service Binding Operator to project the binding data into the application.</simpara>
<orderedlist numeration="discrete">
<title>Procedure</title>
<listitem>
<simpara>Create a <literal>ServiceBinding</literal> CR to project the binding data:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -n my-petclinic -f - &lt;&lt; EOD
---
apiVersion: binding.operators.coreos.com/v1alpha1
kind: ServiceBinding
metadata:
    name: spring-petclinic-pgcluster
spec:
  services: <co xml:id="CO3-1"/>
    - group: postgresql.dev4devs.com
      kind: Database <co xml:id="CO3-2"/>
      name: sampledatabase
      version: v1alpha1
  application: <co xml:id="CO3-3"/>
    name: spring-petclinic
    group: apps
    version: v1
    resource: deployments
EOD</programlisting>
<calloutlist>
<callout arearefs="CO3-1">
<para>Specifies a list of service resources.</para>
</callout>
<callout arearefs="CO3-2">
<para>The CR of the database.</para>
</callout>
<callout arearefs="CO3-3">
<para>The sample application that points to a Deployment or any other similar resource with an embedded PodSpec.</para>
</callout>
</calloutlist>
<simpara>The output verifies that the <literal>ServiceBinding</literal> CR is created to project the binding data into the sample application.</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">servicebinding.binding.operators.coreos.com/spring-petclinic created</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Verify that the request for service binding is successful:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get servicebindings -n my-petclinic</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                          READY   REASON              AGE
spring-petclinic-postgresql   True    ApplicationsBound   47m</programlisting>
</para>
</formalpara>
<simpara>By default, the values from the binding data of the database service are projected as files into the workload container that runs the sample application. For example, all the values from the Secret resource are projected into the <literal>bindings/spring-petclinic-pgcluster</literal> directory.</simpara>
</listitem>
<listitem>
<simpara>Once this is created, you can go to the topology to see the visual connection.</simpara>
<figure>
<title>Connecting spring-petclinic to a sample database</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/img_power.png"/>
</imageobject>
<textobject><phrase>img power</phrase></textobject>
</mediaobject>
</figure>
</listitem>
<listitem>
<simpara>Set up the port forwarding from the application port to access the sample application from your local environment:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc port-forward --address 0.0.0.0 svc/spring-petclinic 8080:80 -n my-petclinic</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">Forwarding from 0.0.0.0:8080 -&gt; 8080
Handling connection for 8080</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Access <link xlink:href="http://localhost:8080">http://localhost:8080</link>.</simpara>
<simpara>You can now remotely access the Spring PetClinic sample application at localhost:8080 and see that the application is now connected to the database service.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="additional-resources_getting-started-with-service-binding-ibm-power-ibm-z" role="_additional-resources">
<title>Additional resources</title>
<itemizedlist>
<listitem>
<simpara><link linkend="installing-sbo">Installing Service Binding Operator</link></simpara>
</listitem>
<listitem>
<simpara><link linkend="odc-creating-applications-using-developer-perspective">Creating applications using the Developer perspective</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/operators/#managing-resources-from-crds">Managing resources from custom resource definitions</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="exposing-binding-data-from-a-service">
<title>Exposing binding data from a service</title>
<simpara role="_abstract">Application developers need access to backing services to build and connect workloads. Connecting workloads to backing services is always a challenge because each service provider requires a different way to access their secrets and consume them in a workload.</simpara>
<simpara>The Service Binding Operator enables application developers to easily bind workloads together with operator-managed backing services, without any manual procedures to configure the binding connection. For the Service Binding Operator to provide the binding data, as an Operator provider or user who creates backing services, you must expose the binding data to be automatically detected by the Service Binding Operator. Then, the Service Binding Operator automatically collects the binding data from the backing service and shares it with a workload to provide a consistent and predictable experience.</simpara>
<section xml:id="sbo-methods-of-exposing-binding-data_exposing-binding-data-from-a-service">
<title>Methods of exposing binding data</title>
<simpara role="_abstract">This section describes the methods you can use to expose the binding data.</simpara>
<simpara>Ensure that you know and understand your workload requirements and environment, and how it works with the provided services.</simpara>
<simpara>Binding data is exposed under the following circumstances:</simpara>
<itemizedlist>
<listitem>
<simpara>Backing service is available as a provisioned service resource.</simpara>
<simpara>The service you intend to connect to is compliant with the Service Binding specification. You must create a <literal>Secret</literal> resource with all the required binding data values and reference it in the backing service custom resource (CR). The detection of all the binding data values is automatic.</simpara>
</listitem>
<listitem>
<simpara>Backing service is not available as a provisioned service resource.</simpara>
<simpara>You must expose the binding data from the backing service. Depending on your workload requirements and environment, you can choose any of the following methods to expose the binding data:</simpara>
<itemizedlist>
<listitem>
<simpara>Direct secret reference</simpara>
</listitem>
<listitem>
<simpara>Declaring binding data through custom resource definition (CRD) or CR annotations</simpara>
</listitem>
<listitem>
<simpara>Detection of binding data through owned resources</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
<section xml:id="provisioned-service_exposing-binding-data-from-a-service">
<title>Provisioned service</title>
<simpara>Provisioned service represents a backing service CR with a reference to a <literal>Secret</literal> resource placed in the <literal>.status.binding.name</literal> field of the backing service CR.</simpara>
<simpara>As an Operator provider or the user who creates backing services, you can use this method to be compliant with the Service Binding specification, by creating a <literal>Secret</literal> resource and referencing it in the <literal>.status.binding.name</literal> section of the backing service CR. This <literal>Secret</literal> resource must provide all the binding data values required for a workload to connect to the backing service.</simpara>
<simpara>The following examples show an <literal>AccountService</literal> CR that represents a backing service and a <literal>Secret</literal> resource referenced from the CR.</simpara>
<formalpara>
<title>Example: <literal>AccountService</literal> CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: example.com/v1alpha1
kind: AccountService
name: prod-account-service
spec:
  ...
status:
  binding:
    name: hippo-pguser-hippo</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example: Referenced <literal>Secret</literal> resource</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Secret
metadata:
  name: hippo-pguser-hippo
data:
  password: "&lt;password&gt;"
  user: "&lt;username&gt;"
  ...</programlisting>
</para>
</formalpara>
<simpara>When creating a service binding resource, you can directly give the details of the <literal>AccountService</literal> resource in the <literal>ServiceBinding</literal> specification as follows:</simpara>
<formalpara>
<title>Example: <literal>ServiceBinding</literal> resource</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: binding.operators.coreos.com/v1alpha1
kind: ServiceBinding
metadata:
  name: account-service
spec:
  ...
  services:
  - group: "example.com"
    version: v1alpha1
    kind: AccountService
    name: prod-account-service
  application:
    name: spring-petclinic
    group: apps
    version: v1
    resource: deployments</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example: <literal>ServiceBinding</literal> resource in Specification API</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: servicebinding.io/v1beta1
kind: ServiceBinding
metadata:
  name: account-service
spec:
  ...
  service:
    apiVersion: example.com/v1alpha1
    kind: AccountService
    name: prod-account-service
  workload:
    apiVersion: apps/v1
    kind: Deployment
    name: spring-petclinic</programlisting>
</para>
</formalpara>
<simpara>This method exposes all the keys in the <literal>hippo-pguser-hippo</literal> referenced <literal>Secret</literal> resource as binding data that is to be projected into the workload.</simpara>
</section>
<section xml:id="direct-secret-reference_exposing-binding-data-from-a-service">
<title>Direct secret reference</title>
<simpara>You can use this method, if all the required binding data values are available in a <literal>Secret</literal> resource that you can reference in your Service Binding definition. In this method, a <literal>ServiceBinding</literal> resource directly references a <literal>Secret</literal> resource to connect to a service. All the keys in the <literal>Secret</literal> resource are exposed as binding data.</simpara>
<formalpara>
<title>Example: Specification with the <literal>binding.operators.coreos.com</literal> API</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: binding.operators.coreos.com/v1alpha1
kind: ServiceBinding
metadata:
  name: account-service
spec:
  ...
  services:
  - group: ""
    version: v1
    kind: Secret
    name: hippo-pguser-hippo</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example: Specification that is compliant with the <literal>servicebinding.io</literal> API</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: servicebinding.io/v1beta1
kind: ServiceBinding
metadata:
  name: account-service
spec:
  ...
  service:
    apiVersion: v1
    kind: Secret
    name: hippo-pguser-hippo</programlisting>
</para>
</formalpara>
</section>
<section xml:id="declaring-binding-data-through-CRD-or-CR-annotations_exposing-binding-data-from-a-service">
<title>Declaring binding data through CRD or CR annotations</title>
<simpara>You can use this method to annotate the resources of the backing service to expose the binding data with specific annotations. Adding annotations under the <literal>metadata</literal> section alters the CRs and CRDs of the backing services. Service Binding Operator detects the annotations added to the CRs and CRDs and then creates a <literal>Secret</literal> resource with the values extracted based on the annotations.</simpara>
<simpara>The following examples show the annotations that are added under the <literal>metadata</literal> section and a referenced <literal>ConfigMap</literal> object from a resource:</simpara>
<formalpara>
<title>Example: Exposing binding data from a <literal>Secret</literal> object defined in the CR annotations</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: postgres-operator.crunchydata.com/v1beta1
kind: PostgresCluster
metadata:
  name: hippo
  namespace: my-petclinic
  annotations:
    service.binding: 'path={.metadata.name}-pguser-{.metadata.name},objectType=Secret'
    ...</programlisting>
</para>
</formalpara>
<simpara>The previous example places the name of the secret name in the <literal>{.metadata.name}-pguser-{.metadata.name}</literal> template that resolves to <literal>hippo-pguser-hippo</literal>. The template can contain multiple JSONPath expressions.</simpara>
<formalpara>
<title>Example: Referenced <literal>Secret</literal> object from a resource</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Secret
metadata:
  name: hippo-pguser-hippo
data:
  password: "&lt;password&gt;"
  user: "&lt;username&gt;"</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example: Exposing binding data from a <literal>ConfigMap</literal> object defined in the CR annotations</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: postgres-operator.crunchydata.com/v1beta1
kind: PostgresCluster
metadata:
  name: hippo
  namespace: my-petclinic
  annotations:
    service.binding: 'path={.metadata.name}-config,objectType=ConfigMap'
    ...</programlisting>
</para>
</formalpara>
<simpara>The previous example places the name of the config map in the <literal>{.metadata.name}-config</literal> template that resolves to <literal>hippo-config</literal>. The template can contain multiple JSONPath expressions.</simpara>
<formalpara>
<title>Example: Referenced <literal>ConfigMap</literal> object from a resource</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: ConfigMap
metadata:
  name: hippo-config
data:
  db_timeout: "10s"
  user: "hippo"</programlisting>
</para>
</formalpara>
</section>
<section xml:id="detection-of-binding-data-through-owned-resources_exposing-binding-data-from-a-service">
<title>Detection of binding data through owned resources</title>
<simpara>You can use this method if your backing service owns one or more Kubernetes resources such as route, service, config map, or secret that you can use to detect the binding data. In this method, the Service Binding Operator detects the binding data from resources owned by the backing service CR.</simpara>
<simpara>The following examples show the <literal>detectBindingResources</literal> API option set to <literal>true</literal> in the <literal>ServiceBinding</literal> CR:</simpara>
<formalpara>
<title>Example</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: binding.operators.coreos.com/v1alpha1
kind: ServiceBinding
metadata:
  name: spring-petclinic-detect-all
  namespace: my-petclinic
spec:
  detectBindingResources: true
  services:
    - group: postgres-operator.crunchydata.com
      version: v1beta1
      kind: PostgresCluster
      name: hippo
  application:
    name: spring-petclinic
    group: apps
    version: v1
    resource: deployments</programlisting>
</para>
</formalpara>
<simpara>In the previous example, <literal>PostgresCluster</literal> custom service resource owns one or more Kubernetes resources such as route, service, config map, or secret.</simpara>
<simpara>The Service Binding Operator automatically detects the binding data exposed on each of the owned resources.</simpara>
</section>
</section>
<section xml:id="sbo-data-model_exposing-binding-data-from-a-service">
<title>Data model</title>
<simpara role="_abstract">The data model used in the annotations follows specific conventions.</simpara>
<simpara>Service binding annotations must use the following convention:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">service.binding(/&lt;NAME&gt;)?:
    "&lt;VALUE&gt;|(path=&lt;JSONPATH_TEMPLATE&gt;(,objectType=&lt;OBJECT_TYPE&gt;)?(,elementType=&lt;ELEMENT_TYPE&gt;)?(,sourceKey=&lt;SOURCE_KEY&gt;)?(,sourceValue=&lt;SOURCE_VALUE&gt;)?)"</programlisting>
<simpara>where:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara><literal>&lt;NAME&gt;</literal></simpara>
</entry>
<entry>
<simpara>Specifies the name under which the binding value is to be exposed. You can exclude it only when the <literal>objectType</literal> parameter is set to <literal>Secret</literal> or <literal>ConfigMap</literal>.</simpara>
</entry>
</row>
<row>
<entry>
<simpara><literal>&lt;VALUE&gt;</literal></simpara>
</entry>
<entry>
<simpara>Specifies the constant value exposed when no <literal>path</literal> is set.</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>The data model provides the details on the allowed values and semantic for the <literal>path</literal>, <literal>elementType</literal>, <literal>objectType</literal>, <literal>sourceKey</literal>, and <literal>sourceValue</literal> parameters.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Parameters and their descriptions</title>
<tgroup cols="3">
<colspec colname="col_1" colwidth="23.0769*"/>
<colspec colname="col_2" colwidth="46.1538*"/>
<colspec colname="col_3" colwidth="30.7693*"/>
<thead>
<row>
<entry align="left" valign="top">Parameter</entry>
<entry align="left" valign="top">Description</entry>
<entry align="left" valign="top">Default value</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>JSONPath template that consists JSONPath expressions enclosed by curly braces {}.</simpara></entry>
<entry align="left" valign="top"><simpara>N/A</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>elementType</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Specifies whether the value of the element referenced in the <literal>path</literal> parameter complies with any one of the following types:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>string</literal></simpara>
</listitem>
<listitem>
<simpara><literal>sliceOfStrings</literal></simpara>
</listitem>
<listitem>
<simpara><literal>sliceOfMaps</literal></simpara>
</listitem>
</itemizedlist></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>objectType</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Specifies whether the value of the element indicated in the <literal>path</literal> parameter refers to a <literal>ConfigMap</literal>, <literal>Secret</literal>, or plain string in the current namespace.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>Secret</literal>, if <literal>elementType</literal> is non-string.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>sourceKey</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Specifies the key in the <literal>ConfigMap</literal> or <literal>Secret</literal> resource to be added to the binding secret when collecting the binding data.<?asciidoc-br?></simpara>
<simpara>Note:</simpara>
<itemizedlist>
<listitem>
<simpara>When used in conjunction with <literal>elementType</literal>=<literal>sliceOfMaps</literal>, the <literal>sourceKey</literal> parameter specifies the key in the slice of maps whose value is used as a key in the binding secret.</simpara>
</listitem>
<listitem>
<simpara>Use this optional parameter to expose a specific entry in the referenced <literal>Secret</literal> or <literal>ConfigMap</literal> resource as binding data.</simpara>
</listitem>
<listitem>
<simpara>When not specified, all keys and values from the <literal>Secret</literal> or <literal>ConfigMap</literal> resource are exposed and are added to the binding secret.</simpara>
</listitem>
</itemizedlist></entry>
<entry align="left" valign="top"><simpara>N/A</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>sourceValue</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Specifies the key in the slice of maps.<?asciidoc-br?></simpara>
<simpara>Note:</simpara>
<itemizedlist>
<listitem>
<simpara>The value of this key is used as the base to generate the value of the entry for the key-value pair to be added to the binding secret.</simpara>
</listitem>
<listitem>
<simpara>In addition, the value of the <literal>sourceKey</literal> is used as the key of the entry for the key-value pair to be added to the binding secret.</simpara>
</listitem>
<listitem>
<simpara>It is mandatory only if <literal>elementType</literal>=<literal>sliceOfMaps</literal>.</simpara>
</listitem>
</itemizedlist></entry>
<entry align="left" valign="top"><simpara>N/A</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<note>
<simpara>The <literal>sourceKey</literal> and <literal>sourceValue</literal> parameters are applicable only if the element indicated in the <literal>path</literal> parameter refers to a <literal>ConfigMap</literal> or <literal>Secret</literal> resource.</simpara>
</note>
</section>
<section xml:id="sbo-setting-annotations-mapping-optional_exposing-binding-data-from-a-service">
<title>Setting annotations mapping to be optional</title>
<simpara>You can have optional fields in the annotations. For example, a path to the credentials might not be present if the service endpoint does not require authentication. In such cases, a field might not exist in the target path of the annotations. As a result, Service Binding Operator generates an error, by default.</simpara>
<simpara>As a service provider, to indicate whether you require annotations mapping, you can set a value for the <literal>optional</literal> flag in your annotations when enabling services. Service Binding Operator provides annotations mapping only if the target path is available. When the target path is not available, the Service Binding Operator skips the optional mapping and continues with the projection of the existing mappings without throwing any errors.</simpara>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>To make a field in the annotations optional, set the <literal>optional</literal> flag value to <literal>true</literal>:</simpara>
<formalpara>
<title>Example</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: apps.example.org/v1beta1
kind: Database
metadata:
  name: my-db
  namespace: my-petclinic
  annotations:
    service.binding/username: path={.spec.name},optional=true
    ...</programlisting>
</para>
</formalpara>
</listitem>
</itemizedlist>
<note>
<itemizedlist>
<listitem>
<simpara>If you set the <literal>optional</literal> flag value to <literal>false</literal> and the Service Binding Operator is unable to find the target path, the Operator fails the annotations mapping.</simpara>
</listitem>
<listitem>
<simpara>If the <literal>optional</literal> flag has no value set, the Service Binding Operator considers the value as <literal>false</literal> by default and fails the annotations mapping.</simpara>
</listitem>
</itemizedlist>
</note>
</section>
<section xml:id="sbo-rbac-requirements_exposing-binding-data-from-a-service">
<title>RBAC requirements</title>
<simpara role="_abstract">To expose the backing service binding data using the Service Binding Operator, you require certain Role-based access control (RBAC) permissions. Specify certain verbs under the <literal>rules</literal> field of the <literal>ClusterRole</literal> resource to grant the RBAC permissions for the backing service resources. When you define these <literal>rules</literal>, you allow the Service Binding Operator to read the binding data of the backing service resources throughout the cluster. If the users do not have permissions to read binding data or modify application resource, the Service Binding Operator prevents such users to bind services to application. Adhering to the RBAC requirements avoids unnecessary permission elevation for the user and prevents access to unauthorized services or applications.</simpara>
<simpara>The Service Binding Operator performs requests against the Kubernetes API using a dedicated service account. By default, this account has permissions to bind services to workloads, both represented by the following standard Kubernetes or OpenShift objects:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>Deployments</literal></simpara>
</listitem>
<listitem>
<simpara><literal>DaemonSets</literal></simpara>
</listitem>
<listitem>
<simpara><literal>ReplicaSets</literal></simpara>
</listitem>
<listitem>
<simpara><literal>StatefulSets</literal></simpara>
</listitem>
<listitem>
<simpara><literal>DeploymentConfigs</literal></simpara>
</listitem>
</itemizedlist>
<simpara>The Operator service account is bound to an aggregated cluster role, allowing Operator providers or cluster administrators to enable binding custom service resources to workloads. To grant the required permissions within a <literal>ClusterRole</literal>, label it with the <literal>servicebinding.io/controller</literal> flag and set the flag value to <literal>true</literal>. The following example shows how to allow the Service Binding Operator to <literal>get</literal>, <literal>watch</literal>, and <literal>list</literal> the custom resources (CRs) of Crunchy PostgreSQL Operator:</simpara>
<formalpara>
<title>Example: Enable binding to PostgreSQL database instances provisioned by Crunchy PostgreSQL Operator</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: postgrescluster-reader
  labels:
     servicebinding.io/controller: "true"
rules:
- apiGroups:
    - postgres-operator.crunchydata.com
  resources:
    - postgresclusters
  verbs:
    - get
    - watch
    - list
  ...</programlisting>
</para>
</formalpara>
<simpara>This cluster role can be deployed during the installation of the backing service Operator.</simpara>
</section>
<section xml:id="sbo-categories-of-exposable-binding-data_exposing-binding-data-from-a-service">
<title>Categories of exposable binding data</title>
<simpara role="_abstract">The Service Binding Operator enables you to expose the binding data values from the backing service resources and custom resource definitions (CRDs).</simpara>
<simpara>This section provides examples to show how you can use the various categories of exposable binding data. You must modify these examples to suit your work environment and requirements.</simpara>
<section xml:id="exposing-a-string-from-a-resource_exposing-binding-data-from-a-service">
<title>Exposing a string from a resource</title>
<simpara>The following example shows how to expose the string from the <literal>metadata.name</literal> field of the <literal>PostgresCluster</literal> custom resource (CR) as a username:</simpara>
<formalpara>
<title>Example</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: postgres-operator.crunchydata.com/v1beta1
kind: PostgresCluster
metadata:
  name: hippo
  namespace: my-petclinic
  annotations:
    service.binding/username: path={.metadata.name}
    ...</programlisting>
</para>
</formalpara>
</section>
<section xml:id="exposing-a-constant-value-as-the-binding-item_exposing-binding-data-from-a-service">
<title>Exposing a constant value as the binding item</title>
<simpara>The following examples show how to expose a constant value from the <literal>PostgresCluster</literal> custom resource (CR):</simpara>
<formalpara>
<title>Example: Exposing a constant value</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: postgres-operator.crunchydata.com/v1beta1
kind: PostgresCluster
metadata:
  name: hippo
  namespace: my-petclinic
  annotations:
    "service.binding/type": "postgresql" <co xml:id="CO4-1"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO4-1">
<para>Binding <literal>type</literal> to be exposed with the <literal>postgresql</literal> value.</para>
</callout>
</calloutlist>
</section>
<section xml:id="exposing-an-entire-config-map-or-secret-that-is-referenced-from-a-resource_exposing-binding-data-from-a-service">
<title>Exposing an entire config map or secret that is referenced from a resource</title>
<simpara>The following examples show how to expose an entire secret through annotations:</simpara>
<formalpara>
<title>Example: Exposing an entire secret through annotations</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: postgres-operator.crunchydata.com/v1beta1
kind: PostgresCluster
metadata:
  name: hippo
  namespace: my-petclinic
  annotations:
    service.binding: 'path={.metadata.name}-pguser-{.metadata.name},objectType=Secret'</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example: The referenced secret from the backing service resource</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Secret
metadata:
  name: hippo-pguser-hippo
data:
  password: "&lt;password&gt;"
  user: "&lt;username&gt;"</programlisting>
</para>
</formalpara>
</section>
<section xml:id="exposing-a-specific-entry-from-a-config-map-or-secret-that-is-referenced-from-a-resource_exposing-binding-data-from-a-service">
<title>Exposing a specific entry from a config map or secret that is referenced from a resource</title>
<simpara>The following examples show how to expose a specific entry from a config map through annotations:</simpara>
<formalpara>
<title>Example: Exposing an entry from a config map through annotations</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: postgres-operator.crunchydata.com/v1beta1
kind: PostgresCluster
metadata:
  name: hippo
  namespace: my-petclinic
  annotations:
    service.binding: 'path={.metadata.name}-config,objectType=ConfigMap,sourceKey=user'</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example: The referenced config map from the backing service resource</title>
<para>The binding data should have a key with name as <literal>db_timeout</literal> and value as <literal>10s</literal>:</para>
</formalpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: ConfigMap
metadata:
  name: hippo-config
data:
  db_timeout: "10s"
  user: "hippo"</programlisting>
</section>
<section xml:id="exposing-a-resource-definition-value_exposing-binding-data-from-a-service">
<title>Exposing a resource definition value</title>
<simpara>The following example shows how to expose a resource definition value through annotations:</simpara>
<formalpara>
<title>Example: Exposing a resource definition value through annotations</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: postgres-operator.crunchydata.com/v1beta1
kind: PostgresCluster
metadata:
  name: hippo
  namespace: my-petclinic
  annotations:
    service.binding/username: path={.metadata.name}
    ...</programlisting>
</para>
</formalpara>
</section>
<section xml:id="exposing-entries-of-a-collection-with-the-key-and-value-from-each-entry_exposing-binding-data-from-a-service">
<title>Exposing entries of a collection with the key and value from each entry</title>
<simpara>The following example shows how to expose the entries of a collection with the key and value from each entry through annotations:</simpara>
<formalpara>
<title>Example: Exposing the entries of a collection through annotations</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: postgres-operator.crunchydata.com/v1beta1
kind: PostgresCluster
metadata:
  name: hippo
  namespace: my-petclinic
  annotations:
    "service.binding/uri": "path={.status.connections},elementType=sliceOfMaps,sourceKey=type,sourceValue=url"
spec:
  ...
status:
  connections:
    - type: primary
      url: primary.example.com
    - type: secondary
      url: secondary.example.com
    - type: '404'
      url: black-hole.example.com</programlisting>
</para>
</formalpara>
<simpara>The following example shows how the previous entries of a collection in annotations are projected into the bound application.</simpara>
<formalpara>
<title>Example: Binding data files</title>
<para>
<programlisting language="text" linenumbering="unnumbered">/bindings/&lt;binding-name&gt;/uri_primary =&gt; primary.example.com
/bindings/&lt;binding-name&gt;/uri_secondary =&gt; secondary.example.com
/bindings/&lt;binding-name&gt;/uri_404 =&gt; black-hole.example.com</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example: Configuration from a backing service resource</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">status:
  connections:
    - type: primary
      url: primary.example.com
    - type: secondary
      url: secondary.example.com
    - type: '404'
      url: black-hole.example.com</programlisting>
</para>
</formalpara>
<simpara>The previous example helps you to project all those values with keys such as <literal>primary</literal>,
<literal>secondary</literal>, and so on.</simpara>
</section>
<section xml:id="exposing-items-of-a-collection-with-one-key-per-item_exposing-binding-data-from-a-service">
<title>Exposing items of a collection with one key per item</title>
<simpara>The following example shows how to expose the items of a collection with one key per item through annotations:</simpara>
<formalpara>
<title>Example: Exposing the items of a collection through annotations</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: postgres-operator.crunchydata.com/v1beta1
kind: PostgresCluster
metadata:
  name: hippo
  namespace: my-petclinic
  annotations:
    "service.binding/tags": "path={.spec.tags},elementType=sliceOfStrings"
spec:
    tags:
      - knowledge
      - is
      - power</programlisting>
</para>
</formalpara>
<simpara>The following example shows how the previous items of a collection in annotations are projected into the bound application.</simpara>
<formalpara>
<title>Example: Binding data files</title>
<para>
<programlisting language="text" linenumbering="unnumbered">/bindings/&lt;binding-name&gt;/tags_0 =&gt; knowledge
/bindings/&lt;binding-name&gt;/tags_1 =&gt; is
/bindings/&lt;binding-name&gt;/tags_2 =&gt; power</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example: Configuration from a backing service resource</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">spec:
  tags:
  - knowledge
  - is
  - power</programlisting>
</para>
</formalpara>
</section>
<section xml:id="exposing-values-of-collection-entries-with-one-key-per-entry-value_exposing-binding-data-from-a-service">
<title>Exposing values of collection entries with one key per entry value</title>
<simpara>The following example shows how to expose the values of collection entries with one key per entry value through annotations:</simpara>
<formalpara>
<title>Example: Exposing the values of collection entries through annotations</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: postgres-operator.crunchydata.com/v1beta1
kind: PostgresCluster
metadata:
  name: hippo
  namespace: my-petclinic
  annotations:
    "service.binding/url": "path={.spec.connections},elementType=sliceOfStrings,sourceValue=url"
spec:
  connections:
    - type: primary
      url: primary.example.com
    - type: secondary
      url: secondary.example.com
    - type: '404'
      url: black-hole.example.com</programlisting>
</para>
</formalpara>
<simpara>The following example shows how the previous values of a collection in annotations are projected into the bound application.</simpara>
<formalpara>
<title>Example: Binding data files</title>
<para>
<programlisting language="text" linenumbering="unnumbered">/bindings/&lt;binding-name&gt;/url_0 =&gt; primary.example.com
/bindings/&lt;binding-name&gt;/url_1 =&gt; secondary.example.com
/bindings/&lt;binding-name&gt;/url_2 =&gt; black-hole.example.com</programlisting>
</para>
</formalpara>
</section>
</section>
<section xml:id="additional-resources_exposing-binding-data" role="_additional-resources">
<title>Additional resources</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/operators/#osdk-generating-csvs">Defining cluster service versions (CSVs)</link>.</simpara>
</listitem>
<listitem>
<simpara><link linkend="projecting-binding-data">Projecting binding data</link>.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="projecting-binding-data">
<title>Projecting binding data</title>
<simpara role="_abstract">This section provides information on how you can consume the binding data.</simpara>
<section xml:id="_consumption-of-binding-data">
<title>Consumption of binding data</title>
<simpara>After the backing service exposes the binding data, for a workload to access and consume this data, you must project it into the workload from a backing service. Service Binding Operator automatically projects this set of data into the workload in the following methods:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>By default, as files.</simpara>
</listitem>
<listitem>
<simpara>As environment variables, after you configure the <literal>.spec.bindAsFiles</literal> parameter from the <literal>ServiceBinding</literal> resource.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="sbo-configuration-of-directory-path-to-project-binding-data_projecting-binding-data">
<title>Configuration of the directory path to project the binding data inside workload container</title>
<simpara>By default, Service Binding Operator mounts the binding data as files at a specific directory in your workload resource. You can configure the directory path using the <literal>SERVICE_BINDING_ROOT</literal> environment variable setup in the container where your workload runs.</simpara>
<formalpara>
<title>Example: Binding data mounted as files</title>
<para>
<screen>$SERVICE_BINDING_ROOT <co xml:id="CO5-1"/>
├── account-database <co xml:id="CO5-2"/>
│   ├── type <co xml:id="CO5-3"/>
│   ├── provider <co xml:id="CO5-4"/>
│   ├── uri
│   ├── username
│   └── password
└── transaction-event-stream <co xml:id="CO5-5"/>
    ├── type
    ├── connection-count
    ├── uri
    ├── certificates
    └── private-key</screen>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO5-1">
<para>Root directory.</para>
</callout>
<callout arearefs="CO5-2 CO5-5">
<para>Directory that stores the binding data.</para>
</callout>
<callout arearefs="CO5-3">
<para>Mandatory identifier that identifies the type of the binding data projected into the corresponding directory.</para>
</callout>
<callout arearefs="CO5-4">
<para>Optional: Identifier to identify the provider so that the application can identify the type of backing service it can connect to.</para>
</callout>
</calloutlist>
<simpara>To consume the binding data as environment variables, use the built-in language feature of your programming language of choice that can read environment variables.</simpara>
<formalpara>
<title>Example: Python client usage</title>
<para>
<screen>import os
username = os.getenv("USERNAME")
password = os.getenv("PASSWORD")</screen>
</para>
</formalpara>
<warning>
<formalpara>
<title>For using the binding data directory name to look up the binding data</title>
<para>Service Binding Operator uses the <literal>ServiceBinding</literal> resource name (<literal>.metadata.name</literal>) as the binding data directory name. The spec also provides a way to override that name through the <literal>.spec.name</literal> field. As a result, there is a chance for binding data name collision if there are multiple <literal>ServiceBinding</literal> resources in the namespace. However, due to the nature of the volume mount in Kubernetes, the binding data directory will contain values from only one of the <literal>Secret</literal> resources.</para>
</formalpara>
</warning>
<section xml:id="computation-of-the-final-path-for-projecting-the-binding-data-as-files_projecting-binding-data">
<title>Computation of the final path for projecting the binding data as files</title>
<simpara>The following table summarizes the configuration of how the final path for the binding data projection is computed when files are mounted at a specific directory:</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Summary of the final path computation</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top"><literal>SERVICE_BINDING_ROOT</literal></entry>
<entry align="left" valign="top">Final path</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Not available</simpara></entry>
<entry align="left" valign="top"><simpara><literal>/bindings/&lt;ServiceBinding_ResourceName&gt;</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>dir/path/root</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>dir/path/root/&lt;ServiceBinding_ResourceName&gt;</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>In the previous table, the <literal>&lt;ServiceBinding_ResourceName&gt;</literal> entry specifies the name of the <literal>ServiceBinding</literal> resource that you configure in the <literal>.metadata.name</literal> section of the custom resource (CR).</simpara>
<note>
<simpara>By default, the projected files get their permissions set to 0644.  Service Binding Operator cannot set specific permissions due to a bug in Kubernetes that causes issues if the service expects specific permissions such as <literal>0600</literal>.  As a workaround, you can modify the code of the program or the application that is running inside a workload resource to copy the file to the <literal>/tmp</literal> directory and set the appropriate permissions.</simpara>
</note>
<simpara>To access and consume the binding data within the existing <literal>SERVICE_BINDING_ROOT</literal> environment variable, use the built-in language feature of your programming language of choice that can read environment variables.</simpara>
<formalpara>
<title>Example: Python client usage</title>
<para>
<screen>from pyservicebinding import binding
try:
    sb = binding.ServiceBinding()
except binding.ServiceBindingRootMissingError as msg:
    # log the error message and retry/exit
    print("SERVICE_BINDING_ROOT env var not set")
sb = binding.ServiceBinding()
bindings_list = sb.bindings("postgresql")</screen>
</para>
</formalpara>
<simpara>In the previous example, the <literal>bindings_list</literal> variable contains the binding data for the <literal>postgresql</literal> database service type.</simpara>
</section>
</section>
<section xml:id="sbo-projecting-the-binding-data_projecting-binding-data">
<title>Projecting the binding data</title>
<simpara>Depending on your workload requirements and environment, you can choose to project the binding data either as files or environment variables.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You understand the following concepts:</simpara>
<itemizedlist>
<listitem>
<simpara>Environment and requirements of your workload, and how it works with the provided services.</simpara>
</listitem>
<listitem>
<simpara>Consumption of the binding data in your workload resource.</simpara>
</listitem>
<listitem>
<simpara>Configuration of how the final path for data projection is computed for the default method.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>The binding data is exposed from the backing service.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To project the binding data as files, determine the destination folder by ensuring that the existing <literal>SERVICE_BINDING_ROOT</literal> environment variable is present in the container where your workload runs.</simpara>
</listitem>
<listitem>
<simpara>To project the binding data as environment variables, set the value for the <literal>.spec.bindAsFiles</literal> parameter to <literal>false</literal> from the <literal>ServiceBinding</literal> resource in the custom resource (CR).</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="additional-resources_projecting-binding-data-sbo" role="_additional-resources">
<title>Additional resources</title>
<itemizedlist>
<listitem>
<simpara><link linkend="exposing-binding-data-from-a-service">Exposing binding data from a service</link>.</simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://redhat-developer.github.io/service-binding-operator/userguide/using-projected-bindings/using-projected-bindings.html">Using the projected binding data in the source code of the application</link>.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="binding-workloads-using-sbo">
<title>Binding workloads using Service Binding Operator</title>
<simpara>Application developers must bind a workload to one or more backing services by using a binding secret. This secret is generated for the purpose of storing information to be consumed by the workload.</simpara>
<simpara>As an example, consider that the service you want to connect to is already exposing the binding data. In this case, you would also need a workload to be used along with the <literal>ServiceBinding</literal> custom resource (CR). By using this <literal>ServiceBinding</literal> CR, the workload sends a binding request with the details of the services to bind with.</simpara>
<formalpara>
<title>Example of <literal>ServiceBinding</literal> CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: binding.operators.coreos.com/v1alpha1
kind: ServiceBinding
metadata:
    name: spring-petclinic-pgcluster
    namespace: my-petclinic
spec:
    services: <co xml:id="CO6-1"/>
    - group: postgres-operator.crunchydata.com
      version: v1beta1
      kind: PostgresCluster
      name: hippo
    application: <co xml:id="CO6-2"/>
      name: spring-petclinic
      group: apps
      version: v1
      resource: deployments</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO6-1">
<para>Specifies a list of service resources.</para>
</callout>
<callout arearefs="CO6-2">
<para>The sample application that points to a Deployment or any other similar resource with an embedded PodSpec.</para>
</callout>
</calloutlist>
<simpara>As shown in the previous example, you can also directly use a <literal>ConfigMap</literal> or a <literal>Secret</literal> itself as a service resource to be used as a source of binding data.</simpara>
<section xml:id="sbo-naming-strategies_binding-workloads-using-sbo">
<title>Naming strategies</title>
<simpara role="_abstract">Naming strategies are available only for the <literal>binding.operators.coreos.com</literal> API group.</simpara>
<simpara>Naming strategies use Go templates to help you define custom binding names through the service binding request. Naming strategies apply for all attributes including the mappings in the <literal>ServiceBinding</literal> custom resource (CR).</simpara>
<simpara>A backing service projects the binding names as files or environment variables into the workload. If a workload expects the projected binding names in a particular format, but the binding names to be projected from the backing service are not available in that format, then you can change the binding names using naming strategies.</simpara>
<formalpara>
<title>Predefined post-processing functions</title>
<para>While using naming strategies, depending on the expectations or requirements of your workload, you can use the following predefined post-processing functions in any combination to convert the character strings:</para>
</formalpara>
<itemizedlist>
<listitem>
<simpara><literal>upper</literal>: Converts the character strings into capital or uppercase letters.</simpara>
</listitem>
<listitem>
<simpara><literal>lower</literal>: Converts the character strings into lowercase letters.</simpara>
</listitem>
<listitem>
<simpara><literal>title</literal>: Converts the character strings where the first letter of each word is capitalized except for certain minor words.</simpara>
</listitem>
</itemizedlist>
<formalpara>
<title>Predefined naming strategies</title>
<para>Binding names declared through annotations are processed for their name change before their projection into the workload according to the following predefined naming strategies:</para>
</formalpara>
<itemizedlist>
<listitem>
<simpara><literal>none</literal>: When applied, there are no changes in the binding names.</simpara>
<formalpara>
<title>Example</title>
<para>After the template compilation, the binding names take the <literal>{{ .name }}</literal> form.</para>
</formalpara>
<programlisting language="yaml" linenumbering="unnumbered">host: hippo-pgbouncer
port: 5432</programlisting>
</listitem>
<listitem>
<simpara><literal>upper</literal>: Applied when no <literal>namingStrategy</literal> is defined. When applied, converts all the character strings of the binding name key into capital or uppercase letters.</simpara>
<formalpara>
<title>Example</title>
<para>After the template compilation, the binding names take the <literal>{{ .service.kind | upper}}_{{ .name | upper }}</literal> form.</para>
</formalpara>
<programlisting language="yaml" linenumbering="unnumbered">DATABASE_HOST: hippo-pgbouncer
DATABASE_PORT: 5432</programlisting>
<simpara>If your workload requires a different format, you can define a custom naming strategy and change the binding name using a prefix and a separator, for example, <literal>PORT_DATABASE</literal>.</simpara>
</listitem>
</itemizedlist>
<note>
<itemizedlist>
<listitem>
<simpara>When the binding names are projected as files, by default the predefined <literal>none</literal> naming strategy is applied, and the binding names do not change.</simpara>
</listitem>
<listitem>
<simpara>When the binding names are projected as environment variables and no <literal>namingStrategy</literal> is defined, by default the predefined <literal>uppercase</literal> naming strategy is applied.</simpara>
</listitem>
<listitem>
<simpara>You can override the predefined naming strategies by defining custom naming strategies using different combinations of custom binding names and predefined post-processing functions.</simpara>
</listitem>
</itemizedlist>
</note>
</section>
<section xml:id="sbo-advanced-binding-options_binding-workloads-using-sbo">
<title>Advanced binding options</title>
<simpara>You can define the <literal>ServiceBinding</literal> custom resource (CR) to use the following advanced binding options:</simpara>
<itemizedlist>
<listitem>
<simpara>Changing binding names: This option is available only for the <literal>binding.operators.coreos.com</literal> API group.</simpara>
</listitem>
<listitem>
<simpara>Composing custom binding data: This option is available only for the <literal>binding.operators.coreos.com</literal> API group.</simpara>
</listitem>
<listitem>
<simpara>Binding workloads using label selectors: This option is available for both the <literal>binding.operators.coreos.com</literal> and <literal>servicebinding.io</literal> API groups.</simpara>
</listitem>
</itemizedlist>
<section xml:id="changing-binding-names_binding-workloads-using-sbo">
<title>Changing the binding names before projecting them into the workload</title>
<simpara>You can specify the rules to change the binding names in the <literal>.spec.namingStrategy</literal> attribute of the <literal>ServiceBinding</literal> CR. For example, consider a Spring PetClinic sample application that connects to the PostgreSQL database. In this case, the PostgreSQL database service exposes the <literal>host</literal> and <literal>port</literal> fields of the database to use for binding. The Spring PetClinic sample application can access this exposed binding data through the binding names.</simpara>
<formalpara>
<title>Example: Spring PetClinic sample application in the <literal>ServiceBinding</literal> CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">...
    application:
      name: spring-petclinic
      group: apps
      version: v1
      resource: deployments
...</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example: PostgreSQL database service in the <literal>ServiceBinding</literal> CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">...
    services:
    - group: postgres-operator.crunchydata.com
      version: v1beta1
      kind: PostgresCluster
      name: hippo
...</programlisting>
</para>
</formalpara>
<simpara>If <literal>namingStrategy</literal> is not defined and the binding names are projected as environment variables, then the <literal>host: hippo-pgbouncer</literal> value in the backing service and the projected environment variable would appear as shown in the following example:</simpara>
<formalpara>
<title>Example</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">DATABASE_HOST: hippo-pgbouncer</programlisting>
</para>
</formalpara>
<simpara>where:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara><literal>DATABASE</literal></simpara>
</entry>
<entry>
<simpara>Specifies the <literal>kind</literal> backend service.</simpara>
</entry>
</row>
<row>
<entry>
<simpara><literal>HOST</literal></simpara>
</entry>
<entry>
<simpara>Specifies the binding name.</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>After applying the <literal>POSTGRESQL_{{ .service.kind | upper }}_{{ .name | upper }}_ENV</literal> naming strategy, the  list of custom binding names prepared by the service binding request appears as shown in the following example:</simpara>
<formalpara>
<title>Example</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">POSTGRESQL_DATABASE_HOST_ENV: hippo-pgbouncer
POSTGRESQL_DATABASE_PORT_ENV: 5432</programlisting>
</para>
</formalpara>
<simpara>The following items describe the expressions defined in the <literal>POSTGRESQL_{{ .service.kind | upper }}_{{ .name | upper }}_ENV</literal> naming strategy:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>.name</literal>: Refers to the binding name exposed by the backing service. In the previous example, the binding names are <literal>HOST</literal> and <literal>PORT</literal>.</simpara>
</listitem>
<listitem>
<simpara><literal>.service.kind</literal>: Refers to the kind of service resource whose binding names are changed with the naming strategy.</simpara>
</listitem>
<listitem>
<simpara><literal>upper</literal>: String function used to post-process the character string while compiling the Go template string.</simpara>
</listitem>
<listitem>
<simpara><literal>POSTGRESQL</literal>: Prefix of the custom binding name.</simpara>
</listitem>
<listitem>
<simpara><literal>ENV</literal>: Suffix of the custom binding name.</simpara>
</listitem>
</itemizedlist>
<simpara>Similar to the previous example, you can define the string templates in <literal>namingStrategy</literal> to define how each key of the binding names should be prepared by the service binding request.</simpara>
</section>
<section xml:id="composing-custom-binding-data_binding-workloads-using-sbo">
<title>Composing custom binding data</title>
<simpara>As an application developer, you can compose custom binding data under the following circumstances:</simpara>
<itemizedlist>
<listitem>
<simpara>The backing service does not expose binding data.</simpara>
</listitem>
<listitem>
<simpara>The values exposed are not available in the required format as expected by the workload.</simpara>
</listitem>
</itemizedlist>
<simpara>For example, consider a case where the backing service CR exposes the host, port, and database user as binding data, but the workload requires that the binding data be consumed as a connection string.
You can compose custom binding data using attributes in the Kubernetes resource representing the backing service.</simpara>
<formalpara>
<title>Example</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: binding.operators.coreos.com/v1alpha1
kind: ServiceBinding
metadata:
    name: spring-petclinic-pgcluster
    namespace: my-petclinic
spec:
    services:
    - group: postgres-operator.crunchydata.com
      version: v1beta1
      kind: PostgresCluster
      name: hippo <co xml:id="CO7-1"/>
      id: postgresDB <co xml:id="CO7-2"/>
    - group: ""
      version: v1
      kind: Secret
      name: hippo-pguser-hippo
      id: postgresSecret
    application:
      name: spring-petclinic
      group: apps
      version: v1
      resource: deployments
    mappings:
      ## From the database service
      - name: JDBC_URL
        value: 'jdbc:postgresql://{{ .postgresDB.metadata.annotations.proxy }}:{{ .postgresDB.spec.port }}/{{ .postgresDB.metadata.name }}'
      ## From both the services!
      - name: CREDENTIALS
        value: '{{ .postgresDB.metadata.name }}{{ translationService.postgresSecret.data.password }}'
      ## Generate JSON
      - name: DB_JSON <co xml:id="CO7-3"/>
        value: {{ json .postgresDB.status }} <co xml:id="CO7-4"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO7-1">
<para>Name of the backing service resource.</para>
</callout>
<callout arearefs="CO7-2">
<para>Optional identifier.</para>
</callout>
<callout arearefs="CO7-3">
<para>The JSON name that the Service Binding Operator generates. The Service Binding Operator projects this JSON name as the name of a file or environment variable.</para>
</callout>
<callout arearefs="CO7-4">
<para>The JSON value that the Service Binding Operator generates. The Service Binding Operator projects this JSON value as a file or environment variable. The JSON value contains the attributes from your specified field of the backing service custom resource.</para>
</callout>
</calloutlist>
</section>
<section xml:id="binding-workloads-using-a-label-selector_binding-workloads-using-sbo">
<title>Binding workloads using a label selector</title>
<simpara>You can use a label selector to specify the workload to bind. If you declare a service binding using the label selectors to pick up workloads, the Service Binding Operator periodically attempts to find and bind new workloads that match the given label selector.</simpara>
<simpara>For example, as a cluster administrator, you can bind a service to every <literal>Deployment</literal> in a namespace with the <literal>environment: production</literal> label by setting an appropriate <literal>labelSelector</literal> field in the <literal>ServiceBinding</literal> CR. This enables the Service Binding Operator to bind each of these workloads with one <literal>ServiceBinding</literal> CR.</simpara>
<formalpara>
<title>Example <literal>ServiceBinding</literal> CR in the <literal>binding.operators.coreos.com/v1alpha1</literal> API</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: binding.operators.coreos.com/v1alpha1
kind: ServiceBinding
metadata:
  name: multi-application-binding
  namespace: service-binding-demo
spec:
  application:
    labelSelector: <co xml:id="CO8-1"/>
      matchLabels:
        environment: production
    group: apps
    version: v1
    resource: deployments
  services:
    group: ""
    version: v1
    kind: Secret
    name: super-secret-data</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO8-1">
<para>Specifies the workload that is being bound.</para>
</callout>
</calloutlist>
<formalpara>
<title>Example <literal>ServiceBinding</literal> CR in the <literal>servicebinding.io</literal> API</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: servicebindings.io/v1beta1
kind: ServiceBinding
metadata:
  name: multi-application-binding
  namespace: service-binding-demo
spec:
  workload:
    selector: <co xml:id="CO9-1"/>
      matchLabels:
        environment: production
    apiVersion: app/v1
    kind: Deployment
  service:
    apiVersion: v1
    kind: Secret
    name: super-secret-data</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO9-1">
<para>Specifies the workload that is being bound.</para>
</callout>
</calloutlist>
<important>
<simpara>If you define the following pairs of fields, Service Binding Operator refuses the binding operation and generates an error:</simpara>
<itemizedlist>
<listitem>
<simpara>The <literal>name</literal> and <literal>labelSelector</literal> fields in the <literal>binding.operators.coreos.com/v1alpha1</literal> API.</simpara>
</listitem>
<listitem>
<simpara>The <literal>name</literal> and <literal>selector</literal> fields in the <literal>servicebinding.io</literal> API (Spec API).</simpara>
</listitem>
</itemizedlist>
</important>
<formalpara>
<title>Understanding the rebinding behavior</title>
<para>Consider a case where, after a successful binding, you use the <literal>name</literal> field to identify a workload. If you delete and recreate that workload, the <literal>ServiceBinding</literal> reconciler does not rebind the workload, and the Operator cannot project the binding data to the workload. However, if you use the <literal>labelSelector</literal> field to identify a workload, the <literal>ServiceBinding</literal> reconciler rebinds the workload, and the Operator projects the binding data.</para>
</formalpara>
</section>
</section>
<section xml:id="sbo-binding-workloads-that-are-not-compliant-with-PodSpec_binding-workloads-using-sbo">
<title>Binding secondary workloads that are not compliant with PodSpec</title>
<simpara>A typical scenario in service binding involves configuring the backing service, the workload (Deployment), and Service Binding Operator. Consider a scenario that involves a secondary workload (which can also be an application Operator) that is not compliant with PodSpec and is between the primary workload (Deployment) and Service Binding Operator.</simpara>
<simpara>For such secondary workload resources, the location of the container path is arbitrary. For service binding, if the secondary workload in a CR is not compliant with the PodSpec, you must specify the location of the container path. Doing so projects the binding data into the container path specified in the secondary workload of the <literal>ServiceBinding</literal> custom resource (CR), for example, when you do not want the binding data inside a pod.</simpara>
<simpara>In Service Binding Operator, you can configure the path of where containers or secrets reside within a workload and bind these paths at a custom location.</simpara>
<section xml:id="configuring-custom-location-of-container-path_binding-workloads-using-sbo">
<title>Configuring the custom location of the container path</title>
<simpara>This custom location is available for the <literal>binding.operators.coreos.com</literal> API group when Service Binding Operator projects the binding data as environment variables.</simpara>
<simpara>Consider a secondary workload CR, which is not compliant with the PodSpec and has containers located at the <literal>spec.containers</literal> path:</simpara>
<formalpara>
<title>Example: Secondary workload CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: "operator.sbo.com/v1"
kind: SecondaryWorkload
metadata:
    name: secondary-workload
spec:
    containers:
    - name: hello-world
      image: quay.io/baijum/secondary-workload:latest
      ports:
      - containerPort: 8080</programlisting>
</para>
</formalpara>
<itemizedlist mark="discrete">
<title>Procedure</title>
<listitem>
<simpara>Configure the <literal>spec.containers</literal> path by specifying a value in the <literal>ServiceBinding</literal> CR and bind this path to a <literal>spec.application.bindingPath.containersPath</literal> custom location:</simpara>
<formalpara>
<title>Example: <literal>ServiceBinding</literal> CR with the <literal>spec.containers</literal> path in a custom location</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: binding.operators.coreos.com/v1alpha1
kind: ServiceBinding
metadata:
    name: spring-petclinic-pgcluster
spec:
    services:
    - group: postgres-operator.crunchydata.com
      version: v1beta1
      kind: PostgresCluster
      name: hippo
      id: postgresDB
    - group: ""
      version: v1
      kind: Secret
      name: hippo-pguser-hippo
      id: postgresSecret
    application: <co xml:id="CO10-1"/>
      name: spring-petclinic
      group: apps
      version: v1
      resource: deployments
    application: <co xml:id="CO10-2"/>
      name: secondary-workload
      group: operator.sbo.com
      version: v1
      resource: secondaryworkloads
      bindingPath:
        containersPath: spec.containers <co xml:id="CO10-3"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO10-1">
<para>The sample application that points to a Deployment or any other similar resource with an embedded PodSpec.</para>
</callout>
<callout arearefs="CO10-2">
<para>The secondary workload, which is not compliant with the PodSpec.</para>
</callout>
<callout arearefs="CO10-3">
<para>The custom location of the container path.</para>
</callout>
</calloutlist>
</listitem>
</itemizedlist>
<simpara>After you specify the location of the container path, Service Binding Operator generates the binding data, which becomes available in the container path specified in the secondary workload of the <literal>ServiceBinding</literal> CR.</simpara>
<simpara>The following example shows the <literal>spec.containers</literal> path with the <literal>envFrom</literal> and <literal>secretRef</literal> fields:</simpara>
<formalpara>
<title>Example: Secondary workload CR with the <literal>envFrom</literal> and <literal>secretRef</literal> fields</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: "operator.sbo.com/v1"
kind: SecondaryWorkload
metadata:
    name: secondary-workload
spec:
    containers:
    - env: <co xml:id="CO11-1"/>
      - name: ServiceBindingOperatorChangeTriggerEnvVar
        value: "31793"
      envFrom:
      - secretRef:
          name: secret-resource-name <co xml:id="CO11-2"/>
      image: quay.io/baijum/secondary-workload:latest
      name: hello-world
      ports:
      - containerPort: 8080
      resources: {}</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO11-1">
<para>Unique array of containers with values generated by the Service Binding Operator. These values are based on the backing service CR.</para>
</callout>
<callout arearefs="CO11-2">
<para>Name of the <literal>Secret</literal> resource generated by the Service Binding Operator.</para>
</callout>
</calloutlist>
</section>
<section xml:id="configuring-custom-location-of-secret-path_binding-workloads-using-sbo">
<title>Configuring the custom location of the secret path</title>
<simpara>This custom location is available for the <literal>binding.operators.coreos.com</literal> API group when Service Binding Operator projects the binding data as environment variables.</simpara>
<simpara>Consider a secondary workload CR, which is not compliant with the PodSpec, with only the secret at the <literal>spec.secret</literal> path:</simpara>
<formalpara>
<title>Example: Secondary workload CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: "operator.sbo.com/v1"
kind: SecondaryWorkload
metadata:
    name: secondary-workload
spec:
    secret: ""</programlisting>
</para>
</formalpara>
<itemizedlist mark="discrete">
<title>Procedure</title>
<listitem>
<simpara>Configure the <literal>spec.secret</literal> path by specifying a value in the <literal>ServiceBinding</literal> CR and bind this path at a <literal>spec.application.bindingPath.secretPath</literal> custom location:</simpara>
<formalpara>
<title>Example: <literal>ServiceBinding</literal> CR with the <literal>spec.secret</literal> path in a custom location</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: binding.operators.coreos.com/v1alpha1
kind: ServiceBinding
metadata:
    name: spring-petclinic-pgcluster
spec:
...
    application: <co xml:id="CO12-1"/>
      name: secondary-workload
      group: operator.sbo.com
      version: v1
      resource: secondaryworkloads
      bindingPath:
        secretPath: spec.secret <co xml:id="CO12-2"/>
...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO12-1">
<para>The secondary workload, which is not compliant with the PodSpec.</para>
</callout>
<callout arearefs="CO12-2">
<para>The custom location of the secret path that contains the name of the <literal>Secret</literal> resource.</para>
</callout>
</calloutlist>
</listitem>
</itemizedlist>
<simpara>After you specify the location of the secret path, Service Binding Operator generates the binding data, which becomes available in the secret path specified in the secondary workload of the <literal>ServiceBinding</literal> CR.</simpara>
<simpara>The following example shows the <literal>spec.secret</literal> path with the <literal>binding-request</literal> value:</simpara>
<formalpara>
<title>Example: Secondary workload CR with the <literal>binding-request</literal> value</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">...
apiVersion: "operator.sbo.com/v1"
kind: SecondaryWorkload
metadata:
    name: secondary-workload
spec:
    secret: binding-request-72ddc0c540ab3a290e138726940591debf14c581 <co xml:id="CO13-1"/>
...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO13-1">
<para>The unique name of the <literal>Secret</literal> resource that Service Binding Operator generates.</para>
</callout>
</calloutlist>
</section>
<section xml:id="workload-resource-mapping_binding-workloads-using-sbo">
<title>Workload resource mapping</title>
<note>
<itemizedlist>
<listitem>
<simpara>Workload resource mapping is available for the secondary workloads of the <literal>ServiceBinding</literal> custom resource (CR) for both the API groups: <literal>binding.operators.coreos.com</literal> and <literal>servicebinding.io</literal>.</simpara>
</listitem>
<listitem>
<simpara>You must define <literal>ClusterWorkloadResourceMapping</literal> resources only under the <literal>servicebinding.io</literal> API group. However, the <literal>ClusterWorkloadResourceMapping</literal> resources interact with <literal>ServiceBinding</literal> resources under both the <literal>binding.operators.coreos.com</literal> and <literal>servicebinding.io</literal> API groups.</simpara>
</listitem>
</itemizedlist>
</note>
<simpara>If you cannot configure custom path locations by using the configuration method for container path, you can define exactly where binding data needs to be projected. Specify where to project the binding data for a given workload kind by defining the <literal>ClusterWorkloadResourceMapping</literal> resources in the <literal>servicebinding.io</literal> API group.</simpara>
<simpara>The following example shows how to define a mapping for the <literal>CronJob.batch/v1</literal> resources.</simpara>
<formalpara>
<title>Example: Mapping for <literal>CronJob.batch/v1</literal> resources</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: servicebinding.io/v1beta1
kind: ClusterWorkloadResourceMapping
metadata:
 name: cronjobs.batch <co xml:id="CO14-1"/>
spec:
  versions:
  - version: "v1" <co xml:id="CO14-2"/>
    annotations: .spec.jobTemplate.spec.template.metadata.annotations <co xml:id="CO14-3"/>
    containers:
    - path: .spec.jobTemplate.spec.template.spec.containers[*] <co xml:id="CO14-4"/>
    - path: .spec.jobTemplate.spec.template.spec.initContainers[*]
      name: .name <co xml:id="CO14-5"/>
      env: .env <co xml:id="CO14-6"/>
      volumeMounts: .volumeMounts <co xml:id="CO14-7"/>
    volumes: .spec.jobTemplate.spec.template.spec.volumes <co xml:id="CO14-8"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO14-1">
<para>Name of the <literal>ClusterWorkloadResourceMapping</literal> resource, which must be qualified as the <literal>plural.group</literal> of the mapped workload resource.</para>
</callout>
<callout arearefs="CO14-2">
<para>Version of the resource that is being mapped.  Any version that is not specified can be matched with the "*" wildcard.</para>
</callout>
<callout arearefs="CO14-3">
<para>Optional: Identifier of the <literal>.annotations</literal> field in a pod, specified with a fixed JSONPath.  The default value is <literal>.spec.template.spec.annotations</literal>.</para>
</callout>
<callout arearefs="CO14-4">
<para>Identifier of the <literal>.containers</literal> and <literal>.initContainers</literal> fields in a pod, specified with a JSONPath. If no entries under the <literal>containers</literal> field are defined, the Service Binding Operator defaults to two paths: <literal>.spec.template.spec.containers[*]</literal> and <literal>.spec.template.spec.initContainers[\*]</literal>, with all other fields set as their default. However, if you specify an entry, then you must define the <literal>.path</literal> field.</para>
</callout>
<callout arearefs="CO14-5">
<para>Optional: Identifier of the <literal>.name</literal> field in a container, specified with a fixed JSONPath. The default value is <literal>.name</literal>.</para>
</callout>
<callout arearefs="CO14-6">
<para>Optional: Identifier of the <literal>.env</literal> field in a container, specified with a fixed JSONPath. The default value is <literal>.env</literal>.</para>
</callout>
<callout arearefs="CO14-7">
<para>Optional: Identifier of the <literal>.volumeMounts</literal> field in a container, specified with a fixed JSONPath. The default value is <literal>.volumeMounts</literal>.</para>
</callout>
<callout arearefs="CO14-8">
<para>Optional: Identifier of the <literal>.volumes</literal> field in a pod, specified with a fixed JSONPath. The default value is <literal>.spec.template.spec.volumes</literal>.</para>
</callout>
</calloutlist>
<important>
<itemizedlist>
<listitem>
<simpara>In this context, a fixed JSONPath is a subset of the JSONPath grammar that accepts only the following operations:</simpara>
<itemizedlist>
<listitem>
<simpara>Field lookup: <literal>.spec.template</literal></simpara>
</listitem>
<listitem>
<simpara>Array indexing: <literal>.spec['template']</literal></simpara>
</listitem>
</itemizedlist>
<simpara>All other operations are not accepted.</simpara>
</listitem>
<listitem>
<simpara>Most of these fields are optional. When they are not specified, the Service Binding Operator assumes defaults compatible with <literal>PodSpec</literal> resources.</simpara>
</listitem>
<listitem>
<simpara>The Service Binding Operator requires that each of these fields is structurally equivalent to the corresponding field in a pod deployment. For example, the contents of the <literal>.env</literal> field in a workload resource must be able to accept the same structure of data that the <literal>.env</literal> field in a Pod resource would. Otherwise, projecting binding data into such a workload might result in unexpected behavior from the Service Binding Operator.</simpara>
</listitem>
</itemizedlist>
</important>
<formalpara>
<title>Behavior specific to the <literal>binding.operators.coreos.com</literal> API group</title>
<para>You can expect the following behaviors when <literal>ClusterWorkloadResourceMapping</literal> resources interact with <literal>ServiceBinding</literal> resources under the <literal>binding.operators.coreos.com</literal> API group:</para>
</formalpara>
<itemizedlist>
<listitem>
<simpara>If a <literal>ServiceBinding</literal> resource with the <literal>bindAsFiles: false</literal> flag value is created together with one of these mappings, then environment variables are projected into the <literal>.envFrom</literal> field underneath each <literal>path</literal> field specified in the corresponding <literal>ClusterWorkloadResourceMapping</literal> resource.</simpara>
</listitem>
<listitem>
<simpara>As a cluster administrator, you can specify both a <literal>ClusterWorkloadResourceMapping</literal> resource and the <literal>.spec.application.bindingPath.containersPath</literal> field in a <literal>ServiceBinding.bindings.coreos.com</literal> resource for binding purposes.</simpara>
<simpara>The Service Binding Operator attempts to project binding data into the locations specified in both a <literal>ClusterWorkloadResourceMapping</literal> resource and the <literal>.spec.application.bindingPath.containersPath</literal> field. This behavior is equivalent to adding a container entry to the corresponding <literal>ClusterWorkloadResourceMapping</literal> resource with the <literal>path: $containersPath</literal> attribute, with all other values taking their default value.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="sbo-unbinding-workloads-from-a-backing-service_binding-workloads-using-sbo">
<title>Unbinding workloads from a backing service</title>
<simpara role="_abstract">You can unbind a workload from a backing service by using the <literal>oc</literal> tool.</simpara>
<itemizedlist>
<listitem>
<simpara>To unbind a workload from a backing service, delete the <literal>ServiceBinding</literal> custom resource (CR) linked to it:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc delete ServiceBinding &lt;.metadata.name&gt;</programlisting>
<formalpara>
<title>Example</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">$ oc delete ServiceBinding spring-petclinic-pgcluster</programlisting>
</para>
</formalpara>
<simpara>where:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara><literal>spring-petclinic-pgcluster</literal></simpara>
</entry>
<entry>
<simpara>Specifies the name of the <literal>ServiceBinding</literal> CR.</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</listitem>
</itemizedlist>
</section>
<section xml:id="additional-resources_binding-workloads-sbo" role="_additional-resources">
<title>Additional resources</title>
<itemizedlist>
<listitem>
<simpara><link linkend="binding-a-workload-together-with-a-backing-service_understanding-service-binding-operator">Binding a workload together with a backing service</link>.</simpara>
</listitem>
<listitem>
<simpara><link linkend="connecting-the-spring-petclinic-sample-application-to-the-postgresql-database-service">Connecting the Spring PetClinic sample application to the PostgreSQL database service</link>.</simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/operators/#crd-creating-custom-resources-from-file_crd-managing-resources-from-crds">Creating custom resources from a file</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://redhat-developer.github.io/service-binding-operator/userguide/binding-workloads-using-sbo/custom-path-injection.html#_workload_resource_mapping">Example schema of the ClusterWorkloadResourceMapping resource</link>.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="odc-connecting-an-application-to-a-service-using-the-developer-perspective">
<title>Connecting an application to a service using the Developer perspective</title>
<simpara role="_abstract">Use the <emphasis role="strong">Topology</emphasis> view for the following purposes:</simpara>
<itemizedlist>
<listitem>
<simpara>Group multiple components within an application.</simpara>
</listitem>
<listitem>
<simpara>Connect components with each other.</simpara>
</listitem>
<listitem>
<simpara>Connect multiple resources to services with labels.</simpara>
</listitem>
</itemizedlist>
<simpara>You can either use a binding or a visual connector to connect components.</simpara>
<simpara>A binding connection between the components can be established only if the target node is an Operator-backed service. This is indicated by the <emphasis role="strong">Create a binding connector</emphasis> tool-tip which appears when you drag an arrow to such a target node. When an application is connected to a service by using a binding connector a <literal>ServiceBinding</literal> resource is created. Then, the Service Binding Operator controller projects the necessary binding data into the application deployment. After the request is successful, the application is redeployed establishing an interaction between the connected components.</simpara>
<simpara>A visual connector establishes only a visual connection between the components, depicting an intent to connect. No interaction between the components is established. If the target node is not an Operator-backed service the <emphasis role="strong">Create a visual connector</emphasis> tool-tip is displayed when you drag an arrow to a target node.</simpara>
<section xml:id="odc-discovering-and-identifying-operator-backed-bindable-services_odc-connecting-an-application-to-a-service-using-the-developer-perspective">
<title>Discovering and identifying Operator-backed bindable services</title>
<simpara>As a user, if you want to create a bindable service, you must know which services are bindable. Bindable services are services that the applications can consume easily because they expose their binding data such as credentials, connection details, volume mounts, secrets, and other binding data in a standard way. The <emphasis role="strong">Developer</emphasis> perspective helps you discover and identify such bindable services.</simpara>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>To discover and identify Operator-backed bindable services, consider the following alternative approaches:</simpara>
<itemizedlist>
<listitem>
<simpara>Click <emphasis role="strong">+Add</emphasis> &#8594; <emphasis role="strong">Developer Catalog</emphasis> &#8594; <emphasis role="strong">Operator Backed</emphasis> to see the Operator-backed tiles. Operator-backed services that support service binding features have a <emphasis role="strong">Bindable</emphasis> badge on the tiles.</simpara>
</listitem>
<listitem>
<simpara>On the left pane of the <emphasis role="strong">Operator Backed</emphasis> page, select the <emphasis role="strong">Bindable</emphasis> checkbox.</simpara>
<tip>
<simpara>Click the help icon next to <emphasis role="strong">Service binding</emphasis> to see more information about bindable services.</simpara>
</tip>
</listitem>
<listitem>
<simpara>Click  <emphasis role="strong">+Add</emphasis> &#8594; <emphasis role="strong">Add</emphasis> and search for Operator-backed services. When you click the bindable service, you can view the <emphasis role="strong">Bindable</emphasis> badge in the side panel to the right.</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</section>
<section xml:id="odc-creating-a-visual-connection-between-components_odc-connecting-an-application-to-a-service-using-the-developer-perspective">
<title>Creating a visual connection between components</title>
<simpara>You can depict an intent to connect application components by using the visual connector.</simpara>
<simpara>This procedure walks you through an example of creating a visual connection between a PostgreSQL Database service and a Spring PetClinic sample application.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have created and deployed a Spring PetClinic sample application by using the <emphasis role="strong">Developer</emphasis> perspective.</simpara>
</listitem>
<listitem>
<simpara>You have created and deployed a Crunchy PostgreSQL database instance by using the <emphasis role="strong">Developer</emphasis> perspective. This instance has the following components: <literal>hippo-backup</literal>, <literal>hippo-instance</literal>, <literal>hippo-repo-host</literal>, and  <literal>hippo-pgbouncer</literal>.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Hover over the Spring PetClinic sample application to see a dangling arrow on the node.</simpara>
<figure>
<title>Visual connector</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_connector.png"/>
</imageobject>
<textobject><phrase>odc connector</phrase></textobject>
</mediaobject>
</figure>
</listitem>
<listitem>
<simpara>Click and drag the arrow towards the <literal>hippo-pgbouncer</literal> deployment to connect the Spring PetClinic sample application with it.</simpara>
</listitem>
<listitem>
<simpara>Click the <literal>spring-petclinic</literal> deployment to see the <emphasis role="strong">Overview</emphasis> panel. Under the <emphasis role="strong">Details</emphasis> tab, click the edit icon in the <emphasis role="strong">Annotations</emphasis> section to see the <emphasis role="strong">Key = <literal>app.openshift.io/connects-to</literal></emphasis> and <emphasis role="strong">Value = <literal>[{"apiVersion":"apps/v1","kind":"Deployment","name":"hippo-pgbouncer"}]</literal></emphasis> annotation added to the deployment.</simpara>
</listitem>
<listitem>
<simpara>Optional: You can repeat these steps to establish visual connections between other applications and components you create.</simpara>
<figure>
<title>Connecting multiple applications</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_connecting_multiple_applications.png"/>
</imageobject>
<textobject><phrase>odc connecting multiple applications</phrase></textobject>
</mediaobject>
</figure>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-creating-a-binding-connection-between-components_odc-connecting-an-application-to-a-service-using-the-developer-perspective">
<title>Creating a binding connection between components</title>
<simpara>You can create a binding connection with Operator-backed components, as demonstrated in the following example, which uses a PostgreSQL Database service and a Spring PetClinic sample application. To create a binding connection with a service that the PostgreSQL Database Operator backs, you must first add the Red Hat-provided PostgreSQL Database Operator to the <emphasis role="strong">OperatorHub</emphasis>, and then install the Operator. The PostreSQL Database Operator then creates and manages the Database resource, which exposes the binding data in secrets, config maps, status, and spec attributes.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You created and deployed a Spring PetClinic sample application in the <emphasis role="strong">Developer</emphasis> perspective.</simpara>
</listitem>
<listitem>
<simpara>You installed Service Binding Operator from the <emphasis role="strong">OperatorHub</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>You installed the <emphasis role="strong">Crunchy Postgres for Kubernetes</emphasis> Operator from the OperatorHub in the <literal>v5</literal> <emphasis role="strong">Update</emphasis> channel.</simpara>
</listitem>
<listitem>
<simpara>You created a <emphasis role="strong">PostgresCluster</emphasis> resource in the <emphasis role="strong">Developer</emphasis> perspective, which resulted in a Crunchy PostgreSQL database instance with the following components: <literal>hippo-backup</literal>, <literal>hippo-instance</literal>, <literal>hippo-repo-host</literal>, and <literal>hippo-pgbouncer</literal>.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the <emphasis role="strong">Developer</emphasis> perspective, switch to the relevant project, for example, <literal>my-petclinic</literal>.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Topology</emphasis> view, hover over the Spring PetClinic sample application to see a dangling arrow on the node.</simpara>
</listitem>
<listitem>
<simpara>Drag and drop the arrow onto the <emphasis role="strong">hippo</emphasis> database icon in the Postgres Cluster to make a binding connection with the Spring PetClinic sample application.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Create Service Binding</emphasis> dialog, keep the default name or add a different name for the service binding, and then click <emphasis role="strong">Create</emphasis>.</simpara>
<figure>
<title>Service Binding dialog</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc-sbc-modal.png"/>
</imageobject>
<textobject><phrase>odc sbc modal</phrase></textobject>
</mediaobject>
</figure>
</listitem>
<listitem>
<simpara>Optional: If there is difficulty in making a binding connection using the Topology view, go to <emphasis role="strong">+Add</emphasis> &#8594; <emphasis role="strong">YAML</emphasis> &#8594; <emphasis role="strong">Import YAML</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Optional: In the YAML editor, add the <literal>ServiceBinding</literal> resource:</simpara>
<programlisting language="YAML" linenumbering="unnumbered">apiVersion: binding.operators.coreos.com/v1alpha1
kind: ServiceBinding
metadata:
    name: spring-petclinic-pgcluster
    namespace: my-petclinic
spec:
    services:
    - group: postgres-operator.crunchydata.com
      version: v1beta1
      kind: PostgresCluster
      name: hippo
    application:
      name: spring-petclinic
      group: apps
      version: v1
      resource: deployments</programlisting>
<simpara>A service binding request is created and a binding connection is created through a <literal>ServiceBinding</literal> resource. When the database service connection request succeeds, the application is redeployed and the connection is established.</simpara>
<figure>
<title>Binding connector</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc-binding-connector.png"/>
</imageobject>
<textobject><phrase>odc binding connector</phrase></textobject>
</mediaobject>
</figure>
<tip>
<simpara>You can also use the context menu by dragging the dangling arrow to add and create a binding connection to an operator-backed service.</simpara>
<figure>
<title>Context menu to create binding connection</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_context_operator.png"/>
</imageobject>
<textobject><phrase>odc context operator</phrase></textobject>
</mediaobject>
</figure>
</tip>
</listitem>
<listitem>
<simpara>In the navigation menu, click <emphasis role="strong">Topology</emphasis>. The spring-petclinic deployment in the Topology view includes an Open URL link to view its web page.</simpara>
</listitem>
<listitem>
<simpara>Click the <emphasis role="strong">Open URL</emphasis> link.</simpara>
</listitem>
</orderedlist>
<simpara>You can now view the Spring PetClinic sample application remotely to confirm that the application is now connected to the database service and that the data has been successfully projected to the application from the Crunchy PostgreSQL database service.</simpara>
<simpara>The Service Binding Operator has successfully created a working connection between the application and the database service.</simpara>
</section>
<section xml:id="odc-verifying-the-status-of-your-service-binding-from-the-topology-view_odc-connecting-an-application-to-a-service-using-the-developer-perspective">
<title>Verifying the status of your service binding from the Topology view</title>
<simpara>The <emphasis role="strong">Developer</emphasis> perspective helps you verify the status of your service binding through the <emphasis role="strong">Topology</emphasis> view.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>If a service binding was successful, click the binding connector. A side panel appears displaying the <emphasis role="strong">Connected</emphasis> status under the <emphasis role="strong">Details</emphasis> tab.</simpara>
<simpara>Optionally, you can view the <emphasis role="strong">Connected</emphasis> status on the following pages from the <emphasis role="strong">Developer</emphasis> perspective:</simpara>
<itemizedlist>
<listitem>
<simpara>The <emphasis role="strong">ServiceBindings</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>The <emphasis role="strong">ServiceBinding details</emphasis> page. In addition, the page title displays a <emphasis role="strong">Connected</emphasis> badge.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>If a service binding was unsuccessful, the binding connector shows a red arrowhead and a red cross in the middle of the connection. Click this connector to view the <emphasis role="strong">Error</emphasis> status in the side panel under the <emphasis role="strong">Details</emphasis> tab. Optionally, click the <emphasis role="strong">Error</emphasis> status to view specific information about the underlying problem.</simpara>
<simpara>You can also view the <emphasis role="strong">Error</emphasis> status and a tooltip on the following pages from the <emphasis role="strong">Developer</emphasis> perspective:</simpara>
<itemizedlist>
<listitem>
<simpara>The <emphasis role="strong">ServiceBindings</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>The <emphasis role="strong">ServiceBinding details</emphasis> page. In addition, the page title displays an <emphasis role="strong">Error</emphasis> badge.</simpara>
</listitem>
</itemizedlist>
</listitem>
</orderedlist>
<tip>
<simpara>In the <emphasis role="strong">ServiceBindings</emphasis> page, use the <emphasis role="strong">Filter</emphasis> dropdown to list the service bindings based on their status.</simpara>
</tip>
</section>
<section xml:id="odc-visualizing-the-binding-connections-to-resources_odc-connecting-an-application-to-a-service-using-the-developer-perspective">
<title>Visualizing the binding connections to resources</title>
<simpara>As a user, use <emphasis role="strong">Label Selector</emphasis> in the <emphasis role="strong">Topology</emphasis> view to visualize a service binding and simplify the process of binding applications to backing services. When creating <literal>ServiceBinding</literal> resources, specify labels by using <emphasis role="strong">Label Selector</emphasis> to find and connect applications instead of using the name of the application. The Service Binding Operator then consumes these <literal>ServiceBinding</literal> resources and specified labels to find the applications to create a service binding with.</simpara>
<tip>
<simpara>To navigate to a list of all connected resources, click the label selector associated with the <literal>ServiceBinding</literal> resource.</simpara>
</tip>
<simpara>To view the <emphasis role="strong">Label Selector</emphasis>, consider the following approaches:</simpara>
<itemizedlist>
<listitem>
<simpara>After you import a <literal>ServiceBinding</literal> resource, view the <emphasis role="strong">Label Selector</emphasis> associated with the service binding on the <emphasis role="strong">ServiceBinding details</emphasis> page.</simpara>
<figure>
<title>ServiceBinding details page</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc-label-selector-sb-details.png"/>
</imageobject>
<textobject><phrase>odc label selector sb details</phrase></textobject>
</mediaobject>
</figure>
</listitem>
</itemizedlist>
<note>
<simpara>To use <emphasis role="strong">Label Selector</emphasis> and to create one or more connections at once, you must import the YAML file of the <literal>ServiceBinding</literal> resource.</simpara>
</note>
<itemizedlist>
<listitem>
<simpara>After the connection is established and when you click the binding connector, the service binding connector <emphasis role="strong">Details</emphasis> side panel appears. You can view the <emphasis role="strong">Label Selector</emphasis> associated with the service binding on this panel.</simpara>
<figure>
<title>Topology label selector side panel</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc-label-selector-topology-side-panel.png"/>
</imageobject>
<textobject><phrase>odc label selector topology side panel</phrase></textobject>
</mediaobject>
</figure>
<note>
<simpara>When you delete a binding connector (a single connection within <emphasis role="strong">Topology</emphasis> along with a service binding), the action removes all connections that are tied to the deleted service binding. While deleting a binding connector, a confirmation dialog appears, which informs that all connectors will be deleted.</simpara>
<figure>
<title>Delete ServiceBinding confirmation dialog</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc-delete-service-binding.png"/>
</imageobject>
<textobject><phrase>odc delete service binding</phrase></textobject>
</mediaobject>
</figure>
</note>
</listitem>
</itemizedlist>
</section>
<section xml:id="additional-resources-odc-connecting-an-application-to-a-service-using-the-developer-perspective" role="_additional-resources">
<title>Additional resources</title>
<itemizedlist>
<listitem>
<simpara><link linkend="getting-started-with-service-binding">Getting started with service binding</link>.</simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://github.com/redhat-developer/service-binding-operator#known-bindable-operators">Known bindable Operators</link>.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</chapter>
<chapter xml:id="_working-with-helm-charts">
<title>Working with Helm charts</title>
<section xml:id="understanding-helm">
<title>Understanding Helm</title>
<simpara role="_abstract">Helm is a software package manager that simplifies deployment of applications and services to OpenShift Container Platform clusters.</simpara>
<simpara>Helm uses a packaging format called <emphasis>charts</emphasis>.
A Helm chart is a collection of files that describes the OpenShift Container Platform resources.</simpara>
<simpara>Creating a chart in a cluster creates a running instance of the chart known as a <emphasis>release</emphasis>.</simpara>
<simpara>Each time a chart is created, or a release is upgraded or rolled back, an incremental revision is created.</simpara>
<section xml:id="_key-features">
<title>Key features</title>
<simpara>Helm provides the ability to:</simpara>
<itemizedlist>
<listitem>
<simpara>Search through a large collection of charts stored in the chart repository.</simpara>
</listitem>
<listitem>
<simpara>Modify existing charts.</simpara>
</listitem>
<listitem>
<simpara>Create your own charts with OpenShift Container Platform or Kubernetes resources.</simpara>
</listitem>
<listitem>
<simpara>Package and share your applications as charts.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="_red-hat-certification-of-helm-charts-for-openshift">
<title>Red Hat Certification of Helm charts for OpenShift</title>
<simpara>You can choose to verify and certify your Helm charts by Red Hat for all the components you will be deploying on the Red Hat OpenShift Container Platform. Charts go through an automated Red Hat OpenShift certification workflow that guarantees security compliance as well as best integration and experience with the platform. Certification assures the integrity of the chart and ensures that the Helm chart works seamlessly on Red Hat OpenShift clusters.</simpara>
</section>
<section xml:id="_additional-resources-3" role="_additional-resources">
<title>Additional resources</title>
<itemizedlist>
<listitem>
<simpara>For more information on how to certify your Helm charts as a Red Hat partner, see <link xlink:href="https://redhat-connect.gitbook.io/partner-guide-for-red-hat-openshift-and-container/helm-chart-certification/overview">Red Hat Certification of Helm charts for OpenShift</link>.</simpara>
</listitem>
<listitem>
<simpara>For more information on OpenShift and Container certification guides for Red Hat partners, see <link xlink:href="https://access.redhat.com/documentation/en-us/red_hat_software_certification/8.51/html-single/red_hat_software_certification_workflow_guide/index#con_container-certification_openshift-sw-cert-workflow-introduction-to-redhat-openshift-operator-certification">Partner Guide for OpenShift and Container Certification</link>.</simpara>
</listitem>
<listitem>
<simpara>For a list of the charts, see <link xlink:href="https://charts.openshift.io/index.yaml">the Red Hat <literal>Helm index</literal> file</link>.</simpara>
</listitem>
<listitem>
<simpara>You can view the available charts at the <link xlink:href="https://marketplace.redhat.com/en-us/documentation/access-red-hat-marketplace">Red Hat Marketplace</link>. For more information, see <link linkend="red-hat-marketplace">Using the Red Hat Marketplace</link>.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="installing-helm">
<title>Installing Helm</title>
<simpara>The following section describes how to install Helm on different platforms using the CLI.</simpara>
<simpara>You can also find the URL to the latest binaries from the OpenShift Container Platform web console by clicking the <emphasis role="strong">?</emphasis> icon in the upper-right corner and selecting <emphasis role="strong">Command Line Tools</emphasis>.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have installed Go, version 1.13 or higher.</simpara>
</listitem>
</itemizedlist>
<section xml:id="_on-linux">
<title>On Linux</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Download the Helm binary and add it to your path:</simpara>
<itemizedlist>
<listitem>
<simpara>Linux (x86_64, amd64)</simpara>
<programlisting language="terminal" linenumbering="unnumbered"># curl -L https://mirror.openshift.com/pub/openshift-v4/clients/helm/latest/helm-linux-amd64 -o /usr/local/bin/helm</programlisting>
</listitem>
<listitem>
<simpara>Linux on IBM Z&#174; and IBM&#174; LinuxONE (s390x)</simpara>
<programlisting language="terminal" linenumbering="unnumbered"># curl -L https://mirror.openshift.com/pub/openshift-v4/clients/helm/latest/helm-linux-s390x -o /usr/local/bin/helm</programlisting>
</listitem>
<listitem>
<simpara>Linux on IBM Power&#174; (ppc64le)</simpara>
<programlisting language="terminal" linenumbering="unnumbered"># curl -L https://mirror.openshift.com/pub/openshift-v4/clients/helm/latest/helm-linux-ppc64le -o /usr/local/bin/helm</programlisting>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Make the binary file executable:</simpara>
<programlisting language="terminal" linenumbering="unnumbered"># chmod +x /usr/local/bin/helm</programlisting>
</listitem>
<listitem>
<simpara>Check the installed version:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ helm version</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">version.BuildInfo{Version:"v3.0", GitCommit:"b31719aab7963acf4887a1c1e6d5e53378e34d93", GitTreeState:"clean", GoVersion:"go1.13.4"}</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</section>
<section xml:id="_on-windows-78">
<title>On Windows 7/8</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Download the latest <link xlink:href="https://mirror.openshift.com/pub/openshift-v4/clients/helm/latest/helm-windows-amd64.exe"><literal>.exe</literal> file</link> and put in a directory of your preference.</simpara>
</listitem>
<listitem>
<simpara>Right click <emphasis role="strong">Start</emphasis> and click <emphasis role="strong">Control Panel</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">System and Security</emphasis> and then click <emphasis role="strong">System</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>From the menu on the left, select <emphasis role="strong">Advanced systems settings</emphasis> and click <emphasis role="strong">Environment Variables</emphasis> at the bottom.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">Path</emphasis> from the <emphasis role="strong">Variable</emphasis> section and click <emphasis role="strong">Edit</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">New</emphasis> and type the path to the folder with the <literal>.exe</literal> file into the field or click <emphasis role="strong">Browse</emphasis> and select the directory, and click <emphasis role="strong">OK</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="_on-windows-10">
<title>On Windows 10</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Download the latest <link xlink:href="https://mirror.openshift.com/pub/openshift-v4/clients/helm/latest/helm-windows-amd64.exe"><literal>.exe</literal> file</link> and put in a directory of your preference.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Search</emphasis> and type <literal>env</literal> or <literal>environment</literal>.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">Edit environment variables for your account</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">Path</emphasis> from the <emphasis role="strong">Variable</emphasis> section and click <emphasis role="strong">Edit</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">New</emphasis> and type the path to the directory with the exe file into the field or click <emphasis role="strong">Browse</emphasis> and select the directory, and click <emphasis role="strong">OK</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="_on-macos">
<title>On MacOS</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Download the Helm binary and add it to your path:</simpara>
<programlisting language="terminal" linenumbering="unnumbered"># curl -L https://mirror.openshift.com/pub/openshift-v4/clients/helm/latest/helm-darwin-amd64 -o /usr/local/bin/helm</programlisting>
</listitem>
<listitem>
<simpara>Make the binary file executable:</simpara>
<programlisting language="terminal" linenumbering="unnumbered"># chmod +x /usr/local/bin/helm</programlisting>
</listitem>
<listitem>
<simpara>Check the installed version:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ helm version</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">version.BuildInfo{Version:"v3.0", GitCommit:"b31719aab7963acf4887a1c1e6d5e53378e34d93", GitTreeState:"clean", GoVersion:"go1.13.4"}</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</section>
</section>
<section xml:id="configuring-custom-helm-chart-repositories">
<title>Configuring custom Helm chart repositories</title>
<simpara role="_abstract">You can create Helm releases on an OpenShift Container Platform cluster using the following methods:</simpara>
<itemizedlist>
<listitem>
<simpara>The CLI.</simpara>
</listitem>
<listitem>
<simpara>The <emphasis role="strong">Developer</emphasis> perspective of the web console.</simpara>
</listitem>
</itemizedlist>
<simpara>The <emphasis role="strong">Developer Catalog</emphasis>, in the <emphasis role="strong">Developer</emphasis> perspective of the web console, displays the Helm charts available in the cluster. By default, it lists the Helm charts from the Red Hat OpenShift Helm chart repository. For a list of the charts, see <link xlink:href="https://charts.openshift.io/index.yaml">the Red Hat <literal>Helm index</literal> file</link>.</simpara>
<simpara>As a cluster administrator, you can add multiple cluster-scoped and namespace-scoped Helm chart repositories, separate from the default cluster-scoped Helm repository, and display the Helm charts from these repositories in the <emphasis role="strong">Developer Catalog</emphasis>.</simpara>
<simpara>As a regular user or project member with the appropriate role-based access control (RBAC) permissions, you can add multiple namespace-scoped Helm chart repositories, apart from the default cluster-scoped Helm repository, and display the Helm charts from these repositories in the <emphasis role="strong">Developer Catalog</emphasis>.</simpara>
<simpara>In the <emphasis role="strong">Developer</emphasis> perspective of the web console, you can use the <emphasis role="strong">Helm</emphasis> page to:</simpara>
<itemizedlist>
<listitem>
<simpara>Create Helm Releases and Repositories using the <emphasis role="strong">Create</emphasis> button.</simpara>
</listitem>
<listitem>
<simpara>Create, update, or delete a cluster-scoped or namespace-scoped Helm chart repository.</simpara>
</listitem>
<listitem>
<simpara>View the list of the existing Helm chart repositories in the Repositories tab, which can also be easily distinguished as either cluster scoped or namespace scoped.</simpara>
</listitem>
</itemizedlist>
<section xml:id="installing-a-helm-chart-on-an-openshift-cluster_configuring-custom-helm-chart-repositories">
<title>Installing a Helm chart on an OpenShift Container Platform cluster</title>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have a running OpenShift Container Platform cluster and you have logged into it.</simpara>
</listitem>
<listitem>
<simpara>You have installed Helm.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a new project:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-project vault</programlisting>
</listitem>
<listitem>
<simpara>Add a repository of Helm charts to your local Helm client:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ helm repo add openshift-helm-charts https://charts.openshift.io/</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">"openshift-helm-charts" has been added to your repositories</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Update the repository:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ helm repo update</programlisting>
</listitem>
<listitem>
<simpara>Install an example HashiCorp Vault:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ helm install example-vault openshift-helm-charts/hashicorp-vault</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME: example-vault
LAST DEPLOYED: Fri Mar 11 12:02:12 2022
NAMESPACE: vault
STATUS: deployed
REVISION: 1
NOTES:
Thank you for installing HashiCorp Vault!</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Verify that the chart has installed successfully:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ helm list</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME         	NAMESPACE	REVISION	UPDATED                                	STATUS  	CHART       	APP VERSION
example-vault	vault    	1       	2022-03-11 12:02:12.296226673 +0530 IST	deployed	vault-0.19.0	1.9.2</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-creating-helm-releases-using-developer-perspective_configuring-custom-helm-chart-repositories">
<title>Creating Helm releases using the Developer perspective</title>
<simpara>You can use either the <emphasis role="strong">Developer</emphasis> perspective in the web console or the CLI to select and create a release from the Helm charts listed in the <emphasis role="strong">Developer Catalog</emphasis>. You can create Helm releases by installing Helm charts and see them in the <emphasis role="strong">Developer</emphasis> perspective of the web console.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have logged in to the web console and have switched to <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/web_console/#about-developer-perspective_web-console-overview">the <emphasis role="strong">Developer</emphasis> perspective</link>.</simpara>
</listitem>
</itemizedlist>
<formalpara>
<title>Procedure</title>
<para>To create Helm releases from the Helm charts provided in the <emphasis role="strong">Developer Catalog</emphasis>:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>In the <emphasis role="strong">Developer</emphasis> perspective, navigate to the <emphasis role="strong">+Add</emphasis> view and select a project. Then click <emphasis role="strong">Helm Chart</emphasis> option to see all the Helm Charts in the <emphasis role="strong">Developer Catalog</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select a chart and read the description, README, and other details about the chart.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Create</emphasis>.</simpara>
<figure>
<title>Helm charts in developer catalog</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_helm_chart_devcatalog_new.png"/>
</imageobject>
<textobject><phrase>odc helm chart devcatalog new</phrase></textobject>
</mediaobject>
</figure>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Create Helm Release</emphasis> page:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Enter a unique name for the release in the <emphasis role="strong">Release Name</emphasis> field.</simpara>
</listitem>
<listitem>
<simpara>Select the required chart version from the <emphasis role="strong">Chart Version</emphasis> drop-down list.</simpara>
</listitem>
<listitem>
<simpara>Configure your Helm chart by using the <emphasis role="strong">Form View</emphasis> or the <emphasis role="strong">YAML View</emphasis>.</simpara>
<note>
<simpara>Where available, you can switch between the <emphasis role="strong">YAML View</emphasis> and <emphasis role="strong">Form View</emphasis>. The data is persisted when switching between the views.</simpara>
</note>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Create</emphasis> to create a Helm release. The web console displays the new release in the <emphasis role="strong">Topology</emphasis> view.</simpara>
<simpara>If a Helm chart has release notes, the web console displays them.</simpara>
<simpara>If a Helm chart creates workloads, the web console displays them on the <emphasis role="strong">Topology</emphasis> or <emphasis role="strong">Helm release details</emphasis> page. The workloads are <literal>DaemonSet</literal>, <literal>CronJob</literal>, <literal>Pod</literal>, <literal>Deployment</literal>, and <literal>DeploymentConfig</literal>.</simpara>
</listitem>
<listitem>
<simpara>View the newly created Helm release in the <emphasis role="strong">Helm Releases</emphasis> page.</simpara>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
<simpara>You can upgrade, rollback, or delete a Helm release by using the <emphasis role="strong">Actions</emphasis> button on the side panel or by right-clicking a Helm release.</simpara>
</section>
<section xml:id="_using-helm-in-the-web-terminal">
<title>Using Helm in the web terminal</title>
<simpara>You can use Helm by <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/web_console/#odc-access-web-terminal_odc-using-web-terminal">Accessing the web terminal</link> in the <emphasis role="strong">Developer</emphasis> perspective of the web console.</simpara>
</section>
<section xml:id="creating-a-custom-helm-chart-on-openshift_configuring-custom-helm-chart-repositories">
<title>Creating a custom Helm chart on OpenShift Container Platform</title>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a new project:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-project nodejs-ex-k</programlisting>
</listitem>
<listitem>
<simpara>Download an example Node.js chart that contains OpenShift Container Platform objects:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ git clone https://github.com/redhat-developer/redhat-helm-charts</programlisting>
</listitem>
<listitem>
<simpara>Go to the directory with the sample chart:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ cd redhat-helm-charts/alpha/nodejs-ex-k/</programlisting>
</listitem>
<listitem>
<simpara>Edit the <literal>Chart.yaml</literal> file  and add a description of your chart:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v2 <co xml:id="CO15-1"/>
name: nodejs-ex-k <co xml:id="CO15-2"/>
description: A Helm chart for OpenShift <co xml:id="CO15-3"/>
icon: https://static.redhat.com/libs/redhat/brand-assets/latest/corp/logo.svg <co xml:id="CO15-4"/>
version: 0.2.1 <co xml:id="CO15-5"/></programlisting>
<calloutlist>
<callout arearefs="CO15-1">
<para>The chart API version. It should be <literal>v2</literal> for Helm charts that require at least Helm 3.</para>
</callout>
<callout arearefs="CO15-2">
<para>The name of your chart.</para>
</callout>
<callout arearefs="CO15-3">
<para>The description of your chart.</para>
</callout>
<callout arearefs="CO15-4">
<para>The URL to an image to be used as an icon.</para>
</callout>
<callout arearefs="CO15-5">
<para>The Version of your chart as per the Semantic Versioning (SemVer) 2.0.0 Specification.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Verify that the chart is formatted properly:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ helm lint</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">[INFO] Chart.yaml: icon is recommended

1 chart(s) linted, 0 chart(s) failed</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Navigate to the previous directory level:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ cd ..</programlisting>
</listitem>
<listitem>
<simpara>Install the chart:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ helm install nodejs-chart nodejs-ex-k</programlisting>
</listitem>
<listitem>
<simpara>Verify that the chart has installed successfully:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ helm list</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION
nodejs-chart nodejs-ex-k 1 2019-12-05 15:06:51.379134163 -0500 EST deployed nodejs-0.1.0  1.16.0</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</section>
<section xml:id="adding-helm-chart-repositories_configuring-custom-helm-chart-repositories">
<title>Adding custom Helm chart repositories</title>
<simpara>As a cluster administrator, you can add custom Helm chart repositories to your cluster and enable access to the Helm charts from these repositories in the <emphasis role="strong">Developer Catalog</emphasis>.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To add a new Helm Chart Repository, you must add the Helm Chart Repository custom resource (CR) to your cluster.</simpara>
<formalpara>
<title>Sample Helm Chart Repository CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: helm.openshift.io/v1beta1
kind: HelmChartRepository
metadata:
  name: &lt;name&gt;
spec:
 # optional name that might be used by console
 # name: &lt;chart-display-name&gt;
  connectionConfig:
    url: &lt;helm-chart-repository-url&gt;</programlisting>
</para>
</formalpara>
<simpara>For example, to add an Azure sample chart repository, run:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ cat &lt;&lt;EOF | oc apply -f -
apiVersion: helm.openshift.io/v1beta1
kind: HelmChartRepository
metadata:
  name: azure-sample-repo
spec:
  name: azure-sample-repo
  connectionConfig:
    url: https://raw.githubusercontent.com/Azure-Samples/helm-charts/master/docs
EOF</programlisting>
</listitem>
<listitem>
<simpara>Navigate to  the <emphasis role="strong">Developer Catalog</emphasis> in the web console to verify that the Helm charts from the chart repository are displayed.</simpara>
<simpara>For example, use the <emphasis role="strong">Chart repositories</emphasis> filter to search for a Helm chart from the repository.</simpara>
<figure>
<title>Chart repositories filter</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_helm_chart_repo_filter.png"/>
</imageobject>
<textobject><phrase>odc helm chart repo filter</phrase></textobject>
</mediaobject>
</figure>
<note>
<simpara>If a cluster administrator removes all of the chart repositories, then you cannot view the Helm option in the <emphasis role="strong">+Add</emphasis> view, <emphasis role="strong">Developer Catalog</emphasis>, and left navigation panel.</simpara>
</note>
</listitem>
</orderedlist>
</section>
<section xml:id="adding-namespace-scoped-helm-chart-repositories.adoc_configuring-custom-helm-chart-repositories">
<title>Adding namespace-scoped custom Helm chart repositories</title>
<simpara role="_abstract">The cluster-scoped <literal>HelmChartRepository</literal> custom resource definition (CRD) for Helm repository provides the ability for administrators to add Helm repositories as custom resources. The namespace-scoped <literal>ProjectHelmChartRepository</literal> CRD allows project members with the appropriate role-based access control (RBAC) permissions to create Helm repository resources of their choice but scoped to their namespace. Such project members can see charts from both cluster-scoped and namespace-scoped Helm repository resources.</simpara>
<note>
<itemizedlist>
<listitem>
<simpara>Administrators can limit users from creating namespace-scoped Helm repository resources. By limiting users, administrators have the flexibility to control the RBAC through a namespace role instead of a cluster role. This avoids unnecessary permission elevation for the user and prevents access to unauthorized services or applications.</simpara>
</listitem>
<listitem>
<simpara>The addition of the namespace-scoped Helm repository does not impact the behavior of the existing cluster-scoped Helm repository.</simpara>
</listitem>
</itemizedlist>
</note>
<simpara>As a regular user or project member with the appropriate RBAC permissions, you can add custom namespace-scoped Helm chart repositories to your cluster and enable access to the Helm charts from these repositories in the <emphasis role="strong">Developer Catalog</emphasis>.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To add a new namespace-scoped Helm Chart Repository, you must add the Helm Chart Repository custom resource (CR) to your namespace.</simpara>
<formalpara>
<title>Sample Namespace-scoped Helm Chart Repository CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: helm.openshift.io/v1beta1
kind: ProjectHelmChartRepository
metadata:
  name: &lt;name&gt;
spec:
  url: https://my.chart-repo.org/stable

  # optional name that might be used by console
  name: &lt;chart-repo-display-name&gt;

  # optional and only needed for UI purposes
  description: &lt;My private chart repo&gt;

  # required: chart repository URL
  connectionConfig:
    url: &lt;helm-chart-repository-url&gt;</programlisting>
</para>
</formalpara>
<simpara>For example, to add an Azure sample chart repository scoped to your <literal>my-namespace</literal> namespace, run:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ cat &lt;&lt;EOF | oc apply --namespace my-namespace -f -
apiVersion: helm.openshift.io/v1beta1
kind: ProjectHelmChartRepository
metadata:
  name: azure-sample-repo
spec:
  name: azure-sample-repo
  connectionConfig:
    url: https://raw.githubusercontent.com/Azure-Samples/helm-charts/master/docs
EOF</programlisting>
<simpara>The output verifies that the namespace-scoped Helm Chart Repository CR is created:</simpara>
<formalpara>
<title>Example output</title>
<para>
<screen>projecthelmchartrepository.helm.openshift.io/azure-sample-repo created</screen>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Navigate to  the <emphasis role="strong">Developer Catalog</emphasis> in the web console to verify that the Helm charts from the chart repository are displayed in your <literal>my-namespace</literal> namespace.</simpara>
<simpara>For example, use the <emphasis role="strong">Chart repositories</emphasis> filter to search for a Helm chart from the repository.</simpara>
<figure>
<title>Chart repositories filter in your namespace</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_namespace_helm_chart_repo_filter.png"/>
</imageobject>
<textobject><phrase>odc namespace helm chart repo filter</phrase></textobject>
</mediaobject>
</figure>
<simpara>Alternatively, run:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get projecthelmchartrepositories --namespace my-namespace</programlisting>
<formalpara>
<title>Example output</title>
<para>
<screen>NAME                     AGE
azure-sample-repo        1m</screen>
</para>
</formalpara>
<note>
<simpara>If a cluster administrator or a regular user with appropriate RBAC permissions removes all of the chart repositories in a specific namespace, then you cannot view the Helm option in the <emphasis role="strong">+Add</emphasis> view, <emphasis role="strong">Developer Catalog</emphasis>, and left navigation panel for that specific namespace.</simpara>
</note>
</listitem>
</orderedlist>
</section>
<section xml:id="creating-credentials-and-certificates-to-add-helm-repositories_configuring-custom-helm-chart-repositories">
<title>Creating credentials and CA certificates to add Helm chart repositories</title>
<simpara>Some Helm chart repositories need credentials and custom certificate authority (CA) certificates to connect to it. You can use the web console as well as the CLI to add credentials and certificates.</simpara>
<formalpara>
<title>Procedure</title>
<para>To configure the credentials and certificates, and then add a Helm chart repository using the CLI:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>In the <literal>openshift-config</literal> namespace, create a <literal>ConfigMap</literal> object with a custom CA certificate in PEM encoded format, and store it under the <literal>ca-bundle.crt</literal> key within the config map:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create configmap helm-ca-cert \
--from-file=ca-bundle.crt=/path/to/certs/ca.crt \
-n openshift-config</programlisting>
</listitem>
<listitem>
<simpara>In the <literal>openshift-config</literal> namespace, create a <literal>Secret</literal> object to add the client TLS configurations:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create secret tls helm-tls-configs \
--cert=/path/to/certs/client.crt \
--key=/path/to/certs/client.key \
-n openshift-config</programlisting>
<simpara>Note that the client certificate and key must be in PEM encoded format and stored under the keys <literal>tls.crt</literal> and <literal>tls.key</literal>, respectively.</simpara>
</listitem>
<listitem>
<simpara>Add the Helm repository as follows:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ cat &lt;&lt;EOF | oc apply -f -
apiVersion: helm.openshift.io/v1beta1
kind: HelmChartRepository
metadata:
  name: &lt;helm-repository&gt;
spec:
  name: &lt;helm-repository&gt;
  connectionConfig:
    url: &lt;URL for the Helm repository&gt;
    tlsConfig:
        name: helm-tls-configs
    ca:
	name: helm-ca-cert
EOF</programlisting>
<simpara>The <literal>ConfigMap</literal> and <literal>Secret</literal> are consumed in the HelmChartRepository CR using the <literal>tlsConfig</literal> and <literal>ca</literal> fields. These certificates are used to connect to the Helm repository URL.</simpara>
</listitem>
<listitem>
<simpara>By default, all authenticated users have access to all configured charts. However, for chart repositories where certificates are needed, you must provide users with read access to the <literal>helm-ca-cert</literal> config map and <literal>helm-tls-configs</literal> secret in the <literal>openshift-config</literal> namespace, as follows:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ cat &lt;&lt;EOF | kubectl apply -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: openshift-config
  name: helm-chartrepos-tls-conf-viewer
rules:
- apiGroups: [""]
  resources: ["configmaps"]
  resourceNames: ["helm-ca-cert"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["secrets"]
  resourceNames: ["helm-tls-configs"]
  verbs: ["get"]
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: openshift-config
  name: helm-chartrepos-tls-conf-viewer
subjects:
  - kind: Group
    apiGroup: rbac.authorization.k8s.io
    name: 'system:authenticated'
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: helm-chartrepos-tls-conf-viewer
EOF</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="filtering-helm-charts-by-certification-level_configuring-custom-helm-chart-repositories">
<title>Filtering Helm Charts by their certification level</title>
<simpara>You can filter Helm charts based on their certification level in the <emphasis role="strong">Developer Catalog</emphasis>.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the <emphasis role="strong">Developer</emphasis> perspective, navigate to the <emphasis role="strong">+Add</emphasis> view and select a project.</simpara>
</listitem>
<listitem>
<simpara>From the <emphasis role="strong">Developer Catalog</emphasis> tile, select the <emphasis role="strong">Helm Chart</emphasis> option to see all the Helm charts in the <emphasis role="strong">Developer Catalog</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Use the filters to the left of the list of Helm charts to filter the required charts:</simpara>
<itemizedlist>
<listitem>
<simpara>Use the <emphasis role="strong">Chart Repositories</emphasis> filter to filter charts provided by <emphasis role="strong">Red Hat Certification Charts</emphasis> or <emphasis role="strong">OpenShift Helm Charts</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Use the <emphasis role="strong">Source</emphasis> filter to filter charts sourced from <emphasis role="strong">Partners</emphasis>, <emphasis role="strong">Community</emphasis>, or <emphasis role="strong">Red Hat</emphasis>. Certified charts are indicated with the (<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_verified_icon.png"/>
</imageobject>
<textobject><phrase>odc verified icon</phrase></textobject>
</inlinemediaobject>) icon.</simpara>
</listitem>
</itemizedlist>
</listitem>
</orderedlist>
<note>
<simpara>The <emphasis role="strong">Source</emphasis> filter will not be visible when there is only one provider type.</simpara>
</note>
<simpara>You can now select the required chart and install it.</simpara>
</section>
<section xml:id="helm-disabling-helm-chart-repositories_configuring-custom-helm-chart-repositories">
<title>Disabling Helm Chart repositories</title>
<simpara>You can disable Helm Charts from a particular Helm Chart Repository in the catalog by setting the <literal>disabled</literal> property in the <literal>HelmChartRepository</literal> custom resource to <literal>true</literal>.</simpara>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>To disable a Helm Chart repository by using CLI, add the <literal>disabled: true</literal> flag to the custom resource. For example, to remove an Azure sample chart repository, run:</simpara>
<screen>$ cat &lt;&lt;EOF | oc apply -f -
apiVersion: helm.openshift.io/v1beta1
kind: HelmChartRepository
metadata:
  name: azure-sample-repo
spec:
  connectionConfig:
   url:https://raw.githubusercontent.com/Azure-Samples/helm-charts/master/docs
  disabled: true
EOF</screen>
</listitem>
<listitem>
<simpara>To disable a recently added Helm Chart repository by using Web Console:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Go to <emphasis role="strong">Custom Resource Definitions</emphasis> and search for the <literal>HelmChartRepository</literal> custom resource.</simpara>
</listitem>
<listitem>
<simpara>Go to <emphasis role="strong">Instances</emphasis>, find the repository you want to disable, and click its name.</simpara>
</listitem>
<listitem>
<simpara>Go to the <emphasis role="strong">YAML</emphasis> tab, add the <literal>disabled: true</literal> flag in the <literal>spec</literal> section, and click <literal>Save</literal>.</simpara>
<formalpara>
<title>Example</title>
<para>
<screen>spec:
  connectionConfig:
    url: &lt;url-of-the-repositoru-to-be-disabled&gt;
  disabled: true</screen>
</para>
</formalpara>
<simpara>The repository is now disabled and will not appear in the catalog.</simpara>
</listitem>
</orderedlist>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="odc-working-with-helm-releases">
<title>Working with Helm releases</title>
<simpara>You can use the <emphasis role="strong">Developer</emphasis> perspective in the web console to update, rollback, or delete a Helm release.</simpara>
<section xml:id="_prerequisites-5">
<title>Prerequisites</title>
<itemizedlist>
<listitem>
<simpara>You have logged in to the web console and have switched to <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/web_console/#about-developer-perspective_web-console-overview">the <emphasis role="strong">Developer</emphasis> perspective</link>.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="odc-upgrading-helm-release_working-with-helm-releases">
<title>Upgrading a Helm release</title>
<simpara>You can upgrade a Helm release to upgrade to a new chart version or update your release configuration.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the <emphasis role="strong">Topology</emphasis> view, select the Helm release to see the side panel.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Actions</emphasis> &#8594; <emphasis role="strong">Upgrade Helm Release</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Upgrade Helm Release</emphasis> page, select the <emphasis role="strong">Chart Version</emphasis> you want to upgrade to, and then click <emphasis role="strong">Upgrade</emphasis> to create another Helm release. The <emphasis role="strong">Helm Releases</emphasis> page displays the two revisions.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-rolling-back-helm-release_working-with-helm-releases">
<title>Rolling back a Helm release</title>
<simpara>If a release fails, you can rollback the Helm release to a previous version.</simpara>
<formalpara>
<title>Procedure</title>
<para>To rollback a release using the <emphasis role="strong">Helm</emphasis> view:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>In the <emphasis role="strong">Developer</emphasis> perspective, navigate to the <emphasis role="strong">Helm</emphasis> view to see the <emphasis role="strong">Helm Releases</emphasis> in the namespace.</simpara>
</listitem>
<listitem>
<simpara>Click the <emphasis role="strong">Options</emphasis> menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> adjoining the listed release, and select <emphasis role="strong">Rollback</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Rollback Helm Release</emphasis> page, select the <emphasis role="strong">Revision</emphasis> you want to rollback to and click <emphasis role="strong">Rollback</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Helm Releases</emphasis> page, click on the chart to see the details and resources for that release.</simpara>
</listitem>
<listitem>
<simpara>Go to the <emphasis role="strong">Revision History</emphasis> tab to see all the revisions for the chart.</simpara>
<figure>
<title>Helm revision history</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_helm_revision_history.png"/>
</imageobject>
<textobject><phrase>odc helm revision history</phrase></textobject>
</mediaobject>
</figure>
</listitem>
<listitem>
<simpara>If required, you can further use the <emphasis role="strong">Options</emphasis> menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> adjoining a particular revision and select the revision to rollback to.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-deleting-helm-release_working-with-helm-releases">
<title>Deleting a Helm release</title>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the <emphasis role="strong">Topology</emphasis> view, right-click the Helm release and select <emphasis role="strong">Delete Helm Release</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>In the confirmation prompt, enter the name of the chart and click <emphasis role="strong">Delete</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
</section>
</chapter>
<chapter xml:id="_deployments">
<title>Deployments</title>
<section xml:id="what-deployments-are">
<title>Understanding deployments</title>
<simpara>The <literal>Deployment</literal> and <literal>DeploymentConfig</literal> API objects in OpenShift Container Platform provide two similar but different methods for fine-grained management over common user applications. They are composed of the following separate API objects:</simpara>
<itemizedlist>
<listitem>
<simpara>A <literal>Deployment</literal> or <literal>DeploymentConfig</literal> object, either of which describes the desired state of a particular component of the application as a pod template.</simpara>
</listitem>
<listitem>
<simpara><literal>Deployment</literal> objects involve one or more <emphasis>replica sets</emphasis>, which contain a point-in-time record of the state of a deployment as a pod template. Similarly, <literal>DeploymentConfig</literal> objects involve one or more <emphasis>replication controllers</emphasis>, which preceded replica sets.</simpara>
</listitem>
<listitem>
<simpara>One or more pods, which represent an instance of a particular version of an application.</simpara>
</listitem>
</itemizedlist>
<simpara>Use <literal>Deployment</literal> objects unless you need a specific feature or behavior provided by <literal>DeploymentConfig</literal> objects.</simpara>
<important>
<simpara>As of OpenShift Container Platform 4.14, <literal>DeploymentConfig</literal> objects are deprecated. <literal>DeploymentConfig</literal> objects are still supported, but are not recommended for new installations. Only security-related and critical issues will be fixed.</simpara>
<simpara>Instead, use <literal>Deployment</literal> objects or another alternative to provide declarative updates for pods.</simpara>
</important>
<section xml:id="what-deployments-are-build-blocks">
<title>Building blocks of a deployment</title>
<simpara>Deployments and deployment configs are enabled by the use of native Kubernetes API objects <literal>ReplicaSet</literal> and <literal>ReplicationController</literal>, respectively, as their building blocks.</simpara>
<simpara>Users do not have to manipulate replica sets, replication controllers, or pods owned by <literal>Deployment</literal> or <literal>DeploymentConfig</literal> objects. The deployment systems ensure changes are propagated appropriately.</simpara>
<tip>
<simpara>If the existing deployment strategies are not suited for your use case and you must run manual steps during the lifecycle of your deployment, then you should consider creating a custom deployment strategy.</simpara>
</tip>
<simpara>The following sections provide further details on these objects.</simpara>
<section xml:id="deployments-repliasets_what-deployments-are">
<title>Replica sets</title>
<simpara>A <literal>ReplicaSet</literal> is a native Kubernetes API object that ensures a specified number of pod replicas are running at any given time.</simpara>
<note>
<simpara>Only use replica sets if you require custom update orchestration or do not require updates at all. Otherwise, use deployments. Replica sets can be used independently, but are used by deployments to orchestrate pod creation, deletion, and updates. Deployments manage their replica sets automatically, provide declarative updates to pods, and do not have to manually manage the replica sets that they create.</simpara>
</note>
<simpara>The following is an example <literal>ReplicaSet</literal> definition:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: frontend-1
  labels:
    tier: frontend
spec:
  replicas: 3
  selector: <co xml:id="CO16-1"/>
    matchLabels: <co xml:id="CO16-2"/>
      tier: frontend
    matchExpressions: <co xml:id="CO16-3"/>
      - {key: tier, operator: In, values: [frontend]}
  template:
    metadata:
      labels:
        tier: frontend
    spec:
      containers:
      - image: openshift/hello-openshift
        name: helloworld
        ports:
        - containerPort: 8080
          protocol: TCP
      restartPolicy: Always</programlisting>
<calloutlist>
<callout arearefs="CO16-1">
<para>A label query over a set of resources. The result of <literal>matchLabels</literal> and <literal>matchExpressions</literal> are logically conjoined.</para>
</callout>
<callout arearefs="CO16-2">
<para>Equality-based selector to specify resources with labels that match the selector.</para>
</callout>
<callout arearefs="CO16-3">
<para>Set-based selector to filter keys. This selects all resources with key equal to <literal>tier</literal> and value equal to <literal>frontend</literal>.</para>
</callout>
</calloutlist>
</section>
<section xml:id="deployments-replicationcontrollers_what-deployments-are">
<title>Replication controllers</title>
<simpara>Similar to a replica set, a replication controller ensures that a specified number of replicas of a pod are running at all times. If pods exit or are deleted, the replication controller instantiates more up to the defined number. Likewise, if there are more running than desired, it deletes as many as necessary to match the defined amount. The difference between a replica set and a replication controller is that a replica set supports set-based selector requirements whereas a replication controller only supports equality-based selector requirements.</simpara>
<simpara>A replication controller configuration consists of:</simpara>
<itemizedlist>
<listitem>
<simpara>The number of replicas desired, which can be adjusted at run time.</simpara>
</listitem>
<listitem>
<simpara>A <literal>Pod</literal> definition to use when creating a replicated pod.</simpara>
</listitem>
<listitem>
<simpara>A selector for identifying managed pods.</simpara>
</listitem>
</itemizedlist>
<simpara>A selector is a set of labels assigned to the pods that are managed by the replication controller. These labels are included in the <literal>Pod</literal> definition that the replication controller instantiates. The replication controller uses the selector to determine how many instances of the pod are already running in order to adjust as needed.</simpara>
<simpara>The replication controller does not perform auto-scaling based on load or traffic, as it does not track either. Rather, this requires its replica
count to be adjusted by an external auto-scaler.</simpara>
<note>
<simpara>Use a <literal>DeploymentConfig</literal> to create a replication controller instead of creating replication controllers directly.</simpara>
<simpara>If you require custom orchestration or do not require updates, use replica sets instead of replication controllers.</simpara>
</note>
<simpara>The following is an example definition of a replication controller:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: ReplicationController
metadata:
  name: frontend-1
spec:
  replicas: 1  <co xml:id="CO17-1"/>
  selector:    <co xml:id="CO17-2"/>
    name: frontend
  template:    <co xml:id="CO17-3"/>
    metadata:
      labels:  <co xml:id="CO17-4"/>
        name: frontend <co xml:id="CO17-5"/>
    spec:
      containers:
      - image: openshift/hello-openshift
        name: helloworld
        ports:
        - containerPort: 8080
          protocol: TCP
      restartPolicy: Always</programlisting>
<calloutlist>
<callout arearefs="CO17-1">
<para>The number of copies of the pod to run.</para>
</callout>
<callout arearefs="CO17-2">
<para>The label selector of the pod to run.</para>
</callout>
<callout arearefs="CO17-3">
<para>A template for the pod the controller creates.</para>
</callout>
<callout arearefs="CO17-4">
<para>Labels on the pod should include those from the label selector.</para>
</callout>
<callout arearefs="CO17-5">
<para>The maximum name length after expanding any parameters is 63 characters.</para>
</callout>
</calloutlist>
</section>
</section>
<section xml:id="deployments-kube-deployments_what-deployments-are">
<title>Deployments</title>
<simpara>Kubernetes provides a first-class, native API object type in OpenShift Container Platform called <literal>Deployment</literal>. <literal>Deployment</literal> objects describe the desired state of a particular component of an application as a pod template. Deployments create replica sets, which orchestrate pod lifecycles.</simpara>
<simpara>For example, the following deployment definition creates a replica set to bring up one <literal>hello-openshift</literal> pod:</simpara>
<formalpara>
<title>Deployment definition</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-openshift
spec:
  replicas: 1
  selector:
    matchLabels:
      app: hello-openshift
  template:
    metadata:
      labels:
        app: hello-openshift
    spec:
      containers:
      - name: hello-openshift
        image: openshift/hello-openshift:latest
        ports:
        - containerPort: 80</programlisting>
</para>
</formalpara>
</section>
<section xml:id="deployments-and-deploymentconfigs_what-deployments-are">
<title>DeploymentConfig objects</title>
<important>
<simpara>As of OpenShift Container Platform 4.14, <literal>DeploymentConfig</literal> objects are deprecated. <literal>DeploymentConfig</literal> objects are still supported, but are not recommended for new installations. Only security-related and critical issues will be fixed.</simpara>
<simpara>Instead, use <literal>Deployment</literal> objects or another alternative to provide declarative updates for pods.</simpara>
</important>
<simpara>Building on replication controllers, OpenShift Container Platform adds expanded support for the software development and deployment lifecycle with the concept of <literal>DeploymentConfig</literal> objects. In the simplest case, a <literal>DeploymentConfig</literal> object creates a new replication controller and lets it start up pods.</simpara>
<simpara>However, OpenShift Container Platform deployments from <literal>DeploymentConfig</literal> objects also provide the ability to transition from an existing deployment of an image to a new one and also define hooks to be run before or after creating the replication controller.</simpara>
<simpara>The <literal>DeploymentConfig</literal> deployment system provides the following capabilities:</simpara>
<itemizedlist>
<listitem>
<simpara>A <literal>DeploymentConfig</literal> object, which is a template for running applications.</simpara>
</listitem>
<listitem>
<simpara>Triggers that drive automated deployments in response to events.</simpara>
</listitem>
<listitem>
<simpara>User-customizable deployment strategies to transition from the previous version to the new version. A strategy runs inside a pod commonly referred as the deployment process.</simpara>
</listitem>
<listitem>
<simpara>A set of hooks (lifecycle hooks) for executing custom behavior in different points during the lifecycle of a deployment.</simpara>
</listitem>
<listitem>
<simpara>Versioning of your application to support rollbacks either manually or automatically in case of deployment failure.</simpara>
</listitem>
<listitem>
<simpara>Manual replication scaling and autoscaling.</simpara>
</listitem>
</itemizedlist>
<simpara>When you create a <literal>DeploymentConfig</literal> object, a replication controller is created representing the <literal>DeploymentConfig</literal> object&#8217;s pod template. If the deployment changes, a new replication controller is created with the latest pod template, and a deployment process runs to scale down the old replication controller and scale up the new one.</simpara>
<simpara>Instances of your application are automatically added and removed from both service load balancers and routers as they are created. As long as your application supports graceful shutdown when it receives the <literal>TERM</literal> signal, you can ensure that running user connections are given a chance to complete normally.</simpara>
<simpara>The OpenShift Container Platform <literal>DeploymentConfig</literal> object defines the following details:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>The elements of a <literal>ReplicationController</literal> definition.</simpara>
</listitem>
<listitem>
<simpara>Triggers for creating a new deployment automatically.</simpara>
</listitem>
<listitem>
<simpara>The strategy for transitioning between deployments.</simpara>
</listitem>
<listitem>
<simpara>Lifecycle hooks.</simpara>
</listitem>
</orderedlist>
<simpara>Each time a deployment is triggered, whether manually or automatically, a deployer pod manages the deployment (including scaling down the old
replication controller, scaling up the new one, and running hooks). The deployment pod remains for an indefinite amount of time after it completes the deployment to retain its logs of the deployment. When a deployment is superseded by another, the previous replication controller is retained to enable easy rollback if needed.</simpara>
<formalpara>
<title>Example <literal>DeploymentConfig</literal> definition</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: apps.openshift.io/v1
kind: DeploymentConfig
metadata:
  name: frontend
spec:
  replicas: 5
  selector:
    name: frontend
  template: { ... }
  triggers:
  - type: ConfigChange <co xml:id="CO18-1"/>
  - imageChangeParams:
      automatic: true
      containerNames:
      - helloworld
      from:
        kind: ImageStreamTag
        name: hello-openshift:latest
    type: ImageChange  <co xml:id="CO18-2"/>
  strategy:
    type: Rolling      <co xml:id="CO18-3"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO18-1">
<para>A configuration change trigger results in a new replication controller whenever changes are detected in the pod template of the deployment configuration.</para>
</callout>
<callout arearefs="CO18-2">
<para>An image change trigger causes a new deployment to be created each time a new version of the backing image is available in the named image stream.</para>
</callout>
<callout arearefs="CO18-3">
<para>The default <literal>Rolling</literal> strategy makes a downtime-free transition between deployments.</para>
</callout>
</calloutlist>
</section>
<section xml:id="deployments-comparing-deploymentconfigs_what-deployments-are">
<title>Comparing Deployment and DeploymentConfig objects</title>
<simpara>Both Kubernetes <literal>Deployment</literal> objects and OpenShift Container Platform-provided <literal>DeploymentConfig</literal> objects are supported in OpenShift Container Platform; however, it is recommended to use <literal>Deployment</literal> objects unless you need a specific feature or behavior provided by <literal>DeploymentConfig</literal> objects.</simpara>
<simpara>The following sections go into more detail on the differences between the two object types to further help you decide which type to use.</simpara>
<important>
<simpara>As of OpenShift Container Platform 4.14, <literal>DeploymentConfig</literal> objects are deprecated. <literal>DeploymentConfig</literal> objects are still supported, but are not recommended for new installations. Only security-related and critical issues will be fixed.</simpara>
<simpara>Instead, use <literal>Deployment</literal> objects or another alternative to provide declarative updates for pods.</simpara>
</important>
<section xml:id="deployments-design_what-deployments-are">
<title>Design</title>
<simpara>One important difference between <literal>Deployment</literal> and <literal>DeploymentConfig</literal> objects is the properties of the <link xlink:href="https://en.wikipedia.org/wiki/CAP_theorem">CAP theorem</link> that each design has chosen for the rollout process. <literal>DeploymentConfig</literal> objects  prefer consistency, whereas <literal>Deployments</literal> objects take availability over consistency.</simpara>
<simpara>For <literal>DeploymentConfig</literal> objects, if a node running a deployer pod goes down, it will not get replaced. The process waits until the node comes back online or is manually deleted. Manually deleting the node also deletes the corresponding pod. This means that you can not delete the pod to unstick the rollout, as the kubelet is responsible for deleting the associated pod.</simpara>
<simpara>However, deployment rollouts are driven from a controller manager. The controller manager runs in high availability mode on masters and uses leader election algorithms to value availability over consistency. During a failure it is possible for other masters to act on the same deployment at the same time, but this issue will be reconciled shortly after the failure occurs.</simpara>
</section>
<section xml:id="delpoyments-specific-features_what-deployments-are">
<title>Deployment-specific features</title>
<bridgehead xml:id="_rollover" renderas="sect6">Rollover</bridgehead>
<simpara>The deployment process for <literal>Deployment</literal> objects is driven by a controller loop, in contrast to <literal>DeploymentConfig</literal> objects that use deployer pods for every new rollout. This means that the <literal>Deployment</literal> object can have as many active replica sets as possible, and eventually the deployment controller will scale down all old replica sets and scale up the newest one.</simpara>
<simpara><literal>DeploymentConfig</literal> objects can have at most one deployer pod running, otherwise multiple deployers might conflict when trying to scale up what they think should be the newest replication controller. Because of this, only two replication controllers can be active at any point in time. Ultimately, this results in faster rapid rollouts for <literal>Deployment</literal> objects.</simpara>
<bridgehead xml:id="_proportional-scaling" renderas="sect6">Proportional scaling</bridgehead>
<simpara>Because the deployment controller is the sole source of truth for the sizes of new and old replica sets owned by a <literal>Deployment</literal> object, it can scale ongoing rollouts. Additional replicas are distributed proportionally based on the size of each replica set.</simpara>
<simpara><literal>DeploymentConfig</literal> objects cannot be scaled when a rollout is ongoing because the controller will have issues with the deployer process about the size of the new replication controller.</simpara>
<bridgehead xml:id="_pausing-mid-rollout" renderas="sect6">Pausing mid-rollout</bridgehead>
<simpara>Deployments can be paused at any point in time, meaning you can also pause ongoing rollouts. However, you currently cannot pause deployer pods; if you try to pause a deployment in the middle of a rollout, the deployer process is not affected and continues until it finishes.</simpara>
</section>
<section xml:id="delpoymentconfigs-specific-features_what-deployments-are">
<title>DeploymentConfig object-specific features</title>
<bridgehead xml:id="_automatic-rollbacks" renderas="sect6">Automatic rollbacks</bridgehead>
<simpara>Currently, deployments do not support automatically rolling back to the last successfully deployed replica set in case of a failure.</simpara>
<bridgehead xml:id="_triggers" renderas="sect6">Triggers</bridgehead>
<simpara>Deployments have an implicit config change trigger in that every change in the pod template of a deployment automatically triggers a new rollout.
If you do not want new rollouts on pod template changes, pause the deployment:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc rollout pause deployments/&lt;name&gt;</programlisting>
<bridgehead xml:id="_lifecycle-hooks" renderas="sect6">Lifecycle hooks</bridgehead>
<simpara>Deployments do not yet support any lifecycle hooks.</simpara>
<bridgehead xml:id="_custom-strategies" renderas="sect6">Custom strategies</bridgehead>
<simpara>Deployments do not support user-specified custom deployment strategies.</simpara>
</section>
</section>
</section>
<section xml:id="deployment-operations">
<title>Managing deployment processes</title>
<section xml:id="deploymentconfig-operations">
<title>Managing DeploymentConfig objects</title>
<important>
<simpara>As of OpenShift Container Platform 4.14, <literal>DeploymentConfig</literal> objects are deprecated. <literal>DeploymentConfig</literal> objects are still supported, but are not recommended for new installations. Only security-related and critical issues will be fixed.</simpara>
<simpara>Instead, use <literal>Deployment</literal> objects or another alternative to provide declarative updates for pods.</simpara>
</important>
<simpara><literal>DeploymentConfig</literal> objects can be managed from the OpenShift Container Platform web console&#8217;s <emphasis role="strong">Workloads</emphasis> page or using the <literal>oc</literal> CLI. The following procedures show CLI usage unless otherwise stated.</simpara>
<section xml:id="deployments-starting-a-deployment_deployment-operations">
<title>Starting a deployment</title>
<simpara>You can start a rollout to begin the deployment process of your application.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To start a new deployment process from an existing <literal>DeploymentConfig</literal> object, run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc rollout latest dc/&lt;name&gt;</programlisting>
<note>
<simpara>If a deployment process is already in progress, the command displays a message and a new replication controller will not be deployed.</simpara>
</note>
</listitem>
</orderedlist>
</section>
<section xml:id="deployments-viewing-a-deployment_deployment-operations">
<title>Viewing a deployment</title>
<simpara>You can view a deployment to get basic information about all the available revisions of your application.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To show details about all recently created replication controllers for the provided <literal>DeploymentConfig</literal> object, including any currently running deployment process, run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc rollout history dc/&lt;name&gt;</programlisting>
</listitem>
<listitem>
<simpara>To view details specific to a revision, add the <literal>--revision</literal> flag:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc rollout history dc/&lt;name&gt; --revision=1</programlisting>
</listitem>
<listitem>
<simpara>For more detailed information about a <literal>DeploymentConfig</literal> object and its latest revision, use the <literal>oc describe</literal> command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc describe dc &lt;name&gt;</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="deployments-retrying-deployment_deployment-operations">
<title>Retrying a deployment</title>
<simpara>If the current revision of your <literal>DeploymentConfig</literal> object failed to deploy, you can restart the deployment process.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To restart a failed deployment process:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc rollout retry dc/&lt;name&gt;</programlisting>
<simpara>If the latest revision of it was deployed successfully, the command displays a message and the deployment process is not retried.</simpara>
<note>
<simpara>Retrying a deployment restarts the deployment process and does not create a new deployment revision. The restarted replication controller has the same configuration it had when it failed.</simpara>
</note>
</listitem>
</orderedlist>
</section>
<section xml:id="deployments-rolling-back_deployment-operations">
<title>Rolling back a deployment</title>
<simpara>Rollbacks revert an application back to a previous revision and can be performed using the REST API, the CLI, or the web console.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To rollback to the last successful deployed revision of your configuration:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc rollout undo dc/&lt;name&gt;</programlisting>
<simpara>The <literal>DeploymentConfig</literal> object&#8217;s template is reverted to match the deployment revision specified in the undo command, and a new replication controller is started. If no revision is specified with <literal>--to-revision</literal>, then the last successfully deployed revision is used.</simpara>
</listitem>
<listitem>
<simpara>Image change triggers on the <literal>DeploymentConfig</literal> object are disabled as part of the rollback to prevent accidentally starting a new deployment process soon after the rollback is complete.</simpara>
<simpara>To re-enable the image change triggers:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc set triggers dc/&lt;name&gt; --auto</programlisting>
</listitem>
</orderedlist>
<note>
<simpara>Deployment configs also support automatically rolling back to the last successful revision of the configuration in case the latest deployment process fails. In that case, the latest template that failed to deploy stays intact by the system and it is up to users to fix their configurations.</simpara>
</note>
</section>
<section xml:id="deployments-exe-cmd-in-container_deployment-operations">
<title>Executing commands inside a container</title>
<simpara>You can add a command to a container, which modifies the container&#8217;s startup behavior by overruling the image&#8217;s <literal>ENTRYPOINT</literal>. This is different from a lifecycle hook, which instead can be run once per deployment at a specified time.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Add the <literal>command</literal> parameters to the <literal>spec</literal> field of the <literal>DeploymentConfig</literal> object. You can also add an <literal>args</literal> field, which modifies the <literal>command</literal> (or the <literal>ENTRYPOINT</literal> if <literal>command</literal> does not exist).</simpara>
<programlisting language="yaml" linenumbering="unnumbered">spec:
  containers:
  - name: &lt;container_name&gt;
    image: 'image'
    command:
      - '&lt;command&gt;'
    args:
      - '&lt;argument_1&gt;'
      - '&lt;argument_2&gt;'
      - '&lt;argument_3&gt;'</programlisting>
<simpara>For example, to execute the <literal>java</literal> command with the <literal>-jar</literal> and <literal>/opt/app-root/springboots2idemo.jar</literal> arguments:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">spec:
  containers:
  - name: example-spring-boot
    image: 'image'
    command:
      - java
    args:
      - '-jar'
      - /opt/app-root/springboots2idemo.jar</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="deployments-viewing-logs_deployment-operations">
<title>Viewing deployment logs</title>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To stream the logs of the latest revision for a given <literal>DeploymentConfig</literal> object:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc logs -f dc/&lt;name&gt;</programlisting>
<simpara>If the latest revision is running or failed, the command returns the logs of the process that is responsible for deploying your pods. If it is successful, it returns the logs from a pod of your application.</simpara>
</listitem>
<listitem>
<simpara>You can also view logs from older failed deployment processes, if and only if these processes (old replication controllers and their deployer pods) exist and have not been pruned or deleted manually:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc logs --version=1 dc/&lt;name&gt;</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="deployments-triggers_deployment-operations">
<title>Deployment triggers</title>
<simpara>A <literal>DeploymentConfig</literal> object can contain triggers, which drive the creation of new deployment processes in response to events inside the cluster.</simpara>
<warning>
<simpara>If no triggers are defined on a <literal>DeploymentConfig</literal> object, a config change trigger is added by default. If triggers are defined as an empty field, deployments must be started manually.</simpara>
</warning>
<bridgehead xml:id="deployments-configchange-trigger_deployment-operations" renderas="sect6">Config change deployment triggers</bridgehead>
<simpara>The config change trigger results in a new replication controller whenever configuration changes are detected in the pod template of the <literal>DeploymentConfig</literal> object.</simpara>
<note>
<simpara>If a config change trigger is defined on a <literal>DeploymentConfig</literal> object, the first replication controller is automatically created soon after the <literal>DeploymentConfig</literal> object itself is created and it is not paused.</simpara>
</note>
<formalpara>
<title>Config change deployment trigger</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">triggers:
  - type: "ConfigChange"</programlisting>
</para>
</formalpara>
<bridgehead xml:id="deployments-imagechange-trigger_deployment-operations" renderas="sect6">Image change deployment triggers</bridgehead>
<simpara>The image change trigger results in a new replication controller whenever the content of an image stream tag changes (when a new version of the image is pushed).</simpara>
<formalpara>
<title>Image change deployment trigger</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">triggers:
  - type: "ImageChange"
    imageChangeParams:
      automatic: true <co xml:id="CO19-1"/>
      from:
        kind: "ImageStreamTag"
        name: "origin-ruby-sample:latest"
        namespace: "myproject"
      containerNames:
        - "helloworld"</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO19-1">
<para>If the <literal>imageChangeParams.automatic</literal> field is set to <literal>false</literal>, the trigger is disabled.</para>
</callout>
</calloutlist>
<simpara>With the above example, when the <literal>latest</literal> tag value of the <literal>origin-ruby-sample</literal> image stream changes and the new image value differs from the current image specified in the <literal>DeploymentConfig</literal> object&#8217;s <literal>helloworld</literal> container, a new replication controller is created using the new image for the <literal>helloworld</literal> container.</simpara>
<note>
<simpara>If an image change trigger is defined on a <literal>DeploymentConfig</literal> object (with a config change trigger and <literal>automatic=false</literal>, or with <literal>automatic=true</literal>) and the image stream tag pointed by the image change trigger does not exist yet, the initial deployment process will automatically start as soon as an image is imported or pushed by a build to the image stream tag.</simpara>
</note>
<section xml:id="deployments-setting-triggers_deployment-operations">
<title>Setting deployment triggers</title>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>You can set deployment triggers for a <literal>DeploymentConfig</literal> object using the <literal>oc set triggers</literal> command. For example, to set a image change trigger, use the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc set triggers dc/&lt;dc_name&gt; \
    --from-image=&lt;project&gt;/&lt;image&gt;:&lt;tag&gt; -c &lt;container_name&gt;</programlisting>
</listitem>
</orderedlist>
</section>
</section>
<section xml:id="deployments-setting-resources_deployment-operations">
<title>Setting deployment resources</title>
<simpara>A deployment is completed by a pod that consumes resources (memory, CPU, and ephemeral storage) on a node. By default, pods consume unbounded node resources. However, if a project specifies default container limits, then pods consume resources up to those limits.</simpara>
<note>
<simpara>The minimum memory limit for a deployment is 12 MB. If a container fails to start due to a <literal>Cannot allocate memory</literal> pod event, the memory limit is too low. Either increase or remove the memory limit. Removing the limit allows pods to consume unbounded node resources.</simpara>
</note>
<simpara>You can also limit resource use by specifying resource limits as part of the deployment strategy. Deployment resources can be used with the recreate, rolling, or custom deployment strategies.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the following example, each of <literal>resources</literal>, <literal>cpu</literal>, <literal>memory</literal>, and <literal>ephemeral-storage</literal> is optional:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">type: "Recreate"
resources:
  limits:
    cpu: "100m" <co xml:id="CO20-1"/>
    memory: "256Mi" <co xml:id="CO20-2"/>
    ephemeral-storage: "1Gi" <co xml:id="CO20-3"/></programlisting>
<calloutlist>
<callout arearefs="CO20-1">
<para><literal>cpu</literal> is in CPU units: <literal>100m</literal> represents 0.1 CPU units (100 * 1e-3).</para>
</callout>
<callout arearefs="CO20-2">
<para><literal>memory</literal> is in bytes: <literal>256Mi</literal> represents 268435456 bytes (256 * 2 ^ 20).</para>
</callout>
<callout arearefs="CO20-3">
<para><literal>ephemeral-storage</literal> is in bytes: <literal>1Gi</literal> represents 1073741824 bytes (2 ^ 30).</para>
</callout>
</calloutlist>
<simpara>However, if a quota has been defined for your project, one of the following two items is required:</simpara>
<itemizedlist>
<listitem>
<simpara>A <literal>resources</literal> section set with an explicit <literal>requests</literal>:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">  type: "Recreate"
  resources:
    requests: <co xml:id="CO21-1"/>
      cpu: "100m"
      memory: "256Mi"
      ephemeral-storage: "1Gi"</programlisting>
<calloutlist>
<callout arearefs="CO21-1">
<para>The <literal>requests</literal> object contains the list of resources that correspond to the list of resources in the quota.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>A limit range defined in your project, where the defaults from the <literal>LimitRange</literal> object apply to pods created during the deployment process.</simpara>
</listitem>
</itemizedlist>
<simpara>To set deployment resources, choose one of the above options. Otherwise, deploy pod creation fails, citing a failure to satisfy quota.</simpara>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara>For more information about resource limits and requests, see <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/nodes/#nodes-cluster-resource-configure-about_nodes-cluster-resource-configure">Understanding managing application memory</link>.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="deployments-scaling-manually_deployment-operations">
<title>Scaling manually</title>
<simpara>In addition to rollbacks, you can exercise fine-grained control over the number of replicas by manually scaling them.</simpara>
<note>
<simpara>Pods can also be auto-scaled using the <literal>oc autoscale</literal> command.</simpara>
</note>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To manually scale a <literal>DeploymentConfig</literal> object, use the <literal>oc scale</literal> command. For example, the following command sets the replicas in the <literal>frontend</literal> <literal>DeploymentConfig</literal> object to <literal>3</literal>.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc scale dc frontend --replicas=3</programlisting>
<simpara>The number of replicas eventually propagates to the desired and current state of the deployment configured by the <literal>DeploymentConfig</literal> object <literal>frontend</literal>.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="deployments-accessing-private-repos_deployment-operations">
<title>Accessing private repositories from DeploymentConfig objects</title>
<simpara>You can add a secret to your <literal>DeploymentConfig</literal> object so that it can access images from a private repository. This procedure shows the OpenShift Container Platform web console method.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a new project.</simpara>
</listitem>
<listitem>
<simpara>From the <emphasis role="strong">Workloads</emphasis> page, create a secret that contains credentials for accessing a private image repository.</simpara>
</listitem>
<listitem>
<simpara>Create a <literal>DeploymentConfig</literal> object.</simpara>
</listitem>
<listitem>
<simpara>On the <literal>DeploymentConfig</literal> object editor page, set the <emphasis role="strong">Pull Secret</emphasis> and save your changes.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="deployments-assigning-pods-to-nodes_deployment-operations">
<title>Assigning pods to specific nodes</title>
<simpara>You can use node selectors in conjunction with labeled nodes to control pod
placement.</simpara>
<simpara>Cluster administrators can set the default node selector for a project in order
to restrict pod placement to specific nodes. As a developer, you can set a node
selector on a <literal>Pod</literal> configuration to restrict nodes even further.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To add a node selector when creating a pod, edit the <literal>Pod</literal> configuration, and add
the <literal>nodeSelector</literal> value. This can be added to a single <literal>Pod</literal> configuration, or in
a <literal>Pod</literal> template:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
spec:
  nodeSelector:
    disktype: ssd
...</programlisting>
<simpara>Pods created when the node selector is in place are assigned to nodes with the
specified labels. The labels specified here are used in conjunction with the
labels added by a cluster administrator.</simpara>
<simpara>For example, if a project has the <literal>type=user-node</literal> and <literal>region=east</literal> labels
added to a project by the cluster administrator, and you add the above
<literal>disktype: ssd</literal> label to a pod, the pod is only ever scheduled on nodes that
have all three labels.</simpara>
<note>
<simpara>Labels can only be set to one value, so setting a node selector of <literal>region=west</literal>
in a <literal>Pod</literal> configuration that has <literal>region=east</literal> as the administrator-set default,
results in a pod that will never be scheduled.</simpara>
</note>
</listitem>
</orderedlist>
</section>
<section xml:id="deployments-running-pod-svc-acct_deployment-operations">
<title>Running a pod with a different service account</title>
<simpara>You can run a pod with a service account other than the default.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Edit the <literal>DeploymentConfig</literal> object:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit dc/&lt;deployment_config&gt;</programlisting>
</listitem>
<listitem>
<simpara>Add the <literal>serviceAccount</literal> and <literal>serviceAccountName</literal> parameters to the <literal>spec</literal> field, and specify the service account you want to use:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">spec:
  securityContext: {}
  serviceAccount: &lt;service_account&gt;
  serviceAccountName: &lt;service_account&gt;</programlisting>
</listitem>
</orderedlist>
</section>
</section>
</section>
<section xml:id="deployment-strategies">
<title>Using deployment strategies</title>
<simpara><emphasis>Deployment strategies</emphasis> are used to change or upgrade applications without downtime so that users barely notice a change.</simpara>
<simpara>Because users generally access applications through a route handled by a router, deployment strategies can focus on <literal>DeploymentConfig</literal> object features or routing features. Strategies that focus on <literal>DeploymentConfig</literal> object features impact all routes that use the application. Strategies that use router features target individual routes.</simpara>
<simpara>Most deployment strategies are supported through the <literal>DeploymentConfig</literal> object, and some additional strategies are supported through router features.</simpara>
<section xml:id="choosing-deployment-strategies">
<title>Choosing a deployment strategy</title>
<simpara>Consider the following when choosing a deployment strategy:</simpara>
<itemizedlist>
<listitem>
<simpara>Long-running connections must be handled gracefully.</simpara>
</listitem>
<listitem>
<simpara>Database conversions can be complex and must be done and rolled back along with the application.</simpara>
</listitem>
<listitem>
<simpara>If the application is a hybrid of microservices and traditional components, downtime might be required to complete the transition.</simpara>
</listitem>
<listitem>
<simpara>You must have the infrastructure to do this.</simpara>
</listitem>
<listitem>
<simpara>If you have a non-isolated test environment, you can break both new and old versions.</simpara>
</listitem>
</itemizedlist>
<simpara>A deployment strategy uses readiness checks to determine if a new pod is ready for use. If a readiness check fails, the <literal>DeploymentConfig</literal> object retries to run the pod until it times out. The default timeout is <literal>10m</literal>, a value set in <literal>TimeoutSeconds</literal> in <literal>dc.spec.strategy.*params</literal>.</simpara>
</section>
<section xml:id="deployments-rolling-strategy_deployment-strategies">
<title>Rolling strategy</title>
<simpara>A rolling deployment slowly replaces instances of the previous version of an application with instances of the new version of the application. The rolling strategy is the default deployment strategy used if no strategy is specified on a <literal>DeploymentConfig</literal> object.</simpara>
<simpara>A rolling deployment typically waits for new pods to become <literal>ready</literal> via a readiness check before scaling down the old components. If a significant issue occurs, the rolling deployment can be aborted.</simpara>
<simpara><emphasis role="strong">When to use a rolling deployment:</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>When you want to take no downtime during an application update.</simpara>
</listitem>
<listitem>
<simpara>When your application supports having old code and new code running at the same time.</simpara>
</listitem>
</itemizedlist>
<simpara>A rolling deployment means you have both old and new versions of your code running at the same time. This typically requires that your application handle N-1 compatibility.</simpara>
<formalpara>
<title>Example rolling strategy definition</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">strategy:
  type: Rolling
  rollingParams:
    updatePeriodSeconds: 1 <co xml:id="CO22-1"/>
    intervalSeconds: 1 <co xml:id="CO22-2"/>
    timeoutSeconds: 120 <co xml:id="CO22-3"/>
    maxSurge: "20%" <co xml:id="CO22-4"/>
    maxUnavailable: "10%" <co xml:id="CO22-5"/>
    pre: {} <co xml:id="CO22-6"/>
    post: {}</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO22-1">
<para>The time to wait between individual pod updates. If unspecified, this value defaults to <literal>1</literal>.</para>
</callout>
<callout arearefs="CO22-2">
<para>The time to wait between polling the deployment status after update. If unspecified, this value defaults to <literal>1</literal>.</para>
</callout>
<callout arearefs="CO22-3">
<para>The time to wait for a scaling event before giving up. Optional; the default is <literal>600</literal>. Here, <emphasis>giving up</emphasis> means automatically rolling back to the previous complete deployment.</para>
</callout>
<callout arearefs="CO22-4">
<para><literal>maxSurge</literal> is optional and defaults to <literal>25%</literal> if not specified. See the information below the following procedure.</para>
</callout>
<callout arearefs="CO22-5">
<para><literal>maxUnavailable</literal> is optional and defaults to <literal>25%</literal> if not specified. See the information below the following procedure.</para>
</callout>
<callout arearefs="CO22-6">
<para><literal>pre</literal> and <literal>post</literal> are both lifecycle hooks.</para>
</callout>
</calloutlist>
<simpara>The rolling strategy:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Executes any <literal>pre</literal> lifecycle hook.</simpara>
</listitem>
<listitem>
<simpara>Scales up the new replication controller based on the surge count.</simpara>
</listitem>
<listitem>
<simpara>Scales down the old replication controller based on the max unavailable count.</simpara>
</listitem>
<listitem>
<simpara>Repeats this scaling until the new replication controller has reached the desired replica count and the old replication controller has been scaled to zero.</simpara>
</listitem>
<listitem>
<simpara>Executes any <literal>post</literal> lifecycle hook.</simpara>
</listitem>
</orderedlist>
<important>
<simpara>When scaling down, the rolling strategy waits for pods to become ready so it can decide whether further scaling would affect availability. If scaled up pods never become ready, the deployment process will eventually time out and result in a deployment failure.</simpara>
</important>
<simpara>The <literal>maxUnavailable</literal> parameter is the maximum number of pods that can be unavailable during the update. The <literal>maxSurge</literal> parameter is the maximum number of pods that can be scheduled above the original number of pods. Both parameters can be set to either a percentage (e.g., <literal>10%</literal>) or an absolute value (e.g., <literal>2</literal>). The default value for both is <literal>25%</literal>.</simpara>
<simpara>These parameters allow the deployment to be tuned for availability and speed. For example:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>maxUnavailable*=0</literal> and <literal>maxSurge*=20%</literal> ensures full capacity is maintained during the update and rapid scale up.</simpara>
</listitem>
<listitem>
<simpara><literal>maxUnavailable*=10%</literal> and <literal>maxSurge*=0</literal> performs an update using no extra capacity (an in-place update).</simpara>
</listitem>
<listitem>
<simpara><literal>maxUnavailable*=10%</literal> and <literal>maxSurge*=10%</literal> scales up and down quickly with some potential for capacity loss.</simpara>
</listitem>
</itemizedlist>
<simpara>Generally, if you want fast rollouts, use <literal>maxSurge</literal>. If you have to take into account resource quota and can accept partial unavailability, use
<literal>maxUnavailable</literal>.</simpara>
<section xml:id="deployments-canary-deployments_deployment-strategies">
<title>Canary deployments</title>
<simpara>All rolling deployments in OpenShift Container Platform are <emphasis>canary deployments</emphasis>; a new version (the canary) is tested before all of the old instances are replaced. If the readiness check never succeeds, the canary instance is removed and the <literal>DeploymentConfig</literal> object will be automatically rolled back.</simpara>
<simpara>The readiness check is part of the application code and can be as sophisticated as necessary to ensure the new instance is ready to be used. If you must implement more complex checks of the application (such as sending real user workloads to the new instance), consider implementing a custom deployment or using a blue-green deployment strategy.</simpara>
</section>
<section xml:id="deployments-creating-rolling-deployment_deployment-strategies">
<title>Creating a rolling deployment</title>
<simpara>Rolling deployments are the default type in OpenShift Container Platform. You can create a rolling deployment using the CLI.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create an application based on the example deployment images found in <link xlink:href="https://quay.io/repository/openshifttest/deployment-example">Quay.io</link>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app quay.io/openshifttest/deployment-example:latest</programlisting>
</listitem>
<listitem>
<simpara>If you have the router installed, make the application available via a route or use the service IP directly.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc expose svc/deployment-example</programlisting>
</listitem>
<listitem>
<simpara>Browse to the application at <literal>deployment-example.&lt;project&gt;.&lt;router_domain&gt;</literal> to verify you see the <literal>v1</literal> image.</simpara>
</listitem>
<listitem>
<simpara>Scale the <literal>DeploymentConfig</literal> object up to three replicas:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc scale dc/deployment-example --replicas=3</programlisting>
</listitem>
<listitem>
<simpara>Trigger a new deployment automatically by tagging a new version of the example as the <literal>latest</literal> tag:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc tag deployment-example:v2 deployment-example:latest</programlisting>
</listitem>
<listitem>
<simpara>In your browser, refresh the page until you see the <literal>v2</literal> image.</simpara>
</listitem>
<listitem>
<simpara>When using the CLI, the following command shows how many pods are on version 1 and how many are on version 2. In the web console, the pods are progressively added to v2 and removed from v1:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc describe dc deployment-example</programlisting>
</listitem>
</orderedlist>
<simpara>During the deployment process, the new replication controller is incrementally scaled up. After the new pods are marked as <literal>ready</literal> (by passing their readiness check), the deployment process continues.</simpara>
<simpara>If the pods do not become ready, the process aborts, and the deployment rolls back to its previous version.</simpara>
</section>
<section xml:id="odc-editing-deployments_rolling-strategy">
<title>Editing a deployment by using the Developer perspective</title>
<simpara>You can edit the deployment strategy, image settings, environment variables, and advanced options for your deployment by using the <emphasis role="strong">Developer</emphasis> perspective.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You are in the <emphasis role="strong">Developer</emphasis> perspective of the web console.</simpara>
</listitem>
<listitem>
<simpara>You have created an application.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to the <emphasis role="strong">Topology</emphasis> view. Click on your application to see the <emphasis role="strong">Details</emphasis> panel.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Actions</emphasis> drop-down menu, select <emphasis role="strong">Edit Deployment</emphasis> to view the <emphasis role="strong">Edit Deployment</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>You can edit the following <emphasis role="strong">Advanced options</emphasis> for your deployment:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Optional: You can pause rollouts by clicking <emphasis role="strong">Pause rollouts</emphasis>, and then selecting the <emphasis role="strong">Pause rollouts for this deployment</emphasis> checkbox.</simpara>
<simpara>By pausing rollouts, you can make changes to your application without triggering a rollout. You can resume rollouts at any time.</simpara>
</listitem>
<listitem>
<simpara>Optional: Click <emphasis role="strong">Scaling</emphasis> to change the number of instances of your image by modifying the number of <emphasis role="strong">Replicas</emphasis>.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Save</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-starting-rolling-deployment_rolling-strategy">
<title>Starting a rolling deployment using the Developer perspective</title>
<simpara>You can upgrade an application by starting a rolling deployment.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You are in the <emphasis role="strong">Developer</emphasis> perspective of the web console.</simpara>
</listitem>
<listitem>
<simpara>You have created an application.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the <emphasis role="strong">Topology</emphasis> view of the <emphasis role="strong">Developer</emphasis> perspective, click on the application node to see the <emphasis role="strong">Overview</emphasis> tab in the side panel. Note that the <emphasis role="strong">Update Strategy</emphasis> is set to the default <emphasis role="strong">Rolling</emphasis> strategy.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Actions</emphasis> drop-down menu, select <emphasis role="strong">Start Rollout</emphasis> to start a rolling update. The rolling deployment spins up the new version of the application and then terminates the old one.</simpara>
<figure>
<title>Rolling update</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc-rolling-update.png"/>
</imageobject>
<textobject><phrase>odc rolling update</phrase></textobject>
</mediaobject>
</figure>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link linkend="odc-creating-applications-using-developer-perspective">Creating and deploying applications on OpenShift Container Platform using the <emphasis role="strong">Developer</emphasis> perspective</link></simpara>
</listitem>
<listitem>
<simpara><link linkend="odc-viewing-application-composition-using-topology-view">Viewing the applications in your project</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="deployments-recreate-strategy_rolling-strategy">
<title>Recreate strategy</title>
<simpara>The recreate strategy has basic rollout behavior and supports lifecycle hooks for injecting code into the deployment process.</simpara>
<formalpara>
<title>Example recreate strategy definition</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">strategy:
  type: Recreate
  recreateParams: <co xml:id="CO23-1"/>
    pre: {} <co xml:id="CO23-2"/>
    mid: {}
    post: {}</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO23-1">
<para><literal>recreateParams</literal> are optional.</para>
</callout>
<callout arearefs="CO23-2">
<para><literal>pre</literal>, <literal>mid</literal>, and <literal>post</literal> are lifecycle hooks.</para>
</callout>
</calloutlist>
<simpara>The recreate strategy:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Executes any <literal>pre</literal> lifecycle hook.</simpara>
</listitem>
<listitem>
<simpara>Scales down the previous deployment to zero.</simpara>
</listitem>
<listitem>
<simpara>Executes any <literal>mid</literal> lifecycle hook.</simpara>
</listitem>
<listitem>
<simpara>Scales up the new deployment.</simpara>
</listitem>
<listitem>
<simpara>Executes any <literal>post</literal> lifecycle hook.</simpara>
</listitem>
</orderedlist>
<important>
<simpara>During scale up, if the replica count of the deployment is greater than one, the first replica of the deployment will be validated for readiness before fully scaling up the deployment. If the validation of the first replica fails, the deployment will be considered a failure.</simpara>
</important>
<simpara><emphasis role="strong">When to use a recreate deployment:</emphasis></simpara>
<itemizedlist>
<listitem>
<simpara>When you must run migrations or other data transformations before your new code starts.</simpara>
</listitem>
<listitem>
<simpara>When you do not support having new and old versions of your application code running at the same time.</simpara>
</listitem>
<listitem>
<simpara>When you want to use a RWO volume, which is not supported being shared between multiple replicas.</simpara>
</listitem>
</itemizedlist>
<simpara>A recreate deployment incurs downtime because, for a brief period, no instances of your application are running. However, your old code and new code do not run at the same time.</simpara>
<section xml:id="odc-editing-deployments_recreate-strategy">
<title>Editing a deployment by using the Developer perspective</title>
<simpara>You can edit the deployment strategy, image settings, environment variables, and advanced options for your deployment by using the <emphasis role="strong">Developer</emphasis> perspective.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You are in the <emphasis role="strong">Developer</emphasis> perspective of the web console.</simpara>
</listitem>
<listitem>
<simpara>You have created an application.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to the <emphasis role="strong">Topology</emphasis> view. Click on your application to see the <emphasis role="strong">Details</emphasis> panel.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Actions</emphasis> drop-down menu, select <emphasis role="strong">Edit Deployment</emphasis> to view the <emphasis role="strong">Edit Deployment</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>You can edit the following <emphasis role="strong">Advanced options</emphasis> for your deployment:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Optional: You can pause rollouts by clicking <emphasis role="strong">Pause rollouts</emphasis>, and then selecting the <emphasis role="strong">Pause rollouts for this deployment</emphasis> checkbox.</simpara>
<simpara>By pausing rollouts, you can make changes to your application without triggering a rollout. You can resume rollouts at any time.</simpara>
</listitem>
<listitem>
<simpara>Optional: Click <emphasis role="strong">Scaling</emphasis> to change the number of instances of your image by modifying the number of <emphasis role="strong">Replicas</emphasis>.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Save</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-starting-recreate-deployment_recreate-strategy">
<title>Starting a recreate deployment using the Developer perspective</title>
<simpara>You can switch the deployment strategy from the default rolling update to a recreate update using the <emphasis role="strong">Developer</emphasis> perspective in the web console.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Ensure that you are in the <emphasis role="strong">Developer</emphasis> perspective of the web console.</simpara>
</listitem>
<listitem>
<simpara>Ensure that you have created an application using the <emphasis role="strong">Add</emphasis> view and see it deployed in the <emphasis role="strong">Topology</emphasis> view.</simpara>
</listitem>
</itemizedlist>
<formalpara>
<title>Procedure</title>
<para>To switch to a recreate update strategy and to upgrade an application:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>In the <emphasis role="strong">Actions</emphasis> drop-down menu, select <emphasis role="strong">Edit Deployment Config</emphasis> to see the deployment configuration details of the application.</simpara>
</listitem>
<listitem>
<simpara>In the YAML editor, change the <literal>spec.strategy.type</literal> to <literal>Recreate</literal> and click <emphasis role="strong">Save</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Topology</emphasis> view, select the node to see the <emphasis role="strong">Overview</emphasis> tab in the side panel. The <emphasis role="strong">Update Strategy</emphasis> is now set to <emphasis role="strong">Recreate</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Use the <emphasis role="strong">Actions</emphasis> drop-down menu to select <emphasis role="strong">Start Rollout</emphasis> to start an update using the recreate strategy. The recreate strategy first terminates pods for the older version of the application and then spins up pods for the new version.</simpara>
<figure>
<title>Recreate update</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc-recreate-update.png"/>
</imageobject>
<textobject><phrase>odc recreate update</phrase></textobject>
</mediaobject>
</figure>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link linkend="odc-creating-applications-using-developer-perspective">Creating and deploying applications on OpenShift Container Platform using the <emphasis role="strong">Developer</emphasis> perspective</link></simpara>
</listitem>
<listitem>
<simpara><link linkend="odc-viewing-application-composition-using-topology-view">Viewing the applications in your project</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="deployments-custom-strategy_recreate-strategy">
<title>Custom strategy</title>
<simpara>The custom strategy allows you to provide your own deployment behavior.</simpara>
<formalpara>
<title>Example custom strategy definition</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">strategy:
  type: Custom
  customParams:
    image: organization/strategy
    command: [ "command", "arg1" ]
    environment:
      - name: ENV_1
        value: VALUE_1</programlisting>
</para>
</formalpara>
<simpara>In the above example, the <literal>organization/strategy</literal> container image provides the deployment behavior. The optional <literal>command</literal> array overrides any <literal>CMD</literal> directive specified in the image&#8217;s <literal>Dockerfile</literal>. The optional environment variables provided are added to the execution environment of the strategy process.</simpara>
<simpara>Additionally, OpenShift Container Platform provides the following environment variables to the deployment process:</simpara>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="2">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="66.6667*"/>
<thead>
<row>
<entry align="left" valign="top">Environment variable</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="middle"><simpara><literal>OPENSHIFT_DEPLOYMENT_NAME</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The name of the new deployment, a replication controller.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>OPENSHIFT_DEPLOYMENT_NAMESPACE</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The name space of the new deployment.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>The replica count of the new deployment will initially be zero. The responsibility of the strategy is to make the new deployment active using the
logic that best serves the needs of the user.</simpara>
<simpara>Alternatively, use the <literal>customParams</literal> object to inject the custom deployment logic into the existing deployment strategies. Provide a custom shell script logic and call the <literal>openshift-deploy</literal> binary. Users do not have to supply their custom deployer container image; in this case, the default OpenShift Container Platform deployer image is used instead:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">strategy:
  type: Rolling
  customParams:
    command:
    - /bin/sh
    - -c
    - |
      set -e
      openshift-deploy --until=50%
      echo Halfway there
      openshift-deploy
      echo Complete</programlisting>
<simpara>This results in following deployment:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">Started deployment #2
--&gt; Scaling up custom-deployment-2 from 0 to 2, scaling down custom-deployment-1 from 2 to 0 (keep 2 pods available, don't exceed 3 pods)
    Scaling custom-deployment-2 up to 1
--&gt; Reached 50% (currently 50%)
Halfway there
--&gt; Scaling up custom-deployment-2 from 1 to 2, scaling down custom-deployment-1 from 2 to 0 (keep 2 pods available, don't exceed 3 pods)
    Scaling custom-deployment-1 down to 1
    Scaling custom-deployment-2 up to 2
    Scaling custom-deployment-1 down to 0
--&gt; Success
Complete</programlisting>
<simpara>If the custom deployment strategy process requires access to the OpenShift Container Platform API or the Kubernetes API the container that executes the strategy can use the service account token available inside the container for authentication.</simpara>
<section xml:id="odc-editing-deployments_custom-strategy">
<title>Editing a deployment by using the Developer perspective</title>
<simpara>You can edit the deployment strategy, image settings, environment variables, and advanced options for your deployment by using the <emphasis role="strong">Developer</emphasis> perspective.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You are in the <emphasis role="strong">Developer</emphasis> perspective of the web console.</simpara>
</listitem>
<listitem>
<simpara>You have created an application.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to the <emphasis role="strong">Topology</emphasis> view. Click on your application to see the <emphasis role="strong">Details</emphasis> panel.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Actions</emphasis> drop-down menu, select <emphasis role="strong">Edit Deployment</emphasis> to view the <emphasis role="strong">Edit Deployment</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>You can edit the following <emphasis role="strong">Advanced options</emphasis> for your deployment:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Optional: You can pause rollouts by clicking <emphasis role="strong">Pause rollouts</emphasis>, and then selecting the <emphasis role="strong">Pause rollouts for this deployment</emphasis> checkbox.</simpara>
<simpara>By pausing rollouts, you can make changes to your application without triggering a rollout. You can resume rollouts at any time.</simpara>
</listitem>
<listitem>
<simpara>Optional: Click <emphasis role="strong">Scaling</emphasis> to change the number of instances of your image by modifying the number of <emphasis role="strong">Replicas</emphasis>.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Save</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
</section>
<section xml:id="deployments-lifecycle-hooks_custom-strategy">
<title>Lifecycle hooks</title>
<simpara>The rolling and recreate strategies support <emphasis>lifecycle hooks</emphasis>, or deployment hooks, which allow behavior to be injected into the deployment process at predefined points within the strategy:</simpara>
<formalpara>
<title>Example <literal>pre</literal> lifecycle hook</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">pre:
  failurePolicy: Abort
  execNewPod: {} <co xml:id="CO24-1"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO24-1">
<para><literal>execNewPod</literal> is a pod-based lifecycle hook.</para>
</callout>
</calloutlist>
<simpara>Every hook has a <emphasis>failure policy</emphasis>, which defines the action the strategy should take when a hook failure is encountered:</simpara>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="2">
<colspec colname="col_1" colwidth="20*"/>
<colspec colname="col_2" colwidth="80*"/>
<tbody>
<row>
<entry align="left" valign="middle"><simpara><literal>Abort</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The deployment process will be considered a failure if the hook fails.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>Retry</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The hook execution should be retried until it succeeds.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>Ignore</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Any hook failure should be ignored and the deployment should proceed.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>Hooks have a type-specific field that describes how to execute the hook. Currently, pod-based hooks are the only supported hook type, specified by the <literal>execNewPod</literal> field.</simpara>
<bridgehead xml:id="_pod-based-lifecycle-hook" renderas="sect6">Pod-based lifecycle hook</bridgehead>
<simpara>Pod-based lifecycle hooks execute hook code in a new pod derived from the template in a <literal>DeploymentConfig</literal> object.</simpara>
<simpara>The following simplified example deployment uses the rolling strategy. Triggers and some other minor details are omitted for brevity:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">kind: DeploymentConfig
apiVersion: apps.openshift.io/v1
metadata:
  name: frontend
spec:
  template:
    metadata:
      labels:
        name: frontend
    spec:
      containers:
        - name: helloworld
          image: openshift/origin-ruby-sample
  replicas: 5
  selector:
    name: frontend
  strategy:
    type: Rolling
    rollingParams:
      pre:
        failurePolicy: Abort
        execNewPod:
          containerName: helloworld <co xml:id="CO25-1"/>
          command: [ "/usr/bin/command", "arg1", "arg2" ] <co xml:id="CO25-2"/>
          env: <co xml:id="CO25-3"/>
            - name: CUSTOM_VAR1
              value: custom_value1
          volumes:
            - data <co xml:id="CO25-4"/></programlisting>
<calloutlist>
<callout arearefs="CO25-1">
<para>The <literal>helloworld</literal> name refers to <literal>spec.template.spec.containers[0].name</literal>.</para>
</callout>
<callout arearefs="CO25-2">
<para>This <literal>command</literal> overrides any <literal>ENTRYPOINT</literal> defined by the <literal>openshift/origin-ruby-sample</literal> image.</para>
</callout>
<callout arearefs="CO25-3">
<para><literal>env</literal> is an optional set of environment variables for the hook container.</para>
</callout>
<callout arearefs="CO25-4">
<para><literal>volumes</literal> is an optional set of volume references for the hook container.</para>
</callout>
</calloutlist>
<simpara>In this example, the <literal>pre</literal> hook will be executed in a new pod using the <literal>openshift/origin-ruby-sample</literal> image from the <literal>helloworld</literal> container. The hook pod has the following properties:</simpara>
<itemizedlist>
<listitem>
<simpara>The hook command is <literal>/usr/bin/command arg1 arg2</literal>.</simpara>
</listitem>
<listitem>
<simpara>The hook container has the <literal>CUSTOM_VAR1=custom_value1</literal> environment variable.</simpara>
</listitem>
<listitem>
<simpara>The hook failure policy is <literal>Abort</literal>, meaning the deployment process fails if the hook fails.</simpara>
</listitem>
<listitem>
<simpara>The hook pod inherits the <literal>data</literal> volume from the <literal>DeploymentConfig</literal> object pod.</simpara>
</listitem>
</itemizedlist>
<section xml:id="deployments-setting-lifecycle-hooks_custom-strategy">
<title>Setting lifecycle hooks</title>
<simpara>You can set lifecycle hooks, or deployment hooks, for a deployment using the CLI.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Use the <literal>oc set deployment-hook</literal> command to set the type of hook you want: <literal>--pre</literal>, <literal>--mid</literal>, or <literal>--post</literal>. For example, to set a pre-deployment hook:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc set deployment-hook dc/frontend \
    --pre -c helloworld -e CUSTOM_VAR1=custom_value1 \
    --volumes data --failure-policy=abort -- /usr/bin/command arg1 arg2</programlisting>
</listitem>
</orderedlist>
</section>
</section>
</section>
<section xml:id="route-based-deployment-strategies">
<title>Using route-based deployment strategies</title>
<simpara>Deployment strategies provide a way for the application to evolve. Some strategies use <literal>Deployment</literal> objects to make changes that are seen by users of all routes that resolve to the application. Other advanced strategies, such as the ones described in this section, use router features in conjunction with <literal>Deployment</literal> objects to impact specific routes.</simpara>
<simpara>The most common route-based strategy is to use a <emphasis>blue-green deployment</emphasis>. The new version (the green version) is brought up for testing and evaluation, while the users still use the stable version (the blue version). When ready, the users are switched to the green version. If a problem arises, you can switch back to the blue version.</simpara>
<simpara>A common alternative strategy is to use <emphasis>A/B versions</emphasis> that are both active at the same time and some users use one version, and some users use the other version. This can be used for experimenting with user interface changes and other features to get user feedback. It can also be used to verify proper operation in a production context where problems impact a limited number of users.</simpara>
<simpara>A canary deployment tests the new version but when a problem is detected it quickly falls back to the previous version. This can be done with both of the above strategies.</simpara>
<simpara>The route-based deployment strategies do not scale the number of pods in the services. To maintain desired performance characteristics the deployment configurations might have to be scaled.</simpara>
<section xml:id="deployments-proxy-shard_route-based-deployment-strategies">
<title>Proxy shards and traffic splitting</title>
<simpara>In production environments, you can precisely control the distribution of
traffic that lands on a particular shard. When dealing with large numbers of
instances, you can use the relative scale of individual shards to implement
percentage based traffic. That combines well with a <emphasis>proxy shard</emphasis>, which
forwards or splits the traffic it receives to a separate service or application
running elsewhere.</simpara>
<simpara>In the simplest configuration, the proxy forwards requests unchanged. In
more complex setups, you can duplicate the incoming requests and send to
both a separate cluster as well as to a local instance of the application, and
compare the result. Other patterns include keeping the caches of a DR
installation warm, or sampling incoming traffic for analysis purposes.</simpara>
<simpara>Any TCP (or UDP) proxy could be run under the desired shard. Use the <literal>oc scale</literal>
command to alter the relative number of instances serving requests under the
proxy shard. For more complex traffic management, consider customizing the
OpenShift Container Platform router with proportional balancing capabilities.</simpara>
</section>
<section xml:id="deployments-n1-compatibility_route-based-deployment-strategies">
<title>N-1 compatibility</title>
<simpara>Applications that have new code and old code running at the same time must be
careful to ensure that data written by the new code can be read and handled (or
gracefully ignored) by the old version of the code. This is sometimes called
<emphasis>schema evolution</emphasis> and is a complex problem.</simpara>
<simpara>This can take many forms: data stored on disk, in a database, in a temporary
cache, or that is part of a user&#8217;s browser session. While most web applications
can support rolling deployments, it is important to test and design your
application to handle it.</simpara>
<simpara>For some applications, the period of time that old code and new code is running
side by side is short, so bugs or some failed user transactions are acceptable.
For others, the failure pattern may result in the entire application becoming
non-functional.</simpara>
<simpara>One way to validate N-1 compatibility is to use an A/B deployment: run the old
code and new code at the same time in a controlled way in a test environment,
and verify that traffic that flows to the new deployment does not cause failures
in the old deployment.</simpara>
</section>
<section xml:id="deployments-graceful-termination_route-based-deployment-strategies">
<title>Graceful termination</title>
<simpara>OpenShift Container Platform and Kubernetes give application instances time to shut down before removing them from load balancing rotations. However, applications must ensure they cleanly terminate user connections as well before they exit.</simpara>
<simpara>On shutdown, OpenShift Container Platform sends a <literal>TERM</literal> signal to the processes in the container. Application code, on receiving <literal>SIGTERM</literal>, stop accepting new connections. This ensures that load balancers route traffic to other active instances. The application code then waits until all open connections are closed, or gracefully terminate individual connections at the next opportunity, before exiting.</simpara>
<simpara>After the graceful termination period expires, a process that has not exited is sent the <literal>KILL</literal> signal, which immediately ends the process. The
<literal>terminationGracePeriodSeconds</literal> attribute of a pod or pod template controls the graceful termination period (default 30 seconds) and can be customized per application as necessary.</simpara>
</section>
<section xml:id="deployments-blue-green_route-based-deployment-strategies">
<title>Blue-green deployments</title>
<simpara>Blue-green deployments involve running two versions of an application at the same time and moving traffic from the in-production version (the blue version) to the newer version (the green version). You can use a rolling strategy or switch services in a route.</simpara>
<simpara>Because many applications depend on persistent data, you must have an application that supports <emphasis>N-1 compatibility</emphasis>, which means it shares data and implements live migration between the database, store, or disk by creating two copies of the data layer.</simpara>
<simpara>Consider the data used in testing the new version. If it is the production data, a bug in the new version can break the production version.</simpara>
<section xml:id="deployments-blue-green-setting-up_route-based-deployment-strategies">
<title>Setting up a blue-green deployment</title>
<simpara>Blue-green deployments use two <literal>Deployment</literal> objects. Both are running, and the one in production depends on the service the route specifies, with each <literal>Deployment</literal> object exposed to a different service.</simpara>
<note>
<simpara>Routes are intended for web (HTTP and HTTPS) traffic, so this technique is best suited for web applications.</simpara>
</note>
<simpara>You can create a new route to the new version and test it. When ready, change the service in the production route to point to the new service and the new (green) version is live.</simpara>
<simpara>If necessary, you can roll back to the older (blue) version by switching the service back to the previous version.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create two independent application components.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Create a copy of the example application running the <literal>v1</literal> image under the <literal>example-blue</literal> service:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app openshift/deployment-example:v1 --name=example-blue</programlisting>
</listitem>
<listitem>
<simpara>Create a second copy that uses the <literal>v2</literal> image under the <literal>example-green</literal> service:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app openshift/deployment-example:v2 --name=example-green</programlisting>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Create a route that points to the old service:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc expose svc/example-blue --name=bluegreen-example</programlisting>
</listitem>
<listitem>
<simpara>Browse to the application at <literal>bluegreen-example-&lt;project&gt;.&lt;router_domain&gt;</literal> to verify you see the <literal>v1</literal> image.</simpara>
</listitem>
<listitem>
<simpara>Edit the route and change the service name to <literal>example-green</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc patch route/bluegreen-example -p '{"spec":{"to":{"name":"example-green"}}}'</programlisting>
</listitem>
<listitem>
<simpara>To verify that the route has changed, refresh the browser until you see the <literal>v2</literal> image.</simpara>
</listitem>
</orderedlist>
</section>
</section>
<section xml:id="deployments-ab-testing_route-based-deployment-strategies">
<title>A/B deployments</title>
<simpara>The A/B deployment strategy lets you try a new version of the application in a
limited way in the production environment. You can specify that the production
version gets most of the user requests while a limited fraction of requests go
to the new version.</simpara>
<simpara>Because you control the portion of requests to each version, as testing
progresses you can increase the fraction of requests to the new version and
ultimately stop using the previous version. As you adjust the request load on
each version, the number of pods in each service might have to be scaled as well
to provide the expected performance.</simpara>
<simpara>In addition to upgrading software, you can use this feature to experiment with
versions of the user interface. Since some users get the old version and some
the new, you can evaluate the user&#8217;s reaction to the different versions to
inform design decisions.</simpara>
<simpara>For this to be effective, both the old and new versions must be similar enough
that both can run at the same time. This is common with bug fix releases and
when new features do not interfere with the old. The versions require N-1
compatibility to properly work together.</simpara>
<simpara>OpenShift Container Platform supports N-1 compatibility through the web console as well as
the CLI.</simpara>
<section xml:id="deployments-ab-testing-lb_route-based-deployment-strategies">
<title>Load balancing for A/B testing</title>
<simpara>The user sets up a route with multiple services. Each service handles a version of the application.</simpara>
<simpara>Each service is assigned a <literal>weight</literal> and the portion of requests to each service is the <literal>service_weight</literal> divided by the <literal>sum_of_weights</literal>. The <literal>weight</literal> for each service is distributed to the service&#8217;s endpoints so that the sum of the endpoint <literal>weights</literal> is the service <literal>weight</literal>.</simpara>
<simpara>The route can have up to four services. The <literal>weight</literal> for the service can be between <literal>0</literal> and <literal>256</literal>. When the <literal>weight</literal> is <literal>0</literal>, the service does not participate in load-balancing but continues to serve existing persistent connections. When the service <literal>weight</literal> is not <literal>0</literal>, each endpoint has a minimum <literal>weight</literal> of <literal>1</literal>. Because of this, a service with a lot of endpoints can end up with higher <literal>weight</literal> than intended. In this case, reduce the number of pods to get the expected load balance <literal>weight</literal>.</simpara>
<formalpara>
<title>Procedure</title>
<para>To set up the A/B environment:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Create the two applications and give them different names. Each creates a <literal>Deployment</literal> object. The applications are versions of the same program; one is usually the current production version and the other the proposed new version.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Create the first application. The following example creates an application called <literal>ab-example-a</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app openshift/deployment-example --name=ab-example-a</programlisting>
</listitem>
<listitem>
<simpara>Create the second application:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app openshift/deployment-example:v2 --name=ab-example-b</programlisting>
<simpara>Both applications are deployed and services are created.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Make the application available externally via a route. At this point, you can expose either. It can be convenient to expose the current production version first and later modify the route to add the new version.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc expose svc/ab-example-a</programlisting>
<simpara>Browse to the application at <literal>ab-example-a.&lt;project&gt;.&lt;router_domain&gt;</literal> to verify that you see the expected version.</simpara>
</listitem>
<listitem>
<simpara>When you deploy the route, the router balances the traffic according to the <literal>weights</literal> specified for the services. At this point, there is a single service with default <literal>weight=1</literal> so all requests go to it. Adding the other service as an <literal>alternateBackends</literal> and adjusting the <literal>weights</literal> brings the A/B setup to life. This can be done by the <literal>oc set route-backends</literal> command or by editing the route.</simpara>
<note>
<simpara>When using <literal>alternateBackends</literal>, also use the <literal>roundrobin</literal> load-balancing strategy to ensure requests are distributed as expected to the services based on weight. <literal>roundrobin</literal> can be set for a route by using a <link xlink:href="https://docs.openshift.com/container-platform/4.13/networking/routes/route-configuration.html#nw-route-specific-annotations_route-configuration">route annotation</link>.</simpara>
</note>
<simpara>Setting the <literal>oc set route-backend</literal> to <literal>0</literal> means the service does not participate in load-balancing, but continues to serve existing persistent connections.</simpara>
<note>
<simpara>Changes to the route just change the portion of traffic to the various services. You might have to scale the deployment to adjust the number of pods to handle the anticipated loads.</simpara>
</note>
<simpara>To edit the route, run:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit route &lt;route_name&gt;</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">...
metadata:
  name: route-alternate-service
  annotations:
    haproxy.router.openshift.io/balance: roundrobin
spec:
  host: ab-example.my-project.my-domain
  to:
    kind: Service
    name: ab-example-a
    weight: 10
  alternateBackends:
  - kind: Service
    name: ab-example-b
    weight: 15
...</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
<section xml:id="deployments-ab-testing-lb-web_route-based-deployment-strategies">
<title>Managing weights of an existing route using the web console</title>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to the <emphasis role="strong">Networking</emphasis> &#8594; <emphasis role="strong">Routes</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Click the Actions menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> next to the route you want to edit and select <emphasis role="strong">Edit Route</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Edit the YAML file. Update the <literal>weight</literal> to be an integer between <literal>0</literal> and <literal>256</literal> that specifies the relative weight of the target against other target reference objects. The value <literal>0</literal> suppresses requests to this back end. The default is <literal>100</literal>. Run <literal>oc explain routes.spec.alternateBackends</literal> for more information about the options.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Save</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="deployments-ab-testing-lb-web-new-route_route-based-deployment-strategies">
<title>Managing weights of an new route using the web console</title>
<orderedlist numeration="arabic">
<listitem>
<simpara>Navigate to the <emphasis role="strong">Networking</emphasis> &#8594; <emphasis role="strong">Routes</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Create Route</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Enter the route <emphasis role="strong">Name</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select the <emphasis role="strong">Service</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Add Alternate Service</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Enter a value for <emphasis role="strong">Weight</emphasis> and <emphasis role="strong">Alternate Service Weight</emphasis>. Enter a number between <literal>0</literal> and <literal>255</literal> that depicts relative weight compared with other targets. The default is <literal>100</literal>.</simpara>
</listitem>
<listitem>
<simpara>Select the <emphasis role="strong">Target Port</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Create</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="deployments-ab-testing-lb-cli_route-based-deployment-strategies">
<title>Managing weights using the CLI</title>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To manage the services and corresponding weights load balanced by the route, use the <literal>oc set route-backends</literal> command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc set route-backends ROUTENAME \
    [--zero|--equal] [--adjust] SERVICE=WEIGHT[%] [...] [options]</programlisting>
<simpara>For example, the following sets <literal>ab-example-a</literal> as the primary service with <literal>weight=198</literal> and <literal>ab-example-b</literal> as the first alternate service with a <literal>weight=2</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc set route-backends ab-example ab-example-a=198 ab-example-b=2</programlisting>
<simpara>This means 99% of traffic is sent to service <literal>ab-example-a</literal> and 1% to service <literal>ab-example-b</literal>.</simpara>
<simpara>This command does not scale the deployment. You might be required to do so to have enough pods to handle the request load.</simpara>
</listitem>
<listitem>
<simpara>Run the command with no flags to verify the current configuration:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc set route-backends ab-example</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                    KIND     TO           WEIGHT
routes/ab-example       Service  ab-example-a 198 (99%)
routes/ab-example       Service  ab-example-b 2   (1%)</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>To alter the weight of an individual service relative to itself or to the primary service, use the <literal>--adjust</literal> flag. Specifying a percentage adjusts the service relative to either the primary or the first alternate (if you specify the primary). If there are other backends, their weights are kept proportional to the changed.</simpara>
<simpara>The following example alters the weight of <literal>ab-example-a</literal> and <literal>ab-example-b</literal> services:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc set route-backends ab-example --adjust ab-example-a=200 ab-example-b=10</programlisting>
<simpara>Alternatively, alter the weight of a service by specifying a percentage:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc set route-backends ab-example --adjust ab-example-b=5%</programlisting>
<simpara>By specifying <literal>+</literal> before the percentage declaration, you can adjust a weighting relative to the current setting. For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc set route-backends ab-example --adjust ab-example-b=+15%</programlisting>
<simpara>The <literal>--equal</literal> flag sets the <literal>weight</literal> of all services to <literal>100</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc set route-backends ab-example --equal</programlisting>
<simpara>The <literal>--zero</literal> flag sets the <literal>weight</literal> of all services to <literal>0</literal>. All requests then return with a 503 error.</simpara>
<note>
<simpara>Not all routers may support multiple or weighted backends.</simpara>
</note>
</listitem>
</orderedlist>
</section>
<section xml:id="deployments-ab-one-service-multi-dc_route-based-deployment-strategies">
<title>One service, multiple <literal>Deployment</literal> objects</title>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a new application, adding a label <literal>ab-example=true</literal> that will be common to all shards:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app openshift/deployment-example --name=ab-example-a --as-deployment-config=true --labels=ab-example=true --env=SUBTITLE\=shardA
$ oc delete svc/ab-example-a</programlisting>
<simpara>The application is deployed and a service is created. This is the first shard.</simpara>
</listitem>
<listitem>
<simpara>Make the application available via a route, or use the service IP directly:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc expose deployment ab-example-a --name=ab-example --selector=ab-example\=true
$ oc expose service ab-example</programlisting>
</listitem>
<listitem>
<simpara>Browse to the application at <literal>ab-example-&lt;project_name&gt;.&lt;router_domain&gt;</literal> to verify you see the <literal>v1</literal> image.</simpara>
</listitem>
<listitem>
<simpara>Create a second shard based on the same source image and label as the first shard, but with a different tagged version and unique environment variables:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-app openshift/deployment-example:v2 \
    --name=ab-example-b --labels=ab-example=true \
    SUBTITLE="shard B" COLOR="red" --as-deployment-config=true
$ oc delete svc/ab-example-b</programlisting>
</listitem>
<listitem>
<simpara>At this point, both sets of pods are being served under the route. However, because both browsers (by leaving a connection open) and the router (by default, through a cookie) attempt to preserve your connection to a back-end server, you might not see both shards being returned to you.</simpara>
<simpara>To force your browser to one or the other shard:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Use the <literal>oc scale</literal> command to reduce replicas of <literal>ab-example-a</literal> to <literal>0</literal>.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc scale dc/ab-example-a --replicas=0</programlisting>
<simpara>Refresh your browser to show <literal>v2</literal> and <literal>shard B</literal> (in red).</simpara>
</listitem>
<listitem>
<simpara>Scale <literal>ab-example-a</literal> to <literal>1</literal> replica and <literal>ab-example-b</literal> to <literal>0</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc scale dc/ab-example-a --replicas=1; oc scale dc/ab-example-b --replicas=0</programlisting>
<simpara>Refresh your browser to show <literal>v1</literal> and <literal>shard A</literal> (in blue).</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>If you trigger a deployment on either shard, only the pods in that shard are affected. You can trigger a deployment by changing the <literal>SUBTITLE</literal> environment variable in either <literal>Deployment</literal> object:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit dc/ab-example-a</programlisting>
<simpara>or</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit dc/ab-example-b</programlisting>
</listitem>
</orderedlist>
</section>
</section>
</section>
</section>
</chapter>
<chapter xml:id="_quotas">
<title>Quotas</title>
<section xml:id="quotas-setting-per-project">
<title>Resource quotas per project</title>
<simpara>A <emphasis>resource quota</emphasis>, defined by a <literal>ResourceQuota</literal> object, provides constraints that limit aggregate resource consumption per project. It can limit the quantity of objects that can be created in a project by type, as well as the total amount of compute resources and storage that might be consumed by resources in that project.</simpara>
<simpara>This guide describes how resource quotas work, how cluster administrators can set and manage resource quotas on a per project basis, and how developers and cluster administrators can view them.</simpara>
<section xml:id="quotas-resources-managed_quotas-setting-per-project">
<title>Resources managed by quotas</title>
<simpara>The following describes the set of compute resources and object types that can be managed by a quota.</simpara>
<note>
<simpara>A pod is in a terminal state if <literal>status.phase in (Failed, Succeeded)</literal> is true.</simpara>
</note>
<table frame="all" rowsep="1" colsep="1">
<title>Compute resources managed by quota</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="27.2727*"/>
<colspec colname="col_2" colwidth="72.7273*"/>
<thead>
<row>
<entry align="left" valign="top">Resource Name</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>cpu</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The sum of CPU requests across all pods in a non-terminal state cannot exceed this value. <literal>cpu</literal> and <literal>requests.cpu</literal> are the same value and can be used interchangeably.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>memory</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The sum of memory requests across all pods in a non-terminal state cannot exceed this value. <literal>memory</literal> and <literal>requests.memory</literal> are the same value and can be used interchangeably.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>requests.cpu</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The sum of CPU requests across all pods in a non-terminal state cannot exceed this value. <literal>cpu</literal> and <literal>requests.cpu</literal> are the same value and can be used interchangeably.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>requests.memory</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The sum of memory requests across all pods in a non-terminal state cannot exceed this value. <literal>memory</literal> and <literal>requests.memory</literal> are the same value and can be used interchangeably.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>limits.cpu</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The sum of CPU limits across all pods in a non-terminal state cannot exceed this value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>limits.memory</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The sum of memory limits across all pods in a non-terminal state cannot exceed this value.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<table frame="all" rowsep="1" colsep="1">
<title>Storage resources managed by quota</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="27.2727*"/>
<colspec colname="col_2" colwidth="72.7273*"/>
<thead>
<row>
<entry align="left" valign="top">Resource Name</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>requests.storage</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The sum of storage requests across all persistent volume claims in any state cannot exceed this value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>persistentvolumeclaims</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The total number of persistent volume claims that can exist in the project.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>&lt;storage-class-name&gt;.storageclass.storage.k8s.io/requests.storage</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The sum of storage requests across all persistent volume claims in any state that have a matching storage class, cannot exceed this value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>&lt;storage-class-name&gt;.storageclass.storage.k8s.io/persistentvolumeclaims</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The total number of persistent volume claims with a matching storage class that can exist in the project.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ephemeral-storage</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The sum of local ephemeral storage requests across all pods in a non-terminal state cannot exceed this value. <literal>ephemeral-storage</literal> and <literal>requests.ephemeral-storage</literal> are the same value and can be used interchangeably.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>requests.ephemeral-storage</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The sum of ephemeral storage requests across all pods in a non-terminal state cannot exceed this value. <literal>ephemeral-storage</literal> and <literal>requests.ephemeral-storage</literal> are the same value and can be used interchangeably.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>limits.ephemeral-storage</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The sum of ephemeral storage limits across all pods in a non-terminal state cannot exceed this value.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<table xml:id="quotas-object-counts-managed_quotas-setting-per-project" frame="all" rowsep="1" colsep="1">
<title>Object counts managed by quota</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="27.2727*"/>
<colspec colname="col_2" colwidth="72.7273*"/>
<thead>
<row>
<entry align="left" valign="top">Resource Name</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>pods</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The total number of pods in a non-terminal state that can exist in the project.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>replicationcontrollers</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The total number of ReplicationControllers that can exist in the project.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>resourcequotas</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The total number of resource quotas that can exist in the project.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>services</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The total number of services that can exist in the project.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>services.loadbalancers</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The total number of services of type <literal>LoadBalancer</literal> that can exist in the project.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>services.nodeports</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The total number of services of type <literal>NodePort</literal> that can exist in the project.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>secrets</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The total number of secrets that can exist in the project.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>configmaps</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The total number of <literal>ConfigMap</literal> objects that can exist in the project.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>persistentvolumeclaims</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The total number of persistent volume claims that can exist in the project.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>openshift.io/imagestreams</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The total number of imagestreams that can exist in the project.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section xml:id="quotas-scopes_quotas-setting-per-project">
<title>Quota scopes</title>
<simpara>Each quota can have an associated set of <emphasis>scopes</emphasis>. A quota only measures usage
for a resource if it matches the intersection of enumerated scopes.</simpara>
<simpara>Adding a scope to a quota restricts the set of resources to which that quota can
apply. Specifying a resource outside of the allowed set results in a validation
error.</simpara>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Scope</simpara></entry>
<entry align="left" valign="top"><simpara>Description</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>BestEffort</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Match pods that have best effort quality of service for either <literal>cpu</literal> or
<literal>memory</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>NotBestEffort</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Match pods that do not have best effort quality of service for <literal>cpu</literal> and
<literal>memory</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>A <literal>BestEffort</literal> scope restricts a quota to limiting the following resources:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>pods</literal></simpara>
</listitem>
</itemizedlist>
<simpara>A <literal>NotBestEffort</literal> scope restricts a quota to tracking the following resources:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>pods</literal></simpara>
</listitem>
<listitem>
<simpara><literal>memory</literal></simpara>
</listitem>
<listitem>
<simpara><literal>requests.memory</literal></simpara>
</listitem>
<listitem>
<simpara><literal>limits.memory</literal></simpara>
</listitem>
<listitem>
<simpara><literal>cpu</literal></simpara>
</listitem>
<listitem>
<simpara><literal>requests.cpu</literal></simpara>
</listitem>
<listitem>
<simpara><literal>limits.cpu</literal></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="quota-enforcement_quotas-setting-per-project">
<title>Quota enforcement</title>
<simpara>After a resource quota for a project is first created, the project restricts the
ability to create any new resources that may violate a quota constraint until it
has calculated updated usage statistics.</simpara>
<simpara>After a quota is created and usage statistics are updated, the project accepts
the creation of new content. When you create or modify resources, your quota
usage is incremented immediately upon the request to create or modify the
resource.</simpara>
<simpara>When you delete a resource, your quota use is decremented during the next full
recalculation of quota statistics for the project. A configurable amount of time
determines how long it takes to reduce quota usage statistics to their current
observed system value.</simpara>
<simpara>If project modifications exceed a quota usage limit, the server denies the
action, and an appropriate error message is returned to the user explaining the
quota constraint violated, and what their currently observed usage statistics
are in the system.</simpara>
</section>
<section xml:id="quotas-requests-vs-limits_quotas-setting-per-project">
<title>Requests versus limits</title>
<simpara>When allocating compute resources, each container might specify a request and a
limit value each for CPU, memory, and ephemeral storage. Quotas can restrict any
of these values.</simpara>
<simpara>If the quota has a value specified for <literal>requests.cpu</literal> or <literal>requests.memory</literal>,
then it requires that every incoming container make an explicit request for
those resources. If the quota has a value specified for <literal>limits.cpu</literal> or
<literal>limits.memory</literal>, then it requires that every incoming container specify an
explicit limit for those resources.</simpara>
</section>
<section xml:id="quotas-sample-resource-quota-definitions_quotas-setting-per-project">
<title>Sample resource quota definitions</title>
<formalpara>
<title><literal>core-object-counts.yaml</literal></title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: ResourceQuota
metadata:
  name: core-object-counts
spec:
  hard:
    configmaps: "10" <co xml:id="CO26-1"/>
    persistentvolumeclaims: "4" <co xml:id="CO26-2"/>
    replicationcontrollers: "20" <co xml:id="CO26-3"/>
    secrets: "10" <co xml:id="CO26-4"/>
    services: "10" <co xml:id="CO26-5"/>
    services.loadbalancers: "2" <co xml:id="CO26-6"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO26-1">
<para>The total number of <literal>ConfigMap</literal> objects that can exist in the project.</para>
</callout>
<callout arearefs="CO26-2">
<para>The total number of persistent volume claims (PVCs) that can exist in the
project.</para>
</callout>
<callout arearefs="CO26-3">
<para>The total number of replication controllers that can exist in the project.</para>
</callout>
<callout arearefs="CO26-4">
<para>The total number of secrets that can exist in the project.</para>
</callout>
<callout arearefs="CO26-5">
<para>The total number of services that can exist in the project.</para>
</callout>
<callout arearefs="CO26-6">
<para>The total number of services of type <literal>LoadBalancer</literal> that can exist in the project.</para>
</callout>
</calloutlist>
<formalpara>
<title><literal>openshift-object-counts.yaml</literal></title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: ResourceQuota
metadata:
  name: openshift-object-counts
spec:
  hard:
    openshift.io/imagestreams: "10" <co xml:id="CO27-1"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO27-1">
<para>The total number of image streams that can exist in the project.</para>
</callout>
</calloutlist>
<formalpara>
<title><literal>compute-resources.yaml</literal></title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-resources
spec:
  hard:
    pods: "4" <co xml:id="CO28-1"/>
    requests.cpu: "1" <co xml:id="CO28-2"/>
    requests.memory: 1Gi <co xml:id="CO28-3"/>
    limits.cpu: "2" <co xml:id="CO28-4"/>
    limits.memory: 2Gi <co xml:id="CO28-5"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO28-1">
<para>The total number of pods in a non-terminal state that can exist in the project.</para>
</callout>
<callout arearefs="CO28-2">
<para>Across all pods in a non-terminal state, the sum of CPU requests cannot exceed 1 core.</para>
</callout>
<callout arearefs="CO28-3">
<para>Across all pods in a non-terminal state, the sum of memory requests cannot exceed 1Gi.</para>
</callout>
<callout arearefs="CO28-4">
<para>Across all pods in a non-terminal state, the sum of CPU limits cannot exceed 2 cores.</para>
</callout>
<callout arearefs="CO28-5">
<para>Across all pods in a non-terminal state, the sum of memory limits cannot exceed 2Gi.</para>
</callout>
</calloutlist>
<formalpara>
<title><literal>besteffort.yaml</literal></title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: ResourceQuota
metadata:
  name: besteffort
spec:
  hard:
    pods: "1" <co xml:id="CO29-1"/>
  scopes:
  - BestEffort <co xml:id="CO29-2"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO29-1">
<para>The total number of pods in a non-terminal state with <literal>BestEffort</literal> quality of service that can exist in the project.</para>
</callout>
<callout arearefs="CO29-2">
<para>Restricts the quota to only matching pods that have <literal>BestEffort</literal> quality of service for either memory or CPU.</para>
</callout>
</calloutlist>
<formalpara>
<title><literal>compute-resources-long-running.yaml</literal></title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-resources-long-running
spec:
  hard:
    pods: "4" <co xml:id="CO30-1"/>
    limits.cpu: "4" <co xml:id="CO30-2"/>
    limits.memory: "2Gi" <co xml:id="CO30-3"/>
  scopes:
  - NotTerminating <co xml:id="CO30-4"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO30-1">
<para>The total number of pods in a non-terminal state.</para>
</callout>
<callout arearefs="CO30-2">
<para>Across all pods in a non-terminal state, the sum of CPU limits cannot exceed this value.</para>
</callout>
<callout arearefs="CO30-3">
<para>Across all pods in a non-terminal state, the sum of memory limits cannot exceed this value.</para>
</callout>
<callout arearefs="CO30-4">
<para>Restricts the quota to only matching pods where <literal>spec.activeDeadlineSeconds</literal> is set to <literal>nil</literal>. Build pods fall under <literal>NotTerminating</literal> unless the <literal>RestartNever</literal> policy is applied.</para>
</callout>
</calloutlist>
<formalpara>
<title><literal>compute-resources-time-bound.yaml</literal></title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-resources-time-bound
spec:
  hard:
    pods: "2" <co xml:id="CO31-1"/>
    limits.cpu: "1" <co xml:id="CO31-2"/>
    limits.memory: "1Gi" <co xml:id="CO31-3"/>
  scopes:
  - Terminating <co xml:id="CO31-4"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO31-1">
<para>The total number of pods in a terminating state.</para>
</callout>
<callout arearefs="CO31-2">
<para>Across all pods in a terminating state, the sum of CPU limits cannot exceed this value.</para>
</callout>
<callout arearefs="CO31-3">
<para>Across all pods in a terminating state, the sum of memory limits cannot exceed this value.</para>
</callout>
<callout arearefs="CO31-4">
<para>Restricts the quota to only matching pods where <literal>spec.activeDeadlineSeconds &gt;=0</literal>. For example, this quota charges for build or deployer pods, but not long running pods like a web server or database.</para>
</callout>
</calloutlist>
<formalpara>
<title><literal>storage-consumption.yaml</literal></title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: ResourceQuota
metadata:
  name: storage-consumption
spec:
  hard:
    persistentvolumeclaims: "10" <co xml:id="CO32-1"/>
    requests.storage: "50Gi" <co xml:id="CO32-2"/>
    gold.storageclass.storage.k8s.io/requests.storage: "10Gi" <co xml:id="CO32-3"/>
    silver.storageclass.storage.k8s.io/requests.storage: "20Gi" <co xml:id="CO32-4"/>
    silver.storageclass.storage.k8s.io/persistentvolumeclaims: "5" <co xml:id="CO32-5"/>
    bronze.storageclass.storage.k8s.io/requests.storage: "0" <co xml:id="CO32-6"/>
    bronze.storageclass.storage.k8s.io/persistentvolumeclaims: "0" <co xml:id="CO32-7"/>
    requests.ephemeral-storage: 2Gi <co xml:id="CO32-8"/>
    limits.ephemeral-storage: 4Gi <co xml:id="CO32-9"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO32-1">
<para>The total number of persistent volume claims in a project</para>
</callout>
<callout arearefs="CO32-2">
<para>Across all persistent volume claims in a project, the sum of storage requested cannot exceed this value.</para>
</callout>
<callout arearefs="CO32-3">
<para>Across all persistent volume claims in a project, the sum of storage requested in the gold storage class cannot exceed this value.</para>
</callout>
<callout arearefs="CO32-4">
<para>Across all persistent volume claims in a project, the sum of storage requested in the silver storage class cannot exceed this value.</para>
</callout>
<callout arearefs="CO32-5">
<para>Across all persistent volume claims in a project, the total number of claims in the silver storage class cannot exceed this value.</para>
</callout>
<callout arearefs="CO32-6">
<para>Across all persistent volume claims in a project, the sum of storage requested in the bronze storage class cannot exceed this value. When this is set to <literal>0</literal>, it means bronze storage class cannot request storage.</para>
</callout>
<callout arearefs="CO32-7">
<para>Across all persistent volume claims in a project, the sum of storage requested in the bronze storage class cannot exceed this value. When this is set to <literal>0</literal>, it means bronze storage class cannot create claims.</para>
</callout>
<callout arearefs="CO32-8">
<para>Across all pods in a non-terminal state, the sum of ephemeral storage requests cannot exceed 2Gi.</para>
</callout>
<callout arearefs="CO32-9">
<para>Across all pods in a non-terminal state, the sum of ephemeral storage limits cannot exceed 4Gi.</para>
</callout>
</calloutlist>
</section>
<section xml:id="quotas-creating-a-quota_quotas-setting-per-project">
<title>Creating a quota</title>
<simpara>You can create a quota to constrain resource usage in a given project.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Define the quota in a file.</simpara>
</listitem>
<listitem>
<simpara>Use the file to create the quota and apply it to a project:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create -f &lt;file&gt; [-n &lt;project_name&gt;]</programlisting>
<simpara>For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create -f core-object-counts.yaml -n demoproject</programlisting>
</listitem>
</orderedlist>
<section xml:id="quota-creating-object-count-quotas_quotas-setting-per-project">
<title>Creating object count quotas</title>
<simpara>You can create an object count quota for all standard namespaced resource types on OpenShift Container Platform, such as <literal>BuildConfig</literal> and <literal>DeploymentConfig</literal> objects. An object quota count places a defined quota on all standard namespaced resource types.</simpara>
<simpara>When using a resource quota, an object is charged against the quota upon creation. These types of quotas are useful to protect against exhaustion of resources. The quota can only be created if there are enough spare resources within the project.</simpara>
<formalpara>
<title>Procedure</title>
<para>To configure an object count quota for a resource:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create quota &lt;name&gt; \
    --hard=count/&lt;resource&gt;.&lt;group&gt;=&lt;quota&gt;,count/&lt;resource&gt;.&lt;group&gt;=&lt;quota&gt; <co xml:id="CO33-1"/></programlisting>
<calloutlist>
<callout arearefs="CO33-1">
<para>The <literal>&lt;resource&gt;</literal> variable is the name of the resource, and <literal>&lt;group&gt;</literal> is the API group, if applicable. Use the <literal>oc api-resources</literal> command for a list of resources and their associated API groups.</para>
</callout>
</calloutlist>
<simpara>For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create quota test \
    --hard=count/deployments.extensions=2,count/replicasets.extensions=4,count/pods=3,count/secrets=4</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">resourcequota "test" created</programlisting>
</para>
</formalpara>
<simpara>This example limits the listed resources to the hard limit in each project in the cluster.</simpara>
</listitem>
<listitem>
<simpara>Verify that the quota was created:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc describe quota test</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">Name:                         test
Namespace:                    quota
Resource                      Used  Hard
--------                      ----  ----
count/deployments.extensions  0     2
count/pods                    0     3
count/replicasets.extensions  0     4
count/secrets                 0     4</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</section>
<section xml:id="setting-resource-quota-for-extended-resources_quotas-setting-per-project">
<title>Setting resource quota for extended resources</title>
<simpara>Overcommitment of resources is not allowed for extended resources, so you must specify <literal>requests</literal> and <literal>limits</literal> for the same extended resource in a quota. Currently, only quota items with the prefix <literal>requests.</literal> is allowed for extended resources. The following is an example scenario of how to set resource quota for the GPU resource <literal>nvidia.com/gpu</literal>.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Determine how many GPUs are available on a node in your cluster. For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered"># oc describe node ip-172-31-27-209.us-west-2.compute.internal | egrep 'Capacity|Allocatable|gpu'</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">                    openshift.com/gpu-accelerator=true
Capacity:
 nvidia.com/gpu:  2
Allocatable:
 nvidia.com/gpu:  2
  nvidia.com/gpu  0           0</programlisting>
</para>
</formalpara>
<simpara>In this example, 2 GPUs are available.</simpara>
</listitem>
<listitem>
<simpara>Set a quota in the namespace <literal>nvidia</literal>. In this example, the quota is <literal>1</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered"># cat gpu-quota.yaml</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">apiVersion: v1
kind: ResourceQuota
metadata:
  name: gpu-quota
  namespace: nvidia
spec:
  hard:
    requests.nvidia.com/gpu: 1</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Create the quota:</simpara>
<programlisting language="terminal" linenumbering="unnumbered"># oc create -f gpu-quota.yaml</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">resourcequota/gpu-quota created</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Verify that the namespace has the correct quota set:</simpara>
<programlisting language="terminal" linenumbering="unnumbered"># oc describe quota gpu-quota -n nvidia</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">Name:                    gpu-quota
Namespace:               nvidia
Resource                 Used  Hard
--------                 ----  ----
requests.nvidia.com/gpu  0     1</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Define a pod that asks for a single GPU. The following example definition file is called <literal>gpu-pod.yaml</literal>:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  generateName: gpu-pod-
  namespace: nvidia
spec:
  restartPolicy: OnFailure
  containers:
  - name: rhel7-gpu-pod
    image: rhel7
    env:
      - name: NVIDIA_VISIBLE_DEVICES
        value: all
      - name: NVIDIA_DRIVER_CAPABILITIES
        value: "compute,utility"
      - name: NVIDIA_REQUIRE_CUDA
        value: "cuda&gt;=5.0"
    command: ["sleep"]
    args: ["infinity"]
    resources:
      limits:
        nvidia.com/gpu: 1</programlisting>
</listitem>
<listitem>
<simpara>Create the pod:</simpara>
<programlisting language="terminal" linenumbering="unnumbered"># oc create -f gpu-pod.yaml</programlisting>
</listitem>
<listitem>
<simpara>Verify that the pod is running:</simpara>
<programlisting language="terminal" linenumbering="unnumbered"># oc get pods</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME              READY     STATUS      RESTARTS   AGE
gpu-pod-s46h7     1/1       Running     0          1m</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Verify that the quota <literal>Used</literal> counter is correct:</simpara>
<programlisting language="terminal" linenumbering="unnumbered"># oc describe quota gpu-quota -n nvidia</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">Name:                    gpu-quota
Namespace:               nvidia
Resource                 Used  Hard
--------                 ----  ----
requests.nvidia.com/gpu  1     1</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Attempt to create a second GPU pod in the <literal>nvidia</literal> namespace. This is technically available on the node because it has 2 GPUs:</simpara>
<programlisting language="terminal" linenumbering="unnumbered"># oc create -f gpu-pod.yaml</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">Error from server (Forbidden): error when creating "gpu-pod.yaml": pods "gpu-pod-f7z2w" is forbidden: exceeded quota: gpu-quota, requested: requests.nvidia.com/gpu=1, used: requests.nvidia.com/gpu=1, limited: requests.nvidia.com/gpu=1</programlisting>
</para>
</formalpara>
<simpara>This <emphasis role="strong">Forbidden</emphasis> error message is expected because you have a quota of 1 GPU and this pod tried to allocate a second GPU, which exceeds its quota.</simpara>
</listitem>
</orderedlist>
</section>
</section>
<section xml:id="quota-viewing-quotas_quotas-setting-per-project">
<title>Viewing a quota</title>
<simpara>You can view usage statistics related to any hard limits defined in a project&#8217;s
quota by navigating in the web console to the project&#8217;s <emphasis role="strong">Quota</emphasis> page.</simpara>
<simpara>You can also use the CLI to view quota details.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Get the list of quotas defined in the project. For example, for a project called
<literal>demoproject</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get quota -n demoproject</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                AGE
besteffort          11m
compute-resources   2m
core-object-counts  29m</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Describe the quota you are interested in, for example the <literal>core-object-counts</literal>
quota:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc describe quota core-object-counts -n demoproject</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">Name:			core-object-counts
Namespace:		demoproject
Resource		Used	Hard
--------		----	----
configmaps		3	10
persistentvolumeclaims	0	4
replicationcontrollers	3	20
secrets			9	10
services		2	10</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</section>
<section xml:id="configuring-explicit-resource-quotas_quotas-setting-per-project">
<title>Configuring explicit resource quotas</title>
<simpara>Configure explicit resource quotas in a project request template to apply specific resource quotas in new projects.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Access to the cluster as a user with the cluster-admin role.</simpara>
</listitem>
<listitem>
<simpara>Install the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Add a resource quota definition to a project request template:</simpara>
<itemizedlist>
<listitem>
<simpara>If a project request template does not exist in a cluster:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Create a bootstrap project template and output it to a file called <literal>template.yaml</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm create-bootstrap-project-template -o yaml &gt; template.yaml</programlisting>
</listitem>
<listitem>
<simpara>Add a resource quota definition to <literal>template.yaml</literal>. The following example defines a resource quota named 'storage-consumption'. The definition must be added before the <literal>parameters:</literal> section in the template:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">- apiVersion: v1
  kind: ResourceQuota
  metadata:
    name: storage-consumption
    namespace: ${PROJECT_NAME}
  spec:
    hard:
      persistentvolumeclaims: "10" <co xml:id="CO34-1"/>
      requests.storage: "50Gi" <co xml:id="CO34-2"/>
      gold.storageclass.storage.k8s.io/requests.storage: "10Gi" <co xml:id="CO34-3"/>
      silver.storageclass.storage.k8s.io/requests.storage: "20Gi" <co xml:id="CO34-4"/>
      silver.storageclass.storage.k8s.io/persistentvolumeclaims: "5" <co xml:id="CO34-5"/>
      bronze.storageclass.storage.k8s.io/requests.storage: "0" <co xml:id="CO34-6"/>
      bronze.storageclass.storage.k8s.io/persistentvolumeclaims: "0" <co xml:id="CO34-7"/></programlisting>
<calloutlist>
<callout arearefs="CO34-1">
<para>The total number of persistent volume claims in a project.</para>
</callout>
<callout arearefs="CO34-2">
<para>Across all persistent volume claims in a project, the sum of storage requested cannot exceed this value.</para>
</callout>
<callout arearefs="CO34-3">
<para>Across all persistent volume claims in a project, the sum of storage requested in the gold storage class cannot exceed this value.</para>
</callout>
<callout arearefs="CO34-4">
<para>Across all persistent volume claims in a project, the sum of storage requested in the silver storage class cannot exceed this value.</para>
</callout>
<callout arearefs="CO34-5">
<para>Across all persistent volume claims in a project, the total number of claims in the silver storage class cannot exceed this value.</para>
</callout>
<callout arearefs="CO34-6">
<para>Across all persistent volume claims in a project, the sum of storage requested in the bronze storage class cannot exceed this value. When this value is set to <literal>0</literal>, the bronze storage class cannot request storage.</para>
</callout>
<callout arearefs="CO34-7">
<para>Across all persistent volume claims in a project, the sum of storage requested in the bronze storage class cannot exceed this value. When this value is set to <literal>0</literal>, the bronze storage class cannot create claims.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Create a project request template from the modified <literal>template.yaml</literal> file in the <literal>openshift-config</literal> namespace:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create -f template.yaml -n openshift-config</programlisting>
<note>
<simpara>To include the configuration as a <literal>kubectl.kubernetes.io/last-applied-configuration</literal> annotation, add the <literal>--save-config</literal> option to the <literal>oc create</literal> command.</simpara>
</note>
<simpara>By default, the template is called <literal>project-request</literal>.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>If a project request template already exists within a cluster:</simpara>
<note>
<simpara>If you declaratively or imperatively manage objects within your cluster by using configuration files, edit the existing project request template through those files instead.</simpara>
</note>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>List templates in the <literal>openshift-config</literal> namespace:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get templates -n openshift-config</programlisting>
</listitem>
<listitem>
<simpara>Edit an existing project request template:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit template &lt;project_request_template&gt; -n openshift-config</programlisting>
</listitem>
<listitem>
<simpara>Add a resource quota definition, such as the preceding <literal>storage-consumption</literal> example, into the existing template. The definition must be added before the <literal>parameters:</literal> section in the template.</simpara>
</listitem>
</orderedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>If you created a project request template, reference it in the cluster&#8217;s project configuration resource:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Access the project configuration resource for editing:</simpara>
<itemizedlist>
<listitem>
<simpara>By using the web console:</simpara>
<orderedlist numeration="lowerroman">
<listitem>
<simpara>Navigate to the <emphasis role="strong">Administration</emphasis> &#8594; <emphasis role="strong">Cluster Settings</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Configuration</emphasis> to view all configuration resources.</simpara>
</listitem>
<listitem>
<simpara>Find the entry for <emphasis role="strong">Project</emphasis> and click <emphasis role="strong">Edit YAML</emphasis>.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>By using the CLI:</simpara>
<orderedlist numeration="lowerroman">
<listitem>
<simpara>Edit the <literal>project.config.openshift.io/cluster</literal> resource:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit project.config.openshift.io/cluster</programlisting>
</listitem>
</orderedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Update the <literal>spec</literal> section of the project configuration resource to include the <literal>projectRequestTemplate</literal> and <literal>name</literal> parameters. The following example references the default project request template name <literal>project-request</literal>:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: config.openshift.io/v1
kind: Project
metadata:
  ...
spec:
  projectRequestTemplate:
    name: project-request</programlisting>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Verify that the resource quota is applied when projects are created:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Create a project:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc new-project &lt;project_name&gt;</programlisting>
</listitem>
<listitem>
<simpara>List the project&#8217;s resource quotas:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get resourcequotas</programlisting>
</listitem>
<listitem>
<simpara>Describe the resource quota in detail:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc describe resourcequotas &lt;resource_quota_name&gt;</programlisting>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
</section>
</section>
<section xml:id="setting-quotas-across-multiple-projects">
<title>Resource quotas across multiple projects</title>
<simpara>A multi-project quota, defined by a <literal>ClusterResourceQuota</literal> object, allows quotas to be shared across multiple projects. Resources used in each selected project are aggregated and that aggregate is used to limit resources across all the selected projects.</simpara>
<simpara>This guide describes how cluster administrators can set and manage resource quotas across multiple projects.</simpara>
<important>
<simpara>Do not run workloads in or share access to default projects. Default projects are reserved for running core cluster components.</simpara>
<simpara>The following default projects are considered highly privileged: <literal>default</literal>, <literal>kube-public</literal>, <literal>kube-system</literal>, <literal>openshift</literal>, <literal>openshift-infra</literal>, <literal>openshift-node</literal>, and other system-created projects that have the <literal>openshift.io/run-level</literal> label set to <literal>0</literal> or <literal>1</literal>. Functionality that relies on admission plugins, such as pod security admission, security context constraints, cluster resource quotas, and image reference resolution, does not work in highly privileged projects.</simpara>
</important>
<section xml:id="quotas-setting-projects_setting-quotas-across-multiple-projects">
<title>Selecting multiple projects during quota creation</title>
<simpara>When creating quotas, you can select multiple projects based on annotation selection, label selection, or both.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To select projects based on annotations, run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create clusterquota for-user \
     --project-annotation-selector openshift.io/requester=&lt;user_name&gt; \
     --hard pods=10 \
     --hard secrets=20</programlisting>
<simpara>This creates the following <literal>ClusterResourceQuota</literal> object:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: quota.openshift.io/v1
kind: ClusterResourceQuota
metadata:
  name: for-user
spec:
  quota: <co xml:id="CO35-1"/>
    hard:
      pods: "10"
      secrets: "20"
  selector:
    annotations: <co xml:id="CO35-2"/>
      openshift.io/requester: &lt;user_name&gt;
    labels: null <co xml:id="CO35-3"/>
status:
  namespaces: <co xml:id="CO35-4"/>
  - namespace: ns-one
    status:
      hard:
        pods: "10"
        secrets: "20"
      used:
        pods: "1"
        secrets: "9"
  total: <co xml:id="CO35-5"/>
    hard:
      pods: "10"
      secrets: "20"
    used:
      pods: "1"
      secrets: "9"</programlisting>
<calloutlist>
<callout arearefs="CO35-1">
<para>The <literal>ResourceQuotaSpec</literal> object that will be enforced over the selected projects.</para>
</callout>
<callout arearefs="CO35-2">
<para>A simple key-value selector for annotations.</para>
</callout>
<callout arearefs="CO35-3">
<para>A label selector that can be used to select projects.</para>
</callout>
<callout arearefs="CO35-4">
<para>A per-namespace map that describes current quota usage in each selected project.</para>
</callout>
<callout arearefs="CO35-5">
<para>The aggregate usage across all selected projects.</para>
</callout>
</calloutlist>
<simpara>This multi-project quota document controls all projects requested by <literal>&lt;user_name&gt;</literal> using the default project request endpoint. You are limited to 10 pods and 20 secrets.</simpara>
</listitem>
<listitem>
<simpara>Similarly, to select projects based on labels, run this command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$  oc create clusterresourcequota for-name \<co xml:id="CO36-1"/>
    --project-label-selector=name=frontend \<co xml:id="CO36-2"/>
    --hard=pods=10 --hard=secrets=20</programlisting>
<calloutlist>
<callout arearefs="CO36-1">
<para>Both <literal>clusterresourcequota</literal> and <literal>clusterquota</literal> are aliases of the same command. <literal>for-name</literal> is the name of the <literal>ClusterResourceQuota</literal> object.</para>
</callout>
<callout arearefs="CO36-2">
<para>To select projects by label, provide a key-value pair by using the format <literal>--project-label-selector=key=value</literal>.</para>
</callout>
</calloutlist>
<simpara>This creates the following <literal>ClusterResourceQuota</literal> object definition:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: quota.openshift.io/v1
kind: ClusterResourceQuota
metadata:
  creationTimestamp: null
  name: for-name
spec:
  quota:
    hard:
      pods: "10"
      secrets: "20"
  selector:
    annotations: null
    labels:
      matchLabels:
        name: frontend</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="quotas-viewing-clusterresourcequotas_setting-quotas-across-multiple-projects">
<title>Viewing applicable cluster resource quotas</title>
<simpara>A project administrator is not allowed to create or modify the multi-project quota that limits his or her project, but the administrator is allowed to view the multi-project quota documents that are applied to his or her project. The project administrator can do this via the <literal>AppliedClusterResourceQuota</literal> resource.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To view quotas applied to a project, run:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc describe AppliedClusterResourceQuota</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">Name:   for-user
Namespace:  &lt;none&gt;
Created:  19 hours ago
Labels:   &lt;none&gt;
Annotations:  &lt;none&gt;
Label Selector: &lt;null&gt;
AnnotationSelector: map[openshift.io/requester:&lt;user-name&gt;]
Resource  Used  Hard
--------  ----  ----
pods        1     10
secrets     9     20</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</section>
<section xml:id="quotas-selection-granularity_setting-quotas-across-multiple-projects">
<title>Selection granularity</title>
<simpara>Because of the locking consideration when claiming quota allocations, the number of
active projects selected by a multi-project quota is an important consideration.
Selecting more than 100 projects under a single multi-project quota can have
detrimental effects on API server responsiveness in those projects.</simpara>
</section>
</section>
</chapter>
<chapter xml:id="config-maps">
<title>Using config maps with applications</title>
<simpara>Config maps allow you to decouple configuration artifacts from image content to keep containerized applications portable.</simpara>
<simpara>The following sections define config maps and how to create and use them.</simpara>
<simpara>For information on creating config maps, see <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/nodes/#creating-and-using-config-maps">Creating and using config maps</link>.</simpara>
<section xml:id="nodes-pods-configmap-overview_config-maps">
<title>Understanding config maps</title>
<simpara>Many applications require configuration by using some combination of configuration files, command line arguments, and environment variables. In OpenShift Container Platform, these configuration artifacts are decoupled from image content to keep containerized applications portable.</simpara>
<simpara>The <literal>ConfigMap</literal> object provides mechanisms to inject containers with configuration data while keeping containers agnostic of OpenShift Container Platform. A config map can be used to store fine-grained information like individual properties or coarse-grained information like entire configuration files or JSON blobs.</simpara>
<simpara>The <literal>ConfigMap</literal> object holds key-value pairs of configuration data that can be consumed in pods or used to store configuration data for system components such as controllers. For example:</simpara>
<formalpara>
<title><literal>ConfigMap</literal> Object Definition</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">kind: ConfigMap
apiVersion: v1
metadata:
  creationTimestamp: 2016-02-18T19:14:38Z
  name: example-config
  namespace: my-namespace
data: <co xml:id="CO37-1"/>
  example.property.1: hello
  example.property.2: world
  example.property.file: |-
    property.1=value-1
    property.2=value-2
    property.3=value-3
binaryData:
  bar: L3Jvb3QvMTAw <co xml:id="CO37-2"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO37-1">
<para>Contains the configuration data.</para>
</callout>
<callout arearefs="CO37-2">
<para>Points to a file that contains non-UTF8 data, for example, a binary Java keystore file. Enter the file data in Base 64.</para>
</callout>
</calloutlist>
<note>
<simpara>You can use the <literal>binaryData</literal> field when you create a config map from a binary file, such as an image.</simpara>
</note>
<simpara>Configuration data can be consumed in pods in a variety of ways. A config map can be used to:</simpara>
<itemizedlist>
<listitem>
<simpara>Populate environment variable values in containers</simpara>
</listitem>
<listitem>
<simpara>Set command-line arguments in a container</simpara>
</listitem>
<listitem>
<simpara>Populate configuration files in a volume</simpara>
</listitem>
</itemizedlist>
<simpara>Users and system components can store configuration data in a config map.</simpara>
<simpara>A config map is similar to a secret, but designed to more conveniently support working with strings that do not contain sensitive information.</simpara>
<bridgehead xml:id="_config-map-restrictions" renderas="sect3">Config map restrictions</bridgehead>
<simpara><emphasis role="strong">A config map must be created before its contents can be consumed in pods.</emphasis></simpara>
<simpara>Controllers can be written to tolerate missing configuration data. Consult individual components configured by using config maps on a case-by-case basis.</simpara>
<simpara><emphasis role="strong"><literal>ConfigMap</literal> objects reside in a project.</emphasis></simpara>
<simpara>They can only be referenced by pods in the same project.</simpara>
<simpara><emphasis role="strong">The Kubelet only supports the use of a config map for pods it gets from the API server.</emphasis></simpara>
<simpara>This includes any pods created by using the CLI, or indirectly from a replication controller. It does not include pods created by using the OpenShift Container Platform node&#8217;s <literal>--manifest-url</literal> flag, its <literal>--config</literal> flag, or its REST API because these are not common ways to create pods.</simpara>
</section>
<section xml:id="nodes-pods-config-maps-consuming-configmap-in-pods">
<title>Use cases: Consuming config maps in pods</title>
<simpara>The following sections describe some uses cases when consuming <literal>ConfigMap</literal>
objects in pods.</simpara>
<section xml:id="nodes-pods-configmaps-use-case-consuming-in-env-vars_config-maps">
<title>Populating environment variables in containers by using config maps</title>
<simpara>You can use config maps to populate individual environment variables in containers or to populate environment variables in containers from all keys that form valid environment variable names.</simpara>
<simpara>As an example, consider the following config map:</simpara>
<formalpara>
<title><literal>ConfigMap</literal> with two environment variables</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: ConfigMap
metadata:
  name: special-config <co xml:id="CO38-1"/>
  namespace: default <co xml:id="CO38-2"/>
data:
  special.how: very <co xml:id="CO38-3"/>
  special.type: charm <co xml:id="CO38-4"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO38-1">
<para>Name of the config map.</para>
</callout>
<callout arearefs="CO38-2">
<para>The project in which the config map resides. Config maps can only be referenced by pods in the same project.</para>
</callout>
<callout arearefs="CO38-3 CO38-4">
<para>Environment variables to inject.</para>
</callout>
</calloutlist>
<formalpara>
<title><literal>ConfigMap</literal> with one environment variable</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: ConfigMap
metadata:
  name: env-config <co xml:id="CO39-1"/>
  namespace: default
data:
  log_level: INFO <co xml:id="CO39-2"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO39-1">
<para>Name of the config map.</para>
</callout>
<callout arearefs="CO39-2">
<para>Environment variable to inject.</para>
</callout>
</calloutlist>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>You can consume the keys of this <literal>ConfigMap</literal> in a pod using <literal>configMapKeyRef</literal> sections.</simpara>
<formalpara>
<title>Sample <literal>Pod</literal> specification configured to inject specific environment variables</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  name: dapi-test-pod
spec:
  containers:
    - name: test-container
      image: gcr.io/google_containers/busybox
      command: [ "/bin/sh", "-c", "env" ]
      env: <co xml:id="CO40-1"/>
        - name: SPECIAL_LEVEL_KEY <co xml:id="CO40-2"/>
          valueFrom:
            configMapKeyRef:
              name: special-config <co xml:id="CO40-3"/>
              key: special.how <co xml:id="CO40-4"/>
        - name: SPECIAL_TYPE_KEY
          valueFrom:
            configMapKeyRef:
              name: special-config <co xml:id="CO40-5"/>
              key: special.type <co xml:id="CO40-6"/>
              optional: true <co xml:id="CO40-7"/>
      envFrom: <co xml:id="CO40-8"/>
        - configMapRef:
            name: env-config <co xml:id="CO40-9"/>
  restartPolicy: Never</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO40-1">
<para>Stanza to pull the specified environment variables from a <literal>ConfigMap</literal>.</para>
</callout>
<callout arearefs="CO40-2">
<para>Name of a pod environment variable that you are injecting a key&#8217;s value into.</para>
</callout>
<callout arearefs="CO40-3 CO40-5">
<para>Name of the <literal>ConfigMap</literal> to pull specific environment variables from.</para>
</callout>
<callout arearefs="CO40-4 CO40-6">
<para>Environment variable to pull from the <literal>ConfigMap</literal>.</para>
</callout>
<callout arearefs="CO40-7">
<para>Makes the environment variable optional. As optional, the pod will be started even if the specified <literal>ConfigMap</literal> and keys do not exist.</para>
</callout>
<callout arearefs="CO40-8">
<para>Stanza to pull all environment variables from a <literal>ConfigMap</literal>.</para>
</callout>
<callout arearefs="CO40-9">
<para>Name of the <literal>ConfigMap</literal> to pull all environment variables from.</para>
</callout>
</calloutlist>
<simpara>When this pod is run, the pod logs will include the following output:</simpara>
<screen>SPECIAL_LEVEL_KEY=very
log_level=INFO</screen>
</listitem>
</itemizedlist>
<note>
<simpara><literal>SPECIAL_TYPE_KEY=charm</literal> is not listed in the example output because <literal>optional: true</literal> is set.</simpara>
</note>
</section>
<section xml:id="nodes-pods-configmaps-use-case-setting-command-line-arguments_config-maps">
<title>Setting command-line arguments for container commands with config maps</title>
<simpara>You can use a config map to set the value of the commands or arguments in a container by using the Kubernetes substitution syntax <literal>$(VAR_NAME)</literal>.</simpara>
<simpara>As an example, consider the following config map:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: ConfigMap
metadata:
  name: special-config
  namespace: default
data:
  special.how: very
  special.type: charm</programlisting>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>To inject values into a command in a container, you must consume the keys you want to use as environment variables. Then you can refer to them in a container&#8217;s command using the <literal>$(VAR_NAME)</literal> syntax.</simpara>
<formalpara>
<title>Sample pod specification configured to inject specific environment variables</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  name: dapi-test-pod
spec:
  containers:
    - name: test-container
      image: gcr.io/google_containers/busybox
      command: [ "/bin/sh", "-c", "echo $(SPECIAL_LEVEL_KEY) $(SPECIAL_TYPE_KEY)" ] <co xml:id="CO41-1"/>
      env:
        - name: SPECIAL_LEVEL_KEY
          valueFrom:
            configMapKeyRef:
              name: special-config
              key: special.how
        - name: SPECIAL_TYPE_KEY
          valueFrom:
            configMapKeyRef:
              name: special-config
              key: special.type
  restartPolicy: Never</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO41-1">
<para>Inject the values into a command in a container using the keys you want to use as environment variables.</para>
</callout>
</calloutlist>
<simpara>When this pod is run, the output from the echo command run in the test-container container is as follows:</simpara>
<screen>very charm</screen>
</listitem>
</itemizedlist>
</section>
<section xml:id="nodes-pods-configmaps-use-case-consuming-in-volumes_config-maps">
<title>Injecting content into a volume by using config maps</title>
<simpara>You can inject content into a volume by using config maps.</simpara>
<formalpara>
<title>Example <literal>ConfigMap</literal> custom resource (CR)</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: ConfigMap
metadata:
  name: special-config
  namespace: default
data:
  special.how: very
  special.type: charm</programlisting>
</para>
</formalpara>
<formalpara>
<title>Procedure</title>
<para>You have a couple different options for injecting content into a volume by using config maps.</para>
</formalpara>
<itemizedlist>
<listitem>
<simpara>The most basic way to inject content into a volume by using a config map is to populate the volume with files where the key is the file name and the content of the file is the value of the key:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  name: dapi-test-pod
spec:
  containers:
    - name: test-container
      image: gcr.io/google_containers/busybox
      command: [ "/bin/sh", "-c", "cat", "/etc/config/special.how" ]
      volumeMounts:
      - name: config-volume
        mountPath: /etc/config
  volumes:
    - name: config-volume
      configMap:
        name: special-config <co xml:id="CO42-1"/>
  restartPolicy: Never</programlisting>
<calloutlist>
<callout arearefs="CO42-1">
<para>File containing key.</para>
</callout>
</calloutlist>
<simpara>When this pod is run, the output of the cat command will be:</simpara>
<screen>very</screen>
</listitem>
<listitem>
<simpara>You can also control the paths within the volume where config map keys are projected:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  name: dapi-test-pod
spec:
  containers:
    - name: test-container
      image: gcr.io/google_containers/busybox
      command: [ "/bin/sh", "-c", "cat", "/etc/config/path/to/special-key" ]
      volumeMounts:
      - name: config-volume
        mountPath: /etc/config
  volumes:
    - name: config-volume
      configMap:
        name: special-config
        items:
        - key: special.how
          path: path/to/special-key <co xml:id="CO43-1"/>
  restartPolicy: Never</programlisting>
<calloutlist>
<callout arearefs="CO43-1">
<para>Path to config map key.</para>
</callout>
</calloutlist>
<simpara>When this pod is run, the output of the cat command will be:</simpara>
<screen>very</screen>
</listitem>
</itemizedlist>
</section>
</section>
</chapter>
<chapter xml:id="odc-monitoring-project-and-application-metrics-using-developer-perspective">
<title>Monitoring project and application metrics using the Developer perspective</title>
<simpara>The <emphasis role="strong">Observe</emphasis> view in the <emphasis role="strong">Developer</emphasis> perspective provides options to monitor your project or application metrics, such as CPU, memory, and bandwidth usage, and network related information.</simpara>
<section xml:id="prerequisites_odc-monitoring-project-and-application-metrics-using-developer-perspective">
<title>Prerequisites</title>
<itemizedlist>
<listitem>
<simpara>You have <link linkend="odc-creating-applications-using-developer-perspective">created and deployed applications on OpenShift Container Platform</link>.</simpara>
</listitem>
<listitem>
<simpara>You have <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/web_console/#web-console">logged in to the web console</link> and have switched to <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/web_console/#about-developer-perspective_web-console-overview">the <emphasis role="strong">Developer</emphasis> perspective</link>.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="odc-monitoring-your-project-metrics_monitoring-project-and-application-metrics-using-developer-perspective">
<title>Monitoring your project metrics</title>
<simpara>After you create applications in your project and deploy them, you can use the <emphasis role="strong">Developer</emphasis> perspective in the web console to see the metrics for your project.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>On the left navigation panel of the <emphasis role="strong">Developer</emphasis> perspective, click <emphasis role="strong">Observe</emphasis> to see the <emphasis role="strong">Dashboard</emphasis>, <emphasis role="strong">Metrics</emphasis>, <emphasis role="strong">Alerts</emphasis>, and <emphasis role="strong">Events</emphasis> for your project.</simpara>
</listitem>
<listitem>
<simpara>Optional: Use the <emphasis role="strong">Dashboard</emphasis> tab to see graphs depicting the following application metrics:</simpara>
<itemizedlist>
<listitem>
<simpara>CPU usage</simpara>
</listitem>
<listitem>
<simpara>Memory usage</simpara>
</listitem>
<listitem>
<simpara>Bandwidth consumption</simpara>
</listitem>
<listitem>
<simpara>Network-related information such as the rate of transmitted and received packets and the rate of dropped packets.</simpara>
</listitem>
</itemizedlist>
<simpara>In the <emphasis role="strong">Dashboard</emphasis> tab, you can access the Kubernetes compute resources dashboards.</simpara>
<figure>
<title>Observe dashboard</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_observe_dashboard.png"/>
</imageobject>
<textobject><phrase>odc observe dashboard</phrase></textobject>
</mediaobject>
</figure>
<note>
<simpara>In the <emphasis role="strong">Dashboard</emphasis> list, <emphasis role="strong">Kubernetes / Compute Resources / Namespace (Pods)</emphasis> dashboard is selected by default.</simpara>
</note>
<simpara>Use the following options to see further details:</simpara>
<itemizedlist>
<listitem>
<simpara>Select a dashboard from the <emphasis role="strong">Dashboard</emphasis> list to see the filtered metrics. All dashboards produce additional sub-menus when selected, except <emphasis role="strong">Kubernetes / Compute Resources / Namespace (Pods)</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select an option from the <emphasis role="strong">Time Range</emphasis> list to determine the time frame for the data being captured.</simpara>
</listitem>
<listitem>
<simpara>Set a custom time range by selecting <emphasis role="strong">Custom time range</emphasis> from the <emphasis role="strong">Time Range</emphasis> list. You can input or select the <emphasis role="strong">From</emphasis> and <emphasis role="strong">To</emphasis> dates and times. Click <emphasis role="strong">Save</emphasis> to save the custom time range.</simpara>
</listitem>
<listitem>
<simpara>Select an option from the <emphasis role="strong">Refresh Interval</emphasis> list to determine the time period after which the data is refreshed.</simpara>
</listitem>
<listitem>
<simpara>Hover your cursor over the graphs to see specific details for your pod.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Inspect</emphasis> located in the upper-right corner of every graph to see any particular graph details. The graph details appear in the <emphasis role="strong">Metrics</emphasis> tab.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Optional: Use the <emphasis role="strong">Metrics</emphasis> tab to query for the required project metric.</simpara>
<figure>
<title>Monitoring metrics</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_project_metrics.png"/>
</imageobject>
<textobject><phrase>odc project metrics</phrase></textobject>
</mediaobject>
</figure>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>In the <emphasis role="strong">Select Query</emphasis> list, select an option to filter the required details for your project. The filtered metrics for all the application pods in your project are displayed in the graph. The pods in your project are also listed below.</simpara>
</listitem>
<listitem>
<simpara>From the list of pods, clear the colored square boxes to remove the metrics for specific pods to further filter your query result.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Show PromQL</emphasis> to see the Prometheus query. You can further modify this query with the help of prompts to customize the query and filter the metrics you want to see for that namespace.</simpara>
</listitem>
<listitem>
<simpara>Use the drop-down list to set a time range for the data being displayed. You can click <emphasis role="strong">Reset Zoom</emphasis> to reset it to the default time range.</simpara>
</listitem>
<listitem>
<simpara>Optional: In the <emphasis role="strong">Select Query</emphasis> list, select <emphasis role="strong">Custom Query</emphasis> to create a custom Prometheus query and filter relevant metrics.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Optional: Use the <emphasis role="strong">Alerts</emphasis> tab to do the following tasks:</simpara>
<itemizedlist>
<listitem>
<simpara>See the rules that trigger alerts for the applications in your project.</simpara>
</listitem>
<listitem>
<simpara>Identify the alerts firing in the project.</simpara>
</listitem>
<listitem>
<simpara>Silence such alerts if required.</simpara>
</listitem>
</itemizedlist>
<figure>
<title>Monitoring alerts</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_project_alerts.png"/>
</imageobject>
<textobject><phrase>odc project alerts</phrase></textobject>
</mediaobject>
</figure>
<simpara>Use the following options to see further details:</simpara>
<itemizedlist>
<listitem>
<simpara>Use the <emphasis role="strong">Filter</emphasis> list to filter the alerts by their <emphasis role="strong">Alert State</emphasis> and <emphasis role="strong">Severity</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click on an alert to go to the details page for that alert. In the <emphasis role="strong">Alerts Details</emphasis> page, you can click <emphasis role="strong">View Metrics</emphasis> to see the metrics for the alert.</simpara>
</listitem>
<listitem>
<simpara>Use the <emphasis role="strong">Notifications</emphasis> toggle adjoining an alert rule to silence all the alerts for that rule, and then select the duration for which the alerts will be silenced from the <emphasis role="strong">Silence for</emphasis> list.
You must have the permissions to edit alerts to see the <emphasis role="strong">Notifications</emphasis> toggle.</simpara>
</listitem>
<listitem>
<simpara>Use the <emphasis role="strong">Options</emphasis> menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> adjoining an alert rule to see the details of the alerting rule.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Optional: Use the <emphasis role="strong">Events</emphasis> tab to see the events for your project.</simpara>
<figure>
<title>Monitoring events</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_project_events.png"/>
</imageobject>
<textobject><phrase>odc project events</phrase></textobject>
</mediaobject>
</figure>
<simpara>You can filter the displayed events using the following options:</simpara>
<itemizedlist>
<listitem>
<simpara>In the <emphasis role="strong">Resources</emphasis> list, select a resource to see events for that resource.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">All Types</emphasis> list, select a type of event to see events relevant to that type.</simpara>
</listitem>
<listitem>
<simpara>Search for specific events using the <emphasis role="strong">Filter events by names or messages</emphasis> field.</simpara>
</listitem>
</itemizedlist>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-monitoring-your-application-metrics_monitoring-project-and-application-metrics-using-developer-perspective">
<title>Monitoring your application metrics</title>
<simpara>After you create applications in your project and deploy them, you can use the <emphasis role="strong">Topology</emphasis> view in the <emphasis role="strong">Developer</emphasis> perspective to see the alerts and metrics for your application. Critical and warning alerts for your application are indicated on the workload node in the <emphasis role="strong">Topology</emphasis> view.</simpara>
<formalpara>
<title>Procedure</title>
<para>To see the alerts for your workload:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>In the <emphasis role="strong">Topology</emphasis> view, click the workload to see the workload details in the right panel.</simpara>
</listitem>
<listitem>
<simpara>Click the <emphasis role="strong">Observe</emphasis> tab to see the critical and warning alerts for the application; graphs for metrics, such as CPU, memory, and bandwidth usage; and all the events for the application.</simpara>
<note>
<simpara>Only critical and warning alerts in the <emphasis role="strong">Firing</emphasis> state are displayed in the <emphasis role="strong">Topology</emphasis> view. Alerts in the <emphasis role="strong">Silenced</emphasis>, <emphasis role="strong">Pending</emphasis> and <emphasis role="strong">Not Firing</emphasis> states are not displayed.</simpara>
</note>
<figure>
<title>Monitoring application metrics</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_app_metrics.png"/>
</imageobject>
<textobject><phrase>odc app metrics</phrase></textobject>
</mediaobject>
</figure>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Click the alert listed in the right panel to see the alert details in the <emphasis role="strong">Alert Details</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Click any of the charts to go to the <emphasis role="strong">Metrics</emphasis> tab to see the detailed metrics for the application.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">View monitoring dashboard</emphasis> to see the monitoring dashboard for that application.</simpara>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-image-vulnerabilities-breakdown_monitoring-project-and-application-metrics-using-developer-perspective">
<title>Image vulnerabilities breakdown</title>
<simpara>In the developer perspective, the project dashboard shows the <emphasis role="strong">Image Vulnerabilities</emphasis> link in the <emphasis role="strong">Status</emphasis> section. Using this link, you can view the <emphasis role="strong">Image Vulnerabilities breakdown</emphasis> window, which includes details regarding vulnerable container images and fixable container images. The icon color indicates severity:</simpara>
<itemizedlist>
<listitem>
<simpara>Red: High priority. Fix immediately.</simpara>
</listitem>
<listitem>
<simpara>Orange: Medium priority. Can be fixed after high-priority vulnerabilities.</simpara>
</listitem>
<listitem>
<simpara>Yellow: Low priority. Can be fixed after high and medium-priority vulnerabilities.</simpara>
</listitem>
</itemizedlist>
<simpara>Based on the severity level, you can prioritize vulnerabilities and fix them in an organized manner.</simpara>
<figure>
<title>Viewing image vulnerabilities</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_image_vulnerabilities.png"/>
</imageobject>
<textobject><phrase>odc image vulnerabilities</phrase></textobject>
</mediaobject>
</figure>
</section>
<section xml:id="odc-monitoring-your-application-image-vulnerabilities-metrics_monitoring-project-and-application-metrics-using-developer-perspective">
<title>Monitoring your application and image vulnerabilities metrics</title>
<simpara>After you create applications in your project and deploy them, use the <emphasis role="strong">Developer</emphasis> perspective in the web console to see the metrics for your application dependency vulnerabilities across your cluster. The metrics help you to analyze the following image vulnerabilities in detail:</simpara>
<itemizedlist>
<listitem>
<simpara>Total count of vulnerable images in a selected project</simpara>
</listitem>
<listitem>
<simpara>Severity-based counts of all vulnerable images in a selected project</simpara>
</listitem>
<listitem>
<simpara>Drilldown into severity to obtain the details, such as count of vulnerabilities, count of fixable vulnerabilities, and number of affected pods for each vulnerable image</simpara>
</listitem>
</itemizedlist>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have installed the Red Hat Quay Container Security operator from the Operator Hub.</simpara>
<note>
<simpara>The Red Hat Quay Container Security operator detects vulnerabilities by scanning the images that are in the quay registry.</simpara>
</note>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>For a general overview of the image vulnerabilities, on the navigation panel of the <emphasis role="strong">Developer</emphasis> perspective, click <emphasis role="strong">Project</emphasis> to see the project dashboard.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Image Vulnerabilities</emphasis> in the <emphasis role="strong">Status</emphasis> section. The window that opens displays details such as <emphasis role="strong">Vulnerable Container Images</emphasis> and <emphasis role="strong">Fixable Container Images</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>For a detailed vulnerabilities overview, click the <emphasis role="strong">Vulnerabilities</emphasis> tab on the project dashboard.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>To get more detail about an image, click its name.</simpara>
</listitem>
<listitem>
<simpara>View the default graph with all types of vulnerabilities in the <emphasis role="strong">Details</emphasis> tab.</simpara>
</listitem>
<listitem>
<simpara>Optional: Click the toggle button to view a specific type of vulnerability. For example, click <emphasis role="strong">App dependency</emphasis> to see vulnerabilities specific to application dependency.</simpara>
</listitem>
<listitem>
<simpara>Optional: You can filter the list of vulnerabilities based on their <emphasis role="strong">Severity</emphasis> and <emphasis role="strong">Type</emphasis> or sort them by <emphasis role="strong">Severity</emphasis>, <emphasis role="strong">Package</emphasis>, <emphasis role="strong">Type</emphasis>, <emphasis role="strong">Source</emphasis>, <emphasis role="strong">Current Version</emphasis>, and <emphasis role="strong">Fixed in Version</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click a <emphasis role="strong">Vulnerability</emphasis> to get its associated details:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Base image</emphasis> vulnerabilities display information from a Red Hat Security Advisory (RHSA).</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">App dependency</emphasis> vulnerabilities display information from the Snyk security application.</simpara>
</listitem>
</itemizedlist>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
</section>
<section xml:id="additional-resources-odc-monitoring-project-and-application-metrics-using-developer-perspective" role="_additional-resources">
<title>Additional resources</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/monitoring/#monitoring-overview">Monitoring overview</link></simpara>
</listitem>
</itemizedlist>
</section>
</chapter>
<chapter xml:id="application-health">
<title>Monitoring application health by using health checks</title>
<simpara>In software systems, components can become unhealthy due to transient issues such as temporary connectivity loss, configuration errors, or problems with external dependencies. OpenShift Container Platform applications have a number of options to detect and handle unhealthy containers.</simpara>
<section xml:id="application-health-about_application-health">
<title>Understanding health checks</title>
<simpara>A health check periodically performs diagnostics on a
running container using any combination of the readiness, liveness, and startup health checks.</simpara>
<simpara>You can include one or more probes in the specification for the pod that contains the container which you want to perform the health checks.</simpara>
<note>
<simpara>If you want to add or edit health checks in an existing pod, you must edit the pod <literal>DeploymentConfig</literal> object or use the <emphasis role="strong">Developer</emphasis> perspective in the web console. You cannot use the CLI to add or edit health checks for an existing pod.</simpara>
</note>
<variablelist>
<varlistentry>
<term>Readiness probe</term>
<listitem>
<simpara>A <emphasis>readiness probe</emphasis> determines if a container is ready to accept service requests. If
the readiness probe fails for a container, the kubelet removes the pod from the list of available service endpoints.</simpara>
<simpara>After a failure, the probe continues to examine the pod. If the pod becomes available, the kubelet adds the pod to the list of available service endpoints.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Liveness health check</term>
<listitem>
<simpara>A <emphasis>liveness probe</emphasis> determines if a container is still
running. If the liveness probe fails due to a condition such as a deadlock, the kubelet kills the container. The pod then
responds based on its restart policy.</simpara>
<simpara>For example, a liveness probe on a pod with a <literal>restartPolicy</literal> of <literal>Always</literal> or <literal>OnFailure</literal>
kills and restarts the container.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Startup probe</term>
<listitem>
<simpara>A <emphasis>startup probe</emphasis> indicates whether the application within a container is started. All other probes are disabled until the startup succeeds. If the startup probe does not succeed within a specified time period, the kubelet kills the container, and the container is subject to the pod <literal>restartPolicy</literal>.</simpara>
<simpara>Some applications can require additional startup time on their first initialization. You can use a startup probe with a liveness or readiness probe to delay that probe long enough to handle lengthy start-up time using the <literal>failureThreshold</literal> and <literal>periodSeconds</literal> parameters.</simpara>
<simpara>For example, you can add a startup probe, with a <literal>failureThreshold</literal> of 30 failures and a <literal>periodSeconds</literal> of 10 seconds (30 * 10s = 300s) for a maximum of 5 minutes, to a liveness probe. After the startup probe succeeds the first time, the liveness probe takes over.</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>You can configure liveness, readiness, and startup probes with any of the following types of tests:</simpara>
<itemizedlist>
<listitem>
<simpara>HTTP <literal>GET</literal>: When using an HTTP <literal>GET</literal> test, the test determines the healthiness of the container by using a web hook. The test is successful if the HTTP response code is between <literal>200</literal> and <literal>399</literal>.</simpara>
<simpara>You can use an HTTP <literal>GET</literal> test with applications that return HTTP status codes when completely initialized.</simpara>
</listitem>
<listitem>
<simpara>Container Command: When using a container command test, the probe executes a command inside the container. The probe is successful if the test exits with a <literal>0</literal> status.</simpara>
</listitem>
<listitem>
<simpara>TCP socket: When using a TCP socket test, the probe attempts to open a socket to the container. The container is only
considered healthy if the probe can establish a connection. You can use a TCP socket test with applications that do not start listening until
initialization is complete.</simpara>
</listitem>
</itemizedlist>
<simpara>You can configure several fields to control the behavior of a probe:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>initialDelaySeconds</literal>: The time, in seconds, after the container starts before the probe can be scheduled. The default is 0.</simpara>
</listitem>
<listitem>
<simpara><literal>periodSeconds</literal>: The delay, in seconds, between performing probes. The default is <literal>10</literal>. This value must be greater than <literal>timeoutSeconds</literal>.</simpara>
</listitem>
<listitem>
<simpara><literal>timeoutSeconds</literal>: The number of seconds of inactivity after which the probe times out and the container is assumed to have failed. The default is <literal>1</literal>. This value must be lower than <literal>periodSeconds</literal>.</simpara>
</listitem>
<listitem>
<simpara><literal>successThreshold</literal>: The number of times that the probe must report success after a failure to reset the container status to successful. The value must be <literal>1</literal> for a liveness probe. The default is <literal>1</literal>.</simpara>
</listitem>
<listitem>
<simpara><literal>failureThreshold</literal>: The number of times that the probe is allowed to fail. The default is 3. After the specified attempts:</simpara>
<itemizedlist>
<listitem>
<simpara>for a liveness probe, the container is restarted</simpara>
</listitem>
<listitem>
<simpara>for a readiness probe, the pod is marked <literal>Unready</literal></simpara>
</listitem>
<listitem>
<simpara>for a startup probe, the container is killed and is subject to the pod&#8217;s <literal>restartPolicy</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
<bridgehead xml:id="application-health-examples" renderas="sect3">Example probes</bridgehead>
<simpara>The following are samples of different probes as they would appear in an object specification.</simpara>
<formalpara>
<title>Sample readiness probe with a container command readiness probe in a pod spec</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  labels:
    test: health-check
  name: my-application
...
spec:
  containers:
  - name: goproxy-app <co xml:id="CO44-1"/>
    args:
    image: registry.k8s.io/goproxy:0.1 <co xml:id="CO44-2"/>
    readinessProbe: <co xml:id="CO44-3"/>
      exec: <co xml:id="CO44-4"/>
        command: <co xml:id="CO44-5"/>
        - cat
        - /tmp/healthy
...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO44-1">
<para>The container name.</para>
</callout>
<callout arearefs="CO44-2">
<para>The container image to deploy.</para>
</callout>
<callout arearefs="CO44-3">
<para>A readiness probe.</para>
</callout>
<callout arearefs="CO44-4">
<para>A container command test.</para>
</callout>
<callout arearefs="CO44-5">
<para>The commands to execute on the container.</para>
</callout>
</calloutlist>
<formalpara>
<title>Sample container command startup probe and liveness probe with container command tests in a pod spec</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  labels:
    test: health-check
  name: my-application
...
spec:
  containers:
  - name: goproxy-app <co xml:id="CO45-1"/>
    args:
    image: registry.k8s.io/goproxy:0.1 <co xml:id="CO45-2"/>
    livenessProbe: <co xml:id="CO45-3"/>
      httpGet: <co xml:id="CO45-4"/>
        scheme: HTTPS <co xml:id="CO45-5"/>
        path: /healthz
        port: 8080 <co xml:id="CO45-6"/>
        httpHeaders:
        - name: X-Custom-Header
          value: Awesome
    startupProbe: <co xml:id="CO45-7"/>
      httpGet: <co xml:id="CO45-8"/>
        path: /healthz
        port: 8080 <co xml:id="CO45-9"/>
      failureThreshold: 30 <co xml:id="CO45-10"/>
      periodSeconds: 10 <co xml:id="CO45-11"/>
...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO45-1">
<para>The container name.</para>
</callout>
<callout arearefs="CO45-2">
<para>Specify the container image to deploy.</para>
</callout>
<callout arearefs="CO45-3">
<para>A liveness probe.</para>
</callout>
<callout arearefs="CO45-4">
<para>An HTTP <literal>GET</literal> test.</para>
</callout>
<callout arearefs="CO45-5">
<para>The internet scheme: <literal>HTTP</literal> or <literal>HTTPS</literal>. The default value is <literal>HTTP</literal>.</para>
</callout>
<callout arearefs="CO45-6">
<para>The port on which the container is listening.</para>
</callout>
<callout arearefs="CO45-7">
<para>A startup probe.</para>
</callout>
<callout arearefs="CO45-8">
<para>An HTTP <literal>GET</literal> test.</para>
</callout>
<callout arearefs="CO45-9">
<para>The port on which the container is listening.</para>
</callout>
<callout arearefs="CO45-10">
<para>The number of times to try the probe after a failure.</para>
</callout>
<callout arearefs="CO45-11">
<para>The number of seconds to perform the probe.</para>
</callout>
</calloutlist>
<formalpara>
<title>Sample liveness probe with a container command test that uses a timeout in a pod spec</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  labels:
    test: health-check
  name: my-application
...
spec:
  containers:
  - name: goproxy-app <co xml:id="CO46-1"/>
    args:
    image: registry.k8s.io/goproxy:0.1 <co xml:id="CO46-2"/>
    livenessProbe: <co xml:id="CO46-3"/>
      exec: <co xml:id="CO46-4"/>
        command: <co xml:id="CO46-5"/>
        - /bin/bash
        - '-c'
        - timeout 60 /opt/eap/bin/livenessProbe.sh
      periodSeconds: 10 <co xml:id="CO46-6"/>
      successThreshold: 1 <co xml:id="CO46-7"/>
      failureThreshold: 3 <co xml:id="CO46-8"/>
...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO46-1">
<para>The container name.</para>
</callout>
<callout arearefs="CO46-2">
<para>Specify the container image to deploy.</para>
</callout>
<callout arearefs="CO46-3">
<para>The liveness probe.</para>
</callout>
<callout arearefs="CO46-4">
<para>The type of probe, here a container command probe.</para>
</callout>
<callout arearefs="CO46-5">
<para>The command line to execute inside the container.</para>
</callout>
<callout arearefs="CO46-6">
<para>How often in seconds to perform the probe.</para>
</callout>
<callout arearefs="CO46-7">
<para>The number of consecutive successes needed to show success after a failure.</para>
</callout>
<callout arearefs="CO46-8">
<para>The number of times to try the probe after a failure.</para>
</callout>
</calloutlist>
<formalpara>
<title>Sample readiness probe and liveness probe with a TCP socket test in a deployment</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">kind: Deployment
apiVersion: apps/v1
...
spec:
...
  template:
    spec:
      containers:
        - resources: {}
          readinessProbe: <co xml:id="CO47-1"/>
            tcpSocket:
              port: 8080
            timeoutSeconds: 1
            periodSeconds: 10
            successThreshold: 1
            failureThreshold: 3
          terminationMessagePath: /dev/termination-log
          name: ruby-ex
          livenessProbe: <co xml:id="CO47-2"/>
            tcpSocket:
              port: 8080
            initialDelaySeconds: 15
            timeoutSeconds: 1
            periodSeconds: 10
            successThreshold: 1
            failureThreshold: 3
...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO47-1">
<para>The readiness probe.</para>
</callout>
<callout arearefs="CO47-2">
<para>The liveness probe.</para>
</callout>
</calloutlist>
</section>
<section xml:id="application-health-configuring_application-health">
<title>Configuring health checks using the CLI</title>
<simpara>To configure readiness, liveness, and startup probes, add one or more probes to the specification for the pod that contains the container which you want to perform the health checks</simpara>
<note>
<simpara>If you want to add or edit health checks in an existing pod, you must edit the pod <literal>DeploymentConfig</literal> object or use the <emphasis role="strong">Developer</emphasis> perspective in the web console. You cannot use the CLI to add or edit health checks for an existing pod.</simpara>
</note>
<formalpara>
<title>Procedure</title>
<para>To add probes for a container:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Create a <literal>Pod</literal> object to add one or more probes:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  labels:
    test: health-check
  name: my-application
spec:
  containers:
  - name: my-container <co xml:id="CO48-1"/>
    args:
    image: registry.k8s.io/goproxy:0.1 <co xml:id="CO48-2"/>
    livenessProbe: <co xml:id="CO48-3"/>
      tcpSocket:  <co xml:id="CO48-4"/>
        port: 8080 <co xml:id="CO48-5"/>
      initialDelaySeconds: 15 <co xml:id="CO48-6"/>
      periodSeconds: 20 <co xml:id="CO48-7"/>
      timeoutSeconds: 10 <co xml:id="CO48-8"/>
    readinessProbe: <co xml:id="CO48-9"/>
      httpGet: <co xml:id="CO48-10"/>
        host: my-host <co xml:id="CO48-11"/>
        scheme: HTTPS <co xml:id="CO48-12"/>
        path: /healthz
        port: 8080 <co xml:id="CO48-13"/>
    startupProbe: <co xml:id="CO48-14"/>
      exec: <co xml:id="CO48-15"/>
        command: <co xml:id="CO48-16"/>
        - cat
        - /tmp/healthy
      failureThreshold: 30 <co xml:id="CO48-17"/>
      periodSeconds: 20 <co xml:id="CO48-18"/>
      timeoutSeconds: 10 <co xml:id="CO48-19"/></programlisting>
<calloutlist>
<callout arearefs="CO48-1">
<para>Specify the container name.</para>
</callout>
<callout arearefs="CO48-2">
<para>Specify the container image to deploy.</para>
</callout>
<callout arearefs="CO48-3">
<para>Optional: Create a Liveness probe.</para>
</callout>
<callout arearefs="CO48-4">
<para>Specify a test to perform, here a TCP Socket test.</para>
</callout>
<callout arearefs="CO48-5">
<para>Specify the port on which the container is listening.</para>
</callout>
<callout arearefs="CO48-6">
<para>Specify the time, in seconds, after the container starts before the probe can be scheduled.</para>
</callout>
<callout arearefs="CO48-7">
<para>Specify the number of seconds to perform the probe. The default is <literal>10</literal>. This value must be greater than <literal>timeoutSeconds</literal>.</para>
</callout>
<callout arearefs="CO48-8">
<para>Specify the number of seconds of inactivity after which the probe is assumed to have failed. The default is <literal>1</literal>. This value must be lower than <literal>periodSeconds</literal>.</para>
</callout>
<callout arearefs="CO48-9">
<para>Optional: Create a Readiness probe.</para>
</callout>
<callout arearefs="CO48-10">
<para>Specify the type of test to perform, here an HTTP test.</para>
</callout>
<callout arearefs="CO48-11">
<para>Specify a host IP address. When <literal>host</literal> is not defined, the <literal>PodIP</literal> is used.</para>
</callout>
<callout arearefs="CO48-12">
<para>Specify <literal>HTTP</literal> or <literal>HTTPS</literal>. When <literal>scheme</literal> is not defined, the <literal>HTTP</literal> scheme is used.</para>
</callout>
<callout arearefs="CO48-13">
<para>Specify the port on which the container is listening.</para>
</callout>
<callout arearefs="CO48-14">
<para>Optional: Create a Startup probe.</para>
</callout>
<callout arearefs="CO48-15">
<para>Specify the type of test to perform, here an Container Execution probe.</para>
</callout>
<callout arearefs="CO48-16">
<para>Specify the commands to execute on the container.</para>
</callout>
<callout arearefs="CO48-17">
<para>Specify the number of times to try the probe after a failure.</para>
</callout>
<callout arearefs="CO48-18">
<para>Specify the number of seconds to perform the probe. The default is <literal>10</literal>. This value must be greater than <literal>timeoutSeconds</literal>.</para>
</callout>
<callout arearefs="CO48-19">
<para>Specify the number of seconds of inactivity after which the probe is assumed to have failed. The default is <literal>1</literal>. This value must be lower than <literal>periodSeconds</literal>.</para>
</callout>
</calloutlist>
<note>
<simpara>If the <literal>initialDelaySeconds</literal> value is lower than the <literal>periodSeconds</literal> value, the first Readiness probe occurs at some point between the two periods due to an issue with timers.</simpara>
<simpara>The <literal>timeoutSeconds</literal> value must be lower than the <literal>periodSeconds</literal> value.</simpara>
</note>
</listitem>
<listitem>
<simpara>Create the <literal>Pod</literal> object:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create -f &lt;file-name&gt;.yaml</programlisting>
</listitem>
<listitem>
<simpara>Verify the state of the health check pod:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc describe pod health-check</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">Events:
  Type    Reason     Age   From                                  Message
  ----    ------     ----  ----                                  -------
  Normal  Scheduled  9s    default-scheduler                     Successfully assigned openshift-logging/liveness-exec to ip-10-0-143-40.ec2.internal
  Normal  Pulling    2s    kubelet, ip-10-0-143-40.ec2.internal  pulling image "registry.k8s.io/liveness"
  Normal  Pulled     1s    kubelet, ip-10-0-143-40.ec2.internal  Successfully pulled image "registry.k8s.io/liveness"
  Normal  Created    1s    kubelet, ip-10-0-143-40.ec2.internal  Created container
  Normal  Started    1s    kubelet, ip-10-0-143-40.ec2.internal  Started container</programlisting>
</para>
</formalpara>
<simpara>The following is the output of a failed probe that restarted a container:</simpara>
<formalpara>
<title>Sample Liveness check output with unhealthy container</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">$ oc describe pod pod1</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">....

Events:
  Type     Reason          Age                From                                               Message
  ----     ------          ----               ----                                               -------
  Normal   Scheduled       &lt;unknown&gt;                                                             Successfully assigned aaa/liveness-http to ci-ln-37hz77b-f76d1-wdpjv-worker-b-snzrj
  Normal   AddedInterface  47s                multus                                             Add eth0 [10.129.2.11/23]
  Normal   Pulled          46s                kubelet, ci-ln-37hz77b-f76d1-wdpjv-worker-b-snzrj  Successfully pulled image "registry.k8s.io/liveness" in 773.406244ms
  Normal   Pulled          28s                kubelet, ci-ln-37hz77b-f76d1-wdpjv-worker-b-snzrj  Successfully pulled image "registry.k8s.io/liveness" in 233.328564ms
  Normal   Created         10s (x3 over 46s)  kubelet, ci-ln-37hz77b-f76d1-wdpjv-worker-b-snzrj  Created container liveness
  Normal   Started         10s (x3 over 46s)  kubelet, ci-ln-37hz77b-f76d1-wdpjv-worker-b-snzrj  Started container liveness
  Warning  Unhealthy       10s (x6 over 34s)  kubelet, ci-ln-37hz77b-f76d1-wdpjv-worker-b-snzrj  Liveness probe failed: HTTP probe failed with statuscode: 500
  Normal   Killing         10s (x2 over 28s)  kubelet, ci-ln-37hz77b-f76d1-wdpjv-worker-b-snzrj  Container liveness failed liveness probe, will be restarted
  Normal   Pulling         10s (x3 over 47s)  kubelet, ci-ln-37hz77b-f76d1-wdpjv-worker-b-snzrj  Pulling image "registry.k8s.io/liveness"
  Normal   Pulled          10s                kubelet, ci-ln-37hz77b-f76d1-wdpjv-worker-b-snzrj  Successfully pulled image "registry.k8s.io/liveness" in 244.116568ms</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-monitoring-application-health-using-developer-perspective">
<title>Monitoring application health using the Developer perspective</title>
<simpara>You can use the <emphasis role="strong">Developer</emphasis> perspective to add three types of health probes to your container to ensure that your application is healthy:</simpara>
<itemizedlist>
<listitem>
<simpara>Use the Readiness probe to check if the container is ready to handle requests.</simpara>
</listitem>
<listitem>
<simpara>Use the Liveness probe to check if the container is running.</simpara>
</listitem>
<listitem>
<simpara>Use the Startup probe to check if the application within the container has started.</simpara>
</listitem>
</itemizedlist>
<simpara>You can add health checks either while creating and deploying an application, or after you have deployed an application.</simpara>
</section>
<section xml:id="odc-adding-health-checks">
<title>Adding health checks using the Developer perspective</title>
<simpara>You can use the <emphasis role="strong">Topology</emphasis> view to add health checks to your deployed application.</simpara>
<itemizedlist>
<title>Prerequisites:</title>
<listitem>
<simpara>You have switched to the <emphasis role="strong">Developer</emphasis> perspective in the web console.</simpara>
</listitem>
<listitem>
<simpara>You have created and deployed an application on OpenShift Container Platform using the <emphasis role="strong">Developer</emphasis> perspective.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the <emphasis role="strong">Topology</emphasis> view, click on the application node to see the side panel. If the container does not have health checks added to ensure the smooth running of your application, a <emphasis role="strong">Health Checks</emphasis> notification is displayed with a link to add health checks.</simpara>
</listitem>
<listitem>
<simpara>In the displayed notification, click the <emphasis role="strong">Add Health Checks</emphasis> link.</simpara>
</listitem>
<listitem>
<simpara>Alternatively, you can also click the <emphasis role="strong">Actions</emphasis> drop-down list and select <emphasis role="strong">Add Health Checks</emphasis>. Note that if the container already has health checks, you will see the <emphasis role="strong">Edit Health Checks</emphasis> option instead of the add option.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Add Health Checks</emphasis> form, if you have deployed multiple containers, use the <emphasis role="strong">Container</emphasis> drop-down list to ensure that the appropriate container is selected.</simpara>
</listitem>
<listitem>
<simpara>Click the required health probe links to add them to the container. Default data for the health checks is prepopulated. You can add the probes with the default data or further customize the values and then add them. For example, to add a Readiness probe that checks if your container is ready to handle requests:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Click <emphasis role="strong">Add Readiness Probe</emphasis>, to see a form containing the parameters for the probe.</simpara>
</listitem>
<listitem>
<simpara>Click the <emphasis role="strong">Type</emphasis> drop-down list to select the request type you want to add. For example, in this case, select <emphasis role="strong">Container Command</emphasis> to select the command that will be executed inside the container.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Command</emphasis> field, add an argument <literal>cat</literal>, similarly, you can add multiple arguments for the check, for example, add another argument <literal>/tmp/healthy</literal>.</simpara>
</listitem>
<listitem>
<simpara>Retain or modify the default values for the other parameters as required.</simpara>
<note>
<simpara>The <literal>Timeout</literal> value must be lower than the <literal>Period</literal> value. The <literal>Timeout</literal> default value is <literal>1</literal>. The <literal>Period</literal> default value is <literal>10</literal>.</simpara>
</note>
</listitem>
<listitem>
<simpara>Click the check mark at the bottom of the form. The <emphasis role="strong">Readiness Probe Added</emphasis> message is displayed.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Add</emphasis> to add the health check. You are redirected to the <emphasis role="strong">Topology</emphasis> view and the container is restarted.</simpara>
</listitem>
<listitem>
<simpara>In the side panel, verify that the probes have been added by clicking on the deployed pod under the <emphasis role="strong">Pods</emphasis> section.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Pod Details</emphasis> page, click the listed container in the <emphasis role="strong">Containers</emphasis> section.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Container Details</emphasis> page, verify that the Readiness probe - <emphasis role="strong">Exec Command</emphasis> <literal>cat</literal> <literal>/tmp/healthy</literal> has been added to the container.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-editing-health-checks">
<title>Editing health checks using the Developer perspective</title>
<simpara>You can use the <emphasis role="strong">Topology</emphasis> view to edit health checks added to your application, modify them, or add more health checks.</simpara>
<itemizedlist>
<title>Prerequisites:</title>
<listitem>
<simpara>You have switched to the <emphasis role="strong">Developer</emphasis> perspective in the web console.</simpara>
</listitem>
<listitem>
<simpara>You have created and deployed an application on OpenShift Container Platform using the <emphasis role="strong">Developer</emphasis> perspective.</simpara>
</listitem>
<listitem>
<simpara>You have added health checks to your application.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the <emphasis role="strong">Topology</emphasis> view, right-click your application and select <emphasis role="strong">Edit Health Checks</emphasis>. Alternatively, in the side panel, click the <emphasis role="strong">Actions</emphasis> drop-down list and select <emphasis role="strong">Edit Health Checks</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Edit Health Checks</emphasis> page:</simpara>
<itemizedlist>
<listitem>
<simpara>To remove a previously added health probe, click the <emphasis role="strong">Remove</emphasis> icon adjoining it.</simpara>
</listitem>
<listitem>
<simpara>To edit the parameters of an existing probe:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Click the <emphasis role="strong">Edit Probe</emphasis> link next to a previously added probe to see the parameters for the probe.</simpara>
</listitem>
<listitem>
<simpara>Modify the parameters as required, and click the check mark to save your changes.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>To add a new health probe, in addition to existing health checks, click the add probe links. For example, to add a Liveness probe that checks if your container is running:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Click <emphasis role="strong">Add Liveness Probe</emphasis>, to see a form containing the parameters for the probe.</simpara>
</listitem>
<listitem>
<simpara>Edit the probe parameters as required.</simpara>
<note>
<simpara>The <literal>Timeout</literal> value must be lower than the <literal>Period</literal> value. The <literal>Timeout</literal> default value is <literal>1</literal>. The <literal>Period</literal> default value is <literal>10</literal>.</simpara>
</note>
</listitem>
<listitem>
<simpara>Click the check mark at the bottom of the form. The <emphasis role="strong">Liveness Probe Added</emphasis> message is displayed.</simpara>
</listitem>
</orderedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Save</emphasis> to save your modifications and add the additional probes to your container. You are redirected to the <emphasis role="strong">Topology</emphasis> view.</simpara>
</listitem>
<listitem>
<simpara>In the side panel, verify that the probes have been added by clicking on the deployed pod under the <emphasis role="strong">Pods</emphasis> section.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Pod Details</emphasis> page, click the listed container in the <emphasis role="strong">Containers</emphasis> section.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Container Details</emphasis> page, verify that the Liveness probe - <literal>HTTP Get 10.129.4.65:8080/</literal> has been added to the container, in addition to the earlier existing probes.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="odc-monitoring-health-checks">
<title>Monitoring health check failures using the Developer perspective</title>
<simpara>In case an application health check fails, you can use the <emphasis role="strong">Topology</emphasis> view to monitor these health check violations.</simpara>
<itemizedlist>
<title>Prerequisites:</title>
<listitem>
<simpara>You have switched to the <emphasis role="strong">Developer</emphasis> perspective in the web console.</simpara>
</listitem>
<listitem>
<simpara>You have created and deployed an application on OpenShift Container Platform using the <emphasis role="strong">Developer</emphasis> perspective.</simpara>
</listitem>
<listitem>
<simpara>You have added health checks to your application.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the <emphasis role="strong">Topology</emphasis> view, click on the application node to see the side panel.</simpara>
</listitem>
<listitem>
<simpara>Click the <emphasis role="strong">Observe</emphasis> tab to see the health check failures in the <emphasis role="strong">Events (Warning)</emphasis> section.</simpara>
</listitem>
<listitem>
<simpara>Click the down arrow adjoining <emphasis role="strong">Events (Warning)</emphasis> to see the details of the health check failure.</simpara>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara>For details on switching to the <emphasis role="strong">Developer</emphasis> perspective in the web console, see <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/web_console/#about-developer-perspective_web-console-overview">About the <emphasis role="strong">Developer</emphasis> perspective</link>.</simpara>
</listitem>
<listitem>
<simpara>For details on adding health checks while creating and deploying an application, see <emphasis role="strong">Advanced Options</emphasis> in the <link linkend="odc-creating-applications-using-developer-perspective">Creating applications using the Developer perspective</link> section.</simpara>
</listitem>
</itemizedlist>
</section>
</chapter>
<chapter xml:id="odc-editing-applications">
<title>Editing applications</title>
<simpara>You can edit the configuration and the source code of the application you create using the <emphasis role="strong">Topology</emphasis> view.</simpara>
<section xml:id="_prerequisites-6">
<title>Prerequisites</title>
<itemizedlist>
<listitem>
<simpara>You have the appropriate <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/authentication_and_authorization/#default-roles_using-rbac">roles and permissions</link> in a project to create and modify applications in OpenShift Container Platform.</simpara>
</listitem>
<listitem>
<simpara>You have <link linkend="odc-creating-applications-using-developer-perspective">created and deployed an application on OpenShift Container Platform using the <emphasis role="strong">Developer</emphasis> perspective</link>.</simpara>
</listitem>
<listitem>
<simpara>You have <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/web_console/#web-console">logged in to the web console</link> and have switched to <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/web_console/#about-developer-perspective_web-console-overview">the <emphasis role="strong">Developer</emphasis> perspective</link>.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="odc-editing-source-code-using-developer-perspective_odc-editing-applications">
<title>Editing the source code of an application using the Developer perspective</title>
<simpara>You can use the <emphasis role="strong">Topology</emphasis> view in the <emphasis role="strong">Developer</emphasis> perspective to edit the source code of your application.</simpara>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>In the <emphasis role="strong">Topology</emphasis> view, click the <emphasis role="strong">Edit Source code</emphasis> icon, displayed at the bottom-right of the deployed application, to access your source code and modify it.</simpara>
<note>
<simpara>This feature is available only when you create applications using the <emphasis role="strong">From Git</emphasis>, <emphasis role="strong">From Catalog</emphasis>, and the <emphasis role="strong">From Dockerfile</emphasis> options.</simpara>
</note>
<simpara>If the <emphasis role="strong">Eclipse Che</emphasis> Operator is installed in your cluster, a Che workspace (<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_che_workspace.png"/>
</imageobject>
<textobject><phrase>odc che workspace</phrase></textobject>
</inlinemediaobject>) is created and you are directed to the workspace to edit your source code. If it is not installed, you will be directed to the Git repository (<inlinemediaobject>
<imageobject>
<imagedata fileref="images/odc_git_repository.png"/>
</imageobject>
<textobject><phrase>odc git repository</phrase></textobject>
</inlinemediaobject>) your source code is hosted in.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="odc-editing-application-configuration-using-developer-perspective_odc-editing-applications">
<title>Editing the application configuration using the Developer perspective</title>
<simpara>You can use the <emphasis role="strong">Topology</emphasis> view in the <emphasis role="strong">Developer</emphasis> perspective to edit the configuration of your application.</simpara>
<note>
<simpara>Currently, only configurations of applications created by using the <emphasis role="strong">From Git</emphasis>, <emphasis role="strong">Container Image</emphasis>, <emphasis role="strong">From Catalog</emphasis>, or <emphasis role="strong">From Dockerfile</emphasis> options in the <emphasis role="strong">Add</emphasis> workflow of the <emphasis role="strong">Developer</emphasis> perspective can be edited. Configurations of applications created by using the CLI or the <emphasis role="strong">YAML</emphasis> option from the <emphasis role="strong">Add</emphasis> workflow cannot be edited.</simpara>
</note>
<formalpara>
<title>Prerequisites</title>
<para>Ensure that you have created an application using  the <emphasis role="strong">From Git</emphasis>, <emphasis role="strong">Container Image</emphasis>, <emphasis role="strong">From Catalog</emphasis>, or <emphasis role="strong">From Dockerfile</emphasis> options in the <emphasis role="strong">Add</emphasis> workflow.</para>
</formalpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>After you have created an application and it is displayed in the <emphasis role="strong">Topology</emphasis> view, right-click the application to see the edit options available.</simpara>
<figure>
<title>Edit application</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_edit_app.png"/>
</imageobject>
<textobject><phrase>odc edit app</phrase></textobject>
</mediaobject>
</figure>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Edit <emphasis>application-name</emphasis></emphasis> to see the <emphasis role="strong">Add</emphasis> workflow you used to create the application. The form is pre-populated with the values you had added while creating the application.</simpara>
</listitem>
<listitem>
<simpara>Edit the necessary values for the application.</simpara>
<note>
<simpara>You cannot edit the <emphasis role="strong">Name</emphasis> field in the <emphasis role="strong">General</emphasis> section, the CI/CD pipelines, or the <emphasis role="strong">Create a route to the application</emphasis> field in the <emphasis role="strong">Advanced Options</emphasis> section.</simpara>
</note>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Save</emphasis> to restart the build and deploy a new image.</simpara>
<figure>
<title>Edit and redeploy application</title>
<mediaobject>
<imageobject>
<imagedata fileref="images/odc_edit_redeploy.png"/>
</imageobject>
<textobject><phrase>odc edit redeploy</phrase></textobject>
</mediaobject>
</figure>
</listitem>
</orderedlist>
</section>
</chapter>
<chapter xml:id="pruning-objects">
<title>Pruning objects to reclaim resources</title>
<simpara>Over time, API objects created in OpenShift Container Platform can accumulate in the
cluster&#8217;s etcd data store through normal user operations, such as when building
and deploying applications.</simpara>
<simpara>Cluster administrators can periodically prune older versions of objects from the
cluster that are no longer required. For example, by pruning images you can delete
older images and layers that are no longer in use, but are still taking up disk
space.</simpara>
<section xml:id="pruning-basic-operations_pruning-objects">
<title>Basic pruning operations</title>
<simpara>The CLI groups prune operations under a common parent command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm prune &lt;object_type&gt; &lt;options&gt;</programlisting>
<simpara>This specifies:</simpara>
<itemizedlist>
<listitem>
<simpara>The <literal>&lt;object_type&gt;</literal> to perform the action on, such as <literal>groups</literal>, <literal>builds</literal>,
<literal>deployments</literal>, or <literal>images</literal>.</simpara>
</listitem>
<listitem>
<simpara>The <literal>&lt;options&gt;</literal> supported to prune that object type.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="pruning-groups_pruning-objects">
<title>Pruning groups</title>
<simpara>To prune groups records from an external provider, administrators can run the
following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm prune groups \
    --sync-config=path/to/sync/config [&lt;options&gt;]</programlisting>
<table frame="all" rowsep="1" colsep="1">
<title><literal>oc adm prune groups</literal> flags</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="66.6667*"/>
<thead>
<row>
<entry align="left" valign="top">Options</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="middle"><simpara><literal>--confirm</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Indicate that pruning should occur, instead of performing a dry-run.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--blacklist</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Path to the group blacklist file.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--whitelist</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Path to the group whitelist file.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--sync-config</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Path to the synchronization configuration file.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To see the groups that the prune command deletes, run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm prune groups --sync-config=ldap-sync-config.yaml</programlisting>
</listitem>
<listitem>
<simpara>To perform the prune operation, add the <literal>--confirm</literal> flag:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm prune groups --sync-config=ldap-sync-config.yaml --confirm</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="pruning-deployments_pruning-objects">
<title>Pruning deployment resources</title>
<simpara>You can prune resources associated with deployments that are no longer required by the system, due to age and status.</simpara>
<simpara>The following command prunes replication controllers associated with <literal>DeploymentConfig</literal> objects:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm prune deployments [&lt;options&gt;]</programlisting>
<note>
<simpara>To also prune replica sets associated with <literal>Deployment</literal> objects, use the <literal>--replica-sets</literal> flag. This flag is currently a Technology Preview feature.</simpara>
</note>
<table frame="all" rowsep="1" colsep="1">
<title><literal>oc adm prune deployments</literal> flags</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="66.6667*"/>
<thead>
<row>
<entry align="left" valign="top">Option</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="middle"><simpara><literal>--confirm</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Indicate that pruning should occur, instead of performing a dry-run.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--keep-complete=&lt;N&gt;</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Per the <literal>DeploymentConfig</literal> object, keep the last <literal>N</literal> replication controllers that have a status of <literal>Complete</literal> and replica count of zero. The default is <literal>5</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--keep-failed=&lt;N&gt;</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Per the <literal>DeploymentConfig</literal> object, keep the last <literal>N</literal> replication controllers that have a status of <literal>Failed</literal> and replica count of zero. The default is <literal>1</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--keep-younger-than=&lt;duration&gt;</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Do not prune any replication controller that is younger than <literal>&lt;duration&gt;</literal> relative to the current time. Valid units of measurement include nanoseconds (<literal>ns</literal>), microseconds (<literal>us</literal>), milliseconds (<literal>ms</literal>), seconds (<literal>s</literal>), minutes (<literal>m</literal>), and hours (<literal>h</literal>). The default is <literal>60m</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--orphans</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Prune all replication controllers that no longer have a <literal>DeploymentConfig</literal> object, has status of <literal>Complete</literal> or <literal>Failed</literal>, and has a replica count of zero.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--replica-sets=true|false</literal></simpara></entry>
<entry align="left" valign="top"><simpara>If <literal>true</literal>, replica sets are included in the pruning process. The default is <literal>false</literal>.</simpara>
<important>
<simpara>This flag is a Technology Preview feature.</simpara>
</important></entry>
</row>
</tbody>
</tgroup>
</table>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To see what a pruning operation would delete, run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm prune deployments --orphans --keep-complete=5 --keep-failed=1 \
    --keep-younger-than=60m</programlisting>
</listitem>
<listitem>
<simpara>To actually perform the prune operation, add the <literal>--confirm</literal> flag:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm prune deployments --orphans --keep-complete=5 --keep-failed=1 \
    --keep-younger-than=60m --confirm</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="pruning-builds_pruning-objects">
<title>Pruning builds</title>
<simpara>To prune builds that are no longer required by the system due to age and status, administrators can run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm prune builds [&lt;options&gt;]</programlisting>
<table frame="all" rowsep="1" colsep="1">
<title><literal>oc adm prune builds</literal> flags</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="66.6667*"/>
<thead>
<row>
<entry align="left" valign="top">Option</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="middle"><simpara><literal>--confirm</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Indicate that pruning should occur, instead of performing a dry-run.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--orphans</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Prune all builds whose build configuration no longer exists, status is complete, failed, error, or canceled.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--keep-complete=&lt;N&gt;</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Per build configuration, keep the last <literal>N</literal> builds whose status is complete. The default is <literal>5</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--keep-failed=&lt;N&gt;</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Per build configuration, keep the last <literal>N</literal> builds whose status is failed, error, or canceled. The default is <literal>1</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--keep-younger-than=&lt;duration&gt;</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Do not prune any object that is younger than <literal>&lt;duration&gt;</literal> relative to the current time. The default is <literal>60m</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To see what a pruning operation would delete, run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm prune builds --orphans --keep-complete=5 --keep-failed=1 \
    --keep-younger-than=60m</programlisting>
</listitem>
<listitem>
<simpara>To actually perform the prune operation, add the <literal>--confirm</literal> flag:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm prune builds --orphans --keep-complete=5 --keep-failed=1 \
    --keep-younger-than=60m --confirm</programlisting>
</listitem>
</orderedlist>
<note>
<simpara>Developers can enable automatic build pruning by modifying their build configuration.</simpara>
</note>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/builds_using_buildconfig/#builds-build-pruning-advanced-build-operations">Performing advanced builds &#8594; Pruning builds</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="pruning-images_pruning-objects">
<title>Automatically pruning images</title>
<simpara>Images from the OpenShift image registry that are no longer required by the system due to age, status, or exceed limits are automatically pruned. Cluster administrators can configure the Pruning Custom Resource, or suspend it.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Cluster administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>Install the <literal>oc</literal> CLI.</simpara>
</listitem>
</itemizedlist>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>Verify that the object named <literal>imagepruners.imageregistry.operator.openshift.io/cluster</literal> contains the following <literal>spec</literal> and <literal>status</literal> fields:</simpara>
</listitem>
</itemizedlist>
<programlisting language="yaml" linenumbering="unnumbered">spec:
  schedule: 0 0 * * * <co xml:id="CO49-1"/>
  suspend: false <co xml:id="CO49-2"/>
  keepTagRevisions: 3 <co xml:id="CO49-3"/>
  keepYoungerThanDuration: 60m <co xml:id="CO49-4"/>
  keepYoungerThan: 3600000000000 <co xml:id="CO49-5"/>
  resources: {} <co xml:id="CO49-6"/>
  affinity: {} <co xml:id="CO49-7"/>
  nodeSelector: {} <co xml:id="CO49-8"/>
  tolerations: [] <co xml:id="CO49-9"/>
  successfulJobsHistoryLimit: 3 <co xml:id="CO49-10"/>
  failedJobsHistoryLimit: 3 <co xml:id="CO49-11"/>
status:
  observedGeneration: 2 <co xml:id="CO49-12"/>
  conditions: <co xml:id="CO49-13"/>
  - type: Available
    status: "True"
    lastTransitionTime: 2019-10-09T03:13:45
    reason: Ready
    message: "Periodic image pruner has been created."
  - type: Scheduled
    status: "True"
    lastTransitionTime: 2019-10-09T03:13:45
    reason: Scheduled
    message: "Image pruner job has been scheduled."
  - type: Failed
    staus: "False"
    lastTransitionTime: 2019-10-09T03:13:45
    reason: Succeeded
    message: "Most recent image pruning job succeeded."</programlisting>
<calloutlist>
<callout arearefs="CO49-1">
<para><literal>schedule</literal>: <literal>CronJob</literal> formatted schedule. This is an optional field, default is daily at midnight.</para>
</callout>
<callout arearefs="CO49-2">
<para><literal>suspend</literal>: If set to <literal>true</literal>, the <literal>CronJob</literal> running pruning is suspended. This is an optional field, default is <literal>false</literal>. The initial value on new clusters is <literal>false</literal>.</para>
</callout>
<callout arearefs="CO49-3">
<para><literal>keepTagRevisions</literal>: The number of revisions per tag to keep. This is an optional field, default is <literal>3</literal>. The initial value is <literal>3</literal>.</para>
</callout>
<callout arearefs="CO49-4">
<para><literal>keepYoungerThanDuration</literal>: Retain images younger than this duration. This is an optional field. If a value is not specified, either <literal>keepYoungerThan</literal> or the default value <literal>60m</literal> (60 minutes) is used.</para>
</callout>
<callout arearefs="CO49-5">
<para><literal>keepYoungerThan</literal>: Deprecated. The same as <literal>keepYoungerThanDuration</literal>, but the duration is specified as an integer in nanoseconds. This is an optional field. When <literal>keepYoungerThanDuration</literal> is set, this field is ignored.</para>
</callout>
<callout arearefs="CO49-6">
<para><literal>resources</literal>: Standard pod resource requests and limits. This is an optional field.</para>
</callout>
<callout arearefs="CO49-7">
<para><literal>affinity</literal>: Standard pod affinity. This is an optional field.</para>
</callout>
<callout arearefs="CO49-8">
<para><literal>nodeSelector</literal>: Standard pod node selector. This is an optional field.</para>
</callout>
<callout arearefs="CO49-9">
<para><literal>tolerations</literal>: Standard pod tolerations. This is an optional field.</para>
</callout>
<callout arearefs="CO49-10">
<para><literal>successfulJobsHistoryLimit</literal>: The maximum number of successful jobs to retain. Must be <literal>&gt;= 1</literal> to ensure metrics are reported. This is an optional field, default is <literal>3</literal>. The initial value is <literal>3</literal>.</para>
</callout>
<callout arearefs="CO49-11">
<para><literal>failedJobsHistoryLimit</literal>: The maximum number of failed jobs to retain. Must be <literal>&gt;= 1</literal> to ensure metrics are reported. This is an optional field, default is <literal>3</literal>. The initial value is <literal>3</literal>.</para>
</callout>
<callout arearefs="CO49-12">
<para><literal>observedGeneration</literal>: The generation observed by the Operator.</para>
</callout>
<callout arearefs="CO49-13">
<para><literal>conditions</literal>: The standard condition objects with the following types:</para>
<itemizedlist>
<listitem>
<simpara><literal>Available</literal>: Indicates if the pruning job has been created. Reasons can be Ready or Error.</simpara>
</listitem>
<listitem>
<simpara><literal>Scheduled</literal>: Indicates if the next pruning job has been scheduled. Reasons can be Scheduled, Suspended, or Error.</simpara>
</listitem>
<listitem>
<simpara><literal>Failed</literal>: Indicates if the most recent pruning job failed.</simpara>
</listitem>
</itemizedlist>
</callout>
</calloutlist>
<important>
<simpara>The Image Registry Operator&#8217;s behavior for managing the pruner is orthogonal to the <literal>managementState</literal> specified on the Image Registry Operator&#8217;s <literal>ClusterOperator</literal> object. If the Image Registry Operator is not in the <literal>Managed</literal> state, the image pruner can still be configured and managed by the Pruning Custom Resource.</simpara>
<simpara>However, the <literal>managementState</literal> of the Image Registry Operator alters the behavior of the deployed image pruner job:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>Managed</literal>: the <literal>--prune-registry</literal> flag for the image pruner is set to <literal>true</literal>.</simpara>
</listitem>
<listitem>
<simpara><literal>Removed</literal>: the <literal>--prune-registry</literal> flag for the image pruner is set to <literal>false</literal>, meaning it only prunes image metatdata in etcd.</simpara>
</listitem>
</itemizedlist>
</important>
</section>
<section xml:id="pruning-images-manual_pruning-objects">
<title>Manually pruning images</title>
<simpara>The pruning custom resource enables automatic image pruning for the images from the OpenShift image registry. However, administrators can manually prune images that are no longer required by the system due to age, status, or exceed limits. There are two methods to manually prune images:</simpara>
<itemizedlist>
<listitem>
<simpara>Running image pruning as a <literal>Job</literal> or <literal>CronJob</literal> on the cluster.</simpara>
</listitem>
<listitem>
<simpara>Running the <literal>oc adm prune images</literal> command.</simpara>
</listitem>
</itemizedlist>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>To prune images, you must first log in to the CLI as a user with an access token. The user must also have the <literal>system:image-pruner</literal> cluster role or greater (for example, <literal>cluster-admin</literal>).</simpara>
</listitem>
<listitem>
<simpara>Expose the image registry.</simpara>
</listitem>
</itemizedlist>
<formalpara>
<title>Procedure</title>
<para>To manually prune images that are no longer required by the system due to age, status, or exceed limits, use one of the following methods:</para>
</formalpara>
<itemizedlist>
<listitem>
<simpara>Run image pruning as a <literal>Job</literal> or <literal>CronJob</literal> on the cluster by creating a YAML file for the <literal>pruner</literal> service account, for example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create -f &lt;filename&gt;.yaml</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">kind: List
apiVersion: v1
items:
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: pruner
    namespace: openshift-image-registry
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    name: openshift-image-registry-pruner
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:image-pruner
  subjects:
  - kind: ServiceAccount
    name: pruner
    namespace: openshift-image-registry
- apiVersion: batch/v1
  kind: CronJob
  metadata:
    name: image-pruner
    namespace: openshift-image-registry
  spec:
    schedule: "0 0 * * *"
    concurrencyPolicy: Forbid
    successfulJobsHistoryLimit: 1
    failedJobsHistoryLimit: 3
    jobTemplate:
      spec:
        template:
          spec:
            restartPolicy: OnFailure
            containers:
            - image: "quay.io/openshift/origin-cli:4.1"
              resources:
                requests:
                  cpu: 1
                  memory: 1Gi
              terminationMessagePolicy: FallbackToLogsOnError
              command:
              - oc
              args:
              - adm
              - prune
              - images
              - --certificate-authority=/var/run/secrets/kubernetes.io/serviceaccount/service-ca.crt
              - --keep-tag-revisions=5
              - --keep-younger-than=96h
              - --confirm=true
              name: image-pruner
            serviceAccountName: pruner</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Run the <literal>oc adm prune images [&lt;options&gt;]</literal> command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm prune images [&lt;options&gt;]</programlisting>
<simpara>Pruning images removes data from the integrated registry unless <literal>--prune-registry=false</literal> is used.</simpara>
<simpara>Pruning images with the <literal>--namespace</literal> flag does not remove images, only image streams. Images are non-namespaced resources. Therefore, limiting pruning to a particular namespace makes it impossible to calculate its current usage.</simpara>
<simpara>By default, the integrated registry caches metadata of blobs to reduce the number of requests to storage, and to increase the request-processing speed. Pruning does not update the integrated registry cache. Images that still contain pruned layers after pruning will be broken because the pruned layers that have metadata in the cache will not be pushed. Therefore, you must redeploy the registry to clear the cache after pruning:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc rollout restart deployment/image-registry -n openshift-image-registry</programlisting>
<simpara>If the integrated registry uses a Redis cache, you must clean the database manually.</simpara>
<simpara>If redeploying the registry after pruning is not an option, then you must permanently disable the cache.</simpara>
<simpara><literal>oc adm prune images</literal> operations require a route for your registry. Registry routes are not created by default.</simpara>
<simpara>The <emphasis role="strong">Prune images CLI configuration options</emphasis> table describes the options you can use with the <literal>oc adm prune images &lt;options&gt;</literal> command.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Prune images CLI configuration options</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="66.6667*"/>
<thead>
<row>
<entry align="left" valign="top">Option</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="middle"><simpara><literal>--all</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Include images that were not pushed to the registry, but have been mirrored by
pullthrough. This is on by default. To limit the pruning to images that were
pushed to the integrated registry, pass <literal>--all=false</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--certificate-authority</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The path to a certificate authority file to use when communicating with the
OpenShift Container Platform-managed registries. Defaults to the certificate authority data
from the current user&#8217;s configuration file. If provided, a secure connection is
initiated.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--confirm</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Indicate that pruning should occur, instead of performing a test-run. This
requires a valid route to the integrated container image registry. If this
command is run outside of the cluster network, the route must be provided
using <literal>--registry-url</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--force-insecure</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Use caution with this option. Allow an insecure connection to the container
registry that is hosted via HTTP or has an invalid HTTPS certificate.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--keep-tag-revisions=&lt;N&gt;</literal></simpara></entry>
<entry align="left" valign="top"><simpara>For each imagestream, keep up to at most <literal>N</literal> image revisions per tag (default
<literal>3</literal>).</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--keep-younger-than=&lt;duration&gt;</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Do not prune any image that is younger than <literal>&lt;duration&gt;</literal> relative to the
current time. Alternately, do not prune any image that is referenced by any other object that
is younger than <literal>&lt;duration&gt;</literal> relative to the current time (default <literal>60m</literal>).</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--prune-over-size-limit</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Prune each image that exceeds the smallest limit defined in the same project.
This flag cannot be combined with <literal>--keep-tag-revisions</literal> nor
<literal>--keep-younger-than</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--registry-url</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The address to use when contacting the registry. The command attempts to use a
cluster-internal URL determined from managed images and image streams. In case
it fails (the registry cannot be resolved or reached), an alternative route that
works needs to be provided using this flag. The registry hostname can be
prefixed by <literal>https://</literal> or <literal>http://</literal>, which enforces particular connection
protocol.</simpara></entry>
</row>
<row>
<entry align="left" valign="middle"><simpara><literal>--prune-registry</literal></simpara></entry>
<entry align="left" valign="top"><simpara>In conjunction with the conditions stipulated by the other options, this option
controls whether the data in the registry corresponding to the OpenShift Container Platform
image API object is pruned. By default, image pruning processes both the image
API objects and corresponding data in the registry.</simpara><simpara>This option is useful when you are only concerned with removing etcd content, to reduce the number of image objects but are not concerned with cleaning up registry storage, or if you intend to do that separately by hard pruning the registry during an appropriate maintenance window for the registry.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</listitem>
</itemizedlist>
<section xml:id="pruning-images-conditions_pruning-objects">
<title>Image prune conditions</title>
<simpara>You can apply conditions to your manually pruned images.</simpara>
<itemizedlist>
<listitem>
<simpara>To remove any image managed by OpenShift Container Platform, or images with the annotation <literal>openshift.io/image.managed</literal>:</simpara>
<itemizedlist>
<listitem>
<simpara>Created at least <literal>--keep-younger-than</literal> minutes ago and are not currently referenced by any:</simpara>
<itemizedlist>
<listitem>
<simpara>Pods created less than <literal>--keep-younger-than</literal> minutes ago</simpara>
</listitem>
<listitem>
<simpara>Image streams created less than <literal>--keep-younger-than</literal> minutes ago</simpara>
</listitem>
<listitem>
<simpara>Running pods</simpara>
</listitem>
<listitem>
<simpara>Pending pods</simpara>
</listitem>
<listitem>
<simpara>Replication controllers</simpara>
</listitem>
<listitem>
<simpara>Deployments</simpara>
</listitem>
<listitem>
<simpara>Deployment configs</simpara>
</listitem>
<listitem>
<simpara>Replica sets</simpara>
</listitem>
<listitem>
<simpara>Build configurations</simpara>
</listitem>
<listitem>
<simpara>Builds</simpara>
</listitem>
<listitem>
<simpara>Jobs</simpara>
</listitem>
<listitem>
<simpara>Cronjobs</simpara>
</listitem>
<listitem>
<simpara>Stateful sets</simpara>
</listitem>
<listitem>
<simpara><literal>--keep-tag-revisions</literal> most recent items in <literal>stream.status.tags[].items</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>That are exceeding the smallest limit defined in the same project and are not currently referenced by any:</simpara>
<itemizedlist>
<listitem>
<simpara>Running pods</simpara>
</listitem>
<listitem>
<simpara>Pending pods</simpara>
</listitem>
<listitem>
<simpara>Replication controllers</simpara>
</listitem>
<listitem>
<simpara>Deployments</simpara>
</listitem>
<listitem>
<simpara>Deployment configs</simpara>
</listitem>
<listitem>
<simpara>Replica sets</simpara>
</listitem>
<listitem>
<simpara>Build configurations</simpara>
</listitem>
<listitem>
<simpara>Builds</simpara>
</listitem>
<listitem>
<simpara>Jobs</simpara>
</listitem>
<listitem>
<simpara>Cronjobs</simpara>
</listitem>
<listitem>
<simpara>Stateful sets</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>There is no support for pruning from external registries.</simpara>
</listitem>
<listitem>
<simpara>When an image is pruned, all references to the image are removed from all
image streams that have a reference to the image in <literal>status.tags</literal>.</simpara>
</listitem>
<listitem>
<simpara>Image layers that are no longer referenced by any images are removed.</simpara>
</listitem>
</itemizedlist>
<note>
<simpara>The <literal>--prune-over-size-limit</literal> flag cannot be combined with the <literal>--keep-tag-revisions</literal> flag nor the <literal>--keep-younger-than</literal> flags. Doing so returns
information that this operation is not allowed.</simpara>
</note>
<simpara>Separating the removal of OpenShift Container Platform image API objects and image data from the registry by using <literal>--prune-registry=false</literal>, followed by hard pruning the registry, can narrow timing windows and is safer when compared to trying to prune both through one command. However, timing windows are not completely removed.</simpara>
<simpara>For example, you can still create a pod referencing an image as pruning identifies that image for pruning. You should still keep track of an API object created during the pruning operations that might reference images so that you can mitigate any references to deleted content.</simpara>
<simpara>Re-doing the pruning without the <literal>--prune-registry</literal> option or with <literal>--prune-registry=true</literal> does not lead to pruning the associated storage in the image registry for images previously pruned by <literal>--prune-registry=false</literal>. Any images that were pruned with <literal>--prune-registry=false</literal> can only be deleted from registry storage by hard pruning the registry.</simpara>
</section>
<section xml:id="pruning-images-running-operation_pruning-objects">
<title>Running the image prune operation</title>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To see what a pruning operation would delete:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Keeping up to three tag revisions, and keeping resources (images, image streams, and pods) younger than 60 minutes:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm prune images --keep-tag-revisions=3 --keep-younger-than=60m</programlisting>
</listitem>
<listitem>
<simpara>Pruning every image that exceeds defined limits:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm prune images --prune-over-size-limit</programlisting>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>To perform the prune operation with the options from the previous step:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm prune images --keep-tag-revisions=3 --keep-younger-than=60m --confirm</programlisting>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm prune images --prune-over-size-limit --confirm</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="pruning-images-secure-insecure_pruning-objects">
<title>Using secure or insecure connections</title>
<simpara>The secure connection is the preferred and recommended approach. It is done over
HTTPS protocol with a mandatory certificate verification. The <literal>prune</literal> command
always attempts to use it if possible. If it is not possible, in some cases it
can fall-back to insecure connection, which is dangerous. In this case, either
certificate verification is skipped or plain HTTP protocol is used.</simpara>
<simpara>The fall-back to insecure connection is allowed in the following cases unless
<literal>--certificate-authority</literal> is specified:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>The <literal>prune</literal> command is run with the <literal>--force-insecure</literal> option.</simpara>
</listitem>
<listitem>
<simpara>The provided <literal>registry-url</literal> is prefixed with the <literal>http://</literal> scheme.</simpara>
</listitem>
<listitem>
<simpara>The provided <literal>registry-url</literal> is a local-link address or <literal>localhost</literal>.</simpara>
</listitem>
<listitem>
<simpara>The configuration of the current user allows for an insecure connection. This
can be caused by the user either logging in using <literal>--insecure-skip-tls-verify</literal>
or choosing the insecure connection when prompted.</simpara>
</listitem>
</orderedlist>
<important>
<simpara>If the registry is secured by a certificate authority different from the one used by OpenShift Container Platform, it must be specified using the
<literal>--certificate-authority</literal> flag. Otherwise, the <literal>prune</literal> command fails with an error.</simpara>
</important>
</section>
<section xml:id="pruning-images-problems_pruning-objects">
<title>Image pruning problems</title>
<bridgehead xml:id="pruning-images-not-being-pruned_pruning-objects" renderas="sect5">Images not being pruned</bridgehead>
<simpara>If your images keep accumulating and the <literal>prune</literal> command removes just a small
portion of what you expect, ensure that you understand the image prune
conditions that must apply for an image to be considered a candidate for
pruning.</simpara>
<simpara>Ensure that images you want removed occur at higher positions in each tag
history than your chosen tag revisions threshold. For example, consider an old
and obsolete image named <literal>sha256:abz</literal>. By running the following command in your
namespace, where the image is tagged, the image is tagged three times in a
single image stream named <literal>myapp</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get is -n &lt;namespace&gt; -o go-template='{{range $isi, $is := .items}}{{range $ti, $tag := $is.status.tags}}'\
'{{range $ii, $item := $tag.items}}{{if eq $item.image "sha256:&lt;hash&gt;"}}{{$is.metadata.name}}:{{$tag.tag}} at position {{$ii}} out of {{len $tag.items}}\n'\
'{{end}}{{end}}{{end}}{{end}}'</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">myapp:v2 at position 4 out of 5
myapp:v2.1 at position 2 out of 2
myapp:v2.1-may-2016 at position 0 out of 1</programlisting>
</para>
</formalpara>
<simpara>When default options are used, the image is never pruned because it occurs at
position <literal>0</literal> in a history of <literal>myapp:v2.1-may-2016</literal> tag. For an image to be
considered for pruning, the administrator must either:</simpara>
<itemizedlist>
<listitem>
<simpara>Specify <literal>--keep-tag-revisions=0</literal> with the <literal>oc adm prune images</literal> command.</simpara>
<warning>
<simpara>This action removes all the tags from all the namespaces with underlying images, unless they are younger or they are referenced by objects younger than the specified threshold.</simpara>
</warning>
</listitem>
<listitem>
<simpara>Delete all the <literal>istags</literal> where the position is below the revision threshold,
which means <literal>myapp:v2.1</literal> and <literal>myapp:v2.1-may-2016</literal>.</simpara>
</listitem>
<listitem>
<simpara>Move the image further in the history, either by running new builds pushing to
the same <literal>istag</literal>, or by tagging other image. This is not always
desirable for old release tags.</simpara>
</listitem>
</itemizedlist>
<simpara>Tags having a date or time of a particular image&#8217;s build in their names should
be avoided, unless the image must be preserved for an undefined amount of time.
Such tags tend to have just one image in their history, which prevents
them from ever being pruned.</simpara>
<bridgehead xml:id="pruning-images-secure-against-insecure_pruning-objects" renderas="sect5">Using a secure connection against insecure registry</bridgehead>
<simpara>If you see a message similar to the following in the output of the <literal>oc adm prune images</literal>
command, then your registry is not secured and the <literal>oc adm prune images</literal>
client attempts to use a secure connection:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">error: error communicating with registry: Get https://172.30.30.30:5000/healthz: http: server gave HTTP response to HTTPS client</programlisting>
<itemizedlist>
<listitem>
<simpara>The recommended solution is to secure the registry. Otherwise, you can force the
client to use an insecure connection by appending <literal>--force-insecure</literal>  to the
command; however, this is not recommended.</simpara>
</listitem>
</itemizedlist>
<bridgehead xml:id="pruning-images-insecure-against-secure_pruning-objects" renderas="sect5">Using an insecure connection against a secured registry</bridgehead>
<simpara>If you see one of the following errors in the output of the <literal>oc adm prune images</literal>
command, it means that your registry is secured using a certificate signed by a
certificate authority other than the one used by <literal>oc adm prune images</literal> client for
connection verification:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">error: error communicating with registry: Get http://172.30.30.30:5000/healthz: malformed HTTP response "\x15\x03\x01\x00\x02\x02"
error: error communicating with registry: [Get https://172.30.30.30:5000/healthz: x509: certificate signed by unknown authority, Get http://172.30.30.30:5000/healthz: malformed HTTP response "\x15\x03\x01\x00\x02\x02"]</programlisting>
<simpara>By default, the certificate authority data stored in the user&#8217;s configuration files is used; the same is true for communication with the master API.</simpara>
<simpara>Use the <literal>--certificate-authority</literal> option to provide the right certificate authority for the container image registry server.</simpara>
<bridgehead xml:id="pruning-images-wrong-ca_pruning-objects" renderas="sect5">Using the wrong certificate authority</bridgehead>
<simpara>The following error means that the certificate authority used to sign the certificate of the secured container image registry is different from the authority used by the client:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">error: error communicating with registry: Get https://172.30.30.30:5000/: x509: certificate signed by unknown authority</programlisting>
<simpara>Make sure to provide the right one with the flag <literal>--certificate-authority</literal>.</simpara>
<simpara>As a workaround, the <literal>--force-insecure</literal> flag can be added instead. However, this is not recommended.</simpara>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/registry/#accessing-the-registry">Accessing the registry</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/registry/#securing-exposing-registry">Exposing the registry</link></simpara>
</listitem>
<listitem>
<simpara>See
<link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/registry/#configuring-registry-operator">Image
Registry Operator in OpenShift Container Platform</link> for information on how to create a
registry route.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="pruning-hard-pruning-registry_pruning-objects">
<title>Hard pruning the registry</title>
<simpara>The OpenShift Container Registry can accumulate blobs that are not referenced by
the OpenShift Container Platform cluster&#8217;s etcd. The basic pruning images procedure,
therefore, is unable to operate on them. These are called <emphasis>orphaned blobs</emphasis>.</simpara>
<simpara>Orphaned blobs can occur from the following scenarios:</simpara>
<itemizedlist>
<listitem>
<simpara>Manually deleting an image with <literal>oc delete image &lt;sha256:image-id&gt;</literal> command,
which only removes the image from etcd, but not from the registry&#8217;s storage.</simpara>
</listitem>
<listitem>
<simpara>Pushing to the registry initiated by daemon failures, which causes some blobs to
get uploaded, but the image manifest (which is uploaded as the very last
component) does not. All unique image blobs become orphans.</simpara>
</listitem>
<listitem>
<simpara>OpenShift Container Platform refusing an image because of quota restrictions.</simpara>
</listitem>
<listitem>
<simpara>The standard image pruner deleting an image manifest, but is interrupted before
it deletes the related blobs.</simpara>
</listitem>
<listitem>
<simpara>A bug in the registry pruner, which fails to remove the intended blobs, causing
the image objects referencing them to be removed and the blobs becoming orphans.</simpara>
</listitem>
</itemizedlist>
<simpara><emphasis>Hard pruning</emphasis> the registry, a separate procedure from basic image pruning,
allows cluster administrators to remove orphaned blobs. You should hard prune if
you are running out of storage space in your OpenShift Container Registry and
believe you have orphaned blobs.</simpara>
<simpara>This should be an infrequent operation and is necessary only when you have
evidence that significant numbers of new orphans have been created. Otherwise,
you can perform standard image pruning at regular intervals, for example, once a
day (depending on the number of images being created).</simpara>
<formalpara>
<title>Procedure</title>
<para>To hard prune orphaned blobs from the registry:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara><emphasis role="strong">Log in.</emphasis></simpara>
<simpara>Log in to the cluster with the CLI as <literal>kubeadmin</literal> or another privileged user that
has access to the <literal>openshift-image-registry</literal> namespace.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Run a basic image prune</emphasis>.</simpara>
<simpara>Basic image pruning removes additional images that are no longer needed. The
hard prune does not remove images on its own. It only removes blobs stored in
the registry storage. Therefore, you should run this just before the hard prune.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Switch the registry to read-only mode.</emphasis></simpara>
<simpara>If the registry is not running in read-only mode, any pushes happening at the
same time as the prune will either:</simpara>
<itemizedlist>
<listitem>
<simpara>fail and cause new orphans, or</simpara>
</listitem>
<listitem>
<simpara>succeed although the images cannot be pulled (because some of the
referenced blobs were deleted).</simpara>
</listitem>
</itemizedlist>
<simpara>Pushes will not succeed until the registry is switched back to read-write mode.
Therefore, the hard prune must be carefully scheduled.</simpara>
<simpara>To switch the registry to read-only mode:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>In <literal>configs.imageregistry.operator.openshift.io/cluster</literal>, set <literal>spec.readOnly</literal> to <literal>true</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc patch configs.imageregistry.operator.openshift.io/cluster -p '{"spec":{"readOnly":true}}' --type=merge</programlisting>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara><emphasis role="strong">Add the <literal>system:image-pruner</literal> role.</emphasis></simpara>
<simpara>The service account used to run the registry instances requires additional
permissions to list some resources.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Get the service account name:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ service_account=$(oc get -n openshift-image-registry \
    -o jsonpath='{.spec.template.spec.serviceAccountName}' deploy/image-registry)</programlisting>
</listitem>
<listitem>
<simpara>Add the <literal>system:image-pruner</literal> cluster role to the service account:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm policy add-cluster-role-to-user \
    system:image-pruner -z \
    ${service_account} -n openshift-image-registry</programlisting>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara><emphasis role="strong">Optional: Run the pruner in dry-run mode.</emphasis></simpara>
<simpara>To see how many blobs would be removed, run the hard pruner in dry-run mode. No changes are actually made. The following example references an image registry pod called <literal>image-registry-3-vhndw</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-image-registry exec pod/image-registry-3-vhndw -- /bin/sh -c '/usr/bin/dockerregistry -prune=check'</programlisting>
<simpara>Alternatively, to get the exact paths for the prune candidates, increase the
logging level:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-image-registry exec pod/image-registry-3-vhndw -- /bin/sh -c 'REGISTRY_LOG_LEVEL=info /usr/bin/dockerregistry -prune=check'</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">time="2017-06-22T11:50:25.066156047Z" level=info msg="start prune (dry-run mode)" distribution_version="v2.4.1+unknown" kubernetes_version=v1.6.1+$Format:%h$ openshift_version=unknown
time="2017-06-22T11:50:25.092257421Z" level=info msg="Would delete blob: sha256:00043a2a5e384f6b59ab17e2c3d3a3d0a7de01b2cabeb606243e468acc663fa5" go.version=go1.7.5 instance.id=b097121c-a864-4e0c-ad6c-cc25f8fdf5a6
time="2017-06-22T11:50:25.092395621Z" level=info msg="Would delete blob: sha256:0022d49612807cb348cabc562c072ef34d756adfe0100a61952cbcb87ee6578a" go.version=go1.7.5 instance.id=b097121c-a864-4e0c-ad6c-cc25f8fdf5a6
time="2017-06-22T11:50:25.092492183Z" level=info msg="Would delete blob: sha256:0029dd4228961086707e53b881e25eba0564fa80033fbbb2e27847a28d16a37c" go.version=go1.7.5 instance.id=b097121c-a864-4e0c-ad6c-cc25f8fdf5a6
time="2017-06-22T11:50:26.673946639Z" level=info msg="Would delete blob: sha256:ff7664dfc213d6cc60fd5c5f5bb00a7bf4a687e18e1df12d349a1d07b2cf7663" go.version=go1.7.5 instance.id=b097121c-a864-4e0c-ad6c-cc25f8fdf5a6
time="2017-06-22T11:50:26.674024531Z" level=info msg="Would delete blob: sha256:ff7a933178ccd931f4b5f40f9f19a65be5eeeec207e4fad2a5bafd28afbef57e" go.version=go1.7.5 instance.id=b097121c-a864-4e0c-ad6c-cc25f8fdf5a6
time="2017-06-22T11:50:26.674675469Z" level=info msg="Would delete blob: sha256:ff9b8956794b426cc80bb49a604a0b24a1553aae96b930c6919a6675db3d5e06" go.version=go1.7.5 instance.id=b097121c-a864-4e0c-ad6c-cc25f8fdf5a6
...
Would delete 13374 blobs
Would free up 2.835 GiB of disk space
Use -prune=delete to actually delete the data</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Run the hard prune.</emphasis></simpara>
<simpara>Execute the following command inside one running instance of a <literal>image-registry</literal> pod to run the hard prune. The following example references an image registry pod called <literal>image-registry-3-vhndw</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-image-registry exec pod/image-registry-3-vhndw -- /bin/sh -c '/usr/bin/dockerregistry -prune=delete'</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">Deleted 13374 blobs
Freed up 2.835 GiB of disk space</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Switch the registry back to read-write mode.</emphasis></simpara>
<simpara>After the prune is finished, the registry can be switched back to read-write
mode. In <literal>configs.imageregistry.operator.openshift.io/cluster</literal>, set
<literal>spec.readOnly</literal> to <literal>false</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc patch configs.imageregistry.operator.openshift.io/cluster -p '{"spec":{"readOnly":false}}' --type=merge</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="pruning-cronjobs_pruning-objects">
<title>Pruning cron jobs</title>
<simpara>Cron jobs can perform pruning of successful jobs, but might not properly handle
failed jobs. Therefore, the cluster administrator should perform regular cleanup of
jobs manually. They should also restrict the access to cron jobs to a small
group of trusted users and set appropriate quota to prevent the cron job from
creating too many jobs and pods.</simpara>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/nodes/#nodes-nodes-jobs_nodes-nodes-jobs">Running tasks in pods using jobs</link></simpara>
</listitem>
<listitem>
<simpara><link linkend="setting-quotas-across-multiple-projects">Resource quotas across multiple projects</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/authentication_and_authorization/#using-rbac">Using RBAC to define and apply permissions</link></simpara>
</listitem>
</itemizedlist>
</section>
</chapter>
<chapter xml:id="idling-applications">
<title>Idling applications</title>
<simpara>Cluster administrators can idle applications to reduce resource consumption. This is useful when the cluster is deployed on a public cloud where cost is related to resource consumption.</simpara>
<simpara>If any scalable resources are not in use, OpenShift Container Platform discovers and idles them by scaling their replicas to <literal>0</literal>. The next time network traffic is directed to the resources, the resources are unidled by scaling up the replicas, and normal operation continues.</simpara>
<simpara>Applications are made of services, as well as other scalable resources, such as deployment configs. The action of idling an application involves idling all associated resources.</simpara>
<section xml:id="idle-idling-applications_idling-applications">
<title>Idling applications</title>
<simpara>Idling an application involves finding the scalable resources (deployment
configurations, replication controllers, and others) associated with a service.
Idling an application finds the service and marks it as idled, scaling down the
resources to zero replicas.</simpara>
<simpara>You can use the <literal>oc idle</literal> command to idle a single service, or use the
<literal>--resource-names-file</literal> option to idle multiple services.</simpara>
<section xml:id="idle-idling-applications-single_idling-applications">
<title>Idling a single service</title>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To idle a single service, run:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc idle &lt;service&gt;</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="idle-idling-applications-multiple_idling-applications">
<title>Idling multiple services</title>
<simpara>Idling multiple services is helpful if an application spans across a set of
services within a project, or when idling multiple services in conjunction with
a script to idle multiple applications in bulk within the same project.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a file containing a list of the services, each on their own line.</simpara>
</listitem>
<listitem>
<simpara>Idle the services using the <literal>--resource-names-file</literal> option:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc idle --resource-names-file &lt;filename&gt;</programlisting>
</listitem>
</orderedlist>
<note>
<simpara>The <literal>idle</literal> command is limited to a single project. For idling applications across
a cluster, run the <literal>idle</literal> command for each project individually.</simpara>
</note>
</section>
</section>
<section xml:id="idle-unidling-applications_idling-applications">
<title>Unidling applications</title>
<simpara>Application services become active again when they receive network traffic and
are scaled back up their previous state. This includes both traffic to the
services and traffic passing through routes.</simpara>
<simpara>Applications can also be manually unidled by scaling up the resources.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>To scale up a DeploymentConfig, run:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc scale --replicas=1 dc &lt;dc_name&gt;</programlisting>
</listitem>
</orderedlist>
<note>
<simpara>Automatic unidling by a router is currently only supported by the default
HAProxy router.</simpara>
</note>
</section>
</chapter>
<chapter xml:id="odc-deleting-applications">
<title>Deleting applications</title>
<simpara>You can delete applications created in your project.</simpara>
<section xml:id="odc-deleting-applications-using-developer-perspective_odc-deleting-applications">
<title>Deleting applications using the Developer perspective</title>
<simpara>You can delete an application and all of its associated components using the <emphasis role="strong">Topology</emphasis> view in the <emphasis role="strong">Developer</emphasis> perspective:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Click the application you want to delete to see the side panel with the resource details of the application.</simpara>
</listitem>
<listitem>
<simpara>Click the <emphasis role="strong">Actions</emphasis> drop-down menu displayed on the upper right of the panel, and select <emphasis role="strong">Delete Application</emphasis> to see a confirmation dialog box.</simpara>
</listitem>
<listitem>
<simpara>Enter the name of the application and click <emphasis role="strong">Delete</emphasis> to delete it.</simpara>
</listitem>
</orderedlist>
<simpara>You can also right-click the application you want to delete and click <emphasis role="strong">Delete Application</emphasis> to delete it.</simpara>
</section>
</chapter>
<chapter xml:id="red-hat-marketplace">
<title>Using the Red Hat Marketplace</title>
<simpara>The <link xlink:href="https://marketplace.redhat.com">Red Hat Marketplace</link> is an open cloud marketplace that makes it easy to discover and access certified software for container-based environments that run on public clouds and on-premises.</simpara>
<section xml:id="red-hat-marketplace-features_red-hat-marketplace">
<title>Red Hat Marketplace features</title>
<simpara>Cluster administrators can use <link xlink:href="https://marketplace.redhat.com/en-us/documentation/getting-started">the Red Hat Marketplace</link> to manage software on OpenShift Container Platform, give developers self-service access to deploy application instances, and correlate application usage against a quota.</simpara>
<section xml:id="marketplace-clusters_red-hat-marketplace">
<title>Connect OpenShift Container Platform clusters to the Marketplace</title>
<simpara>Cluster administrators can install a common set of applications on OpenShift Container Platform clusters that connect to the Marketplace. They can also use the Marketplace to track cluster usage against subscriptions or quotas. Users that they add by using the Marketplace have their product usage tracked and billed to their organization.</simpara>
<simpara>During the <link xlink:href="https://marketplace.redhat.com/en-us/documentation/clusters">cluster connection process</link>,
a Marketplace Operator is installed that updates the image registry secret, manages the catalog, and reports application usage.</simpara>
</section>
<section xml:id="marketplace-install-applications_red-hat-marketplace">
<title>Install applications</title>
<simpara>Cluster administrators can <link xlink:href="https://marketplace.redhat.com/en-us/documentation/operators">install Marketplace applications</link> from within OperatorHub in OpenShift Container Platform, or from the <link xlink:href="https://marketplace.redhat.com">Marketplace web application</link>.</simpara>
<simpara>You can access installed applications from the web console by clicking <emphasis role="strong">Operators &gt; Installed Operators</emphasis>.</simpara>
</section>
<section xml:id="marketplace-deploy_red-hat-marketplace">
<title>Deploy applications from different perspectives</title>
<simpara>You can deploy Marketplace applications from the web console&#8217;s Administrator and Developer perspectives.</simpara>
<bridgehead xml:id="_the-developer-perspective" renderas="sect4">The Developer perspective</bridgehead>
<simpara>Developers can access newly installed capabilities by using the Developer perspective.</simpara>
<simpara>For example, after a database Operator is installed, a developer can create an instance from the catalog within their project. Database usage is aggregated and reported to the cluster administrator.</simpara>
<simpara>This perspective does not include Operator installation and application usage tracking.</simpara>
<bridgehead xml:id="_the-administrator-perspective" renderas="sect4">The Administrator perspective</bridgehead>
<simpara>Cluster administrators can access Operator installation and application usage information from the Administrator perspective.</simpara>
<simpara>They can also launch application instances by browsing custom resource definitions (CRDs) in the <emphasis role="strong">Installed Operators</emphasis> list.</simpara>
</section>
</section>
</chapter>
</book>
