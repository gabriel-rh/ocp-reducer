<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE book [
<!ENTITY % sgml.features "IGNORE">
<!ENTITY % xml.features "INCLUDE">
<!ENTITY % DOCBOOK_ENTS PUBLIC "-//OASIS//ENTITIES DocBook Character Entities V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/dbcentx.mod">
%DOCBOOK_ENTS;
]>
<?asciidoc-toc?>
<?asciidoc-numbered?>
<book xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0">
<info>
<title>Network Observability</title>
<date>2024-02-23</date>
<title>Network Observability</title>
<productname>OpenShift Container Platform</productname>
<productnumber>4.14</productnumber>
<subtitle>Enter a short description here.</subtitle>
<abstract>
    <para>A short overview and summary of the book's subject and purpose, traditionally no more than one paragraph long.</para>
</abstract>
<authorgroup>
    <orgname>Red Hat OpenShift Documentation Team</orgname>
</authorgroup>
<xi:include href="Common_Content/Legal_Notice.xml" xmlns:xi="http://www.w3.org/2001/XInclude" />
</info>
<chapter xml:id="network-observability-operator-release-notes">
<title>Network Observability Operator release notes</title>
<simpara>The Network Observability Operator enables administrators to observe and analyze network traffic flows for OpenShift Container Platform clusters.</simpara>
<simpara>These release notes track the development of the Network Observability Operator in the OpenShift Container Platform.</simpara>
<simpara>For an overview of the Network Observability Operator, see <link linkend="dependency-network-observability">About Network Observability Operator</link>.</simpara>
<section xml:id="network-observability-operator-release-notes-1-4-2">
<title>Network Observability Operator 1.4.2</title>
<simpara>The following advisory is available for the Network Observability Operator 1.4.2:</simpara>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/errata/RHSA-2023:6787">2023:6787 Network Observability Operator 1.4.2</link></simpara>
</listitem>
</itemizedlist>
<section xml:id="_cves">
<title>CVEs</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-39325">2023-39325</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-44487">2023-44487</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="network-observability-operator-release-notes-1-4-1">
<title>Network Observability Operator 1.4.1</title>
<simpara>The following advisory is available for the Network Observability Operator 1.4.1:</simpara>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/errata/RHSA-2023:5974">2023:5974 Network Observability Operator 1.4.1</link></simpara>
</listitem>
</itemizedlist>
<section xml:id="_cves-2">
<title>CVEs</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/cve-2023-44487">2023-44487</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/cve-2023-39325">2023-39325</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/cve-2023-29406">2023-29406</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-29409">2023-29409</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/cve-2023-39322">2023-39322</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/cve-2023-39318">2023-39318</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/cve-2023-39319">2023-39319</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/cve-2023-39321">2023-39321</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="_bug-fixes">
<title>Bug fixes</title>
<itemizedlist>
<listitem>
<simpara>In 1.4, there was a known issue when sending network flow data to Kafka. The Kafka message key was ignored, causing an error with connection tracking. Now the key is used for partitioning, so each flow from the same connection is sent to the same processor. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-926"><emphasis role="strong">NETOBSERV-926</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>In 1.4, the <literal>Inner</literal> flow direction was introduced to account for flows between pods running on the same node. Flows with the <literal>Inner</literal> direction were not taken into account in the generated Prometheus metrics derived from flows, resulting in under-evaluated bytes and packets rates.
Now, derived metrics are including flows with the <literal>Inner</literal> direction, providing correct bytes and packets rates. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-1344"><emphasis role="strong">NETOBSERV-1344</emphasis></link>)</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="network-observability-operator-release-notes-1-4">
<title>Network Observability Operator 1.4.0</title>
<simpara>The following advisory is available for the Network Observability Operator 1.4.0:</simpara>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/errata/RHSA-2023:5379">RHSA-2023:5379 Network Observability Operator 1.4.0</link></simpara>
</listitem>
</itemizedlist>
<section xml:id="network-observability-channel-removal-1.4">
<title>Channel removal</title>
<simpara>You must switch your channel from <literal>v1.0.x</literal> to <literal>stable</literal> to receive the latest Operator updates. The <literal>v1.0.x</literal> channel is now removed.</simpara>
</section>
<section xml:id="network-observability-operator-1.4.0-features-enhancements">
<title>New features and enhancements</title>
<section xml:id="network-observability-enhanced-configuration-and-ui-1.4">
<title>Notable enhancements</title>
<simpara>The 1.4 release of the Network Observability Operator adds improvements and new capabilities to the OpenShift Container Platform web console plugin and the Operator configuration.</simpara>
<bridgehead xml:id="web-console-enhancements-1.4_network-observability-operator-release-notes-v0" renderas="sect5">Web console enhancements:</bridgehead>
<itemizedlist>
<listitem>
<simpara>In the <emphasis role="strong">Query Options</emphasis>, the <emphasis role="strong">Duplicate flows</emphasis> checkbox is added to choose whether or not to show duplicated flows.</simpara>
</listitem>
<listitem>
<simpara>You can now filter source and destination traffic with <inlinemediaobject>
<imageobject>
<imagedata fileref="images/arrow-up-long-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>arrow up long solid</phrase></textobject>
</inlinemediaobject> <emphasis role="strong">One-way</emphasis>, <inlinemediaobject>
<imageobject>
<imagedata fileref="images/arrow-up-long-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>arrow up long solid</phrase></textobject>
</inlinemediaobject> <inlinemediaobject>
<imageobject>
<imagedata fileref="images/arrow-down-long-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>arrow down long solid</phrase></textobject>
</inlinemediaobject> <emphasis role="strong">Back-and-forth</emphasis>, and <emphasis role="strong">Swap</emphasis> filters.</simpara>
</listitem>
<listitem>
<simpara>The Network Observability metrics dashboards in <emphasis role="strong">Observe</emphasis> &#8594; <emphasis role="strong">Dashboards</emphasis> &#8594; <emphasis role="strong">NetObserv</emphasis> and <emphasis role="strong">NetObserv / Health</emphasis> are modified as follows:</simpara>
<itemizedlist>
<listitem>
<simpara>The <emphasis role="strong">NetObserv</emphasis> dashboard shows top bytes, packets sent, packets received per nodes, namespaces, and workloads. Flow graphs are removed from this dashboard.</simpara>
</listitem>
<listitem>
<simpara>The <emphasis role="strong">NetObserv / Health</emphasis> dashboard shows flows overhead as well as top flow rates per nodes, namespaces, and workloads.</simpara>
</listitem>
<listitem>
<simpara>Infrastructure and Application metrics are shown in a split-view for namespaces and workloads.</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
<simpara>For more information, see <link linkend="network-observability-dashboards">Network Observability metrics</link> and <link linkend="network-observability-quickfilternw-observe-network-traffic">Quick filters</link>.</simpara>
<bridgehead xml:id="configuration-enhancements-1.4_network-observability-operator-release-notes-v0" renderas="sect5">Configuration enhancements:</bridgehead>
<itemizedlist>
<listitem>
<simpara>You now have the option to specify different namespaces for any configured ConfigMap or Secret reference, such as in certificates configuration.</simpara>
</listitem>
<listitem>
<simpara>The <literal>spec.processor.clusterName</literal> parameter is added so that the name of the cluster appears in the flows data. This is useful in a multi-cluster context. When using OpenShift Container Platform, leave empty to make it automatically determined.</simpara>
</listitem>
</itemizedlist>
<simpara>For more information, see <link linkend="network-observability-flowcollector-view_network_observability">Flow Collector sample resource</link> and <link linkend="network-observability-flowcollector-api-specifications_network_observability">Flow Collector API Reference</link>.</simpara>
</section>
<section xml:id="network-observability-without-loki-1.4">
<title>Network Observability without Loki</title>
<simpara>The Network Observability Operator is now functional and usable without Loki. If Loki is not installed, it can only export flows to KAFKA or IPFIX format and provide metrics in the Network Observability metrics dashboards. For more information, see <link linkend="network-observability-without-loki_network_observability">Network Observability without Loki</link>.</simpara>
</section>
<section xml:id="network-observability-dns-tracking-1.4">
<title>DNS tracking</title>
<simpara>In 1.4, the Network Observability Operator makes use of eBPF tracepoint hooks to enable DNS tracking. You can monitor your network, conduct security analysis, and troubleshoot DNS issues in the <emphasis role="strong">Network Traffic</emphasis> and <emphasis role="strong">Overview</emphasis> pages in the web console.</simpara>
<simpara>For more information, see <link linkend="network-observability-dns-overview_nw-observe-network-traffic">Configuring DNS tracking</link> and <link linkend="network-observability-dns-tracking_nw-observe-network-traffic">Working with DNS tracking</link>.</simpara>
</section>
<section xml:id="SR-IOV-configuration-1.4">
<title>SR-IOV support</title>
<simpara>You can now collect traffic from a cluster with Single Root I/O Virtualization (SR-IOV) device. For more information, see <link linkend="network-observability-SR-IOV-config_network_observability">Configuring the monitoring of SR-IOV interface traffic</link>.</simpara>
</section>
<section xml:id="IPFIX-support-1.4">
<title>IPFIX exporter support</title>
<simpara>You can now export eBPF-enriched network flows to the IPFIX collector. For more information, see <link linkend="network-observability-enriched-flows_network_observability">Export enriched network flow data</link>.</simpara>
</section>
<section xml:id="network-observability-packet-drop-1.4">
<title>Packet drops</title>
<simpara>In the 1.4 release of the Network Observability Operator, eBPF tracepoint hooks are used to enable packet drop tracking. You can now detect and analyze the cause for packet drops and make decisions to optimize network performance. In OpenShift Container Platform 4.14 and later, both host drops and OVS drops are detected. In OpenShift Container Platform 4.13, only host drops are detected. For more information, see <link xlink:href="../network_observability/observing-network-traffic.xml#network-observability-pktdrop-overview_nw-observe-network-traffic">Configuring packet drop tracking</link> and <link xlink:href="../network_observability/observing-network-traffic.xml#network-observability-packet-drops_nw-observe-network-traffic">Working with packet drops</link>.</simpara>
</section>
<section xml:id="_s390x-architecture-support">
<title>s390x architecture support</title>
<simpara>Network Observability Operator can now run on <literal>s390x</literal> architecture. Previously it ran on <literal>amd64</literal>, <literal>ppc64le</literal>, or <literal>arm64</literal>.</simpara>
</section>
</section>
<section xml:id="network-observability-operator-1.4.0-bug-fixes">
<title>Bug fixes</title>
<itemizedlist>
<listitem>
<simpara>Previously, the Prometheus metrics exported by Network Observability were computed out of potentially duplicated network flows. In the related dashboards, from <emphasis role="strong">Observe</emphasis> &#8594; <emphasis role="strong">Dashboards</emphasis>, this could result in potentially doubled rates. Note that dashboards from the <emphasis role="strong">Network Traffic</emphasis> view were not affected. Now, network flows are filtered to eliminate duplicates prior to metrics calculation, which results in correct traffic rates displayed in the dashboards. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-1131"><emphasis role="strong">NETOBSERV-1131</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Previously, the Network Observability Operator agents were not able to capture traffic on network interfaces when configured with Multus or SR-IOV, non-default network namespaces. Now, all available network namespaces are recognized and used for capturing flows, allowing capturing traffic for SR-IOV. There are <link linkend="network-observability-SR-IOV-config_network_observability">configurations needed</link> for the <literal>FlowCollector</literal> and <literal>SRIOVnetwork</literal> custom resource to collect traffic.
(<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-1283"><emphasis role="strong">NETOBSERV-1283</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Previously, in the Network Observability Operator details from <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>, the <literal>FlowCollector</literal> <emphasis role="strong">Status</emphasis> field might have reported incorrect information about the state of the deployment. The status field now shows the proper conditions with improved messages. The history of events is kept, ordered by event date. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-1224"><emphasis role="strong">NETOBSERV-1224</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Previously, during spikes of network traffic load, certain eBPF pods were OOM-killed and went into a <literal>CrashLoopBackOff</literal> state. Now, the <literal>eBPF</literal> agent memory footprint is improved, so pods are not OOM-killed and entering a <literal>CrashLoopBackOff</literal> state. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-975"><emphasis role="strong">NETOBSERV-975</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Previously when <literal>processor.metrics.tls</literal> was set to <literal>PROVIDED</literal> the <literal>insecureSkipVerify</literal> option value was forced to be <literal>true</literal>. Now you can set <literal>insecureSkipVerify</literal> to <literal>true</literal> or <literal>false</literal>, and provide a CA certificate if needed.  (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-1087">NETOBSERV-1087</link>)</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="network-observability-operator-1.4.0-known-issues">
<title>Known issues</title>
<itemizedlist>
<listitem>
<simpara>Since the 1.2.0 release of the Network Observability Operator, using Loki Operator 5.6, a Loki certificate change periodically affects the <literal>flowlogs-pipeline</literal> pods and results in dropped flows rather than flows written to Loki. The problem self-corrects after some time, but it still causes temporary flow data loss during the Loki certificate change. This issue has only been observed in large-scale environments of 120 nodes or greater. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-980"><emphasis role="strong">NETOBSERV-980</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Currently, when <literal>spec.agent.ebpf.features</literal> includes DNSTracking, larger DNS packets require the <literal>eBPF</literal> agent to look for DNS header outside of the 1st socket buffer (SKB) segment. A new <literal>eBPF</literal> agent helper function needs to be implemented to support it. Currently, there is no workaround for this issue. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-1304"><emphasis role="strong">NETOBSERV-1304</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Currently, when <literal>spec.agent.ebpf.features</literal> includes DNSTracking, DNS over TCP packets requires the <literal>eBPF</literal> agent to look for DNS header outside of the 1st SKB segment. A new <literal>eBPF</literal> agent helper function needs to be implemented to support it. Currently, there is no workaround for this issue. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-1245"><emphasis role="strong">NETOBSERV-1245</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Currently, when using a <literal>KAFKA</literal> deployment model, if conversation tracking is configured, conversation events might be duplicated across Kafka consumers, resulting in inconsistent tracking of conversations, and incorrect volumetric data. For that reason, it is not recommended to configure conversation tracking when <literal>deploymentModel</literal> is set to <literal>KAFKA</literal>. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-926"><emphasis role="strong">NETOBSERV-926</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Currently, when the <literal>processor.metrics.server.tls.type</literal> is configured to use a <literal>PROVIDED</literal> certificate, the operator enters an unsteady state that might affect its performance and resource consumption. It is recommended to not use a <literal>PROVIDED</literal> certificate until this issue is resolved, and instead using an auto-generated certificate, setting <literal>processor.metrics.server.tls.type</literal> to <literal>AUTO</literal>. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-1293)"><emphasis role="strong">NETOBSERV-1293</emphasis></link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="network-observability-operator-release-notes-1-3">
<title>Network Observability Operator 1.3.0</title>
<simpara>The following advisory is available for the Network Observability Operator 1.3.0:</simpara>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/errata/RHSA-2023:3905">RHSA-2023:3905 Network Observability Operator 1.3.0</link></simpara>
</listitem>
</itemizedlist>
<section xml:id="network-observability-channel-deprecation">
<title>Channel deprecation</title>
<simpara>You must switch your channel from <literal>v1.0.x</literal> to <literal>stable</literal> to receive future Operator updates. The <literal>v1.0.x</literal> channel is deprecated and planned for removal in the next release.</simpara>
</section>
<section xml:id="network-observability-operator-1.3.0-features-enhancements">
<title>New features and enhancements</title>
<section xml:id="multi-tenancy-1.3">
<title>Multi-tenancy in Network Observability</title>
<itemizedlist>
<listitem>
<simpara>System administrators can allow and restrict individual user access, or group access, to the flows stored in Loki. For more information, see <link linkend="network-observability-multi-tenancynetwork_observability">Multi-tenancy in Network Observability</link>.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="flow-based-dashboard-1.3">
<title>Flow-based metrics dashboard</title>
<itemizedlist>
<listitem>
<simpara>This release adds a new dashboard, which provides an overview of the network flows in your OpenShift Container Platform cluster. For more information, see <link linkend="network-observability-dashboards">Network Observability metrics</link>.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="must-gather-1.3">
<title>Troubleshooting with the must-gather tool</title>
<itemizedlist>
<listitem>
<simpara>Information about the Network Observability Operator can now be included in the must-gather data for troubleshooting. For more information, see <link linkend="network-observability-must-gather_network-observability-troubleshooting">Network Observability must-gather</link>.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="multi-arch-1.3">
<title>Multiple architectures now supported</title>
<itemizedlist>
<listitem>
<simpara>Network Observability Operator can now run on an <literal>amd64</literal>, <literal>ppc64le</literal>, or <literal>arm64</literal> architectures. Previously, it only ran on <literal>amd64</literal>.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="deprecated-features-1.3">
<title>Deprecated features</title>
<section xml:id="authToken-host">
<title>Deprecated configuration parameter setting</title>
<simpara>The release of Network Observability Operator 1.3 deprecates the <literal>spec.Loki.authToken</literal> <literal>HOST</literal> setting. When using the Loki Operator, you must now only use the <literal>FORWARD</literal> setting.</simpara>
</section>
</section>
<section xml:id="network-observability-operator-1.3.0-bug-fixes">
<title>Bug fixes</title>
<itemizedlist>
<listitem>
<simpara>Previously, when the Operator was installed from the CLI, the <literal>Role</literal> and <literal>RoleBinding</literal> that are necessary for the Cluster Monitoring Operator to read the metrics were not installed as expected. The issue did not occur when the operator was installed from the web console. Now, either way of installing the Operator installs the required <literal>Role</literal> and <literal>RoleBinding</literal>. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-1003"><emphasis role="strong">NETOBSERV-1003</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Since version 1.2, the Network Observability Operator can raise alerts when a problem occurs with the flows collection. Previously, due to a bug, the related configuration to disable alerts, <literal>spec.processor.metrics.disableAlerts</literal> was not working as expected and sometimes ineffectual. Now, this configuration is fixed so that it is possible to disable the alerts. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-976"><emphasis role="strong">NETOBSERV-976</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Previously, when Network Observability was configured with <literal>spec.loki.authToken</literal> set to <literal>DISABLED</literal>, only a <literal>kubeadmin</literal> cluster administrator was able to view network flows. Other types of cluster administrators received authorization failure. Now, any cluster administrator is able to view network flows. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-972"><emphasis role="strong">NETOBSERV-972</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Previously, a bug prevented users from setting <literal>spec.consolePlugin.portNaming.enable</literal> to <literal>false</literal>. Now, this setting can be set to <literal>false</literal> to disable port-to-service name translation. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-971"><emphasis role="strong">NETOBSERV-971</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Previously, the metrics exposed by the console plugin were not collected by the Cluster Monitoring Operator (Prometheus), due to an incorrect configuration. Now the configuration has been fixed so that the console plugin metrics are correctly collected and accessible from the OpenShift Container Platform web console. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-765"><emphasis role="strong">NETOBSERV-765</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Previously, when <literal>processor.metrics.tls</literal> was set to <literal>AUTO</literal> in the <literal>FlowCollector</literal>, the <literal>flowlogs-pipeline servicemonitor</literal> did not adapt the appropriate TLS scheme, and metrics were not visible in the web console. Now the issue is fixed for AUTO mode. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-1070"><emphasis role="strong">NETOBSERV-1070</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Previously, certificate configuration, such as used for Kafka and Loki, did not allow specifying a namespace field, implying that the certificates had to be in the same namespace where Network Observability is deployed. Moreover, when using Kafka with TLS/mTLS, the user had to manually copy the certificate(s) to the privileged namespace where the <literal>eBPF</literal> agent pods are deployed and manually manage certificate updates, such as in the case of certificate rotation. Now, Network Observability setup is simplified by adding a namespace field for certificates in the <literal>FlowCollector</literal> resource. As a result, users can now install Loki or Kafka in different namespaces without needing to manually copy their certificates in the Network Observability namespace. The original certificates are watched so that the copies are automatically updated when needed. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-773"><emphasis role="strong">NETOBSERV-773</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Previously, the SCTP, ICMPv4 and ICMPv6 protocols were not covered by the Network Observability agents, resulting in a less comprehensive network flows coverage. These protocols are now recognized to improve the flows coverage. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-934"><emphasis role="strong">NETOBSERV-934</emphasis></link>)</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="network-observability-operator-1.3.0-known-issues">
<title>Known issues</title>
<itemizedlist>
<listitem>
<simpara>When <literal>processor.metrics.tls</literal> is set to <literal>PROVIDED</literal> in the <literal>FlowCollector</literal>, the <literal>flowlogs-pipeline</literal> <literal>servicemonitor</literal> is not adapted to the TLS scheme. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-1087"><emphasis role="strong">NETOBSERV-1087</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Since the 1.2.0 release of the Network Observability Operator, using Loki Operator 5.6, a Loki certificate change periodically affects the <literal>flowlogs-pipeline</literal> pods and results in dropped flows rather than flows written to Loki. The problem self-corrects after some time, but it still causes temporary flow data loss during the Loki certificate change. This issue has only been observed in large-scale environments of 120 nodes or greater.(<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-980"><emphasis role="strong">NETOBSERV-980</emphasis></link>)</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="network-observability-operator-release-notes-1-2">
<title>Network Observability Operator 1.2.0</title>
<simpara>The following advisory is available for the Network Observability Operator 1.2.0:</simpara>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/errata/RHSA-2023:1817">RHSA-2023:1817 Network Observability Operator 1.2.0</link></simpara>
</listitem>
</itemizedlist>
<section xml:id="network-observability-operator-preparing-to-update">
<title>Preparing for the next update</title>
<simpara>The subscription of an installed Operator specifies an update channel that tracks and receives updates for the Operator. Until the 1.2 release of the Network Observability Operator, the only channel available was <literal>v1.0.x</literal>. The 1.2 release of the Network Observability Operator introduces the <literal>stable</literal> update channel for tracking and receiving updates. You must switch your channel from <literal>v1.0.x</literal> to <literal>stable</literal> to receive future Operator updates. The <literal>v1.0.x</literal> channel is deprecated and planned for removal in a following release.</simpara>
</section>
<section xml:id="network-observability-operator-1.2.0-features-enhancements">
<title>New features and enhancements</title>
<section xml:id="histogram-feature-1.2">
<title>Histogram in Traffic Flows view</title>
<itemizedlist>
<listitem>
<simpara>You can now choose to show a histogram bar chart of flows over time. The histogram enables you to visualize the history of flows without hitting the Loki query limit. For more information, see <link linkend="network-observability-histogram-trafficflow_nw-observe-network-traffic">Using the histogram</link>.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="conversation-tracking-feature-1.2">
<title>Conversation tracking</title>
<itemizedlist>
<listitem>
<simpara>You can now query flows by <emphasis role="strong">Log Type</emphasis>, which enables grouping network flows that are part of the same conversation. For more information, see <link linkend="network-observability-working-with-conversations_nw-observe-network-traffic">Working with conversations</link>.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="health-alerts-feature-1.2">
<title>Network Observability health alerts</title>
<itemizedlist>
<listitem>
<simpara>The Network Observability Operator now creates automatic alerts if the <literal>flowlogs-pipeline</literal> is dropping flows because of errors at the write stage or if the Loki ingestion rate limit has been reached. For more information, see <link linkend="network-observability-alert-dashboard_network_observability">Viewing health information</link>.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="network-observability-operator-1.2.0-bug-fixes">
<title>Bug fixes</title>
<itemizedlist>
<listitem>
<simpara>Previously, after changing the <literal>namespace</literal> value in the FlowCollector spec, <literal>eBPF</literal> agent pods running in the previous namespace were not appropriately deleted. Now, the pods running in the previous namespace are appropriately deleted. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-774"><emphasis role="strong">NETOBSERV-774</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Previously, after changing the <literal>caCert.name</literal> value in the FlowCollector spec (such as in Loki section), FlowLogs-Pipeline pods and Console plug-in pods were not restarted, therefore they were unaware of the configuration change. Now, the pods are restarted, so they get the configuration change. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-772"><emphasis role="strong">NETOBSERV-772</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Previously, network flows between pods running on different nodes were sometimes not correctly identified as being duplicates because they are captured by different network interfaces. This resulted in over-estimated metrics displayed in the console plug-in. Now, flows are correctly identified as duplicates, and the console plug-in displays accurate metrics. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-755"><emphasis role="strong">NETOBSERV-755</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>The "reporter" option in the console plug-in is used to filter flows based on the observation point of either source node or destination node. Previously, this option mixed the flows regardless of the node observation point. This was due to network flows being incorrectly reported as Ingress or Egress at the node level.  Now, the network flow direction reporting is correct. The "reporter" option filters for source observation point, or destination observation point, as expected. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-696"><emphasis role="strong">NETOBSERV-696</emphasis></link>)</simpara>
</listitem>
<listitem>
<simpara>Previously, for agents configured to send flows directly to the processor as gRPC+protobuf requests, the submitted payload could be too large and is rejected by the processors' GRPC server. This occurred under  very-high-load scenarios and with only some configurations of the agent. The agent logged an error message, such as: <emphasis>grpc: received message larger than max</emphasis>. As a consequence, there was information loss about those flows. Now, the gRPC payload is split into several messages when the size exceeds a threshold. As a result, the server maintains connectivity. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-617"><emphasis role="strong">NETOBSERV-617</emphasis></link>)</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="network-observability-operator-1.2.0-known-issues">
<title>Known issue</title>
<itemizedlist>
<listitem>
<simpara>In the 1.2.0 release of the Network Observability Operator, using Loki Operator 5.6, a Loki certificate transition periodically affects the <literal>flowlogs-pipeline</literal> pods and results in dropped flows rather than flows written to Loki. The problem self-corrects after some time, but it still causes temporary flow data loss during the Loki certificate transition. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-980"><emphasis role="strong">NETOBSERV-980</emphasis></link>)</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="network-observability-operator-1.2.0-notable-technical-changes">
<title>Notable technical changes</title>
<itemizedlist>
<listitem>
<simpara>Previously, you could install the Network Observability Operator using a custom namespace. This release introduces the <literal>conversion webhook</literal> which changes the <literal>ClusterServiceVersion</literal>. Because of this change, all the available namespaces are no longer listed. Additionally, to enable Operator metrics collection, namespaces that are shared with other Operators, like the <literal>openshift-operators</literal> namespace, cannot be used. Now, the Operator must be installed in the <literal>openshift-netobserv-operator</literal> namespace. You cannot automatically upgrade to the new Operator version if you previously installed the Network Observability Operator using a custom namespace. If you previously installed the Operator using a custom namespace, you must delete the instance of the Operator that was installed and re-install your operator in the <literal>openshift-netobserv-operator</literal> namespace. It is important to note that custom namespaces, such as the commonly used <literal>netobserv</literal> namespace, are still possible for the <literal>FlowCollector</literal>, Loki, Kafka, and other plug-ins. (<link xlink:href="https://issues.redhat.com/browse/NETOBSERV-907"><emphasis role="strong">NETOBSERV-907</emphasis></link>)(<link xlink:href="https://https://issues.redhat.com/browse/NETOBSERV-956"><emphasis role="strong">NETOBSERV-956</emphasis></link>)</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="network-observability-operator-release-notes-1-1">
<title>Network Observability Operator 1.1.0</title>
<simpara>The following advisory is available for the Network Observability Operator 1.1.0:</simpara>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/errata/RHSA-2023:0786">RHSA-2023:0786 Network Observability Operator Security Advisory Update</link></simpara>
</listitem>
</itemizedlist>
<simpara>The Network Observability Operator is now stable and the release channel is upgraded to <literal>v1.1.0</literal>.</simpara>
<section xml:id="network-observability-operator-1.1.0-bug-fixes">
<title>Bug fix</title>
<itemizedlist>
<listitem>
<simpara>Previously, unless the Loki <literal>authToken</literal> configuration was set to <literal>FORWARD</literal> mode, authentication was no longer enforced, allowing any user who could connect to the OpenShift Container Platform console in an OpenShift Container Platform cluster to retrieve flows without authentication.
Now, regardless of the Loki <literal>authToken</literal> mode, only cluster administrators can retrieve flows. (<link xlink:href="https://bugzilla.redhat.com/show_bug.cgi?id=2169468"><emphasis role="strong">BZ#2169468</emphasis></link>)</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</chapter>
<chapter xml:id="network-observability-overview">
<title>About Network Observability</title>
<simpara>Red Hat offers cluster administrators the Network Observability Operator to observe the network traffic for OpenShift Container Platform clusters. The Network Observability Operator uses the eBPF technology to create network flows. The network flows are then enriched with OpenShift Container Platform information and stored in Loki. You can view and analyze the stored network flows information in the OpenShift Container Platform console for further insight and troubleshooting.</simpara>
<section xml:id="dependency-network-observability">
<title>Optional dependencies of the Network Observability Operator</title>
<itemizedlist>
<listitem>
<simpara>Loki Operator: Loki is the backend that is used to store all collected flows. It is recommended to install Loki to use with the Network Observability Operator. You can choose to use <link linkend="network-observability-without-loki_network_observability">Network Observability without Loki</link>, but there are some considerations for doing this, as described in the linked section. If you choose to install Loki, it is recommended to use the Loki Operator, as it is supported by Red Hat.</simpara>
</listitem>
<listitem>
<simpara>Grafana Operator: You can install Grafana for creating custom dashboards and querying capabilities, by using an open source product, such as the Grafana Operator. Red Hat does not support the Grafana Operator.</simpara>
</listitem>
<listitem>
<simpara>AMQ Streams Operator: Kafka provides scalability, resiliency and high availability in the OpenShift Container Platform cluster for large scale deployments. If you choose to use Kafka, it is recommended to use the AMQ Streams Operator, because it is supported by Red Hat.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="network-observability-operator">
<title>Network Observability Operator</title>
<simpara>The Network Observability Operator provides the Flow Collector API custom resource definition. A Flow Collector instance is created during installation and enables configuration of network flow collection. The Flow Collector instance deploys pods and services that form a monitoring pipeline where network flows are then collected and enriched with the Kubernetes metadata before storing in Loki. The eBPF agent, which is deployed as a <literal>daemonset</literal> object, creates the network flows.</simpara>
</section>
<section xml:id="no-console-integration">
<title>OpenShift Container Platform console integration</title>
<simpara>OpenShift Container Platform console integration offers overview, topology view and traffic flow tables.</simpara>
<section xml:id="network-observability-dashboards">
<title>Network Observability metrics dashboards</title>
<simpara>On the <emphasis role="strong">Overview</emphasis> tab in the OpenShift Container Platform console, you can view the overall aggregated metrics of the network traffic flow on the cluster. You can choose to display the information by node, namespace, owner, pod, and service. Filters and display options can further refine the metrics.</simpara>
<simpara>In <emphasis role="strong">Observe</emphasis> &#8594; <emphasis role="strong">Dashboards</emphasis>, the <emphasis role="strong">Netobserv</emphasis> dashboard provides a quick overview of the network flows in your OpenShift Container Platform cluster. You can view distillations of the network traffic metrics in the following categories:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Top byte rates received per source and destination nodes</emphasis></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Top byte rates received per source and destination namespaces</emphasis></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Top byte rates received per source and destination workloads</emphasis></simpara>
</listitem>
</itemizedlist>
<simpara><emphasis role="strong">Infrastructure</emphasis> and <emphasis role="strong">Application</emphasis> metrics are shown in a split-view for namespace and workloads.
You can configure the <literal>FlowCollector</literal> <literal>spec.processor.metrics</literal> to add or remove metrics by changing the <literal>ignoreTags</literal> list. For more information about available tags, see the <link linkend="network-observability-flowcollector-api-specifications_network_observability">Flow Collector API Reference</link></simpara>
<simpara>Also in <emphasis role="strong">Observe</emphasis> &#8594; <emphasis role="strong">Dashboards</emphasis>, the <emphasis role="strong">Netobserv/Health</emphasis> dashboard provides metrics about the health of the Operator in the following categories.</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Flows</emphasis></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Flows Overhead</emphasis></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Top flow rates per source and destination nodes</emphasis></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Top flow rates per source and destination namespaces</emphasis></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Top flow rates per source and destination workloads</emphasis></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Agents</emphasis></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Processor</emphasis></simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Operator</emphasis></simpara>
</listitem>
</itemizedlist>
<simpara><emphasis role="strong">Infrastructure</emphasis> and <emphasis role="strong">Application</emphasis> metrics are shown in a split-view for namespace and workloads.</simpara>
</section>
<section xml:id="network-observability-topology-views">
<title>Network Observability topology views</title>
<simpara>The OpenShift Container Platform console offers the <emphasis role="strong">Topology</emphasis> tab which displays a graphical representation of the network flows and the amount of traffic. The topology view represents traffic between the OpenShift Container Platform components as a network graph. You can refine the graph by using the filters and display options. You can access the information for node, namespace, owner, pod, and service.</simpara>
</section>
<section xml:id="traffic-flow-tables">
<title>Traffic flow tables</title>
<simpara>The traffic flow table view provides a view for raw flows, non aggregated filtering options, and configurable columns. The OpenShift Container Platform console offers the <emphasis role="strong">Traffic flows</emphasis> tab which displays the data of the network flows and the amount of traffic.</simpara>
</section>
</section>
</chapter>
<chapter xml:id="installing-network-observability-operators">
<title>Installing the Network Observability Operator</title>
<simpara>Installing Loki is a recommended prerequisite for using the Network Observability Operator. You can choose to use <link linkend="network-observability-without-loki_network_observability">Network Observability without Loki</link>, but there are some considerations for doing this, described in the previously linked section.</simpara>
<simpara>The Loki Operator integrates a gateway that implements multi-tenancy and authentication with Loki for data flow storage. The <literal>LokiStack</literal> resource manages Loki, which is a scalable, highly-available, multi-tenant log aggregation system, and a web proxy with OpenShift Container Platform authentication. The <literal>LokiStack</literal> proxy uses OpenShift Container Platform authentication to enforce multi-tenancy and facilitate the saving and indexing of data in Loki log stores.</simpara>
<note>
<simpara>The Loki Operator can also be used for <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/logging/#cluster-logging-loki">configuring the LokiStack log store</link>. The Network Observability Operator requires a dedicated LokiStack separate from the logging.</simpara>
</note>
<section xml:id="network-observability-without-loki_network_observability">
<title>Network Observability without Loki</title>
<simpara>You can use Network Observability without Loki by not performing the Loki installation steps and skipping directly to "Installing the Network Observability Operator". If you only want to export flows to a Kafka consumer or IPFIX collector, or you only need dashboard metrics, then you do not need to install Loki or provide storage for Loki.  Without Loki, there won&#8217;t be a Network Traffic panel under Observe, which means there is no overview charts, flow table, or topology. The following table compares available features with and without Loki:</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Comparison of feature availability with and without Loki</title>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top"></entry>
<entry align="left" valign="top"><emphasis role="strong">With Loki</emphasis></entry>
<entry align="left" valign="top"><emphasis role="strong">Without Loki</emphasis></entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Exporters</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara><inlinemediaobject>
<imageobject>
<imagedata fileref="images/check-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>check solid</phrase></textobject>
</inlinemediaobject></simpara></entry>
<entry align="left" valign="top"><simpara><inlinemediaobject>
<imageobject>
<imagedata fileref="images/check-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>check solid</phrase></textobject>
</inlinemediaobject></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Flow-based metrics and dashboards</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara><inlinemediaobject>
<imageobject>
<imagedata fileref="images/check-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>check solid</phrase></textobject>
</inlinemediaobject></simpara></entry>
<entry align="left" valign="top"><simpara><inlinemediaobject>
<imageobject>
<imagedata fileref="images/check-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>check solid</phrase></textobject>
</inlinemediaobject></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Traffic Flow Overview, Table and Topology views</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara><inlinemediaobject>
<imageobject>
<imagedata fileref="images/check-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>check solid</phrase></textobject>
</inlinemediaobject></simpara></entry>
<entry align="left" valign="top"><simpara><inlinemediaobject>
<imageobject>
<imagedata fileref="images/x-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>x solid</phrase></textobject>
</inlinemediaobject></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Quick Filters</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara><inlinemediaobject>
<imageobject>
<imagedata fileref="images/check-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>check solid</phrase></textobject>
</inlinemediaobject></simpara></entry>
<entry align="left" valign="top"><simpara><inlinemediaobject>
<imageobject>
<imagedata fileref="images/x-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>x solid</phrase></textobject>
</inlinemediaobject></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">OpenShift Container Platform console Network Traffic tab integration</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara><inlinemediaobject>
<imageobject>
<imagedata fileref="images/check-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>check solid</phrase></textobject>
</inlinemediaobject></simpara></entry>
<entry align="left" valign="top"><simpara><inlinemediaobject>
<imageobject>
<imagedata fileref="images/x-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>x solid</phrase></textobject>
</inlinemediaobject></simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link linkend="network-observability-enriched-flows_network_observability">Export enriched network flow data</link>.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="network-observability-loki-installation_network_observability">
<title>Installing the Loki Operator</title>
<simpara>The <link xlink:href="https://catalog.redhat.com/software/containers/openshift-logging/loki-rhel8-operator/622b46bcae289285d6fcda39">Loki Operator versions 5.7+</link> are the supported Loki Operator versions for Network Observabilty; these versions provide the ability to create a <literal>LokiStack</literal> instance using the <literal>openshift-network</literal> tenant configuration mode and provide fully-automatic, in-cluster authentication and authorization support for Network Observability. There are several ways you can install Loki. One way is by using the OpenShift Container Platform web console Operator Hub.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Supported Log Store (AWS S3, Google Cloud Storage, Azure, Swift, Minio, OpenShift Data Foundation)</simpara>
</listitem>
<listitem>
<simpara>OpenShift Container Platform 4.10+</simpara>
</listitem>
<listitem>
<simpara>Linux Kernel 4.18+</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the OpenShift Container Platform web console, click <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">OperatorHub</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Choose  <emphasis role="strong">Loki Operator</emphasis> from the list of available Operators, and click <emphasis role="strong">Install</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Under <emphasis role="strong">Installation Mode</emphasis>, select <emphasis role="strong">All namespaces on the cluster</emphasis>.</simpara>
</listitem>
</orderedlist>
<orderedlist numeration="arabic">
<title>Verification</title>
<listitem>
<simpara>Verify that you installed the Loki Operator. Visit the <emphasis role="strong">Operators</emphasis> → <emphasis role="strong">Installed Operators</emphasis> page and look for <emphasis role="strong">Loki Operator</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Verify that <emphasis role="strong">Loki Operator</emphasis> is listed with <emphasis role="strong">Status</emphasis> as <emphasis role="strong">Succeeded</emphasis> in all the projects.</simpara>
</listitem>
</orderedlist>
<important>
<simpara>To uninstall Loki, refer to the uninstallation process that corresponds with the method you used to install Loki. You might have remaining <literal>ClusterRoles</literal> and <literal>ClusterRoleBindings</literal>, data stored in object store, and persistent volume that must be removed.</simpara>
</important>
<section xml:id="network-observability-loki-secret_network_observability">
<title>Creating a secret for Loki storage</title>
<simpara>The Loki Operator supports a few log storage options, such as AWS S3, Google Cloud Storage, Azure, Swift, Minio, OpenShift Data Foundation. The following example shows how to create a secret for AWS S3 storage. The secret created in this example, <literal>loki-s3</literal>, is referenced in "Creating a LokiStack resource". You can create this secret in the web console or CLI.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Using the web console, navigate to the <emphasis role="strong">Project</emphasis> &#8594; <emphasis role="strong">All Projects</emphasis> dropdown and select <emphasis role="strong">Create Project</emphasis>. Name the project <literal>netobserv</literal> and click <emphasis role="strong">Create</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Navigate to the Import icon, <emphasis role="strong">+</emphasis>, in the top right corner. Paste your YAML file into the editor.</simpara>
<simpara>The following shows an example secret YAML file for S3 storage:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Secret
metadata:
  name: loki-s3
  namespace: netobserv   <co xml:id="CO1-1"/>
stringData:
  access_key_id: QUtJQUlPU0ZPRE5ON0VYQU1QTEUK
  access_key_secret: d0phbHJYVXRuRkVNSS9LN01ERU5HL2JQeFJmaUNZRVhBTVBMRUtFWQo=
  bucketnames: s3-bucket-name
  endpoint: https://s3.eu-central-1.amazonaws.com
  region: eu-central-1</programlisting>
<calloutlist>
<callout arearefs="CO1-1">
<para>The installation examples in this documentation use the same namespace, <literal>netobserv</literal>, across all components. You can optionally use a different namespace for the different components</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
<itemizedlist>
<title>Verification</title>
<listitem>
<simpara>Once you create the secret, you should see it listed under <emphasis role="strong">Workloads</emphasis> &#8594; <emphasis role="strong">Secrets</emphasis> in the web console.</simpara>
</listitem>
</itemizedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link linkend="network-observability-flowcollector-api-specifications_network_observability">Flow Collector API Reference</link></simpara>
</listitem>
<listitem>
<simpara><link linkend="network-observability-flowcollector-view_network_observability">Flow Collector sample resource</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/logging/#logging-loki-storage_installing-log-storage">Loki object storage</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="network-observability-lokistack-create_network_observability">
<title>Creating a LokiStack custom resource</title>
<simpara>You can deploy a LokiStack using the web console or CLI to create a namespace, or new project.</simpara>
<important>
<simpara>Querying application logs for multiple namespaces as a <literal>cluster-admin</literal> user, where the sum total of characters of all of the namespaces in the cluster is greater than 5120, results in the error <literal>Parse error: input size too long (XXXX &gt; 5120)</literal>. For better control over access to logs in LokiStack, make the <literal>cluster-admin</literal> user a member of the <literal>cluster-admin</literal> group. If the <literal>cluster-admin</literal> group does not exist, create it and add the desired users to it.</simpara>
</important>
<simpara>For more information about creating a <literal>cluster-admin</literal> group, see the "Additional resources" section.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>, viewing <emphasis role="strong">All projects</emphasis> from the <emphasis role="strong">Project</emphasis> dropdown.</simpara>
</listitem>
<listitem>
<simpara>Look for <emphasis role="strong">Loki Operator</emphasis>. In the details, under <emphasis role="strong">Provided APIs</emphasis>, select <emphasis role="strong">LokiStack</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Create LokiStack</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Ensure the following fields are specified in either <emphasis role="strong">Form View</emphasis> or <emphasis role="strong">YAML view</emphasis>:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: loki
  namespace: netobserv   <co xml:id="CO2-1"/>
spec:
  size: 1x.small
  storage:
    schemas:
    - version: v12
      effectiveDate: '2022-06-01'
    secret:
      name: loki-s3
      type: s3
  storageClassName: gp3  <co xml:id="CO2-2"/>
  tenants:
    mode: openshift-network</programlisting>
<calloutlist>
<callout arearefs="CO2-1">
<para>The installation examples in this documentation use the same namespace, <literal>netobserv</literal>, across all components. You can optionally use a different namespace.</para>
</callout>
<callout arearefs="CO2-2">
<para>Use a storage class name that is available on the cluster for <literal>ReadWriteOnce</literal> access mode. You can use <literal>oc get storageclasses</literal> to see what is available on your cluster.</para>
</callout>
</calloutlist>
<important>
<simpara>You must not reuse the same <literal>LokiStack</literal> that is used for cluster logging.</simpara>
</important>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Create</emphasis>.</simpara>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/logging/#logging-creating-new-group-cluster-admin-user-role_cluster-logging-loki">Creating a new group for the cluster-admin user role</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="loki-deployment-sizing_network_observability">
<title>Loki deployment sizing</title>
<simpara>Sizing for Loki follows the format of <literal>&lt;N&gt;x.&lt;size&gt;</literal> where the value <literal>&lt;N&gt;</literal> is number of instances and <literal>&lt;size&gt;</literal> specifies performance capabilities.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Loki sizing</title>
<tgroup cols="5">
<colspec colname="col_1" colwidth="20*"/>
<colspec colname="col_2" colwidth="20*"/>
<colspec colname="col_3" colwidth="20*"/>
<colspec colname="col_4" colwidth="20*"/>
<colspec colname="col_5" colwidth="20*"/>
<thead>
<row>
<entry align="left" valign="top"></entry>
<entry align="left" valign="top">1x.demo</entry>
<entry align="left" valign="top">1x.extra-small</entry>
<entry align="left" valign="top">1x.small</entry>
<entry align="left" valign="top">1x.medium</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Data transfer</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Demo use only</simpara></entry>
<entry align="left" valign="top"><simpara>100GB/day</simpara></entry>
<entry align="left" valign="top"><simpara>500GB/day</simpara></entry>
<entry align="left" valign="top"><simpara>2TB/day</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Queries per second (QPS)</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Demo use only</simpara></entry>
<entry align="left" valign="top"><simpara>1-25 QPS at 200ms</simpara></entry>
<entry align="left" valign="top"><simpara>25-50 QPS at 200ms</simpara></entry>
<entry align="left" valign="top"><simpara>25-75 QPS at 200ms</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Replication factor</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>None</simpara></entry>
<entry align="left" valign="top"><simpara>2</simpara></entry>
<entry align="left" valign="top"><simpara>2</simpara></entry>
<entry align="left" valign="top"><simpara>2</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Total CPU requests</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>None</simpara></entry>
<entry align="left" valign="top"><simpara>14 vCPUs</simpara></entry>
<entry align="left" valign="top"><simpara>34 vCPUs</simpara></entry>
<entry align="left" valign="top"><simpara>54 vCPUs</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Total memory requests</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>None</simpara></entry>
<entry align="left" valign="top"><simpara>31Gi</simpara></entry>
<entry align="left" valign="top"><simpara>67Gi</simpara></entry>
<entry align="left" valign="top"><simpara>139Gi</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Total disk requests</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>40Gi</simpara></entry>
<entry align="left" valign="top"><simpara>430Gi</simpara></entry>
<entry align="left" valign="top"><simpara>430Gi</simpara></entry>
<entry align="left" valign="top"><simpara>590Gi</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section xml:id="network-observability-lokistack-configuring-ingestionnetwork_observability">
<title>LokiStack ingestion limits and health alerts</title>
<simpara>The LokiStack instance comes with default settings according to the configured size. It is possible to override some of these settings, such as the ingestion and query limits. You might want to update them if you get Loki errors showing up in the Console plugin, or in <literal>flowlogs-pipeline</literal> logs. An automatic alert in the web console notifies you when these limits are reached.</simpara>
<simpara>Here is an example of configured limits:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">spec:
  limits:
    global:
      ingestion:
        ingestionBurstSize: 40
        ingestionRate: 20
        maxGlobalStreamsPerTenant: 25000
      queries:
        maxChunksPerQuery: 2000000
        maxEntriesLimitPerQuery: 10000
        maxQuerySeries: 3000</programlisting>
<simpara>For more information about these settings, see the <link xlink:href="https://loki-operator.dev/docs/api.md/#loki-grafana-com-v1-IngestionLimitSpec">LokiStack API reference</link>.</simpara>
</section>
<section xml:id="network-observability-auth-mutli-tenancy_network_observability">
<title>Configuring authorization and multi-tenancy</title>
<simpara>Define <literal>ClusterRole</literal> and <literal>ClusterRoleBinding</literal>. The <literal>netobserv-reader</literal> <literal>ClusterRole</literal> enables multi-tenancy and allows individual user access, or group access, to the flows stored in Loki. You can create a YAML file to define these roles.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Using the web console, click the Import icon, <emphasis role="strong">+</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Drop your YAML file into the editor and click <emphasis role="strong">Create</emphasis>:</simpara>
</listitem>
</orderedlist>
<formalpara>
<title>Example ClusterRole reader yaml</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: netobserv-reader    <co xml:id="CO3-1"/>
rules:
- apiGroups:
  - 'loki.grafana.com'
  resources:
  - network
  resourceNames:
  - logs
  verbs:
  - 'get'</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO3-1">
<para>This role can be used for multi-tenancy.</para>
</callout>
</calloutlist>
<formalpara>
<title>Example ClusterRole writer yaml</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: netobserv-writer
rules:
- apiGroups:
  - 'loki.grafana.com'
  resources:
  - network
  resourceNames:
  - logs
  verbs:
  - 'create'</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example ClusterRoleBinding yaml</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: netobserv-writer-flp
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: netobserv-writer
subjects:
- kind: ServiceAccount
  name: flowlogs-pipeline    <co xml:id="CO4-1"/>
  namespace: netobserv
- kind: ServiceAccount
  name: flowlogs-pipeline-transformer
  namespace: netobserv</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO4-1">
<para>The <literal>flowlogs-pipeline</literal> writes to Loki. If you are using Kafka, this value is <literal>flowlogs-pipeline-transformer</literal>.</para>
</callout>
</calloutlist>
</section>
<section xml:id="network-observability-multi-tenancynetwork_observability">
<title>Enabling multi-tenancy in Network Observability</title>
<simpara>Multi-tenancy in the Network Observability Operator allows and restricts individual user access, or group access, to the flows stored in Loki. Access is enabled for project admins. Project admins who have limited access to some namespaces can access flows for only those namespaces.</simpara>
<itemizedlist>
<title>Prerequisite</title>
<listitem>
<simpara>You have installed <link xlink:href="https://catalog.redhat.com/software/containers/openshift-logging/loki-rhel8-operator/622b46bcae289285d6fcda39">Loki Operator version 5.7</link></simpara>
</listitem>
<listitem>
<simpara>The <literal>FlowCollector</literal> <literal>spec.loki.authToken</literal> configuration must be set to <literal>FORWARD</literal>.</simpara>
</listitem>
<listitem>
<simpara>You must be logged in as a project administrator</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Authorize reading permission to <literal>user1</literal> by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm policy add-cluster-role-to-user netobserv-reader user1</programlisting>
<simpara>Now, the data is restricted to only allowed user namespaces. For example, a user that has access to a single namespace can see all the flows internal to this namespace, as well as flows going from and to this namespace.
Project admins have access to the Administrator perspective in the OpenShift Container Platform console to access the Network Flows Traffic page.</simpara>
</listitem>
</orderedlist>
</section>
</section>
<section xml:id="network-observability-operator-installation_network_observability">
<title>Installing the Network Observability Operator</title>
<simpara>You can install the Network Observability Operator using the OpenShift Container Platform web console Operator Hub. When you install the Operator,  it provides the <literal>FlowCollector</literal> custom resource definition (CRD). You can set specifications in the web console when you create the  <literal>FlowCollector</literal>.</simpara>
<important>
<simpara>The actual memory consumption of the Operator depends on your cluster size and the number of resources deployed. Memory consumption might need to be adjusted accordingly. For more information refer to "Network Observability controller manager pod runs out of memory" in the "Important Flow Collector configuration considerations" section.</simpara>
</important>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>If you choose to use Loki, install the <link xlink:href="https://catalog.redhat.com/software/containers/openshift-logging/loki-rhel8-operator/622b46bcae289285d6fcda39">Loki Operator version 5.7+</link>.</simpara>
</listitem>
<listitem>
<simpara>You must have <literal>cluster-admin</literal> privileges.</simpara>
</listitem>
<listitem>
<simpara>One of the following supported architectures is required: <literal>amd64</literal>, <literal>ppc64le</literal>, <literal>arm64</literal>, or <literal>s390x</literal>.</simpara>
</listitem>
<listitem>
<simpara>Any CPU supported by Red Hat Enterprise Linux (RHEL) 9.</simpara>
</listitem>
<listitem>
<simpara>Must be configured with OVN-Kubernetes or OpenShift SDN as the main network plugin, and optionally using secondary interfaces, such as Multus and SR-IOV.</simpara>
</listitem>
</itemizedlist>
<note>
<simpara>This documentation assumes that your <literal>LokiStack</literal> instance name is <literal>loki</literal>. Using a different name requires additional configuration.</simpara>
</note>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the OpenShift Container Platform web console, click <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">OperatorHub</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Choose  <emphasis role="strong">Network Observability Operator</emphasis> from the list of available Operators in the <emphasis role="strong">OperatorHub</emphasis>, and click <emphasis role="strong">Install</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select the checkbox <literal>Enable Operator recommended cluster monitoring on this Namespace</literal>.</simpara>
</listitem>
<listitem>
<simpara>Navigate to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>. Under Provided APIs for Network Observability, select the <emphasis role="strong">Flow Collector</emphasis> link.</simpara>
</listitem>
<listitem>
<simpara>Navigate to the <emphasis role="strong">Flow Collector</emphasis> tab, and click <emphasis role="strong">Create FlowCollector</emphasis>. Make the following selections in the form view:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara><emphasis role="strong">spec.agent.ebpf.Sampling</emphasis>: Specify a sampling size for flows. Lower sampling sizes will have higher impact on resource utilization. For more information, see the "FlowCollector API reference", <literal>spec.agent.ebpf</literal>.</simpara>
</listitem>
<listitem>
<simpara>If you are using Loki, set the following specifications:</simpara>
<orderedlist numeration="lowerroman">
<listitem>
<simpara><emphasis role="strong">spec.loki.enable</emphasis>: Select the check box to enable storing flows in Loki.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">spec.loki.url</emphasis>: Since authentication is specified separately, this URL needs to be updated to <literal><link xlink:href="https://loki-gateway-http.netobserv.svc:8080/api/logs/v1/network">https://loki-gateway-http.netobserv.svc:8080/api/logs/v1/network</link></literal>. The first part of the URL, "loki", must match the name of your <literal>LokiStack</literal>.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">spec.loki.authToken</emphasis>: Select the <literal>FORWARD</literal> value.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">spec.loki.statusUrl</emphasis>: Set this to <literal><link xlink:href="https://loki-query-frontend-http.netobserv.svc:3100/">https://loki-query-frontend-http.netobserv.svc:3100/</link></literal>. The first part of the URL, "loki", must match the name of your <literal>LokiStack</literal>.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">spec.loki.tls.enable</emphasis>: Select the checkbox to enable TLS.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">spec.loki.statusTls</emphasis>: The <literal>enable</literal> value is false by default.</simpara>
<simpara>For the first part of the certificate reference names: <literal>loki-gateway-ca-bundle</literal>, <literal>loki-ca-bundle</literal>, and <literal>loki-query-frontend-http</literal>,<literal>loki</literal>, must match the name of your <literal>LokiStack</literal>.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Optional: If you are in a large-scale environment, consider configuring the <literal>FlowCollector</literal> with Kafka for forwarding data in a more resilient, scalable way. See "Configuring the Flow Collector resource with Kafka storage" in the "Important Flow Collector configuration considerations" section.</simpara>
</listitem>
<listitem>
<simpara>Optional: Configure other optional settings before the next step of creating the <literal>FlowCollector</literal>. For example, if you choose not to use Loki, then you can configure exporting flows to Kafka or IPFIX. See "Export enriched network flow data to Kafka and IPFIX" and more in the "Important Flow Collector configuration considerations" section.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Create</emphasis>.</simpara>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
<formalpara>
<title>Verification</title>
<para>To confirm this was successful, when you navigate to <emphasis role="strong">Observe</emphasis> you should see <emphasis role="strong">Network Traffic</emphasis> listed in the options.</para>
</formalpara>
<simpara>In the absence of <emphasis role="strong">Application Traffic</emphasis> within the OpenShift Container Platform cluster, default filters might show that there are "No results", which results in no visual flow. Beside the filter selections, select <emphasis role="strong">Clear all filters</emphasis> to see the flow.</simpara>
<important>
<simpara>If you installed Loki using the Loki Operator, it is advised not to use <literal>querierUrl</literal>, as it can break the console access to Loki. If you installed Loki using another type of Loki installation, this does not apply.</simpara>
</important>
</section>
<section xml:id="additional-resources_configuring-flow-collector-considerations" role="_additional-resources">
<title>Important Flow Collector configuration considerations</title>
<simpara>Once you create the <literal>FlowCollector</literal> instance, you can reconfigure it, but the pods are terminated and recreated again, which can be disruptive. Therefore, you can consider configuring the following options when creating the <literal>FlowCollector</literal> for the first time:</simpara>
<itemizedlist>
<listitem>
<simpara><link linkend="network-observability-flowcollector-kafka-config_network_observability">Configuring the Flow Collector resource with Kafka</link></simpara>
</listitem>
<listitem>
<simpara><link linkend="network-observability-enriched-flows_network_observability">Export enriched network flow data to Kafka or IPFIX</link></simpara>
</listitem>
<listitem>
<simpara><link linkend="network-observability-SR-IOV-config_network_observability">Configuring monitoring for SR-IOV interface traffic</link></simpara>
</listitem>
<listitem>
<simpara><link linkend="network-observability-working-with-conversations_nw-observe-network-traffic">Working with conversation tracking</link></simpara>
</listitem>
<listitem>
<simpara><link linkend="network-observability-dns-tracking_nw-observe-network-traffic">Working with DNS tracking</link></simpara>
</listitem>
<listitem>
<simpara><link linkend="network-observability-packet-drops_nw-observe-network-traffic">Working with packet drops</link></simpara>
</listitem>
</itemizedlist>
<formalpara role="_additional-resources">
<title>Additional resources</title>
<para>For more general information about Flow Collector specifications and the Network Observability Operator architecture and resource use, see the following resources:</para>
</formalpara>
<itemizedlist>
<listitem>
<simpara><link linkend="network-observability-flowcollector-api-specifications_network_observability">Flow Collector API Reference</link></simpara>
</listitem>
<listitem>
<simpara><link linkend="network-observability-flowcollector-view_network_observability">Flow Collector sample resource</link></simpara>
</listitem>
<listitem>
<simpara><link linkend="network-observability-resources-table_network_observability">Resource considerations</link></simpara>
</listitem>
<listitem>
<simpara><link linkend="controller-manager-pod-runs-out-of-memory_network-observability-troubleshooting">Troubleshooting Network Observability controller manager pod runs out of memory</link></simpara>
</listitem>
<listitem>
<simpara><link linkend="network-observability-architecture_nw-network-observability-operator">Network Observability architecture</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="network-observability-kafka-option_network_observability">
<title>Installing Kafka (optional)</title>
<simpara>The Kafka Operator is supported for large scale environments. Kafka provides high-throughput and low-latency data feeds for forwarding network flow data in a more resilient, scalable way. You can install the Kafka Operator as <link xlink:href="https://access.redhat.com/documentation/en-us/red_hat_amq_streams/2.2">Red Hat AMQ Streams</link> from the Operator Hub, just as the Loki Operator and Network Observability Operator were installed. Refer to "Configuring the FlowCollector resource with Kafka" to configure Kafka as a storage option.</simpara>
<note>
<simpara>To uninstall Kafka, refer to the uninstallation process that corresponds with the method you used to install.</simpara>
</note>
<formalpara role="_additional-resources">
<title>Additional resources</title>
<para><link linkend="network-observability-flowcollector-kafka-config_network_observability">Configuring the FlowCollector resource with Kafka</link>.</para>
</formalpara>
</section>
<section xml:id="network-observability-operator-uninstall_network_observability">
<title>Uninstalling the Network Observability Operator</title>
<simpara>You can uninstall the Network Observability Operator using the OpenShift Container Platform web console Operator Hub, working in the <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis> area.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Remove the <literal>FlowCollector</literal> custom resource.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Click <emphasis role="strong">Flow Collector</emphasis>, which is next to the <emphasis role="strong">Network Observability Operator</emphasis> in the <emphasis role="strong">Provided APIs</emphasis> column.</simpara>
</listitem>
<listitem>
<simpara>Click the options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> for the <emphasis role="strong">cluster</emphasis> and select <emphasis role="strong">Delete FlowCollector</emphasis>.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Uninstall the Network Observability Operator.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Navigate back to the <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis> area.</simpara>
</listitem>
<listitem>
<simpara>Click the options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> next to the  <emphasis role="strong">Network Observability Operator</emphasis> and select <emphasis role="strong">Uninstall Operator</emphasis>.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Home</emphasis> &#8594; <emphasis role="strong">Projects</emphasis> and select <literal>openshift-netobserv-operator</literal></simpara>
</listitem>
<listitem>
<simpara>Navigate to <emphasis role="strong">Actions</emphasis> and select <emphasis role="strong">Delete Project</emphasis></simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Remove the <literal>FlowCollector</literal> custom resource definition (CRD).</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Navigate to <emphasis role="strong">Administration</emphasis> &#8594; <emphasis role="strong">CustomResourceDefinitions</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Look for <emphasis role="strong">FlowCollector</emphasis> and click the options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject>.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">Delete CustomResourceDefinition</emphasis>.</simpara>
<important>
<simpara>The Loki Operator and Kafka remain if they were installed and must be removed separately. Additionally, you might have remaining data stored in an object store, and a persistent volume that must be removed.</simpara>
</important>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
</section>
</chapter>
<chapter xml:id="nw-network-observability-operator">
<title>Network Observability Operator in OpenShift Container Platform</title>
<simpara>Network Observability is an OpenShift operator that deploys a monitoring pipeline to collect and enrich network traffic flows that are produced by the Network Observability eBPF agent.</simpara>
<section xml:id="nw-network-observability-operator_nw-network-observability-operator">
<title>Viewing statuses</title>
<simpara>The Network Observability Operator provides the Flow Collector API. When a Flow Collector resource is created, it deploys pods and services to create and store network flows in the Loki log store, as well as to display dashboards, metrics, and flows in the OpenShift Container Platform web console.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Run the following command to view the state of <literal>FlowCollector</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get flowcollector/cluster</programlisting>
<formalpara>
<title>Example output</title>
<para>
<screen>NAME      AGENT   SAMPLING (EBPF)   DEPLOYMENT MODEL   STATUS
cluster   EBPF    50                DIRECT             Ready</screen>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Check the status of pods running in the <literal>netobserv</literal> namespace by entering the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods -n netobserv</programlisting>
<formalpara>
<title>Example output</title>
<para>
<screen>NAME                              READY   STATUS    RESTARTS   AGE
flowlogs-pipeline-56hbp           1/1     Running   0          147m
flowlogs-pipeline-9plvv           1/1     Running   0          147m
flowlogs-pipeline-h5gkb           1/1     Running   0          147m
flowlogs-pipeline-hh6kf           1/1     Running   0          147m
flowlogs-pipeline-w7vv5           1/1     Running   0          147m
netobserv-plugin-cdd7dc6c-j8ggp   1/1     Running   0          147m</screen>
</para>
</formalpara>
</listitem>
</orderedlist>
<simpara><literal>flowlogs-pipeline</literal> pods collect flows, enriches the collected flows, then send flows to the Loki storage.
<literal>netobserv-plugin</literal> pods create a visualization plugin for the OpenShift Container Platform Console.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Check the status of pods running in the namespace <literal>netobserv-privileged</literal> by entering the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods -n netobserv-privileged</programlisting>
<formalpara>
<title>Example output</title>
<para>
<screen>NAME                         READY   STATUS    RESTARTS   AGE
netobserv-ebpf-agent-4lpp6   1/1     Running   0          151m
netobserv-ebpf-agent-6gbrk   1/1     Running   0          151m
netobserv-ebpf-agent-klpl9   1/1     Running   0          151m
netobserv-ebpf-agent-vrcnf   1/1     Running   0          151m
netobserv-ebpf-agent-xf5jh   1/1     Running   0          151m</screen>
</para>
</formalpara>
</listitem>
</orderedlist>
<simpara><literal>netobserv-ebpf-agent</literal> pods monitor network interfaces of the nodes to get flows and send them to <literal>flowlogs-pipeline</literal> pods.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>If you are using the Loki Operator, check the status of pods running in the <literal>openshift-operators-redhat</literal> namespace by entering the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods -n openshift-operators-redhat</programlisting>
<formalpara>
<title>Example output</title>
<para>
<screen>NAME                                                READY   STATUS    RESTARTS   AGE
loki-operator-controller-manager-5f6cff4f9d-jq25h   2/2     Running   0          18h
lokistack-compactor-0                               1/1     Running   0          18h
lokistack-distributor-654f87c5bc-qhkhv              1/1     Running   0          18h
lokistack-distributor-654f87c5bc-skxgm              1/1     Running   0          18h
lokistack-gateway-796dc6ff7-c54gz                   2/2     Running   0          18h
lokistack-index-gateway-0                           1/1     Running   0          18h
lokistack-index-gateway-1                           1/1     Running   0          18h
lokistack-ingester-0                                1/1     Running   0          18h
lokistack-ingester-1                                1/1     Running   0          18h
lokistack-ingester-2                                1/1     Running   0          18h
lokistack-querier-66747dc666-6vh5x                  1/1     Running   0          18h
lokistack-querier-66747dc666-cjr45                  1/1     Running   0          18h
lokistack-querier-66747dc666-xh8rq                  1/1     Running   0          18h
lokistack-query-frontend-85c6db4fbd-b2xfb           1/1     Running   0          18h
lokistack-query-frontend-85c6db4fbd-jm94f           1/1     Running   0          18h</screen>
</para>
</formalpara>
</listitem>
</orderedlist>
</section>
<section xml:id="network-observability-architecture_nw-network-observability-operator">
<title>Network Observablity Operator architecture</title>
<simpara>The Network Observability Operator provides the <literal>FlowCollector</literal> API, which is instantiated at installation and configured to reconcile the <literal>eBPF agent</literal>, the <literal>flowlogs-pipeline</literal>, and the <literal>netobserv-plugin</literal> components. Only a single <literal>FlowCollector</literal> per cluster is supported.</simpara>
<simpara>The <literal>eBPF agent</literal> runs on each cluster node with some privileges to collect network flows. The <literal>flowlogs-pipeline</literal> receives the network flows data and enriches the data with Kubernetes identifiers. If you are using Loki, the <literal>flowlogs-pipeline</literal> sends flow logs data to Loki for storing and indexing. The <literal>netobserv-plugin</literal>, which is a dynamic OpenShift Container Platform web console plugin, queries Loki to fetch network flows data. Cluster-admins can view the data in the web console.</simpara>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="images/network-observability-architecture.png"/>
</imageobject>
<textobject><phrase>Network Observability eBPF export architecture</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>If you are using the Kafka option, the eBPF agent sends the network flow data to Kafka, and the <literal>flowlogs-pipeline</literal> reads from the Kafka topic before sending to Loki, as shown in the following diagram.</simpara>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="images/network-observability-arch-kafka-FLP.png"/>
</imageobject>
<textobject><phrase>Network Observability using Kafka</phrase></textobject>
</mediaobject>
</informalfigure>
</section>
<section xml:id="nw-status-configuration-network-observability-operator_nw-network-observability-operator">
<title>Viewing Network Observability Operator status and configuration</title>
<simpara>You can inspect the status and view the details of the <literal>FlowCollector</literal> using the <literal>oc describe</literal> command.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Run the following command to view the status and configuration of the Network Observability Operator:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc describe flowcollector/cluster</programlisting>
</listitem>
</orderedlist>
</section>
</chapter>
<chapter xml:id="configuring-network-observability-operators">
<title>Configuring the Network Observability Operator</title>
<simpara>You can update the Flow Collector API resource to configure the Network Observability Operator and its managed components. The  Flow Collector is explicitly created during installation. Since this resource operates cluster-wide, only a single <literal>FlowCollector</literal> is allowed, and it has to be named <literal>cluster</literal>.</simpara>
<section xml:id="network-observability-flowcollector-view_network_observability">
<title>View the FlowCollector resource</title>
<simpara>You can view and edit YAML directly in the OpenShift Container Platform web console.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the web console, navigate to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Under the <emphasis role="strong">Provided APIs</emphasis> heading for the <emphasis role="strong">NetObserv Operator</emphasis>, select <emphasis role="strong">Flow Collector</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">cluster</emphasis> then select the <emphasis role="strong">YAML</emphasis> tab. There, you can modify the <literal>FlowCollector</literal> resource to configure the Network Observability operator.</simpara>
</listitem>
</orderedlist>
<simpara>The following example shows a sample <literal>FlowCollector</literal> resource for OpenShift Container Platform Network Observability operator:</simpara>
<formalpara xml:id="network-observability-flowcollector-configuring-about-sample_network_observability">
<title>Sample <literal>FlowCollector</literal> resource</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: flows.netobserv.io/v1beta1
kind: FlowCollector
metadata:
  name: cluster
spec:
  namespace: netobserv
  deploymentModel: DIRECT
  agent:
    type: EBPF                                <co xml:id="CO5-1"/>
    ebpf:
      sampling: 50                            <co xml:id="CO5-2"/>
      logLevel: info
      privileged: false
      resources:
        requests:
          memory: 50Mi
          cpu: 100m
        limits:
          memory: 800Mi
  processor:
    logLevel: info
    resources:
      requests:
        memory: 100Mi
        cpu: 100m
      limits:
        memory: 800Mi
    conversationEndTimeout: 10s
    logTypes: FLOWS                            <co xml:id="CO5-3"/>
    conversationHeartbeatInterval: 30s
  loki:                                       <co xml:id="CO5-4"/>
    url: 'https://loki-gateway-http.netobserv.svc:8080/api/logs/v1/network'
    statusUrl: 'https://loki-query-frontend-http.netobserv.svc:3100/'
    authToken: FORWARD
    tls:
      enable: true
      caCert:
        type: configmap
        name: loki-gateway-ca-bundle
        certFile: service-ca.crt
        namespace: loki-namespace          #  <co xml:id="CO5-5"/>
  consolePlugin:
    register: true
    logLevel: info
    portNaming:
      enable: true
      portNames:
        "3100": loki
    quickFilters:                             <co xml:id="CO5-6"/>
    - name: Applications
      filter:
        src_namespace!: 'openshift-,netobserv'
        dst_namespace!: 'openshift-,netobserv'
      default: true
    - name: Infrastructure
      filter:
        src_namespace: 'openshift-,netobserv'
        dst_namespace: 'openshift-,netobserv'
    - name: Pods network
      filter:
        src_kind: 'Pod'
        dst_kind: 'Pod'
      default: true
    - name: Services network
      filter:
        dst_kind: 'Service'</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO5-1">
<para>The Agent specification, <literal>spec.agent.type</literal>, must be <literal>EBPF</literal>. eBPF is the only OpenShift Container Platform supported option.</para>
</callout>
<callout arearefs="CO5-2">
<para>You can set the Sampling specification, <literal>spec.agent.ebpf.sampling</literal>, to manage resources. Lower sampling values might consume a large amount of computational, memory and storage resources. You can mitigate this by specifying a sampling ratio value. A value of 100 means 1 flow every 100 is sampled. A value of 0 or 1 means all flows are captured. The lower the value, the increase in returned flows and the accuracy of derived metrics. By default, eBPF sampling is set to a value of 50, so 1 flow every 50 is sampled. Note that more sampled flows also means more storage needed. It is recommend to start with default values and refine empirically, to determine which setting your cluster can manage.</para>
</callout>
<callout arearefs="CO5-3">
<para>The optional specifications <literal>spec.processor.logTypes</literal>, <literal>spec.processor.conversationHeartbeatInterval</literal>, and <literal>spec.processor.conversationEndTimeout</literal> can be set to enable conversation tracking. When enabled, conversation events are queryable in the web console. The values for <literal>spec.processor.logTypes</literal> are as follows: <literal>FLOWS</literal> <literal>CONVERSATIONS</literal>, <literal>ENDED_CONVERSATIONS</literal>, or <literal>ALL</literal>. Storage requirements are highest for <literal>ALL</literal> and lowest for <literal>ENDED_CONVERSATIONS</literal>.</para>
</callout>
<callout arearefs="CO5-4">
<para>The Loki specification, <literal>spec.loki</literal>, specifies the Loki client. The default values match the Loki install paths mentioned in the Installing the Loki Operator section. If you used another installation method for Loki, specify the appropriate client information for your install.</para>
</callout>
<callout arearefs="CO5-5">
<para>The original certificates are copied to the Network Observability instance namespace and watched for updates. When not provided, the namespace defaults to be the same as "spec.namespace". If you chose to install Loki in a different namespace, you must specify it in the <literal>spec.loki.tls.caCert.namespace</literal> field.   Similarly, the <literal>spec.exporters.kafka.tls.caCert.namespace</literal> field is available for Kafka installed in a different namespace.</para>
</callout>
<callout arearefs="CO5-6">
<para>The <literal>spec.quickFilters</literal> specification defines filters that show up in the web console. The <literal>Application</literal> filter keys,<literal>src_namespace</literal> and <literal>dst_namespace</literal>, are negated (<literal>!</literal>), so the <literal>Application</literal> filter shows all traffic that <emphasis>does not</emphasis> originate from, or have a destination to, any <literal>openshift-</literal> or <literal>netobserv</literal> namespaces. For more information, see Configuring quick filters below.</para>
</callout>
</calloutlist>
<formalpara role="_additional-resources">
<title>Additional resources</title>
<para>For more information about conversation tracking, see <link linkend="network-observability-working-with-conversations_nw-observe-network-traffic">Working with conversations</link>.</para>
</formalpara>
</section>
<section xml:id="network-observability-flowcollector-kafka-config_network_observability">
<title>Configuring the Flow Collector resource with Kafka</title>
<simpara>You can configure the <literal>FlowCollector</literal> resource to use Kafka for high-throughput and low-latency data feeds. A Kafka instance needs to be running, and a Kafka topic dedicated to OpenShift Container Platform Network Observability must be created in that instance. For more information, see <link xlink:href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.7/html/using_amq_streams_on_openshift/using-the-topic-operator-str">Kafka documentation with AMQ Streams</link>.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Kafka is installed. Red Hat supports Kafka with AMQ Streams Operator.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the web console, navigate to <emphasis role="strong">Operators</emphasis> → <emphasis role="strong">Installed Operators</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Under the <emphasis role="strong">Provided APIs</emphasis> heading for the Network Observability Operator, select <emphasis role="strong">Flow Collector</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select the cluster and then click the <emphasis role="strong">YAML</emphasis> tab.</simpara>
</listitem>
<listitem>
<simpara>Modify the <literal>FlowCollector</literal> resource for OpenShift Container Platform Network Observability Operator to use Kafka, as shown in the following sample YAML:</simpara>
</listitem>
</orderedlist>
<formalpara xml:id="network-observability-flowcollector-configuring-kafka-sample_network_observability">
<title>Sample Kafka configuration in <literal>FlowCollector</literal> resource</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: flows.netobserv.io/v1beta1
kind: FlowCollector
metadata:
  name: cluster
spec:
  deploymentModel: KAFKA                                    <co xml:id="CO6-1"/>
  kafka:
    address: "kafka-cluster-kafka-bootstrap.netobserv"      <co xml:id="CO6-2"/>
    topic: network-flows                                    <co xml:id="CO6-3"/>
    tls:
      enable: false                                         <co xml:id="CO6-4"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO6-1">
<para>Set <literal>spec.deploymentModel</literal> to <literal>KAFKA</literal> instead of <literal>DIRECT</literal> to enable the Kafka deployment model.</para>
</callout>
<callout arearefs="CO6-2">
<para><literal>spec.kafka.address</literal> refers to the Kafka bootstrap server address. You can specify a port if needed, for instance <literal>kafka-cluster-kafka-bootstrap.netobserv:9093</literal> for using TLS on port 9093.</para>
</callout>
<callout arearefs="CO6-3">
<para><literal>spec.kafka.topic</literal> should match the name of a topic created in Kafka.</para>
</callout>
<callout arearefs="CO6-4">
<para><literal>spec.kafka.tls</literal> can be used to encrypt all communications to and from Kafka with TLS or mTLS. When enabled, the Kafka CA certificate must be available as a ConfigMap or a Secret, both in the namespace where the <literal>flowlogs-pipeline</literal> processor component is deployed (default: <literal>netobserv</literal>) and where the eBPF agents are deployed (default: <literal>netobserv-privileged</literal>). It must be referenced with <literal>spec.kafka.tls.caCert</literal>. When using mTLS, client secrets must be available in these namespaces as well (they can be generated for instance using the AMQ Streams User Operator) and referenced with <literal>spec.kafka.tls.userCert</literal>.</para>
</callout>
</calloutlist>
</section>
<section xml:id="network-observability-enriched-flows_network_observability">
<title>Export enriched network flow data</title>
<simpara>You can send network flows to Kafka, IPFIX, or both at the same time. Any processor or storage that supports Kafka or IPFIX input, such as Splunk, Elasticsearch, or Fluentd, can consume the enriched network flow data.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Your Kafka or IPFIX collector endpoint(s) are available from Network Observability <literal>flowlogs-pipeline</literal> pods.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the web console, navigate to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Under the <emphasis role="strong">Provided APIs</emphasis> heading for the <emphasis role="strong">NetObserv Operator</emphasis>, select <emphasis role="strong">Flow Collector</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">cluster</emphasis> and then select the <emphasis role="strong">YAML</emphasis> tab.</simpara>
</listitem>
<listitem>
<simpara>Edit the <literal>FlowCollector</literal> to configure <literal>spec.exporters</literal> as follows:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: flows.netobserv.io/v1alpha1
kind: FlowCollector
metadata:
  name: cluster
spec:
  exporters:
  - type: KAFKA                         <co xml:id="CO7-1"/>
      kafka:
        address: "kafka-cluster-kafka-bootstrap.netobserv"
        topic: netobserv-flows-export   <co xml:id="CO7-2"/>
        tls:
          enable: false                 <co xml:id="CO7-3"/>
  - type: IPFIX                         <co xml:id="CO7-4"/>
      ipfix:
        targetHost: "ipfix-collector.ipfix.svc.cluster.local"
        targetPort: 4739
        transport: tcp or udp           <co xml:id="CO7-5"/></programlisting>
<calloutlist>
<callout arearefs="CO7-2">
<para>The Network Observability Operator exports all flows to the configured Kafka topic.</para>
</callout>
<callout arearefs="CO7-3">
<para>You can encrypt all communications to and from Kafka with SSL/TLS or mTLS. When enabled, the Kafka CA certificate must be available as a ConfigMap or a Secret, both in the namespace where the <literal>flowlogs-pipeline</literal> processor component is deployed (default: netobserv). It must be referenced with <literal>spec.exporters.tls.caCert</literal>. When using mTLS, client secrets must be available in these namespaces as well (they can be generated for instance using the AMQ Streams User Operator) and referenced with <literal>spec.exporters.tls.userCert</literal>.</para>
</callout>
<callout arearefs="CO7-1 CO7-4">
<para>You can export flows to IPFIX instead of or in conjunction with exporting flows to Kafka.</para>
</callout>
<callout arearefs="CO7-5">
<para>You have the option to specify transport. The default value is <literal>tcp</literal> but you can also specify <literal>udp</literal>.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>After configuration, network flows data can be sent to an available output in a JSON format. For more information, see <emphasis>Network flows format reference</emphasis>.</simpara>
</listitem>
</orderedlist>
<formalpara role="_additional-resources">
<title>Additional resources</title>
<para>For more information about specifying flow format, see <link linkend="network-observability-flows-format_json_reference">Network flows format reference</link>.</para>
</formalpara>
</section>
<section xml:id="network-observability-config-FLP-sampling_network_observability">
<title>Updating the Flow Collector resource</title>
<simpara>As an alternative to editing YAML in the OpenShift Container Platform web console, you can configure specifications, such as eBPF sampling, by patching the <literal>flowcollector</literal> custom resource (CR):</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Run the following command to patch the <literal>flowcollector</literal> CR and update the <literal>spec.agent.ebpf.sampling</literal> value:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc patch flowcollector cluster --type=json -p "[{"op": "replace", "path": "/spec/agent/ebpf/sampling", "value": &lt;new value&gt;}] -n netobserv"</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="network-observability-config-quick-filters_network_observability">
<title>Configuring quick filters</title>
<simpara>You can modify the filters in the <literal>FlowCollector</literal> resource. Exact matches are possible using double-quotes around values. Otherwise, partial matches are used for textual values. The bang (!) character, placed at the end of a key, means negation. See the sample <literal>FlowCollector</literal> resource for more context about modifying the YAML.</simpara>
<note>
<simpara>The filter matching types "all of" or "any of" is a UI setting that the users can modify from the query options. It is not part of this resource configuration.</simpara>
</note>
<simpara>Here is a list of all available filter keys:</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Filter keys</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="9.0909*"/>
<colspec colname="col_2" colwidth="9.0909*"/>
<colspec colname="col_3" colwidth="9.0909*"/>
<colspec colname="col_4" colwidth="72.7273*"/>
<thead>
<row>
<entry align="left" valign="top">Universal*</entry>
<entry align="left" valign="top">Source</entry>
<entry align="left" valign="top">Destination</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>namespace</simpara></entry>
<entry align="left" valign="top"><simpara><literal>src_namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>dst_namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Filter traffic related to a specific namespace.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>name</simpara></entry>
<entry align="left" valign="top"><simpara><literal>src_name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>dst_name</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Filter traffic related to a given leaf resource name, such as a specific pod, service, or node (for host-network traffic).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>kind</simpara></entry>
<entry align="left" valign="top"><simpara><literal>src_kind</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>dst_kind</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Filter traffic related to a given resource kind. The resource kinds include the leaf resource (Pod, Service or Node), or the owner resource (Deployment and StatefulSet).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>owner_name</simpara></entry>
<entry align="left" valign="top"><simpara><literal>src_owner_name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>dst_owner_name</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Filter traffic related to a given resource owner; that is, a workload or a set of pods. For example, it can be a Deployment name, a StatefulSet name, etc.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>resource</simpara></entry>
<entry align="left" valign="top"><simpara><literal>src_resource</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>dst_resource</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Filter traffic related to a specific resource that is denoted by its canonical name, that identifies it uniquely. The canonical notation is <literal>kind.namespace.name</literal> for namespaced kinds, or <literal>node.name</literal> for nodes. For example, <literal>Deployment.my-namespace.my-web-server</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>address</simpara></entry>
<entry align="left" valign="top"><simpara><literal>src_address</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>dst_address</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Filter traffic related to an IP address. IPv4 and IPv6 are supported. CIDR ranges are also supported.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>mac</simpara></entry>
<entry align="left" valign="top"><simpara><literal>src_mac</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>dst_mac</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Filter traffic related to a MAC address.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>port</simpara></entry>
<entry align="left" valign="top"><simpara><literal>src_port</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>dst_port</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Filter traffic related to a specific port.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>host_address</simpara></entry>
<entry align="left" valign="top"><simpara><literal>src_host_address</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>dst_host_address</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Filter traffic related to the host IP address where the pods are running.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>protocol</simpara></entry>
<entry align="left" valign="top"><simpara>N/A</simpara></entry>
<entry align="left" valign="top"><simpara>N/A</simpara></entry>
<entry align="left" valign="top"><simpara>Filter traffic related to a protocol, such as TCP or UDP.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<itemizedlist>
<listitem>
<simpara>Universal keys filter for any of source or destination. For example, filtering <literal>name: 'my-pod'</literal> means all traffic from <literal>my-pod</literal> and all traffic to <literal>my-pod</literal>, regardless of the matching type used, whether <emphasis role="strong">Match all</emphasis> or <emphasis role="strong">Match any</emphasis>.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="network-observability-SR-IOV-config_network_observability">
<title>Configuring monitoring for SR-IOV interface traffic</title>
<simpara>In order to collect traffic from a cluster with a Single Root I/O Virtualization (SR-IOV) device, you must set the <literal>FlowCollector</literal> <literal>spec.agent.ebpf.privileged</literal> field to <literal>true</literal>. Then, the eBPF agent monitors other network namespaces in addition to the host network namespaces, which are monitored by default. When a pod with a virtual functions (VF) interface is created, a new network namespace is created. With <literal>SRIOVNetwork</literal> policy <literal>IPAM</literal> configurations specified, the VF interface is migrated from the host network namespace to the pod network namespace.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Access to an OpenShift Container Platform cluster with a SR-IOV device.</simpara>
</listitem>
<listitem>
<simpara>The <literal>SRIOVNetwork</literal> custom resource (CR) <literal>spec.ipam</literal> configuration must be set with an IP address from the range that the interface lists or from other plugins.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the web console, navigate to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Under the <emphasis role="strong">Provided APIs</emphasis> heading for the <emphasis role="strong">NetObserv Operator</emphasis>, select <emphasis role="strong">Flow Collector</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">cluster</emphasis> and then select the <emphasis role="strong">YAML</emphasis> tab.</simpara>
</listitem>
<listitem>
<simpara>Configure the <literal>FlowCollector</literal> custom resource. A sample configuration is as follows:</simpara>
<formalpara xml:id="network-observability-flowcollector-configuring-SRIOV-monitoringnetwork_observability">
<title>Configure <literal>FlowCollector</literal> for SR-IOV monitoring</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: flows.netobserv.io/v1alpha1
kind: FlowCollector
metadata:
  name: cluster
spec:
  namespace: netobserv
  deploymentModel: DIRECT
  agent:
    type: EBPF
    ebpf:
      privileged: true   <co xml:id="CO8-1"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO8-1">
<para>The <literal>spec.agent.ebpf.privileged</literal> field value must be set to <literal>true</literal> to enable SR-IOV monitoring.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
<formalpara role="_additional-resources">
<title>Additional resources</title>
<para>For more information about creating the <literal>SriovNetwork</literal> custom resource, see <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/networking/#cnf-creating-an-additional-sriov-network-with-vrf-plug-in_configuring-sriov-device">Creating an additional SR-IOV network attachment with the CNI VRF plugin</link>.</para>
</formalpara>
</section>
<section xml:id="network-observability-resource-recommendations_network_observability">
<title>Resource management and performance considerations</title>
<simpara>The amount of resources required by Network Observability depends on the size of your cluster and your requirements for the cluster to ingest and store observability data. To manage resources and set performance criteria for your cluster, consider configuring the following settings. Configuring these settings might meet your optimal setup and observability needs.</simpara>
<simpara>The following settings can help you manage resources and performance from the outset:</simpara>
<variablelist>
<varlistentry>
<term>eBPF Sampling</term>
<listitem>
<simpara>You can set the Sampling specification, <literal>spec.agent.ebpf.sampling</literal>, to manage resources. Smaller sampling values might consume a large amount of computational, memory and storage resources. You can mitigate this by specifying a sampling ratio value. A value of <literal>100</literal> means 1 flow every 100 is sampled. A value of <literal>0</literal> or <literal>1</literal> means all flows are captured. Smaller values result in an increase in returned flows and the accuracy of derived metrics. By default, eBPF sampling is set to a value of 50, so 1 flow every 50 is sampled. Note that more sampled flows also means more storage needed. Consider starting with the default values and refine empirically, in order to determine which setting your cluster can manage.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Restricting or excluding interfaces</term>
<listitem>
<simpara>Reduce the overall observed traffic by setting the values for <literal>spec.agent.ebpf.interfaces</literal> and <literal>spec.agent.ebpf.excludeInterfaces</literal>. By default, the agent fetches all the interfaces in the system, except the ones listed in <literal>excludeInterfaces</literal> and <literal>lo</literal> (local interface). Note that the interface names might vary according to the Container Network Interface (CNI) used.</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>The following settings can be used to fine-tune performance after the Network Observability has been running for a while:</simpara>
<variablelist>
<varlistentry>
<term>Resource requirements and limits</term>
<listitem>
<simpara>Adapt the resource requirements and limits to the load and memory usage you expect on your cluster by using the <literal>spec.agent.ebpf.resources</literal> and <literal>spec.processor.resources</literal> specifications. The default limits of 800MB might be sufficient for most medium-sized clusters.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Cache max flows timeout</term>
<listitem>
<simpara>Control how often flows are reported by the agents by using the eBPF agent&#8217;s <literal>spec.agent.ebpf.cacheMaxFlows</literal> and <literal>spec.agent.ebpf.cacheActiveTimeout</literal> specifications. A larger value results in less traffic being generated by the agents, which correlates with a lower CPU load. However, a larger value leads to a slightly higher memory consumption, and might generate more latency in the flow collection.</simpara>
</listitem>
</varlistentry>
</variablelist>
<section xml:id="network-observability-resources-table_network_observability">
<title>Resource considerations</title>
<simpara>The following table outlines examples of resource considerations for clusters with certain workload sizes.</simpara>
<important>
<simpara>The examples outlined in the table demonstrate scenarios that are tailored to specific workloads. Consider each example only as a baseline from which adjustments can be made to accommodate your workload needs.</simpara>
</important>
<table frame="all" rowsep="1" colsep="1">
<title>Resource recommendations</title>
<tgroup cols="5">
<colspec colname="col_1" colwidth="20*"/>
<colspec colname="col_2" colwidth="20*"/>
<colspec colname="col_3" colwidth="20*"/>
<colspec colname="col_4" colwidth="20*"/>
<colspec colname="col_5" colwidth="20*"/>
<thead>
<row>
<entry align="left" valign="top"></entry>
<entry align="left" valign="top">Extra small (10 nodes)</entry>
<entry align="left" valign="top">Small (25 nodes)</entry>
<entry align="left" valign="top">Medium (65 nodes) <superscript>[2]</superscript></entry>
<entry align="left" valign="top">Large (120 nodes) <superscript>[2]</superscript></entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Worker Node vCPU and memory</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>4 vCPUs| 16GiB mem <superscript>[1]</superscript></simpara></entry>
<entry align="left" valign="top"><simpara>16 vCPUs| 64GiB mem <superscript>[1]</superscript></simpara></entry>
<entry align="left" valign="top"><simpara>16 vCPUs| 64GiB mem  <superscript>[1]</superscript></simpara></entry>
<entry align="left" valign="top"><simpara>16 vCPUs| 64GiB Mem <superscript>[1]</superscript></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">LokiStack size</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara><literal>1x.extra-small</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>1x.small</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>1x.small</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>1x.medium</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Network Observability controller memory limit</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>400Mi (default)</simpara></entry>
<entry align="left" valign="top"><simpara>400Mi (default)</simpara></entry>
<entry align="left" valign="top"><simpara>400Mi (default)</simpara></entry>
<entry align="left" valign="top"><simpara>800Mi</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">eBPF sampling rate</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>50 (default)</simpara></entry>
<entry align="left" valign="top"><simpara>50 (default)</simpara></entry>
<entry align="left" valign="top"><simpara>50 (default)</simpara></entry>
<entry align="left" valign="top"><simpara>50 (default)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">eBPF memory limit</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>800Mi (default)</simpara></entry>
<entry align="left" valign="top"><simpara>800Mi (default)</simpara></entry>
<entry align="left" valign="top"><simpara>2000Mi</simpara></entry>
<entry align="left" valign="top"><simpara>800Mi (default)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">FLP memory limit</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>800Mi (default)</simpara></entry>
<entry align="left" valign="top"><simpara>800Mi (default)</simpara></entry>
<entry align="left" valign="top"><simpara>800Mi (default)</simpara></entry>
<entry align="left" valign="top"><simpara>800Mi (default)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">FLP Kafka partitions</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>N/A</simpara></entry>
<entry align="left" valign="top"><simpara>48</simpara></entry>
<entry align="left" valign="top"><simpara>48</simpara></entry>
<entry align="left" valign="top"><simpara>48</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Kafka consumer replicas</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>N/A</simpara></entry>
<entry align="left" valign="top"><simpara>24</simpara></entry>
<entry align="left" valign="top"><simpara>24</simpara></entry>
<entry align="left" valign="top"><simpara>24</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Kafka brokers</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>N/A</simpara></entry>
<entry align="left" valign="top"><simpara>3 (default)</simpara></entry>
<entry align="left" valign="top"><simpara>3 (default)</simpara></entry>
<entry align="left" valign="top"><simpara>3 (default)</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<para role="small">
<orderedlist numeration="arabic">
<listitem>
<simpara>Tested with AWS M6i instances.</simpara>
</listitem>
<listitem>
<simpara>In addition to this worker and its controller, 3 infra nodes (size <literal>M6i.12xlarge</literal>) and 1 workload node (size <literal>M6i.8xlarge</literal>) were tested.</simpara>
</listitem>
</orderedlist>
</para>
</section>
</section>
</chapter>
<chapter xml:id="network-observability-network-policy">
<title>Network Policy</title>
<simpara>As a user with the <literal>admin</literal> role, you can create a network policy for the <literal>netobserv</literal> namespace.</simpara>
<section xml:id="network-observability-network-policy_network_observability">
<title>Creating a network policy for Network Observability</title>
<simpara>You might need to create a network policy to secure ingress traffic to the <literal>netobserv</literal> namespace. In the web console, you can create a network policy using the form view.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to <emphasis role="strong">Networking</emphasis> &#8594; <emphasis role="strong">NetworkPolicies</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select the <literal>netobserv</literal> project from the <emphasis role="strong">Project</emphasis> dropdown menu.</simpara>
</listitem>
<listitem>
<simpara>Name the policy. For this example, the policy name is <literal>allow-ingress</literal>.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Add ingress rule</emphasis> three times to create three ingress rules.</simpara>
</listitem>
<listitem>
<simpara>Specify the following in the form:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Make the following specifications for the first <emphasis role="strong">Ingress rule</emphasis>:</simpara>
<orderedlist numeration="lowerroman">
<listitem>
<simpara>From the <emphasis role="strong">Add allowed source</emphasis> dropdown menu, select <emphasis role="strong">Allow pods from the same namespace</emphasis>.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Make the following specifications for the second <emphasis role="strong">Ingress rule</emphasis>:</simpara>
<orderedlist numeration="lowerroman">
<listitem>
<simpara>From the <emphasis role="strong">Add allowed source</emphasis> dropdown menu, select <emphasis role="strong">Allow pods from inside the cluster</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">+ Add namespace selector</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Add the label, <literal>kubernetes.io/metadata.name</literal>, and the selector, <literal>openshift-console</literal>.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Make the following specifications for the third <emphasis role="strong">Ingress rule</emphasis>:</simpara>
<orderedlist numeration="lowerroman">
<listitem>
<simpara>From the <emphasis role="strong">Add allowed source</emphasis> dropdown menu, select <emphasis role="strong">Allow pods from inside the cluster</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">+ Add namespace selector</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Add the label, <literal>kubernetes.io/metadata.name</literal>, and the selector, <literal>openshift-monitoring</literal>.</simpara>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
<orderedlist numeration="arabic">
<title>Verification</title>
<listitem>
<simpara>Navigate to <emphasis role="strong">Observe</emphasis> &#8594; <emphasis role="strong">Network Traffic</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>View the <emphasis role="strong">Traffic Flows</emphasis> tab, or any tab, to verify that the data is displayed.</simpara>
</listitem>
<listitem>
<simpara>Navigate to <emphasis role="strong">Observe</emphasis> &#8594; <emphasis role="strong">Dashboards</emphasis>. In the NetObserv/Health selection, verify that the flows are being ingested and sent to Loki, which is represented in the first graph.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="network-observability-sample-network-policy_network_observability">
<title>Example network policy</title>
<simpara>The following annotates an example <literal>NetworkPolicy</literal> object for the <literal>netobserv</literal> namespace:</simpara>
<formalpara xml:id="network-observability-network-policy-sample_network_observability">
<title>Sample network policy</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: allow-ingress
  namespace: netobserv
spec:
  podSelector: {}            <co xml:id="CO9-1"/>
  ingress:
    - from:
        - podSelector: {}    <co xml:id="CO9-2"/>
          namespaceSelector: <co xml:id="CO9-3"/>
            matchLabels:
              kubernetes.io/metadata.name: openshift-console
        - podSelector: {}
          namespaceSelector:
            matchLabels:
              kubernetes.io/metadata.name: openshift-monitoring
  policyTypes:
    - Ingress
status: {}</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO9-1">
<para>A selector that describes the pods to which the policy applies. The policy object can only select pods in the project that defines the <literal>NetworkPolicy</literal> object. In this documentation, it would be the project in which the Network Observability Operator is installed, which is the <literal>netobserv</literal> project.</para>
</callout>
<callout arearefs="CO9-2">
<para>A selector that matches the pods from which the policy object allows ingress traffic. The default is that the selector matches pods in the same namespace as the <literal>NetworkPolicy</literal>.</para>
</callout>
<callout arearefs="CO9-3">
<para>When the <literal>namespaceSelector</literal> is specified, the selector matches pods in the specified namespace.</para>
</callout>
</calloutlist>
<formalpara role="_additional-resources">
<title>Additional resources</title>
<para><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/networking/#nw-networkpolicy-object_creating-network-policy">Creating a network policy using the CLI</link></para>
</formalpara>
</section>
</chapter>
<chapter xml:id="nw-observe-network-traffic">
<title>Observing the network traffic</title>
<simpara>As an administrator, you can observe the network traffic in the OpenShift Container Platform console for detailed troubleshooting and analysis. This feature helps you get insights from different graphical representations of traffic flow. There are several available views to observe the network traffic.</simpara>
<section xml:id="network-observability-overview_nw-observe-network-traffic">
<title>Observing the network traffic from the Overview view</title>
<simpara>The <emphasis role="strong">Overview</emphasis> view displays the overall aggregated metrics of the network traffic flow on the cluster. As an administrator, you can monitor the statistics with the available display options.</simpara>
<section xml:id="network-observability-working-with-overview_nw-observe-network-traffic">
<title>Working with the Overview view</title>
<simpara>As an administrator, you can navigate to the <emphasis role="strong">Overview</emphasis> view to see the graphical representation of the flow rate statistics.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to <emphasis role="strong">Observe</emphasis> → <emphasis role="strong">Network Traffic</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Network Traffic</emphasis> page, click the <emphasis role="strong">Overview</emphasis> tab.</simpara>
</listitem>
</orderedlist>
<simpara>You can configure the scope of each flow rate data by clicking the menu icon.</simpara>
</section>
<section xml:id="network-observability-configuring-options-overview_nw-observe-network-traffic">
<title>Configuring advanced options for the Overview view</title>
<simpara>You can customize the graphical view by using advanced options. To access the advanced options, click <emphasis role="strong">Show advanced options</emphasis>.You can configure the details in the graph by using the <emphasis role="strong">Display options</emphasis> drop-down menu. The options available are:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Metric type</emphasis>: The metrics to be shown in <emphasis role="strong">Bytes</emphasis> or <emphasis role="strong">Packets</emphasis>. The default value is <emphasis role="strong">Bytes</emphasis>.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Scope</emphasis>: To select the detail of components between which the network traffic flows. You can set the scope to <emphasis role="strong">Node</emphasis>, <emphasis role="strong">Namespace</emphasis>, <emphasis role="strong">Owner</emphasis>, or <emphasis role="strong">Resource</emphasis>. <emphasis role="strong">Owner</emphasis> is an aggregation of resources. <emphasis role="strong">Resource</emphasis> can be a pod, service, node, in case of host-network traffic, or an unknown IP address. The default value is <emphasis role="strong">Namespace</emphasis>.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Truncate labels</emphasis>: Select the required width of the label from the drop-down list. The default value is <emphasis role="strong">M</emphasis>.</simpara>
</listitem>
</itemizedlist>
<section xml:id="network-observability-cao-managing-panels-overview_nw-observe-network-traffic">
<title>Managing panels</title>
<simpara>You can select the required statistics to be displayed, and reorder them. To manage columns, click <emphasis role="strong">Manage panels</emphasis>.</simpara>
</section>
<section xml:id="network-observability-pktdrop-overview_nw-observe-network-traffic">
<title>Packet drop tracking</title>
<simpara>You can configure graphical representation of network flow records with packet loss in the <emphasis role="strong">Overview</emphasis> view. By employing eBPF tracepoint hooks, you can gain valuable insights into packet drops for TCP, UDP, SCTP, ICMPv4, and ICMPv6 protocols, which can result in the following actions:</simpara>
<itemizedlist>
<listitem>
<simpara>Identification: Pinpoint the exact locations and network paths where packet drops are occurring. Determine whether specific devices, interfaces, or routes are more prone to drops.</simpara>
</listitem>
<listitem>
<simpara>Root cause analysis: Examine the data collected by the eBPF program to understand the causes of packet drops. For example, are they a result of congestion, buffer issues, or specific network events?</simpara>
</listitem>
<listitem>
<simpara>Performance optimization: With a clearer picture of packet drops, you can take steps to optimize network performance, such as adjust buffer sizes, reconfigure routing paths, or implement Quality of Service (QoS) measures.</simpara>
</listitem>
</itemizedlist>
<simpara>When packet drop tracking is enabled, you can see the following metrics represented in a chart in the <emphasis role="strong">Overview</emphasis>.</simpara>
<itemizedlist>
<listitem>
<simpara>Top X flow dropped rates stacked</simpara>
</listitem>
<listitem>
<simpara>Total dropped rate</simpara>
</listitem>
<listitem>
<simpara>Top X dropped state</simpara>
</listitem>
<listitem>
<simpara>Top X dropped cause</simpara>
</listitem>
<listitem>
<simpara>Top X flow dropped rates stacked with total</simpara>
</listitem>
</itemizedlist>
<simpara>Two kinds of packet drops are detected by Network Observability: host drops and OVS drops. Host drops are prefixed with <literal>SKB_DROP</literal> and OVS drops are prefixed with <literal>OVS_DROP</literal>. Dropped flows are shown in the side panel of the <emphasis role="strong">Traffic flows</emphasis> table along with a link to a description of each drop type. Examples of host drop reasons are as follows:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>SKB_DROP_REASON_NO_SOCKET</literal>: the packet dropped due to a missing socket.</simpara>
</listitem>
<listitem>
<simpara><literal>SKB_DROP_REASON_TCP_CSUM</literal>: the packet dropped due to a TCP checksum error.</simpara>
</listitem>
</itemizedlist>
<simpara>Examples of OVS drops reasons are as follows:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>OVS_DROP_LAST_ACTION</literal>: OVS packets dropped due to an implicit drop action, for example due to a configured network policy.</simpara>
</listitem>
<listitem>
<simpara><literal>OVS_DROP_IP_TTL</literal>: OVS packets dropped due to an expired IP TTL.</simpara>
</listitem>
</itemizedlist>
<simpara>See the <emphasis>Additional Resources</emphasis> of this section for more information about enabling and working with packet drop tracking.</simpara>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara>For more information about configuring packet drops in the <literal>FlowCollector</literal>, see <link linkend="network-observability-packet-drops_nw-observe-network-traffic">Working with packet drops</link>.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="network-observability-dns-overview_nw-observe-network-traffic">
<title>DNS tracking</title>
<simpara>You can configure graphical representation of Domain Name System (DNS) tracking of network flows in the <emphasis role="strong">Overview</emphasis> view. Using DNS tracking with extended Berkeley Packet Filter (eBPF) tracepoint hooks can serve various purposes:</simpara>
<itemizedlist>
<listitem>
<simpara>Network Monitoring: Gain insights into DNS queries and responses, helping network administrators identify unusual patterns, potential bottlenecks, or performance issues.</simpara>
</listitem>
<listitem>
<simpara>Security Analysis: Detect suspicious DNS activities, such as domain name generation algorithms (DGA) used by malware, or identify unauthorized DNS resolutions that might indicate a security breach.</simpara>
</listitem>
<listitem>
<simpara>Troubleshooting: Debug DNS-related issues by tracing DNS resolution steps, tracking latency, and identifying misconfigurations.</simpara>
</listitem>
</itemizedlist>
<simpara>When DNS tracking is enabled, you can see the following metrics represented in a chart in the <emphasis role="strong">Overview</emphasis>. See the <emphasis>Additional Resources</emphasis> in this section for more information about enabling and working with this view.</simpara>
<itemizedlist>
<listitem>
<simpara>Top 5 average DNS latencies</simpara>
</listitem>
<listitem>
<simpara>Top 5 DNS response code</simpara>
</listitem>
<listitem>
<simpara>Top 5 DNS response code stacked with total</simpara>
</listitem>
</itemizedlist>
<simpara>This feature is supported for IPv4 and IPv6 UDP protocol.</simpara>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara>For more information about configuring DNS in the <literal>FlowCollector</literal>, see <link linkend="network-observability-dns-tracking_nw-observe-network-traffic">Working with DNS tracking</link>.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="network-observability-trafficflow_nw-observe-network-traffic">
<title>Observing the network traffic from the Traffic flows view</title>
<simpara>The <emphasis role="strong">Traffic flows</emphasis> view displays the data of the network flows and the amount of traffic in a table. As an administrator, you can monitor the amount of traffic across the application by using the traffic flow table.</simpara>
<section xml:id="network-observability-working-with-trafficflow_nw-observe-network-traffic">
<title>Working with the Traffic flows view</title>
<simpara>As an administrator, you can navigate to <emphasis role="strong">Traffic flows</emphasis> table to see network flow information.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to <emphasis role="strong">Observe</emphasis> → <emphasis role="strong">Network Traffic</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Network Traffic</emphasis> page, click the <emphasis role="strong">Traffic flows</emphasis> tab.</simpara>
</listitem>
</orderedlist>
<simpara>You can click on each row to get the corresponding flow information.</simpara>
</section>
<section xml:id="network-observability-configuring-options-trafficflow_nw-observe-network-traffic">
<title>Configuring advanced options for the Traffic flows view</title>
<simpara>You can customize and export the view by using <emphasis role="strong">Show advanced options</emphasis>.
You can set the row size by using the <emphasis role="strong">Display options</emphasis> drop-down menu. The default value is <emphasis role="strong">Normal</emphasis>.</simpara>
<section xml:id="network-observability-cao-managing-columns-trafficflownw-observe-network-traffic">
<title>Managing columns</title>
<simpara>You can select the required columns to be displayed, and reorder them. To manage columns, click <emphasis role="strong">Manage columns</emphasis>.</simpara>
</section>
<section xml:id="network-observability-cao-export-trafficflow_nw-observe-network-traffic">
<title>Exporting the traffic flow data</title>
<simpara>You can export data from the <emphasis role="strong">Traffic flows</emphasis> view.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Click <emphasis role="strong">Export data</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>In the pop-up window, you can select the <emphasis role="strong">Export all data</emphasis> checkbox to export all the data, and clear the checkbox to select the required fields to be exported.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Export</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
</section>
<section xml:id="network-observability-working-with-conversations_nw-observe-network-traffic">
<title>Working with conversation tracking</title>
<simpara>As an administrator, you can you can group network flows that are part of the same conversation. A conversation is defined as a grouping of peers that are identified by their IP addresses, ports, and protocols, resulting in an unique <emphasis role="strong">Conversation Id</emphasis>. You can query conversation events in the web console. These events are represented in the web console as follows:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Conversation start</emphasis>: This event happens when a connection is starting or TCP flag intercepted</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Conversation tick</emphasis>: This event happens at each specified interval defined in the <literal>FlowCollector</literal> <literal>spec.processor.conversationHeartbeatInterval</literal> parameter while the connection is active.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Conversation end</emphasis>: This event happens when the <literal>FlowCollector</literal> <literal>spec.processor.conversationEndTimeout</literal> parameter is reached or  the TCP flag is intercepted.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Flow</emphasis>: This is the network traffic flow that occurs within the specified interval.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the web console, navigate to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Under the <emphasis role="strong">Provided APIs</emphasis> heading for the <emphasis role="strong">NetObserv Operator</emphasis>, select <emphasis role="strong">Flow Collector</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">cluster</emphasis> then select the <emphasis role="strong">YAML</emphasis> tab.</simpara>
</listitem>
<listitem>
<simpara>Configure the <literal>FlowCollector</literal> custom resource so that <literal>spec.processor.logTypes</literal>, <literal>conversationEndTimeout</literal>, and <literal>conversationHeartbeatInterval</literal> parameters are set according to your observation needs. A sample configuration is as follows:</simpara>
<formalpara xml:id="network-observability-flowcollector-configuring-conversations_nw-observe-network-traffic">
<title>Configure <literal>FlowCollector</literal> for conversation tracking</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: flows.netobserv.io/v1alpha1
kind: FlowCollector
metadata:
  name: cluster
spec:
 processor:
  conversationEndTimeout: 10s                  <co xml:id="CO10-1"/>
  logTypes: FLOWS                              <co xml:id="CO10-2"/>
  conversationHeartbeatInterval: 30s           <co xml:id="CO10-3"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO10-1">
<para>The <emphasis role="strong">Conversation end</emphasis> event represents the point when the <literal>conversationEndTimeout</literal> is reached or the TCP flag is intercepted.</para>
</callout>
<callout arearefs="CO10-2">
<para>When <literal>logTypes</literal> is set to <literal>FLOWS</literal>, only the <emphasis role="strong">Flow</emphasis> event is exported. If you set the value to <literal>ALL</literal>, both conversation and flow events are exported and visible in the <emphasis role="strong">Network Traffic</emphasis> page. To focus only on conversation events, you can specify <literal>CONVERSATIONS</literal> which exports the <emphasis role="strong">Conversation start</emphasis>, <emphasis role="strong">Conversation tick</emphasis> and <emphasis role="strong">Conversation end</emphasis> events; or <literal>ENDED_CONVERSATIONS</literal> exports only the <emphasis role="strong">Conversation end</emphasis> events. Storage requirements are highest for <literal>ALL</literal> and lowest for <literal>ENDED_CONVERSATIONS</literal>.</para>
</callout>
<callout arearefs="CO10-3">
<para>The <emphasis role="strong">Conversation tick</emphasis> event represents each specified interval defined in the <literal>FlowCollector</literal> <literal>conversationHeartbeatInterval</literal> parameter while the network connection is active.</para>
</callout>
</calloutlist>
<note>
<simpara>If you update the <literal>logType</literal> option, the flows from the previous selection do not clear from the console plugin. For example, if you initially set <literal>logType</literal> to <literal>CONVERSATIONS</literal> for a span of time until 10 AM and then move to <literal>ENDED_CONVERSATIONS</literal>, the console plugin shows all conversation events before 10 AM and only ended conversations after 10 AM.</simpara>
</note>
</listitem>
<listitem>
<simpara>Refresh the <emphasis role="strong">Network Traffic</emphasis> page on the <emphasis role="strong">Traffic flows</emphasis> tab. Notice there are two new columns, <emphasis role="strong">Event/Type</emphasis> and <emphasis role="strong">Conversation Id</emphasis>. All the <emphasis role="strong">Event/Type</emphasis> fields are <literal>Flow</literal> when <emphasis role="strong">Flow</emphasis> is the selected query option.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">Query Options</emphasis> and choose the <emphasis role="strong">Log Type</emphasis>, <emphasis role="strong">Conversation</emphasis>. Now the <emphasis role="strong">Event/Type</emphasis> shows all of the desired conversation events.</simpara>
</listitem>
<listitem>
<simpara>Next you can filter on a specific conversation ID or switch between the <emphasis role="strong">Conversation</emphasis> and <emphasis role="strong">Flow</emphasis> log type options from the side panel.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="network-observability-packet-drops_nw-observe-network-traffic">
<title>Working with packet drops</title>
<simpara>Packet loss occurs when one or more packets of network flow data fail to reach their destination. You can track these drops by editing the <literal>FlowCollector</literal> to the specifications in the following YAML example.</simpara>
<important>
<simpara>CPU and memory usage increases when this feature is enabled.</simpara>
</important>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the web console, navigate to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Under the <emphasis role="strong">Provided APIs</emphasis> heading for the <emphasis role="strong">NetObserv Operator</emphasis>, select <emphasis role="strong">Flow Collector</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">cluster</emphasis>, and then select the <emphasis role="strong">YAML</emphasis> tab.</simpara>
</listitem>
<listitem>
<simpara>Configure the <literal>FlowCollector</literal> custom resource for packet drops, for example:</simpara>
<formalpara xml:id="network-observability-flowcollector-configuring-pkt-drop_nw-observe-network-traffic">
<title>Example <literal>FlowCollector</literal> configuration</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: flows.netobserv.io/v1alpha1
kind: FlowCollector
metadata:
  name: cluster
spec:
  namespace: netobserv
  deploymentModel: DIRECT
  agent:
    type: EBPF
    ebpf:
      features:
       - PacketDrop            <co xml:id="CO11-1"/>
      privileged: true         <co xml:id="CO11-2"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO11-1">
<para>You can start reporting the packet drops of each network flow by listing the <literal>PacketDrop</literal> parameter in the <literal>spec.agent.ebpf.features</literal> specification list.</para>
</callout>
<callout arearefs="CO11-2">
<para>The <literal>spec.agent.ebpf.privileged</literal> specification value must be <literal>true</literal> for packet drop tracking.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
<itemizedlist>
<title>Verification</title>
<listitem>
<simpara>When you refresh the <emphasis role="strong">Network Traffic</emphasis> page, the <emphasis role="strong">Overview</emphasis>, <emphasis role="strong">Traffic Flow</emphasis>, and <emphasis role="strong">Topology</emphasis> views display new information about packet drops:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Select new choices in <emphasis role="strong">Manage panels</emphasis> to choose which graphical visualizations of packet drops to display in the <emphasis role="strong">Overview</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select new choices in <emphasis role="strong">Manage columns</emphasis> to choose which packet drop information to display in the <emphasis role="strong">Traffic flows</emphasis> table.</simpara>
<orderedlist numeration="lowerroman">
<listitem>
<simpara>In the <emphasis role="strong">Traffic Flows</emphasis> view, you can also expand the side panel to view more information about packet drops. Host drops are prefixed with <literal>SKB_DROP</literal> and OVS drops are prefixed with <literal>OVS_DROP</literal>.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Topology</emphasis> view, red lines are displayed where drops are present.</simpara>
</listitem>
</orderedlist>
</listitem>
</itemizedlist>
</section>
<section xml:id="network-observability-dns-tracking_nw-observe-network-traffic">
<title>Working with DNS tracking</title>
<simpara>Using DNS tracking, you can monitor your network, conduct security analysis, and troubleshoot DNS issues. You can track DNS by editing the <literal>FlowCollector</literal> to the specifications in the following YAML example.</simpara>
<important>
<simpara>CPU and memory usage increases are observed in the eBPF agent when this feature is enabled.</simpara>
</important>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the web console, navigate to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Under the <emphasis role="strong">Provided APIs</emphasis> heading for the <emphasis role="strong">NetObserv Operator</emphasis>, select <emphasis role="strong">Flow Collector</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">cluster</emphasis> then select the <emphasis role="strong">YAML</emphasis> tab.</simpara>
</listitem>
<listitem>
<simpara>Configure the <literal>FlowCollector</literal> custom resource. A sample configuration is as follows:</simpara>
<formalpara xml:id="network-observability-flowcollector-configuring-dns_nw-observe-network-traffic">
<title>Configure <literal>FlowCollector</literal> for DNS tracking</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: flows.netobserv.io/v1alpha1
kind: FlowCollector
metadata:
  name: cluster
spec:
  namespace: netobserv
  deploymentModel: DIRECT
  agent:
    type: EBPF
    ebpf:
      features:
       - DNSTracking           <co xml:id="CO12-1"/>
      privileged: true         <co xml:id="CO12-2"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO12-1">
<para>You can set the <literal>spec.agent.ebpf.features</literal> parameter list to enable DNS tracking of each network flow in the web console.</para>
</callout>
<callout arearefs="CO12-2">
<para>Note that the <literal>spec.agent.ebpf.privileged</literal> specification value must be <literal>true</literal> for DNS tracking to be enabled.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>When you refresh the <emphasis role="strong">Network Traffic</emphasis> page, there are new DNS representations you can choose to view in the <emphasis role="strong">Overview</emphasis> and <emphasis role="strong">Traffic Flow</emphasis> views and new filters you can apply.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Select new DNS choices in <emphasis role="strong">Manage panels</emphasis> to display graphical visualizations and DNS metrics in the <emphasis role="strong">Overview</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select new choices in <emphasis role="strong">Manage columns</emphasis> to add DNS columns to the <emphasis role="strong">Traffic Flows</emphasis> view.</simpara>
</listitem>
<listitem>
<simpara>Filter on specific DNS metrics, such as <emphasis role="strong">DNS Id</emphasis>, <emphasis role="strong">DNS Latency</emphasis> and <emphasis role="strong">DNS Response Code</emphasis>, and see more information from the side panel.</simpara>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
<section xml:id="network-observability-histogram-trafficflow_nw-observe-network-traffic">
<title>Using the histogram</title>
<simpara>You can click <emphasis role="strong">Show histogram</emphasis> to display a toolbar view for visualizing the history of flows as a bar chart. The histogram shows the number of logs over time. You can select a part of the histogram to filter the network flow data in the table that follows the toolbar.</simpara>
</section>
</section>
</section>
<section xml:id="network-observability-topology_nw-observe-network-traffic">
<title>Observing the network traffic from the Topology view</title>
<simpara>The <emphasis role="strong">Topology</emphasis> view provides a graphical representation of the network flows and the amount of traffic. As an administrator, you can monitor the traffic data across the application by using the <emphasis role="strong">Topology</emphasis> view.</simpara>
<section xml:id="network-observability-working-with-topology_nw-observe-network-traffic">
<title>Working with the Topology view</title>
<simpara>As an administrator, you can navigate to the <emphasis role="strong">Topology</emphasis> view to see the details and metrics of the component.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to <emphasis role="strong">Observe</emphasis> → <emphasis role="strong">Network Traffic</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Network Traffic</emphasis> page, click the <emphasis role="strong">Topology</emphasis> tab.</simpara>
</listitem>
</orderedlist>
<simpara>You can click each component in the <emphasis role="strong">Topology</emphasis> to view the details and metrics of the component.</simpara>
</section>
<section xml:id="network-observability-configuring-options-topology_nw-observe-network-traffic">
<title>Configuring the advanced options for the Topology view</title>
<simpara>You can customize and export the view by using <emphasis role="strong">Show advanced options</emphasis>. The advanced options view has the following features:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Find in view</emphasis>: To search the required components in the view.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Display options</emphasis>: To configure the following options:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Layout</emphasis>: To select the layout of the graphical representation. The default value is <emphasis role="strong">ColaNoForce</emphasis>.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Scope</emphasis>: To select the scope of components between which the network traffic flows. The default value is <emphasis role="strong">Namespace</emphasis>.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Groups</emphasis>: To enchance the understanding of ownership by grouping the components. The default value is <emphasis role="strong">None</emphasis>.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Collapse groups</emphasis>: To expand or collapse the groups. The groups are expanded by default. This option is disabled if <emphasis role="strong">Groups</emphasis> has value <emphasis role="strong">None</emphasis>.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Show</emphasis>: To select the details that need to be displayed. All the options are checked by default. The options available are: <emphasis role="strong">Edges</emphasis>, <emphasis role="strong">Edges label</emphasis>, and <emphasis role="strong">Badges</emphasis>.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Truncate labels</emphasis>: To select the required width of the label from the drop-down list. The default value is <emphasis role="strong">M</emphasis>.</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
<section xml:id="network-observability-cao-export-topology_nw-observe-network-traffic">
<title>Exporting the topology view</title>
<simpara>To export the view, click <emphasis role="strong">Export topology view</emphasis>. The view is downloaded in PNG format.</simpara>
</section>
</section>
</section>
<section xml:id="network-observability-quickfilternw-observe-network-traffic">
<title>Filtering the network traffic</title>
<simpara>By default, the Network Traffic page displays the traffic flow data in the cluster based on the default filters configured in the <literal>FlowCollector</literal> instance. You can use the filter options to observe the required data by changing the preset filter.</simpara>
<variablelist>
<varlistentry>
<term>Query Options</term>
<listitem>
<simpara>You can use <emphasis role="strong">Query Options</emphasis> to optimize the search results, as listed below:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Log Type</emphasis>: The available options <emphasis role="strong">Conversation</emphasis> and <emphasis role="strong">Flows</emphasis> provide the ability to query flows by log type, such as flow log, new conversation, completed conversation, and a heartbeat, which is a periodic record with updates for long conversations. A conversation is an aggregation of flows between the same peers.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Duplicated flows</emphasis>: A flow might be reported from several interfaces, and from both source and destination nodes, making it appear in the data several times. By selecting this query option, you can choose to show duplicated flows. Duplicated flows have the same sources and destinations, including ports, and also have the same protocols, with the exception of <literal>Interface</literal> and <literal>Direction</literal> fields. Duplicates are hidden by default. Use the <emphasis role="strong">Direction</emphasis> filter in the <emphasis role="strong">Common</emphasis> section of the dropdown list to switch between ingress and egress traffic.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Match filters</emphasis>: You can determine the relation between different filter parameters selected in the advanced filter. The available options are <emphasis role="strong">Match all</emphasis> and <emphasis role="strong">Match any</emphasis>. <emphasis role="strong">Match all</emphasis>  provides results that match all the values, and <emphasis role="strong">Match any</emphasis> provides results that match any of the values entered. The default value is <emphasis role="strong">Match all</emphasis>.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Drops filter</emphasis>: You can view different levels of dropped packets with the following query options:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Fully dropped</emphasis> shows flow records with fully dropped packets.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Containing drops</emphasis> shows flow records that contain drops but can be sent.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Without drops</emphasis> shows records that contain sent packets.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">All</emphasis> shows all the aforementioned records.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara><emphasis role="strong">Limit</emphasis>: The data limit for internal backend queries. Depending upon the matching and the filter settings, the number of traffic flow data is displayed within the specified limit.</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>Quick filters</term>
<listitem>
<simpara>The default values in <emphasis role="strong">Quick filters</emphasis> drop-down menu are defined in the <literal>FlowCollector</literal> configuration. You can modify the options from console.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Advanced filters</term>
<listitem>
<simpara>You can set the advanced filters, <emphasis role="strong">Common</emphasis>, <emphasis role="strong">Source</emphasis>, or <emphasis role="strong">Destination</emphasis>, by selecting the parameter to be filtered from the dropdown list. The flow data is filtered based on the selection. To enable or disable the applied filter, you can click on the applied filter listed below the filter options.</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>You can toggle between <inlinemediaobject>
<imageobject>
<imagedata fileref="images/arrow-up-long-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>arrow up long solid</phrase></textobject>
</inlinemediaobject> <emphasis role="strong">One way</emphasis> and <inlinemediaobject>
<imageobject>
<imagedata fileref="images/arrow-up-long-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>arrow up long solid</phrase></textobject>
</inlinemediaobject> <inlinemediaobject>
<imageobject>
<imagedata fileref="images/arrow-down-long-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>arrow down long solid</phrase></textobject>
</inlinemediaobject> <emphasis role="strong">Back and forth</emphasis> filtering. The <inlinemediaobject>
<imageobject>
<imagedata fileref="images/arrow-up-long-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>arrow up long solid</phrase></textobject>
</inlinemediaobject> <emphasis role="strong">One way</emphasis> filter shows only <emphasis role="strong">Source</emphasis> and <emphasis role="strong">Destination</emphasis> traffic according to your filter selections. You can use <emphasis role="strong">Swap</emphasis> to change the directional view of the <emphasis role="strong">Source</emphasis> and <emphasis role="strong">Destination</emphasis> traffic. The <inlinemediaobject>
<imageobject>
<imagedata fileref="images/arrow-up-long-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>arrow up long solid</phrase></textobject>
</inlinemediaobject> <inlinemediaobject>
<imageobject>
<imagedata fileref="images/arrow-down-long-solid.png" contentwidth="10"/>
</imageobject>
<textobject><phrase>arrow down long solid</phrase></textobject>
</inlinemediaobject> <emphasis role="strong">Back and forth</emphasis> filter includes return traffic with the <emphasis role="strong">Source</emphasis> and <emphasis role="strong">Destination</emphasis> filters. The directional flow of network traffic is shown in the <emphasis role="strong">Direction</emphasis> column in the Traffic flows table as <literal>Ingress`or `Egress</literal> for inter-node traffic and `Inner`for traffic inside a single node.</simpara>
<simpara>You can click <emphasis role="strong">Reset defaults</emphasis> to remove the existing filters, and apply the filter defined in <literal>FlowCollector</literal> configuration.</simpara>
<note>
<simpara>To understand the rules of specifying the text value, click <emphasis role="strong">Learn More</emphasis>.</simpara>
</note>
<simpara>Alternatively, you can access the traffic flow data in the <emphasis role="strong">Network Traffic</emphasis> tab of the <emphasis role="strong">Namespaces</emphasis>, <emphasis role="strong">Services</emphasis>, <emphasis role="strong">Routes</emphasis>, <emphasis role="strong">Nodes</emphasis>, and <emphasis role="strong">Workloads</emphasis> pages which provide the filtered data of the corresponding aggregations.</simpara>
<formalpara role="_additional-resources">
<title>Additional resources</title>
<para>For more information about configuring quick filters in the <literal>FlowCollector</literal>, see <link linkend="network-observability-config-quick-filters_network_observability">Configuring Quick Filters</link> and the <link linkend="network-observability-flowcollector-view_network_observability">Flow Collector sample resource</link>.</para>
</formalpara>
</section>
</chapter>
<chapter xml:id="network-observability-operator-monitoring">
<title>Monitoring the Network Observability Operator</title>
<simpara>You can use the web console to monitor alerts related to the health of the Network Observability Operator.</simpara>
<section xml:id="network-observability-alert-dashboard_network_observability">
<title>Viewing health information</title>
<simpara>You can access metrics about health and resource usage of the Network Observability Operator from the <emphasis role="strong">Dashboards</emphasis> page in the web console. A health alert banner that directs you to the dashboard can appear on the <emphasis role="strong">Network Traffic</emphasis> and <emphasis role="strong">Home</emphasis> pages in the event that an alert is triggered. Alerts are generated in the following cases:</simpara>
<itemizedlist>
<listitem>
<simpara>The <literal>NetObservLokiError</literal> alert occurs if the <literal>flowlogs-pipeline</literal> workload is dropping flows because of Loki errors, such as if the Loki ingestion rate limit has been reached.</simpara>
</listitem>
<listitem>
<simpara>The <literal>NetObservNoFlows</literal> alert occurs if no flows are ingested for a certain amount of time.</simpara>
</listitem>
</itemizedlist>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have the Network Observability Operator installed.</simpara>
</listitem>
<listitem>
<simpara>You have access to the cluster as a user with the <literal>cluster-admin</literal> role or with view permissions for all projects.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>From the <emphasis role="strong">Administrator</emphasis> perspective in the web console, navigate to <emphasis role="strong">Observe</emphasis> → <emphasis role="strong">Dashboards</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>From the <emphasis role="strong">Dashboards</emphasis> dropdown, select <emphasis role="strong">Netobserv/Health</emphasis>.
Metrics about the health of the Operator are displayed on the page.</simpara>
</listitem>
</orderedlist>
<section xml:id="network-observability-disable-alerts_network_observability">
<title>Disabling health alerts</title>
<simpara>You can opt out of health alerting by editing the <literal>FlowCollector</literal> resource:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>In the web console, navigate to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Under the <emphasis role="strong">Provided APIs</emphasis> heading for the <emphasis role="strong">NetObserv Operator</emphasis>, select <emphasis role="strong">Flow Collector</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">cluster</emphasis> then select the <emphasis role="strong">YAML</emphasis> tab.</simpara>
</listitem>
<listitem>
<simpara>Add <literal>spec.processor.metrics.disableAlerts</literal> to disable health alerts, as in the following YAML sample:</simpara>
</listitem>
</orderedlist>
<screen>apiVersion: flows.netobserv.io/v1alpha1
kind: FlowCollector
metadata:
  name: cluster
spec:
  processor:
    metrics:
      disableAlerts: [NetObservLokiError, NetObservNoFlows] <co xml:id="CO13-1"/></screen>
<calloutlist>
<callout arearefs="CO13-1">
<para>You can specify one or a list with both types of alerts to disable.</para>
</callout>
</calloutlist>
</section>
</section>
<section xml:id="network-observability-netobserv-dashboard-rate-limit-alerts_network_observability">
<title>Creating Loki rate limit alerts for the NetObserv dashboard</title>
<simpara>You can create custom rules for the <emphasis role="strong">Netobserv</emphasis> dashboard metrics to trigger alerts when Loki rate limits have been reached.</simpara>
<simpara>An example of an alerting rule configuration YAML file is as follows:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: loki-alerts
  namespace: openshift-operators-redhat
spec:
  groups:
  - name: LokiRateLimitAlerts
    rules:
    - alert: LokiTenantRateLimit
      annotations:
        message: |-
          {{ $labels.job }} {{ $labels.route }} is experiencing 429 errors.
        summary: "At any number of requests are responded with the rate limit error code."
      expr: sum(irate(loki_request_duration_seconds_count{status_code="429"}[1m])) by (job, namespace, route) / sum(irate(loki_request_duration_seconds_count[1m])) by (job, namespace, route) * 100 &gt; 0
      for: 10s
      labels:
        severity: warning</programlisting>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara>For more information about creating alerts that you can see on the dashboard, see <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/monitoring/#creating-alerting-rules-for-user-defined-projects_managing-alerts">Creating alerting rules for user-defined projects</link>.</simpara>
</listitem>
</itemizedlist>
</section>
</chapter>
<chapter xml:id="flowcollector-api">
<title>FlowCollector configuration parameters</title>
<simpara>FlowCollector is the Schema for the network flows collection API, which pilots and configures the underlying deployments.</simpara>
<section xml:id="network-observability-flowcollector-api-specifications_network_observability">
<title>FlowCollector API specifications</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>FlowCollector</literal> is the schema for the network flows collection API, which pilots and configures the underlying deployments.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>apiVersion</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and might reject unrecognized values. More info: <link xlink:href="https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources">https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources</link></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>kind</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Kind is a string value representing the REST resource this object represents. Servers might infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: <link xlink:href="https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds">https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds</link></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>metadata</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Standard object&#8217;s metadata. More info: <link xlink:href="https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata">https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata</link></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>spec</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Defines the desired state of the FlowCollector resource. <?asciidoc-br?>
<?asciidoc-br?>
 *: the mention of "unsupported", or "deprecated" for a feature throughout this document means that this feature is not officially supported by Red Hat. It might have been, for example, contributed by the community and accepted without a formal agreement for maintenance. The product maintainers might provide some support for these features as a best effort only.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<section xml:id="_-metadata">
<title>.metadata</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>Standard object&#8217;s metadata. More info: <link xlink:href="https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata">https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata</link></simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section xml:id="_-spec">
<title>.spec</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>Defines the desired state of the FlowCollector resource. <?asciidoc-br?>
<?asciidoc-br?>
 *: the mention of "unsupported", or "deprecated" for a feature throughout this document means that this feature is not officially supported by Red Hat. It might have been, for example, contributed by the community and accepted without a formal agreement for maintenance. The product maintainers might provide some support for these features as a best effort only.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>agent</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Agent configuration for flows extraction.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>consolePlugin</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>consolePlugin</literal> defines the settings related to the OpenShift Container Platform Console plugin, when available.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>deploymentModel</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>deploymentModel</literal> defines the desired type of deployment for flow processing. Possible values are:<?asciidoc-br?>
 - <literal>DIRECT</literal> (default) to make the flow processor listening directly from the agents.<?asciidoc-br?>
 - <literal>KAFKA</literal> to make flows sent to a Kafka pipeline before consumption by the processor.<?asciidoc-br?>
 Kafka can provide better scalability, resiliency, and high availability (for more details, see <link xlink:href="https://www.redhat.com/en/topics/integration/what-is-apache-kafka">https://www.redhat.com/en/topics/integration/what-is-apache-kafka</link>).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>exporters</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>array</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>exporters</literal> define additional optional exporters for custom consumption or storage.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>kafka</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Kafka configuration, allowing to use Kafka as a broker as part of the flow collection pipeline. Available when the <literal>spec.deploymentModel</literal> is <literal>KAFKA</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>loki</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Loki, the flow store, client settings.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Namespace where Network Observability pods are deployed.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>processor</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>processor</literal> defines the settings of the component that receives the flows from the agent, enriches them, generates metrics, and forwards them to the Loki persistence layer and/or any available exporter.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-agent">
<title>.spec.agent</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>Agent configuration for flows extraction.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>ebpf</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>ebpf</literal> describes the settings related to the eBPF-based flow reporter when <literal>spec.agent.type</literal> is set to <literal>EBPF</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ipfix</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>ipfix</literal> [deprecated (*)] - describes the settings related to the IPFIX-based flow reporter when <literal>spec.agent.type</literal> is set to <literal>IPFIX</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>type</literal> selects the flows tracing agent. Possible values are:<?asciidoc-br?>
 - <literal>EBPF</literal> (default) to use Network Observability eBPF agent.<?asciidoc-br?>
 - <literal>IPFIX</literal> [deprecated (*)] - to use the legacy IPFIX collector.<?asciidoc-br?>
 <literal>EBPF</literal> is recommended as it offers better performances and should work regardless of the CNI installed on the cluster. <literal>IPFIX</literal> works with OVN-Kubernetes CNI (other CNIs could work if they support exporting IPFIX, but they would require manual configuration).</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-agent-ebpf">
<title>.spec.agent.ebpf</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>ebpf</literal> describes the settings related to the eBPF-based flow reporter when <literal>spec.agent.type</literal> is set to <literal>EBPF</literal>.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>cacheActiveTimeout</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>cacheActiveTimeout</literal> is the max period during which the reporter aggregates flows before sending. Increasing <literal>cacheMaxFlows</literal> and <literal>cacheActiveTimeout</literal> can decrease the network traffic overhead and the CPU load, however you can expect higher memory consumption and an increased latency in the flow collection.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>cacheMaxFlows</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>cacheMaxFlows</literal> is the max number of flows in an aggregate; when reached, the reporter sends the flows. Increasing <literal>cacheMaxFlows</literal> and <literal>cacheActiveTimeout</literal> can decrease the network traffic overhead and the CPU load, however you can expect higher memory consumption and an increased latency in the flow collection.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>debug</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>debug</literal> allows setting some aspects of the internal configuration of the eBPF agent. This section is aimed exclusively for debugging and fine-grained performance optimizations, such as GOGC and GOMAXPROCS env vars. Users setting its values do it at their own risk.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>excludeInterfaces</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>array (string)</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>excludeInterfaces</literal> contains the interface names that are excluded from flow tracing. An entry is enclosed by slashes, such as <literal>/br-/</literal> and is matched as a regular expression. Otherwise it is matched as a case-sensitive string.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>features</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>array (string)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>List of additional features to enable. They are all disabled by default. Enabling additional features might have performance impacts. Possible values are:<?asciidoc-br?>
 - <literal>PacketDrop</literal>: enable the packets drop flows logging feature. This feature requires mounting the kernel debug filesystem, so the eBPF pod has to run as privileged. If the <literal>spec.agent.eBPF.privileged</literal> parameter is not set, an error is reported.<?asciidoc-br?>
 - <literal>DNSTracking</literal>: enable the DNS tracking feature. This feature requires mounting the kernel debug filesystem hence the eBPF pod has to run as privileged. If the <literal>spec.agent.eBPF.privileged</literal> parameter is not set, an error is reported.<?asciidoc-br?>
 - <literal>FlowRTT</literal> [unsupported (*)]: enable flow latency (RTT) calculations in the eBPF agent during TCP handshakes. This feature better works with <literal>sampling</literal> set to 1.<?asciidoc-br?></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>imagePullPolicy</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>imagePullPolicy</literal> is the Kubernetes pull policy for the image defined above</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>interfaces</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>array (string)</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>interfaces</literal> contains the interface names from where flows are collected. If empty, the agent fetches all the interfaces in the system, excepting the ones listed in ExcludeInterfaces. An entry is enclosed by slashes, such as <literal>/br-/</literal>, is matched as a regular expression. Otherwise it is matched as a case-sensitive string.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>kafkaBatchSize</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>kafkaBatchSize</literal> limits the maximum size of a request in bytes before being sent to a partition. Ignored when not using Kafka. Default: 10MB.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>logLevel</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>logLevel</literal> defines the log level for the Network Observability eBPF Agent</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>privileged</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Privileged mode for the eBPF Agent container. In general this setting can be ignored or set to false: in that case, the operator sets granular capabilities (BPF, PERFMON, NET_ADMIN, SYS_RESOURCE) to the container, to enable its correct operation. If for some reason these capabilities cannot be set, such as if an old kernel version not knowing CAP_BPF is in use, then you can turn on this mode for more global privileges.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>resources</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>resources</literal> are the compute resources required by this container. More info: <link xlink:href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/">https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</link></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>sampling</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Sampling rate of the flow reporter. 100 means one flow on 100 is sent. 0 or 1 means all flows are sampled.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-agent-ebpf-debug">
<title>.spec.agent.ebpf.debug</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>debug</literal> allows setting some aspects of the internal configuration of the eBPF agent. This section is aimed exclusively for debugging and fine-grained performance optimizations, such as GOGC and GOMAXPROCS env vars. Users setting its values do it at their own risk.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>env</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object (string)</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>env</literal> allows passing custom environment variables to underlying components. Useful for passing some very concrete performance-tuning options, such as GOGC and GOMAXPROCS, that should not be publicly exposed as part of the FlowCollector descriptor, as they are only useful in edge debug or support scenarios.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-agent-ebpf-resources">
<title>.spec.agent.ebpf.resources</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>resources</literal> are the compute resources required by this container. More info: <link xlink:href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/">https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</link></simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>limits</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer-or-string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Limits describes the maximum amount of compute resources allowed. More info: <link xlink:href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/">https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</link></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>requests</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer-or-string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: <link xlink:href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/">https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</link></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-agent-ipfix">
<title>.spec.agent.ipfix</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>ipfix</literal> [deprecated (*)] - describes the settings related to the IPFIX-based flow reporter when <literal>spec.agent.type</literal> is set to <literal>IPFIX</literal>.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>cacheActiveTimeout</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>cacheActiveTimeout</literal> is the max period during which the reporter aggregates flows before sending.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>cacheMaxFlows</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>cacheMaxFlows</literal> is the max number of flows in an aggregate; when reached, the reporter sends the flows.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>clusterNetworkOperator</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>clusterNetworkOperator</literal> defines the settings related to the OpenShift Container Platform Cluster Network Operator, when available.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>forceSampleAll</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>forceSampleAll</literal> allows disabling sampling in the IPFIX-based flow reporter. It is not recommended to sample all the traffic with IPFIX, as it might generate cluster instability. If you REALLY want to do that, set this flag to true. Use at your own risk. When it is set to true, the value of <literal>sampling</literal> is ignored.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ovnKubernetes</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>ovnKubernetes</literal> defines the settings of the OVN-Kubernetes CNI, when available. This configuration is used when using OVN&#8217;s IPFIX exports, without OpenShift Container Platform. When using OpenShift Container Platform, refer to the <literal>clusterNetworkOperator</literal> property instead.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>sampling</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>sampling</literal> is the sampling rate on the reporter. 100 means one flow on 100 is sent. To ensure cluster stability, it is not possible to set a value below 2. If you really want to sample every packet, which might impact the cluster stability, refer to <literal>forceSampleAll</literal>. Alternatively, you can use the eBPF Agent instead of IPFIX.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-agent-ipfix-clusternetworkoperator">
<title>.spec.agent.ipfix.clusterNetworkOperator</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>clusterNetworkOperator</literal> defines the settings related to the OpenShift Container Platform Cluster Network Operator, when available.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Namespace  where the config map is going to be deployed.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-agent-ipfix-ovnkubernetes">
<title>.spec.agent.ipfix.ovnKubernetes</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>ovnKubernetes</literal> defines the settings of the OVN-Kubernetes CNI, when available. This configuration is used when using OVN&#8217;s IPFIX exports, without OpenShift Container Platform. When using OpenShift Container Platform, refer to the <literal>clusterNetworkOperator</literal> property instead.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>containerName</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>containerName</literal> defines the name of the container to configure for IPFIX.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>daemonSetName</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>daemonSetName</literal> defines the name of the DaemonSet controlling the OVN-Kubernetes pods.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Namespace where OVN-Kubernetes pods are deployed.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-consoleplugin">
<title>.spec.consolePlugin</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>consolePlugin</literal> defines the settings related to the OpenShift Container Platform Console plugin, when available.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>autoscaler</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>autoscaler</literal> spec of a horizontal pod autoscaler to set up for the plugin Deployment. Refer to HorizontalPodAutoscaler documentation (autoscaling/v2).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>enable</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara>enable the console plugin deployment. spec.Loki.enable must also be true</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>imagePullPolicy</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>imagePullPolicy</literal> is the Kubernetes pull policy for the image defined above</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>logLevel</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>logLevel</literal> for the console plugin backend</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>port</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>port</literal> is the plugin service port. Do not use 9002, which is reserved for metrics.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>portNaming</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>portNaming</literal> defines the configuration of the port-to-service name translation</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>quickFilters</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>array</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>quickFilters</literal> configures quick filter presets for the Console plugin</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>register</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>register</literal> allows, when set to true, to automatically register the provided console plugin with the OpenShift Container Platform Console operator. When set to false, you can still register it manually by editing console.operator.openshift.io/cluster with the following command: <literal>oc patch console.operator.openshift.io cluster --type='json' -p '[{"op": "add", "path": "/spec/plugins/-", "value": "netobserv-plugin"}]'</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>replicas</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>replicas</literal> defines the number of replicas (pods) to start.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>resources</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>resources</literal>, in terms of compute resources, required by this container. More info: <link xlink:href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/">https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</link></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-consoleplugin-autoscaler">
<title>.spec.consolePlugin.autoscaler</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>autoscaler</literal> spec of a horizontal pod autoscaler to set up for the plugin Deployment. Refer to HorizontalPodAutoscaler documentation (autoscaling/v2).</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section xml:id="_-spec-consoleplugin-portnaming">
<title>.spec.consolePlugin.portNaming</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>portNaming</literal> defines the configuration of the port-to-service name translation</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>enable</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Enable the console plugin port-to-service name translation</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>portNames</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object (string)</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>portNames</literal> defines additional port names to use in the console, for example, <literal>portNames: {"3100": "loki"}</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-consoleplugin-quickfilters">
<title>.spec.consolePlugin.quickFilters</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>quickFilters</literal> configures quick filter presets for the Console plugin</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>array</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section xml:id="_-spec-consoleplugin-quickfilters-2">
<title>.spec.consolePlugin.quickFilters[]</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>QuickFilter</literal> defines preset configuration for Console&#8217;s quick filters</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Required</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>filter</literal></simpara>
</listitem>
<listitem>
<simpara><literal>name</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>default</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>default</literal> defines whether this filter should be active by default or not</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>filter</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object (string)</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>filter</literal> is a set of keys and values to be set when this filter is selected. Each key can relate to a list of values using a coma-separated string, for example, <literal>filter: {"src_namespace": "namespace1,namespace2"}</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Name of the filter, that is displayed in the Console</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-consoleplugin-resources">
<title>.spec.consolePlugin.resources</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>resources</literal>, in terms of compute resources, required by this container. More info: <link xlink:href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/">https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</link></simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>limits</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer-or-string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Limits describes the maximum amount of compute resources allowed. More info: <link xlink:href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/">https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</link></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>requests</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer-or-string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: <link xlink:href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/">https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</link></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-exporters">
<title>.spec.exporters</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>exporters</literal> define additional optional exporters for custom consumption or storage.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>array</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section xml:id="_-spec-exporters-2">
<title>.spec.exporters[]</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>FlowCollectorExporter</literal> defines an additional exporter to send enriched flows to.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Required</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>type</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>ipfix</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>IPFIX configuration, such as the IP address and port to send enriched IPFIX flows to.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>kafka</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Kafka configuration, such as the address and topic, to send enriched flows to.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>type</literal> selects the type of exporters. The available options are <literal>KAFKA</literal> and <literal>IPFIX</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-exporters-ipfix">
<title>.spec.exporters[].ipfix</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>IPFIX configuration, such as the IP address and port to send enriched IPFIX flows to.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Required</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>targetHost</literal></simpara>
</listitem>
<listitem>
<simpara><literal>targetPort</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>targetHost</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Address of the IPFIX external receiver</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>targetPort</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Port for the IPFIX external receiver</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>transport</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Transport protocol (<literal>TCP</literal> or <literal>UDP</literal>) to be used for the IPFIX connection, defaults to <literal>TCP</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-exporters-kafka">
<title>.spec.exporters[].kafka</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>Kafka configuration, such as the address and topic, to send enriched flows to.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Required</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>address</literal></simpara>
</listitem>
<listitem>
<simpara><literal>topic</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>address</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Address of the Kafka server</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>sasl</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>SASL authentication configuration. [Unsupported (*)].</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>tls</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>TLS client configuration. When using TLS, verify that the address matches the Kafka port used for TLS, generally 9093.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>topic</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Kafka topic to use. It must exist. Network Observability does not create it.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-exporters-kafka-sasl">
<title>.spec.exporters[].kafka.sasl</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>SASL authentication configuration. [Unsupported (*)].</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>clientIDReference</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Reference to the secret or config map containing the client ID</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>clientSecretReference</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Reference to the secret or config map containing the client secret</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Type of SASL authentication to use, or <literal>DISABLED</literal> if SASL is not used</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-exporters-kafka-sasl-clientidreference">
<title>.spec.exporters[].kafka.sasl.clientIDReference</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>Reference to the secret or config map containing the client ID</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>file</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>File name within the config map or secret</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Name of the config map or secret containing the file</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Namespace of the config map or secret containing the file. If omitted, the default is to use the same namespace as where Network Observability is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Type for the file reference: "configmap" or "secret"</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-exporters-kafka-sasl-clientsecretreference">
<title>.spec.exporters[].kafka.sasl.clientSecretReference</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>Reference to the secret or config map containing the client secret</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>file</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>File name within the config map or secret</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Name of the config map or secret containing the file</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Namespace of the config map or secret containing the file. If omitted, the default is to use the same namespace as where Network Observability is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Type for the file reference: "configmap" or "secret"</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-exporters-kafka-tls">
<title>.spec.exporters[].kafka.tls</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>TLS client configuration. When using TLS, verify that the address matches the Kafka port used for TLS, generally 9093.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>caCert</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>caCert</literal> defines the reference of the certificate for the Certificate Authority</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>enable</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Enable TLS</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>insecureSkipVerify</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>insecureSkipVerify</literal> allows skipping client-side verification of the server certificate. If set to true, the <literal>caCert</literal> field is ignored.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>userCert</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>userCert</literal> defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-exporters-kafka-tls-cacert">
<title>.spec.exporters[].kafka.tls.caCert</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>caCert</literal> defines the reference of the certificate for the Certificate Authority</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>certFile</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certFile</literal> defines the path to the certificate file name within the config map or secret</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>certKey</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certKey</literal> defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Name of the config map or secret containing certificates</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where Network Observability is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Type for the certificate reference: <literal>configmap</literal> or <literal>secret</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-exporters-kafka-tls-usercert">
<title>.spec.exporters[].kafka.tls.userCert</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>userCert</literal> defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>certFile</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certFile</literal> defines the path to the certificate file name within the config map or secret</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>certKey</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certKey</literal> defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Name of the config map or secret containing certificates</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where Network Observability is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Type for the certificate reference: <literal>configmap</literal> or <literal>secret</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-kafka">
<title>.spec.kafka</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>Kafka configuration, allowing to use Kafka as a broker as part of the flow collection pipeline. Available when the <literal>spec.deploymentModel</literal> is <literal>KAFKA</literal>.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Required</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>address</literal></simpara>
</listitem>
<listitem>
<simpara><literal>topic</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>address</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Address of the Kafka server</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>sasl</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>SASL authentication configuration. [Unsupported (*)].</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>tls</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>TLS client configuration. When using TLS, verify that the address matches the Kafka port used for TLS, generally 9093.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>topic</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Kafka topic to use. It must exist, Network Observability does not create it.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-kafka-sasl">
<title>.spec.kafka.sasl</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>SASL authentication configuration. [Unsupported (*)].</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>clientIDReference</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Reference to the secret or config map containing the client ID</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>clientSecretReference</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Reference to the secret or config map containing the client secret</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Type of SASL authentication to use, or <literal>DISABLED</literal> if SASL is not used</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-kafka-sasl-clientidreference">
<title>.spec.kafka.sasl.clientIDReference</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>Reference to the secret or config map containing the client ID</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>file</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>File name within the config map or secret</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Name of the config map or secret containing the file</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Namespace of the config map or secret containing the file. If omitted, the default is to use the same namespace as where Network Observability is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Type for the file reference: "configmap" or "secret"</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-kafka-sasl-clientsecretreference">
<title>.spec.kafka.sasl.clientSecretReference</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>Reference to the secret or config map containing the client secret</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>file</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>File name within the config map or secret</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Name of the config map or secret containing the file</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Namespace of the config map or secret containing the file. If omitted, the default is to use the same namespace as where Network Observability is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Type for the file reference: "configmap" or "secret"</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-kafka-tls">
<title>.spec.kafka.tls</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>TLS client configuration. When using TLS, verify that the address matches the Kafka port used for TLS, generally 9093.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>caCert</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>caCert</literal> defines the reference of the certificate for the Certificate Authority</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>enable</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Enable TLS</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>insecureSkipVerify</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>insecureSkipVerify</literal> allows skipping client-side verification of the server certificate. If set to true, the <literal>caCert</literal> field is ignored.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>userCert</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>userCert</literal> defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-kafka-tls-cacert">
<title>.spec.kafka.tls.caCert</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>caCert</literal> defines the reference of the certificate for the Certificate Authority</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>certFile</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certFile</literal> defines the path to the certificate file name within the config map or secret</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>certKey</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certKey</literal> defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Name of the config map or secret containing certificates</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where Network Observability is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Type for the certificate reference: <literal>configmap</literal> or <literal>secret</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-kafka-tls-usercert">
<title>.spec.kafka.tls.userCert</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>userCert</literal> defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>certFile</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certFile</literal> defines the path to the certificate file name within the config map or secret</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>certKey</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certKey</literal> defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Name of the config map or secret containing certificates</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where Network Observability is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Type for the certificate reference: <literal>configmap</literal> or <literal>secret</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-loki">
<title>.spec.loki</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>Loki, the flow store, client settings.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>authToken</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>authToken</literal> describes the way to get a token to authenticate to Loki.<?asciidoc-br?>
 - <literal>DISABLED</literal> does not send any token with the request.<?asciidoc-br?>
 - <literal>FORWARD</literal> forwards the user token for authorization.<?asciidoc-br?>
 - <literal>HOST</literal> [deprecated (*)] - uses the local pod service account to authenticate to Loki.<?asciidoc-br?>
 When using the Loki Operator, this must be set to <literal>FORWARD</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>batchSize</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>batchSize</literal> is the maximum batch size (in bytes) of logs to accumulate before sending.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>batchWait</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>batchWait</literal> is the maximum time to wait before sending a batch.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>enable</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Set to <literal>enable</literal> to store flows to Loki. It is required for the OpenShift Container Platform Console plugin installation.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>maxBackoff</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>maxBackoff</literal> is the maximum backoff time for client connection between retries.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>maxRetries</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>maxRetries</literal> is the maximum number of retries for client connections.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>minBackoff</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>minBackoff</literal> is the initial backoff time for client connection between retries.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>querierUrl</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>querierURL</literal> specifies the address of the Loki querier service, in case it is different from the Loki ingester URL. If empty, the URL value is used (assuming that the Loki ingester and querier are in the same server). When using the Loki Operator, do not set it, since ingestion and queries use the Loki gateway.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>staticLabels</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object (string)</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>staticLabels</literal> is a map of common labels to set on each flow.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>statusTls</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>TLS client configuration for Loki status URL.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>statusUrl</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>statusURL</literal> specifies the address of the Loki <literal>/ready</literal>, <literal>/metrics</literal> and <literal>/config</literal> endpoints, in case it is different from the Loki querier URL. If empty, the <literal>querierURL</literal> value is used. This is useful to show error messages and some context in the frontend. When using the Loki Operator, set it to the Loki HTTP query frontend service, for example <link xlink:href="https://loki-query-frontend-http.netobserv.svc:3100/">https://loki-query-frontend-http.netobserv.svc:3100/</link>. <literal>statusTLS</literal> configuration is used when <literal>statusUrl</literal> is set.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>tenantID</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>tenantID</literal> is the Loki <literal>X-Scope-OrgID</literal> that identifies the tenant for each request. When using the Loki Operator, set it to <literal>network</literal>, which corresponds to a special tenant mode.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>timeout</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>timeout</literal> is the maximum time connection / request limit. A timeout of zero means no timeout.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>tls</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>TLS client configuration for Loki URL.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>url</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>url</literal> is the address of an existing Loki service to push the flows to. When using the Loki Operator, set it to the Loki gateway service with the <literal>network</literal> tenant set in path, for example <link xlink:href="https://loki-gateway-http.netobserv.svc:8080/api/logs/v1/network">https://loki-gateway-http.netobserv.svc:8080/api/logs/v1/network</link>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-loki-statustls">
<title>.spec.loki.statusTls</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>TLS client configuration for Loki status URL.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>caCert</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>caCert</literal> defines the reference of the certificate for the Certificate Authority</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>enable</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Enable TLS</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>insecureSkipVerify</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>insecureSkipVerify</literal> allows skipping client-side verification of the server certificate. If set to true, the <literal>caCert</literal> field is ignored.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>userCert</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>userCert</literal> defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-loki-statustls-cacert">
<title>.spec.loki.statusTls.caCert</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>caCert</literal> defines the reference of the certificate for the Certificate Authority</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>certFile</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certFile</literal> defines the path to the certificate file name within the config map or secret</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>certKey</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certKey</literal> defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Name of the config map or secret containing certificates</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where Network Observability is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Type for the certificate reference: <literal>configmap</literal> or <literal>secret</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-loki-statustls-usercert">
<title>.spec.loki.statusTls.userCert</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>userCert</literal> defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>certFile</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certFile</literal> defines the path to the certificate file name within the config map or secret</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>certKey</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certKey</literal> defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Name of the config map or secret containing certificates</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where Network Observability is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Type for the certificate reference: <literal>configmap</literal> or <literal>secret</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-loki-tls">
<title>.spec.loki.tls</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>TLS client configuration for Loki URL.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>caCert</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>caCert</literal> defines the reference of the certificate for the Certificate Authority</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>enable</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Enable TLS</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>insecureSkipVerify</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>insecureSkipVerify</literal> allows skipping client-side verification of the server certificate. If set to true, the <literal>caCert</literal> field is ignored.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>userCert</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>userCert</literal> defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-loki-tls-cacert">
<title>.spec.loki.tls.caCert</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>caCert</literal> defines the reference of the certificate for the Certificate Authority</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>certFile</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certFile</literal> defines the path to the certificate file name within the config map or secret</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>certKey</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certKey</literal> defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Name of the config map or secret containing certificates</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where Network Observability is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Type for the certificate reference: <literal>configmap</literal> or <literal>secret</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-loki-tls-usercert">
<title>.spec.loki.tls.userCert</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>userCert</literal> defines the user certificate reference and is used for mTLS (you can ignore it when using one-way TLS)</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>certFile</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certFile</literal> defines the path to the certificate file name within the config map or secret</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>certKey</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certKey</literal> defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Name of the config map or secret containing certificates</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where Network Observability is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Type for the certificate reference: <literal>configmap</literal> or <literal>secret</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-processor">
<title>.spec.processor</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>processor</literal> defines the settings of the component that receives the flows from the agent, enriches them, generates metrics, and forwards them to the Loki persistence layer and/or any available exporter.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>clusterName</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>clusterName</literal> is the name of the cluster to appear in the flows data. This is useful in a multi-cluster context. When using OpenShift Container Platform, leave empty to make it automatically determined.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>conversationEndTimeout</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>conversationEndTimeout</literal> is the time to wait after a network flow is received, to consider the conversation ended. This delay is ignored when a FIN packet is collected for TCP flows (see <literal>conversationTerminatingTimeout</literal> instead).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>conversationHeartbeatInterval</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>conversationHeartbeatInterval</literal> is the time to wait between "tick" events of a conversation</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>conversationTerminatingTimeout</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>conversationTerminatingTimeout</literal> is the time to wait from detected FIN flag to end a conversation. Only relevant for TCP flows.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>debug</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>debug</literal> allows setting some aspects of the internal configuration of the flow processor. This section is aimed exclusively for debugging and fine-grained performance optimizations, such as GOGC and GOMAXPROCS env vars. Users setting its values do it at their own risk.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>dropUnusedFields</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>dropUnusedFields</literal> allows, when set to true, to drop fields that are known to be unused by OVS, to save storage space.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>enableKubeProbes</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>enableKubeProbes</literal> is a flag to enable or disable Kubernetes liveness and readiness probes</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>healthPort</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>healthPort</literal> is a collector HTTP port in the Pod that exposes the health check API</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>imagePullPolicy</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>imagePullPolicy</literal> is the Kubernetes pull policy for the image defined above</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>kafkaConsumerAutoscaler</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>kafkaConsumerAutoscaler</literal> is the spec of a horizontal pod autoscaler to set up for <literal>flowlogs-pipeline-transformer</literal>, which consumes Kafka messages. This setting is ignored when Kafka is disabled. Refer to HorizontalPodAutoscaler documentation (autoscaling/v2).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>kafkaConsumerBatchSize</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>kafkaConsumerBatchSize</literal> indicates to the broker the maximum batch size, in bytes, that the consumer accepts. Ignored when not using Kafka. Default: 10MB.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>kafkaConsumerQueueCapacity</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>kafkaConsumerQueueCapacity</literal> defines the capacity of the internal message queue used in the Kafka consumer client. Ignored when not using Kafka.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>kafkaConsumerReplicas</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>kafkaConsumerReplicas</literal> defines the number of replicas (pods) to start for <literal>flowlogs-pipeline-transformer</literal>, which consumes Kafka messages. This setting is ignored when Kafka is disabled.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>logLevel</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>logLevel</literal> of the processor runtime</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>logTypes</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>logTypes</literal> defines the desired record types to generate. Possible values are:<?asciidoc-br?>
 - <literal>FLOWS</literal> (default) to export regular network flows<?asciidoc-br?>
 - <literal>CONVERSATIONS</literal> to generate events for started conversations, ended conversations as well as periodic "tick" updates<?asciidoc-br?>
 - <literal>ENDED_CONVERSATIONS</literal> to generate only ended conversations events<?asciidoc-br?>
 - <literal>ALL</literal> to generate both network flows and all conversations events<?asciidoc-br?></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>metrics</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>Metrics</literal> define the processor configuration regarding metrics</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>port</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Port of the flow collector (host port). By convention, some values are forbidden. It must be greater than 1024 and different from 4500, 4789 and 6081.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>profilePort</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>profilePort</literal> allows setting up a Go pprof profiler listening to this port</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>resources</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>resources</literal> are the compute resources required by this container. More info: <link xlink:href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/">https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</link></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-processor-debug">
<title>.spec.processor.debug</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>debug</literal> allows setting some aspects of the internal configuration of the flow processor. This section is aimed exclusively for debugging and fine-grained performance optimizations, such as GOGC and GOMAXPROCS env vars. Users setting its values do it at their own risk.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>env</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object (string)</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>env</literal> allows passing custom environment variables to underlying components. Useful for passing some very concrete performance-tuning options, such as GOGC and GOMAXPROCS, that should not be publicly exposed as part of the FlowCollector descriptor, as they are only useful in edge debug or support scenarios.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-processor-kafkaconsumerautoscaler">
<title>.spec.processor.kafkaConsumerAutoscaler</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>kafkaConsumerAutoscaler</literal> is the spec of a horizontal pod autoscaler to set up for <literal>flowlogs-pipeline-transformer</literal>, which consumes Kafka messages. This setting is ignored when Kafka is disabled. Refer to HorizontalPodAutoscaler documentation (autoscaling/v2).</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section xml:id="_-spec-processor-metrics">
<title>.spec.processor.metrics</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>Metrics</literal> define the processor configuration regarding metrics</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>disableAlerts</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>array (string)</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>disableAlerts</literal> is a list of alerts that should be disabled. Possible values are:<?asciidoc-br?>
 <literal>NetObservNoFlows</literal>, which is triggered when no flows are being observed for a certain period.<?asciidoc-br?>
 <literal>NetObservLokiError</literal>, which is triggered when flows are being dropped due to Loki errors.<?asciidoc-br?></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ignoreTags</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>array (string)</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>ignoreTags</literal> is a list of tags to specify which metrics to ignore. Each metric is associated with a list of tags. More details in <link xlink:href="https://github.com/netobserv/network-observability-operator/tree/main/controllers/flowlogspipeline/metrics_definitions">https://github.com/netobserv/network-observability-operator/tree/main/controllers/flowlogspipeline/metrics_definitions</link> . Available tags are: <literal>egress</literal>, <literal>ingress</literal>, <literal>flows</literal>, <literal>bytes</literal>, <literal>packets</literal>, <literal>namespaces</literal>, <literal>nodes</literal>, <literal>workloads</literal>, <literal>nodes-flows</literal>, <literal>namespaces-flows</literal>, <literal>workloads-flows</literal>. Namespace-based metrics are covered by both <literal>workloads</literal> and <literal>namespaces</literal> tags, hence it is recommended to always ignore one of them (<literal>workloads</literal> offering a finer granularity).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>server</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Metrics server endpoint configuration for Prometheus scraper</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-processor-metrics-server">
<title>.spec.processor.metrics.server</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>Metrics server endpoint configuration for Prometheus scraper</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>port</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The prometheus HTTP port</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>tls</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>TLS configuration.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-processor-metrics-server-tls">
<title>.spec.processor.metrics.server.tls</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>TLS configuration.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>insecureSkipVerify</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>boolean</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>insecureSkipVerify</literal> allows skipping client-side verification of the provided certificate. If set to true, the <literal>providedCaFile</literal> field is ignored.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>provided</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>TLS configuration when <literal>type</literal> is set to <literal>PROVIDED</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>providedCaFile</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>object</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Reference to the CA file when <literal>type</literal> is set to <literal>PROVIDED</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Select the type of TLS configuration:<?asciidoc-br?>
 - <literal>DISABLED</literal> (default) to not configure TLS for the endpoint. - <literal>PROVIDED</literal> to manually provide cert file and a key file. - <literal>AUTO</literal> to use OpenShift Container Platform auto generated certificate using annotations.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-processor-metrics-server-tls-provided">
<title>.spec.processor.metrics.server.tls.provided</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>TLS configuration when <literal>type</literal> is set to <literal>PROVIDED</literal>.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>certFile</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certFile</literal> defines the path to the certificate file name within the config map or secret</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>certKey</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>certKey</literal> defines the path to the certificate private key file name within the config map or secret. Omit when the key is not necessary.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Name of the config map or secret containing certificates</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Namespace of the config map or secret containing certificates. If omitted, the default is to use the same namespace as where Network Observability is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Type for the certificate reference: <literal>configmap</literal> or <literal>secret</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-processor-metrics-server-tls-providedcafile">
<title>.spec.processor.metrics.server.tls.providedCaFile</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara>Reference to the CA file when <literal>type</literal> is set to <literal>PROVIDED</literal>.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>file</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>File name within the config map or secret</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Name of the config map or secret containing the file</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>namespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Namespace of the config map or secret containing the file. If omitted, the default is to use the same namespace as where Network Observability is deployed. If the namespace is different, the config map or the secret is copied so that it can be mounted as required.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Type for the file reference: "configmap" or "secret"</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_-spec-processor-resources">
<title>.spec.processor.resources</title>
<variablelist>
<varlistentry>
<term>Description</term>
<listitem>
<simpara><literal>resources</literal> are the compute resources required by this container. More info: <link xlink:href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/">https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</link></simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Type</term>
<listitem>
<simpara><literal>object</literal></simpara>
</listitem>
</varlistentry>
</variablelist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>limits</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer-or-string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Limits describes the maximum amount of compute resources allowed. More info: <link xlink:href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/">https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</link></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>requests</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>integer-or-string</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: <link xlink:href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/">https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</link></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</chapter>
<chapter xml:id="json-flows-format-reference">
<title>Network flows format reference</title>
<simpara>These are the specifications for network flows format, used both internally and when exporting flows to Kafka.</simpara>
<section xml:id="network-observability-flows-format_json_reference">
<title>Network Flows format reference</title>
<simpara>This is the specification of the network flows format, used both internally and when exporting flows to Kafka.</simpara>
<simpara>The document is organized in two main categories: <emphasis>Labels</emphasis> and regular <emphasis>Fields</emphasis>. This distinction only matters when querying Loki. This is because <emphasis>Labels</emphasis>, unlike <emphasis>Fields</emphasis>, must be used in <link xlink:href="https://grafana.com/docs/loki/latest/logql/log_queries/#log-stream-selector">stream selectors</link>.</simpara>
<simpara>If you are reading this specification as a reference for the Kafka export feature, you must treat all <emphasis>Labels</emphasis> and <emphasis>Fields</emphasis> as regular fields and ignore any distinctions between them that are specific to Loki.</simpara>
<section xml:id="_labels">
<title>Labels</title>
<variablelist>
<varlistentry>
<term>SrcK8S_Namespace</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">SrcK8S_Namespace</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Source namespace</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>DstK8S_Namespace</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">DstK8S_Namespace</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Destination namespace</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>SrcK8S_OwnerName</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">SrcK8S_OwnerName</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Source owner, such as Deployment, StatefulSet, etc.</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>DstK8S_OwnerName</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">DstK8S_OwnerName</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Destination owner, such as Deployment, StatefulSet, etc.</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>FlowDirection</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">FlowDirection</emphasis>: <literal>FlowDirection</literal> (see the following section, Enumeration: FlowDirection)</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Flow direction from the node observation point</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>_RecordType</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">_RecordType</emphasis>: <literal>RecordType</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Type of record: 'flowLog' for regular flow logs, or 'allConnections',
'newConnection', 'heartbeat', 'endConnection' for conversation tracking</simpara>
</section>
<section xml:id="_fields">
<title>Fields</title>
<variablelist>
<varlistentry>
<term>SrcAddr</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">SrcAddr</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Source IP address (ipv4 or ipv6)</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>DstAddr</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">DstAddr</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Destination IP address (ipv4 or ipv6)</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>SrcMac</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">SrcMac</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Source MAC address</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>DstMac</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">DstMac</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Destination MAC address</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>SrcK8S_Name</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">SrcK8S_Name</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Name of the source matched Kubernetes object, such as Pod name, Service name, etc.</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>DstK8S_Name</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">DstK8S_Name</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Name of the destination matched Kubernetes object, such as Pod name, Service name, etc.</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>SrcK8S_Type</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">SrcK8S_Type</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Kind of the source matched Kubernetes object, such as Pod, Service, etc.</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>DstK8S_Type</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">DstK8S_Type</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Kind of the destination matched Kubernetes object, such as Pod name, Service name, etc.</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>SrcPort</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">SrcPort</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Source port</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>DstPort</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">DstPort</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Destination port</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>SrcK8S_OwnerType</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">SrcK8S_OwnerType</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Kind of the source Kubernetes owner, such as Deployment, StatefulSet, etc.</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>DstK8S_OwnerType</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">DstK8S_OwnerType</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Kind of the destination Kubernetes owner, such as Deployment, StatefulSet, etc.</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>SrcK8S_HostIP</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">SrcK8S_HostIP</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Source node IP</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>DstK8S_HostIP</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">DstK8S_HostIP</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Destination node IP</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>SrcK8S_HostName</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">SrcK8S_HostName</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Source node name</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>DstK8S_HostName</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">DstK8S_HostName</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Destination node name</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>Proto</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Proto</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>L4 protocol</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>Interface</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">Interface</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Network interface</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>IfDirection</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">IfDirection</emphasis>: <literal>InterfaceDirection</literal> (see the following section, Enumeration: InterfaceDirection)</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Flow direction from the network interface observation point</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>Flags</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">Flags</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>TCP flags</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>Packets</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">Packets</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Number of packets</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>Packets_AB</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">Packets_AB</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>In conversation tracking, A to B packets counter per conversation</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>Packets_BA</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">Packets_BA</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>In conversation tracking, B to A packets counter per conversation</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>Bytes</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">Bytes</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Number of bytes</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>Bytes_AB</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">Bytes_AB</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>In conversation tracking, A to B bytes counter per conversation</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>Bytes_BA</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">Bytes_BA</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>In conversation tracking, B to A bytes counter per conversation</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>IcmpType</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">IcmpType</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>ICMP type</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>IcmpCode</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">IcmpCode</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>ICMP code</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>PktDropLatestState</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">PktDropLatestState</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Pkt TCP state for drops</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>PktDropLatestDropCause</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">PktDropLatestDropCause</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Pkt cause for drops</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>PktDropLatestFlags</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">PktDropLatestFlags</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Pkt TCP flags for drops</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>PktDropPackets</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">PktDropPackets</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Number of packets dropped by the kernel</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>PktDropPackets_AB</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">PktDropPackets_AB</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>In conversation tracking, A to B packets dropped counter per conversation</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>PktDropPackets_BA</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">PktDropPackets_BA</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>In conversation tracking, B to A packets dropped counter per conversation</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>PktDropBytes</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">PktDropBytes</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Number of bytes dropped by the kernel</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>PktDropBytes_AB</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">PktDropBytes_AB</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>In conversation tracking, A to B bytes dropped counter per conversation</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>PktDropBytes_BA</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">PktDropBytes_BA</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>In conversation tracking, B to A bytes dropped counter per conversation</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>DnsId</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">DnsId</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>DNS record id</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>DnsFlags</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">DnsFlags</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>DNS flags for DNS record</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>DnsFlagsResponseCode</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">DnsFlagsResponseCode</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Parsed DNS header RCODEs name</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>DnsLatencyMs</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">DnsLatencyMs</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Calculated time between response and request, in milliseconds</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>TimeFlowStartMs</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">TimeFlowStartMs</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Start timestamp of this flow, in milliseconds</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>TimeFlowEndMs</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">TimeFlowEndMs</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>End timestamp of this flow, in milliseconds</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>TimeReceived</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">TimeReceived</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Timestamp when this flow was received and processed by the flow collector, in seconds</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>TimeFlowRttNs</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">TimeFlowRttNs</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Flow Round Trip Time (RTT) in nanoseconds</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>_HashId</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">_HashId</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>In conversation tracking, the conversation identifier</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>_IsFirst</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">_IsFirst</emphasis>: <literal>string</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>In conversation tracking, a flag identifying the first flow</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>numFlowLogs</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>Optional</literal> <emphasis role="strong">numFlowLogs</emphasis>: <literal>number</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>In conversation tracking, a counter of flow logs per conversation</simpara>
</section>
<section xml:id="_enumeration-flowdirection">
<title>Enumeration: FlowDirection</title>
<variablelist>
<varlistentry>
<term>Ingress</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Ingress</emphasis> = <literal>"0"</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Incoming traffic, from the node observation point</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>Egress</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Egress</emphasis> = <literal>"1"</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Outgoing traffic, from the node observation point</simpara>
<simpara><?asciidoc-hr?></simpara>
<variablelist>
<varlistentry>
<term>Inner</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Inner</emphasis> = <literal>"2"</literal></simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Inner traffic, with the same source and destination node</simpara>
</section>
</section>
</chapter>
<chapter xml:id="installing-troubleshooting">
<title>Troubleshooting Network Observability</title>
<simpara>To assist in troubleshooting Network Observability issues, you can perform some troubleshooting actions.</simpara>
<section xml:id="network-observability-must-gather_network-observability-troubleshooting">
<title>Using the must-gather tool</title>
<simpara>You can use the must-gather tool to collect information about the Network Observability Operator resources and cluster-wide resources, such as pod logs, <literal>FlowCollector</literal>, and <literal>webhook</literal> configurations.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to the directory where you want to store the must-gather data.</simpara>
</listitem>
<listitem>
<simpara>Run the following command to collect cluster-wide must-gather resources:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm must-gather
 --image-stream=openshift/must-gather \
 --image=quay.io/netobserv/must-gather</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="configure-network-traffic-console_network-observability-troubleshooting">
<title>Configuring network traffic menu entry in the OpenShift Container Platform console</title>
<simpara>Manually configure the network traffic menu entry in the OpenShift Container Platform console when the network traffic menu entry is not listed in <emphasis role="strong">Observe</emphasis> menu in the OpenShift Container Platform console.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have installed OpenShift Container Platform version 4.10 or newer.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Check if the <literal>spec.consolePlugin.register</literal> field is set to <literal>true</literal> by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n netobserv get flowcollector cluster -o yaml</programlisting>
<formalpara>
<title>Example output</title>
<para>
<screen>apiVersion: flows.netobserv.io/v1alpha1
kind: FlowCollector
metadata:
  name: cluster
spec:
  consolePlugin:
    register: false</screen>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Optional: Add the <literal>netobserv-plugin</literal> plugin by manually editing the Console Operator config:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit console.operator.openshift.io cluster</programlisting>
<formalpara>
<title>Example output</title>
<para>
<screen>...
spec:
  plugins:
  - netobserv-plugin
...</screen>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Optional: Set the <literal>spec.consolePlugin.register</literal> field to <literal>true</literal> by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n netobserv edit flowcollector cluster -o yaml</programlisting>
<formalpara>
<title>Example output</title>
<para>
<screen>apiVersion: flows.netobserv.io/v1alpha1
kind: FlowCollector
metadata:
  name: cluster
spec:
  consolePlugin:
    register: true</screen>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Ensure the status of console pods is <literal>running</literal> by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods -n openshift-console -l app=console</programlisting>
</listitem>
<listitem>
<simpara>Restart the console pods by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc delete pods -n openshift-console -l app=console</programlisting>
</listitem>
<listitem>
<simpara>Clear your browser cache and history.</simpara>
</listitem>
<listitem>
<simpara>Check the status of Network Observability plugin pods by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods -n netobserv -l app=netobserv-plugin</programlisting>
<formalpara>
<title>Example output</title>
<para>
<screen>NAME                                READY   STATUS    RESTARTS   AGE
netobserv-plugin-68c7bbb9bb-b69q6   1/1     Running   0          21s</screen>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Check the logs of the Network Observability plugin pods by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc logs -n netobserv -l app=netobserv-plugin</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">time="2022-12-13T12:06:49Z" level=info msg="Starting netobserv-console-plugin [build version: , build date: 2022-10-21 15:15] at log level info" module=main
time="2022-12-13T12:06:49Z" level=info msg="listening on https://:9001" module=server</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</section>
<section xml:id="configure-network-traffic-flowlogs-pipeline-kafka_network-observability-troubleshooting">
<title>Flowlogs-Pipeline does not consume network flows after installing Kafka</title>
<simpara>If you deployed the flow collector first with <literal>deploymentModel: KAFKA</literal> and then deployed Kafka, the flow collector might not connect correctly to Kafka. Manually restart the flow-pipeline pods where Flowlogs-pipeline does not consume network flows from Kafka.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Delete the flow-pipeline pods to restart them by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc delete pods -n netobserv -l app=flowlogs-pipeline-transformer</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="configure-network-traffic-interfaces_network-observability-troubleshooting">
<title>Failing to see network flows from both <literal>br-int</literal> and <literal>br-ex</literal> interfaces</title>
<simpara>br-ex` and <literal>br-int</literal> are virtual bridge devices operated at OSI layer 2. The eBPF agent works at the IP and TCP levels, layers 3 and 4 respectively. You can expect that the eBPF agent captures the network traffic passing through <literal>br-ex</literal> and <literal>br-int</literal>, when the network traffic is processed by other interfaces such as physical host or virtual pod interfaces. If you restrict the eBPF agent network interfaces to attach only to <literal>br-ex</literal> and <literal>br-int</literal>, you do not see any network flow.</simpara>
<simpara>Manually remove the part in the <literal>interfaces</literal> or <literal>excludeInterfaces</literal> that restricts the network interfaces to <literal>br-int</literal> and <literal>br-ex</literal>.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Remove the <literal>interfaces: [ 'br-int', 'br-ex' ]</literal> field. This allows the agent to fetch information from all the interfaces. Alternatively, you can specify the Layer-3 interface for example, <literal>eth0</literal>. Run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit -n netobserv flowcollector.yaml -o yaml</programlisting>
<formalpara>
<title>Example output</title>
<para>
<screen>apiVersion: flows.netobserv.io/v1alpha1
kind: FlowCollector
metadata:
  name: cluster
spec:
  agent:
    type: EBPF
    ebpf:
      interfaces: [ 'br-int', 'br-ex' ] <co xml:id="CO14-1"/></screen>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO14-1">
<para>Specifies the network interfaces.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
</section>
<section xml:id="controller-manager-pod-runs-out-of-memory_network-observability-troubleshooting">
<title>Network Observability controller manager pod runs out of memory</title>
<simpara>You can increase memory limits for the Network Observability operator by editing the <literal>spec.config.resources.limits.memory</literal> specification in the <literal>Subscription</literal> object.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the web console, navigate to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis></simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Network Observability</emphasis> and then select <emphasis role="strong">Subscription</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>From the <emphasis role="strong">Actions</emphasis> menu, click <emphasis role="strong">Edit Subscription</emphasis>.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Alternatively, you can use the CLI to open the YAML configuration for the <literal>Subscription</literal> object by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit subscription netobserv-operator -n openshift-netobserv-operator</programlisting>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Edit the <literal>Subscription</literal> object to add the <literal>config.resources.limits.memory</literal> specification and set the value to account for your memory requirements. See the Additional resources for more information about resource considerations:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: netobserv-operator
  namespace: openshift-netobserv-operator
spec:
  channel: stable
  config:
    resources:
      limits:
        memory: 800Mi     <co xml:id="CO15-1"/>
      requests:
        cpu: 100m
        memory: 100Mi
  installPlanApproval: Automatic
  name: netobserv-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
  startingCSV: &lt;network_observability_operator_latest_version&gt; <co xml:id="CO15-2"/></programlisting>
<calloutlist>
<callout arearefs="CO15-1">
<para>For example, you can increase the memory limit to <literal>800Mi</literal>.</para>
</callout>
<callout arearefs="CO15-2">
<para>This value should not be edited, but note that it changes depending on the most current release of the Operator.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link linkend="network-observability-resources-table_network_observability">Resource considerations</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="network-observability-troubleshooting-loki-resource-exhausted_network-observability-troubleshooting">
<title>Troubleshooting Loki ResourceExhausted error</title>
<simpara>Loki may return a <literal>ResourceExhausted</literal> error when network flow data sent by Network Observability exceeds the configured maximum message size. If you are using the Red&#160;Hat Loki Operator, this maximum message size is configured to 100 MiB.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>, viewing <emphasis role="strong">All projects</emphasis> from the <emphasis role="strong">Project</emphasis> drop-down menu.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Provided APIs</emphasis> list, select the Network Observability Operator.</simpara>
</listitem>
<listitem>
<simpara>Click the <emphasis role="strong">Flow Collector</emphasis> then the <emphasis role="strong">YAML view</emphasis> tab.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>If you are using the Loki Operator, check that the <literal>spec.loki.batchSize</literal> value does not exceed 98 MiB.</simpara>
</listitem>
<listitem>
<simpara>If you are using a Loki installation method that is different from the Red&#160;Hat Loki Operator, such as Grafana Loki, verify that the <literal>grpc_server_max_recv_msg_size</literal> <link xlink:href="https://grafana.com/docs/loki/latest/configure/#server">Grafana Loki server setting</link> is higher than the <literal>FlowCollector</literal> resource <literal>spec.loki.batchSize</literal> value. If it is not, you must either increase the <literal>grpc_server_max_recv_msg_size</literal> value, or decrease the <literal>spec.loki.batchSize</literal> value so that it is lower than the limit.</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Save</emphasis> if you edited the <emphasis role="strong">FlowCollector</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="_resource-troubleshooting">
<title>Resource troubleshooting</title>

</section>
<section xml:id="network-observability-troubleshooting-loki-tenant-rate-limit_network-observability-troubleshooting">
<title>LokiStack rate limit errors</title>
<simpara>A rate-limit placed on the Loki tenant can result in potential temporary loss of data and a 429 error: <literal>Per stream rate limit exceeded (limit:xMB/sec) while attempting to ingest for stream</literal>. You might consider having an alert set to notify you of this error. For more information, see "Creating Loki rate limit alerts for the NetObserv dashboard" in the Additional resources of this section.</simpara>
<simpara>You can update the LokiStack CRD with the <literal>perStreamRateLimit</literal> and <literal>perStreamRateLimitBurst</literal> specifications, as shown in the following procedure.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>, viewing <emphasis role="strong">All projects</emphasis> from the <emphasis role="strong">Project</emphasis> dropdown.</simpara>
</listitem>
<listitem>
<simpara>Look for <emphasis role="strong">Loki Operator</emphasis>, and select the <emphasis role="strong">LokiStack</emphasis> tab.</simpara>
</listitem>
<listitem>
<simpara>Create or edit an existing <emphasis role="strong">LokiStack</emphasis> instance using the <emphasis role="strong">YAML view</emphasis> to add the <literal>perStreamRateLimit</literal> and <literal>perStreamRateLimitBurst</literal> specifications:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: loki
  namespace: netobserv
spec:
  limits:
    global:
      ingestion:
        perStreamRateLimit: 6        <co xml:id="CO16-1"/>
        perStreamRateLimitBurst: 30  <co xml:id="CO16-2"/>
  tenants:
    mode: openshift-network
  managementState: Managed</programlisting>
<calloutlist>
<callout arearefs="CO16-1">
<para>The default value for <literal>perStreamRateLimit</literal> is <literal>3</literal>.</para>
</callout>
<callout arearefs="CO16-2">
<para>The default value for <literal>perStreamRateLimitBurst</literal> is <literal>15</literal>.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Save</emphasis>.</simpara>
</listitem>
</orderedlist>
<formalpara>
<title>Verification</title>
<para>Once you update the <literal>perStreamRateLimit</literal> and <literal>perStreamRateLimitBurst</literal> specifications, the pods in your cluster restart and the 429 rate-limit error no longer occurs.</para>
</formalpara>
</section>
</chapter>
</book>
