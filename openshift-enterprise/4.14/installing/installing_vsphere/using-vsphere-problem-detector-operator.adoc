:_mod-docs-content-type: ASSEMBLY
[id="using-vsphere-problem-detector-operator"]
= Using the vSphere Problem Detector Operator
// The {product-title} attribute provides the context-sensitive name of the relevant OpenShift distribution, for example, "OpenShift Container Platform" or "OKD". The {product-version} attribute provides the product version relative to the distribution, for example "4.9".
// {product-title} and {product-version} are parsed when AsciiBinder queries the _distro_map.yml file in relation to the base branch of a pull request.
// See https://github.com/openshift/openshift-docs/blob/main/contributing_to_docs/doc_guidelines.adoc#product-name-and-version for more information on this topic.
// Other common attributes are defined in the following lines:
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:imagesdir: images
:prewrap!:
:op-system-first: Red Hat Enterprise Linux CoreOS (RHCOS)
:op-system: RHCOS
:op-system-lowercase: rhcos
:op-system-base: RHEL
:op-system-base-full: Red Hat Enterprise Linux (RHEL)
:op-system-version: 8.x
:tsb-name: Template Service Broker
:kebab: image:kebab.png[title="Options menu"]
:rh-openstack-first: Red Hat OpenStack Platform (RHOSP)
:rh-openstack: RHOSP
:ai-full: Assisted Installer
:ai-version: 2.3
:cluster-manager-first: Red Hat OpenShift Cluster Manager
:cluster-manager: OpenShift Cluster Manager
:cluster-manager-url: link:https://console.redhat.com/openshift[OpenShift Cluster Manager Hybrid Cloud Console]
:cluster-manager-url-pull: link:https://console.redhat.com/openshift/install/pull-secret[pull secret from the Red Hat OpenShift Cluster Manager]
:insights-advisor-url: link:https://console.redhat.com/openshift/insights/advisor/[Insights Advisor]
:hybrid-console: Red Hat Hybrid Cloud Console
:hybrid-console-second: Hybrid Cloud Console
:oadp-first: OpenShift API for Data Protection (OADP)
:oadp-full: OpenShift API for Data Protection
:oc-first: pass:quotes[OpenShift CLI (`oc`)]
:product-registry: OpenShift image registry
:rh-storage-first: Red Hat OpenShift Data Foundation
:rh-storage: OpenShift Data Foundation
:rh-rhacm-first: Red Hat Advanced Cluster Management (RHACM)
:rh-rhacm: RHACM
:rh-rhacm-version: 2.8
:sandboxed-containers-first: OpenShift sandboxed containers
:sandboxed-containers-operator: OpenShift sandboxed containers Operator
:sandboxed-containers-version: 1.3
:sandboxed-containers-version-z: 1.3.3
:sandboxed-containers-legacy-version: 1.3.2
:cert-manager-operator: cert-manager Operator for Red Hat OpenShift
:secondary-scheduler-operator-full: Secondary Scheduler Operator for Red Hat OpenShift
:secondary-scheduler-operator: Secondary Scheduler Operator
// Backup and restore
:velero-domain: velero.io
:velero-version: 1.11
:launch: image:app-launcher.png[title="Application Launcher"]
:mtc-short: MTC
:mtc-full: Migration Toolkit for Containers
:mtc-version: 1.8
:mtc-version-z: 1.8.0
// builds (Valid only in 4.11 and later)
:builds-v2title: Builds for Red Hat OpenShift
:builds-v2shortname: OpenShift Builds v2
:builds-v1shortname: OpenShift Builds v1
//gitops
:gitops-title: Red Hat OpenShift GitOps
:gitops-shortname: GitOps
:gitops-ver: 1.1
:rh-app-icon: image:red-hat-applications-menu-icon.jpg[title="Red Hat applications"]
//pipelines
:pipelines-title: Red Hat OpenShift Pipelines
:pipelines-shortname: OpenShift Pipelines
:pipelines-ver: pipelines-1.12
:pipelines-version-number: 1.12
:tekton-chains: Tekton Chains
:tekton-hub: Tekton Hub
:artifact-hub: Artifact Hub
:pac: Pipelines as Code
//odo
:odo-title: odo
//OpenShift Kubernetes Engine
:oke: OpenShift Kubernetes Engine
//OpenShift Platform Plus
:opp: OpenShift Platform Plus
//openshift virtualization (cnv)
:VirtProductName: OpenShift Virtualization
:VirtVersion: 4.14
:KubeVirtVersion: v0.59.0
:HCOVersion: 4.14.0
:CNVNamespace: openshift-cnv
:CNVOperatorDisplayName: OpenShift Virtualization Operator
:CNVSubscriptionSpecSource: redhat-operators
:CNVSubscriptionSpecName: kubevirt-hyperconverged
:delete: image:delete.png[title="Delete"]
//distributed tracing
:DTProductName: Red Hat OpenShift distributed tracing platform
:DTShortName: distributed tracing platform
:DTProductVersion: 2.9
:JaegerName: Red Hat OpenShift distributed tracing platform (Jaeger)
:JaegerShortName: distributed tracing platform (Jaeger)
:JaegerVersion: 1.47.0
:OTELName: Red Hat OpenShift distributed tracing data collection
:OTELShortName: distributed tracing data collection
:OTELOperator: Red Hat OpenShift distributed tracing data collection Operator
:OTELVersion: 0.81.0
:TempoName: Red Hat OpenShift distributed tracing platform (Tempo)
:TempoShortName: distributed tracing platform (Tempo)
:TempoOperator: Tempo Operator
:TempoVersion: 2.1.1
//logging
:logging-title: logging subsystem for Red Hat OpenShift
:logging-title-uc: Logging subsystem for Red Hat OpenShift
:logging: logging subsystem
:logging-uc: Logging subsystem
//serverless
:ServerlessProductName: OpenShift Serverless
:ServerlessProductShortName: Serverless
:ServerlessOperatorName: OpenShift Serverless Operator
:FunctionsProductName: OpenShift Serverless Functions
//service mesh v2
:product-dedicated: Red Hat OpenShift Dedicated
:product-rosa: Red Hat OpenShift Service on AWS
:SMProductName: Red Hat OpenShift Service Mesh
:SMProductShortName: Service Mesh
:SMProductVersion: 2.4.4
:MaistraVersion: 2.4
//Service Mesh v1
:SMProductVersion1x: 1.1.18.2
//Windows containers
:productwinc: Red Hat OpenShift support for Windows Containers
// Red Hat Quay Container Security Operator
:rhq-cso: Red Hat Quay Container Security Operator
// Red Hat Quay
:quay: Red Hat Quay
:sno: single-node OpenShift
:sno-caps: Single-node OpenShift
//TALO and Redfish events Operators
:cgu-operator-first: Topology Aware Lifecycle Manager (TALM)
:cgu-operator-full: Topology Aware Lifecycle Manager
:cgu-operator: TALM
:redfish-operator: Bare Metal Event Relay
//Formerly known as CodeReady Containers and CodeReady Workspaces
:openshift-local-productname: Red Hat OpenShift Local
:openshift-dev-spaces-productname: Red Hat OpenShift Dev Spaces
// Factory-precaching-cli tool
:factory-prestaging-tool: factory-precaching-cli tool
:factory-prestaging-tool-caps: Factory-precaching-cli tool
:openshift-networking: Red Hat OpenShift Networking
// TODO - this probably needs to be different for OKD
//ifdef::openshift-origin[]
//:openshift-networking: OKD Networking
//endif::[]
// logical volume manager storage
:lvms-first: Logical volume manager storage (LVM Storage)
:lvms: LVM Storage
//Operator SDK version
:osdk_ver: 1.31.0
//Operator SDK version that shipped with the previous OCP 4.x release
:osdk_ver_n1: 1.28.0
//Next-gen (OCP 4.14+) Operator Lifecycle Manager, aka "v1"
:olmv1: OLM 1.0
:olmv1-first: Operator Lifecycle Manager (OLM) 1.0
:ztp-first: GitOps Zero Touch Provisioning (ZTP)
:ztp: GitOps ZTP
:3no: three-node OpenShift
:3no-caps: Three-node OpenShift
:run-once-operator: Run Once Duration Override Operator
// Web terminal
:web-terminal-op: Web Terminal Operator
:devworkspace-op: DevWorkspace Operator
:secrets-store-driver: Secrets Store CSI driver
:secrets-store-operator: Secrets Store CSI Driver Operator
//AWS STS
:sts-first: Security Token Service (STS)
:sts-full: Security Token Service
:sts-short: STS
//Cloud provider names
//AWS
:aws-first: Amazon Web Services (AWS)
:aws-full: Amazon Web Services
:aws-short: AWS
//GCP
:gcp-first: Google Cloud Platform (GCP)
:gcp-full: Google Cloud Platform
:gcp-short: GCP
//alibaba cloud
:alibaba: Alibaba Cloud
// IBM Cloud VPC
:ibmcloudVPCProductName: IBM Cloud VPC
:ibmcloudVPCRegProductName: IBM(R) Cloud VPC
// IBM Cloud
:ibm-cloud-bm: IBM Cloud Bare Metal (Classic)
:ibm-cloud-bm-reg: IBM Cloud(R) Bare Metal (Classic)
// IBM Power
:ibmpowerProductName: IBM Power
:ibmpowerRegProductName: IBM(R) Power
// IBM zSystems
:ibmzProductName: IBM Z
:ibmzRegProductName: IBM(R) Z
:linuxoneProductName: IBM(R) LinuxONE
//Azure
:azure-full: Microsoft Azure
:azure-short: Azure
//vSphere
:vmw-full: VMware vSphere
:vmw-short: vSphere
//Oracle
:oci-first: Oracle(R) Cloud Infrastructure
:oci: OCI
:ocvs-first: Oracle(R) Cloud VMware Solution (OCVS)
:ocvs: OCVS
:context: vsphere-problem-detector

toc::[]

// About the operator
:leveloffset: +1

// Module included in the following assemblies:
//
// * installing/installing_vsphere/using-vsphere-problem-detector-operator.adoc

:operator-name: vSphere Problem Detector Operator

:_mod-docs-content-type: CONCEPT
[id="vsphere-problem-detector-about_{context}"]
= About the {operator-name}

The {operator-name} checks clusters that are deployed on vSphere for common installation and misconfiguration issues that are related to storage.

The Operator runs in the `openshift-cluster-storage-operator` namespace and is started by the Cluster Storage Operator when the Cluster Storage Operator detects that the cluster is deployed on vSphere. The {operator-name} communicates with the vSphere vCenter Server to determine the virtual machines in the cluster, the default datastore, and other information about the vSphere vCenter Server configuration. The Operator uses the credentials from the Cloud Credential Operator to connect to vSphere.

The Operator runs the checks according to the following schedule:

* The checks run every 8 hours.

* If any check fails, the Operator runs the checks again in intervals of 1 minute, 2 minutes, 4, 8, and so on. The Operator doubles the interval up to a maximum interval of 8 hours.

* When all checks pass, the schedule returns to an 8 hour interval.

The Operator increases the frequency of the checks after a failure so that the Operator can report success quickly after the failure condition is remedied. You can run the Operator manually for immediate troubleshooting information.

// Clear temporary attributes
:!operator-name:

:leveloffset!:

// Run the checks
:leveloffset: +1

// Module included in the following assemblies:
//
// * installing/installing_vsphere/using-vsphere-problem-detector-operator.adoc

:operator-name: vSphere Problem Detector Operator

:_mod-docs-content-type: PROCEDURE
[id="vsphere-problem-detector-running_{context}"]
= Running the {operator-name} checks

You can override the schedule for running the {operator-name} checks and run the checks immediately.

The {operator-name} automatically runs the checks every 8 hours. However, when the Operator starts, it runs the checks immediately. The Operator is started by the Cluster Storage Operator when the Cluster Storage Operator starts and determines that the cluster is running on vSphere. To run the checks immediately, you can scale the {operator-name} to `0` and back to `1` so that it restarts the {operator-name}.

.Prerequisites

* Access to the cluster as a user with the `cluster-admin` role.

.Procedure

. Scale the Operator to `0`:
+
[source,terminal]
----
$ oc scale deployment/vsphere-problem-detector-operator --replicas=0 \
    -n openshift-cluster-storage-operator
----
+
If the deployment does not scale to zero immediately, you can run the following command to wait for the pods to exit:
+
[source,terminal]
----
$ oc wait pods -l name=vsphere-problem-detector-operator \
    --for=delete --timeout=5m -n openshift-cluster-storage-operator
----

. Scale the Operator back to `1`:
+
[source,terminal]
----
$ oc scale deployment/vsphere-problem-detector-operator --replicas=1 \
    -n openshift-cluster-storage-operator
----

. Delete the old leader lock to speed up the new leader election for the Cluster Storage Operator:
+
[source,terminal]
----
$ oc delete -n openshift-cluster-storage-operator \
    cm vsphere-problem-detector-lock
----

.Verification

* View the events or logs that are generated by the {operator-name}. Confirm that the events or logs have recent timestamps.

// Clear temporary attributes
:!operator-name:

:leveloffset!:

// View the events
:leveloffset: +1

// Module included in the following assemblies
//
// * installing/installing_vsphere/using-vsphere-problem-detector-operator.adoc

:operator-name: vSphere Problem Detector Operator

:_mod-docs-content-type: PROCEDURE
[id="vsphere-problem-detector-viewing-events_{context}"]
= Viewing the events from the {operator-name}

After the {operator-name} runs and performs the configuration checks, it creates events that can be viewed from the command line or from the {product-title} web console.

.Procedure

* To view the events by using the command line, run the following command:
+
[source,terminal]
----
$ oc get event -n openshift-cluster-storage-operator \
    --sort-by={.metadata.creationTimestamp}
----
+
.Example output
[source,terminal]
----
16m     Normal    Started             pod/vsphere-problem-detector-operator-xxxxx         Started container vsphere-problem-detector
16m     Normal    Created             pod/vsphere-problem-detector-operator-xxxxx         Created container vsphere-problem-detector
16m     Normal    LeaderElection      configmap/vsphere-problem-detector-lock    vsphere-problem-detector-operator-xxxxx became leader
----

* To view the events by using the {product-title} web console, navigate to *Home* -> *Events* and select `openshift-cluster-storage-operator` from the *Project* menu.

// Clear temporary attributes
:!operator-name:

:leveloffset!:

// View the logs
:leveloffset: +1

// Module included in the following assemblies:
//
// * installing/installing_vsphere/using-vsphere-problem-detector-operator.adoc

:operator-name: vSphere Problem Detector Operator

:_mod-docs-content-type: PROCEDURE
[id="vsphere-problem-detector-viewing-logs_{context}"]
= Viewing the logs from the {operator-name}

After the {operator-name} runs and performs the configuration checks, it creates log records that can be viewed from the command line or from the {product-title} web console.

.Procedure

* To view the logs by using the command line, run the following command:
+
[source,terminal]
----
$ oc logs deployment/vsphere-problem-detector-operator \
    -n openshift-cluster-storage-operator
----
+
.Example output
[source,terminal]
----
I0108 08:32:28.445696       1 operator.go:209] ClusterInfo passed
I0108 08:32:28.451029       1 datastore.go:57] CheckStorageClasses checked 1 storage classes, 0 problems found
I0108 08:32:28.451047       1 operator.go:209] CheckStorageClasses passed
I0108 08:32:28.452160       1 operator.go:209] CheckDefaultDatastore passed
I0108 08:32:28.480648       1 operator.go:271] CheckNodeDiskUUID:<host_name> passed
I0108 08:32:28.480685       1 operator.go:271] CheckNodeProviderID:<host_name> passed
----

* To view the Operator logs with the {product-title} web console, perform the following steps:

.. Navigate to *Workloads* -> *Pods*.

.. Select `openshift-cluster-storage-operator` from the *Projects* menu.

.. Click the link for the `vsphere-problem-detector-operator` pod.

.. Click the *Logs* tab on the *Pod details* page to view the logs.

// Clear temporary attributes
:!operator-name:

:leveloffset!:

// Reference: Problem detector checks
:leveloffset: +1

// Module included in the following assemblies:
//
// * installing/installing_vsphere/using-vsphere-problem-detector-operator.adoc

:operator-name: vSphere Problem Detector Operator

[id="vsphere-problem-detector-config-checks_{context}"]
= Configuration checks run by the {operator-name}

The following tables identify the configuration checks that the {operator-name} runs. Some checks verify the configuration of the cluster. Other checks verify the configuration of each node in the cluster.

.Cluster configuration checks
[options="header",cols="20,80a"]
|===
|Name
|Description

|`CheckDefaultDatastore`
|Verifies that the default datastore name in the vSphere configuration is short enough for use with dynamic provisioning.

If this check fails, you can expect the following:

* `systemd` logs errors to the journal such as `Failed to set up mount unit: Invalid argument`.

* `systemd` does not unmount volumes if the virtual machine is shut down or rebooted without draining all the pods from the node.

If this check fails, reconfigure vSphere with a shorter name for the default datastore.

|`CheckFolderPermissions`
|Verifies the permission to list volumes in the default datastore. This permission is required to create volumes. The Operator verifies the permission by listing the `/` and `/kubevols` directories. The root directory must exist. It is acceptable if the `/kubevols` directory does not exist when the check runs. The `/kubevols` directory is created when the datastore is used with dynamic provisioning if the directory does not already exist.

If this check fails, review the required permissions for the vCenter account that was specified during the {product-title} installation.

|`CheckStorageClasses`
|Verifies the following:

* The fully qualified path to each persistent volume that is provisioned by this storage class is less than 255 characters.

* If a storage class uses a storage policy, the storage class must use one policy only and that policy must be defined.

|`CheckTaskPermissions`
|Verifies the permission to list recent tasks and datastores.

|`ClusterInfo`
|Collects the cluster version and UUID from vSphere vCenter.
|===

.Node configuration checks
[options="header",cols="20,80a"]
|===
|Name
|Description

|`CheckNodeDiskUUID`
|Verifies that all the vSphere virtual machines are configured with `disk.enableUUID=TRUE`.

If this check fails, see the link:https://access.redhat.com/solutions/4606201[How to check 'disk.EnableUUID' parameter from VM in vSphere] Red Hat Knowledgebase solution.

|`CheckNodeProviderID`
|Verifies that all nodes are configured with the `ProviderID` from vSphere vCenter. This check fails when the output from the following command does not include a provider ID for each node.

[source,terminal]
----
$ oc get nodes -o custom-columns=NAME:.metadata.name,PROVIDER_ID:.spec.providerID,UUID:.status.nodeInfo.systemUUID
----

If this check fails, refer to the vSphere product documentation for information about setting the provider ID for each node in the cluster.

|`CollectNodeESXiVersion`
|Reports the version of the ESXi hosts that run nodes.

|`CollectNodeHWVersion`
|Reports the virtual machine hardware version for a node.
|===

// Clear temporary attributes
:!operator-name:

:leveloffset!:

// Concept: Storage class config check
:leveloffset: +1

// Module included in the following assemblies:
//
// * installing/installing_vsphere/using-vsphere-problem-detector-operator.adoc

:operator-name: vSphere Problem Detector Operator

:_mod-docs-content-type: CONCEPT
[id="vsphere-problem-detector-storage-class-config-check_{context}"]
= About the storage class configuration check

The names for persistent volumes that use vSphere storage are related to the datastore name and cluster ID.

When a persistent volume is created, `systemd` creates a mount unit for the persistent volume. The `systemd` process has a 255 character limit for the length of the fully qualified path to the VDMK file that is used for the persistent volume.

The fully qualified path is based on the naming conventions for `systemd` and vSphere. The naming conventions use the following pattern:

[source,text]
----
/var/lib/kubelet/plugins/kubernetes.io/vsphere-volume/mounts/[<datastore>] 00000000-0000-0000-0000-000000000000/<cluster_id>-dynamic-pvc-00000000-0000-0000-0000-000000000000.vmdk
----

* The naming conventions require 205 characters of the 255 character limit.

* The datastore name and the cluster ID are determined from the deployment.

* The datastore name and cluster ID are substituted into the preceding pattern. Then the path is processed with the `systemd-escape` command to escape special characters. For example, a hyphen character uses four characters after it is escaped. The escaped value is `\x2d`.

* After processing with `systemd-escape` to ensure that `systemd` can access the fully qualified path to the VDMK file, the length of the path must be less than 255 characters.

// Clear temporary attributes
:!operator-name:

:leveloffset!:

// Metrics
:leveloffset: +1

// Module included in the following assemblies:
//
// * installing/installing_vsphere/using-vsphere-problem-detector-operator.adoc

:operator-name: vSphere Problem Detector Operator

[id="vsphere-problem-detector-operator-metrics_{context}"]
= Metrics for the {operator-name}

The {operator-name} exposes the following metrics for use by the {product-title} monitoring stack.

.Metrics exposed by the {operator-name}
[cols="2a,8a",options="header"]
|===
|Name |Description

|`vsphere_cluster_check_total`
|Cumulative number of cluster-level checks that the {operator-name} performed. This count includes both successes and failures.

|`vsphere_cluster_check_errors`
|Number of failed cluster-level checks that the {operator-name} performed. For example, a value of `1` indicates that one cluster-level check failed.

|`vsphere_esxi_version_total`
|Number of ESXi hosts with a specific version. Be aware that if a host runs more than one node, the host is counted only once.

|`vsphere_node_check_total`
|Cumulative number of node-level checks that the {operator-name} performed. This count includes both successes and failures.

|`vsphere_node_check_errors`
|Number of failed node-level checks that the {operator-name} performed. For example, a value of `1` indicates that one node-level check failed.

|`vsphere_node_hw_version_total`
|Number of vSphere nodes with a specific hardware version.

|`vsphere_vcenter_info`
|Information about the vSphere vCenter Server.
|===

// Clear temporary attributes
:!operator-name:

:leveloffset!:

[role="_additional-resources"]
== Additional resources

* xref:../../monitoring/monitoring-overview.adoc#monitoring-overview[Monitoring overview]

//# includes=_attributes/common-attributes,modules/vsphere-problem-detector-about,modules/vsphere-problem-detector-running,modules/vsphere-problem-detector-viewing-events,modules/vsphere-problem-detector-viewing-logs,modules/vsphere-problem-detector-config-checks,modules/vsphere-problem-detector-storage-class-config-check,modules/vsphere-problem-detector-metrics
