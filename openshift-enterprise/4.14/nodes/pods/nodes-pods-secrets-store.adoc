:_mod-docs-content-type: ASSEMBLY
[id="nodes-pods-secrets-store"]
= Providing sensitive data to pods by using an external secrets store
// The {product-title} attribute provides the context-sensitive name of the relevant OpenShift distribution, for example, "OpenShift Container Platform" or "OKD". The {product-version} attribute provides the product version relative to the distribution, for example "4.9".
// {product-title} and {product-version} are parsed when AsciiBinder queries the _distro_map.yml file in relation to the base branch of a pull request.
// See https://github.com/openshift/openshift-docs/blob/main/contributing_to_docs/doc_guidelines.adoc#product-name-and-version for more information on this topic.
// Other common attributes are defined in the following lines:
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:imagesdir: images
:prewrap!:
:op-system-first: Red Hat Enterprise Linux CoreOS (RHCOS)
:op-system: RHCOS
:op-system-lowercase: rhcos
:op-system-base: RHEL
:op-system-base-full: Red Hat Enterprise Linux (RHEL)
:op-system-version: 8.x
:tsb-name: Template Service Broker
:kebab: image:kebab.png[title="Options menu"]
:rh-openstack-first: Red Hat OpenStack Platform (RHOSP)
:rh-openstack: RHOSP
:ai-full: Assisted Installer
:ai-version: 2.3
:cluster-manager-first: Red Hat OpenShift Cluster Manager
:cluster-manager: OpenShift Cluster Manager
:cluster-manager-url: link:https://console.redhat.com/openshift[OpenShift Cluster Manager Hybrid Cloud Console]
:cluster-manager-url-pull: link:https://console.redhat.com/openshift/install/pull-secret[pull secret from the Red Hat OpenShift Cluster Manager]
:insights-advisor-url: link:https://console.redhat.com/openshift/insights/advisor/[Insights Advisor]
:hybrid-console: Red Hat Hybrid Cloud Console
:hybrid-console-second: Hybrid Cloud Console
:oadp-first: OpenShift API for Data Protection (OADP)
:oadp-full: OpenShift API for Data Protection
:oc-first: pass:quotes[OpenShift CLI (`oc`)]
:product-registry: OpenShift image registry
:rh-storage-first: Red Hat OpenShift Data Foundation
:rh-storage: OpenShift Data Foundation
:rh-rhacm-first: Red Hat Advanced Cluster Management (RHACM)
:rh-rhacm: RHACM
:rh-rhacm-version: 2.8
:sandboxed-containers-first: OpenShift sandboxed containers
:sandboxed-containers-operator: OpenShift sandboxed containers Operator
:sandboxed-containers-version: 1.3
:sandboxed-containers-version-z: 1.3.3
:sandboxed-containers-legacy-version: 1.3.2
:cert-manager-operator: cert-manager Operator for Red Hat OpenShift
:secondary-scheduler-operator-full: Secondary Scheduler Operator for Red Hat OpenShift
:secondary-scheduler-operator: Secondary Scheduler Operator
// Backup and restore
:velero-domain: velero.io
:velero-version: 1.11
:launch: image:app-launcher.png[title="Application Launcher"]
:mtc-short: MTC
:mtc-full: Migration Toolkit for Containers
:mtc-version: 1.8
:mtc-version-z: 1.8.0
// builds (Valid only in 4.11 and later)
:builds-v2title: Builds for Red Hat OpenShift
:builds-v2shortname: OpenShift Builds v2
:builds-v1shortname: OpenShift Builds v1
//gitops
:gitops-title: Red Hat OpenShift GitOps
:gitops-shortname: GitOps
:gitops-ver: 1.1
:rh-app-icon: image:red-hat-applications-menu-icon.jpg[title="Red Hat applications"]
//pipelines
:pipelines-title: Red Hat OpenShift Pipelines
:pipelines-shortname: OpenShift Pipelines
:pipelines-ver: pipelines-1.12
:pipelines-version-number: 1.12
:tekton-chains: Tekton Chains
:tekton-hub: Tekton Hub
:artifact-hub: Artifact Hub
:pac: Pipelines as Code
//odo
:odo-title: odo
//OpenShift Kubernetes Engine
:oke: OpenShift Kubernetes Engine
//OpenShift Platform Plus
:opp: OpenShift Platform Plus
//openshift virtualization (cnv)
:VirtProductName: OpenShift Virtualization
:VirtVersion: 4.14
:KubeVirtVersion: v0.59.0
:HCOVersion: 4.14.0
:CNVNamespace: openshift-cnv
:CNVOperatorDisplayName: OpenShift Virtualization Operator
:CNVSubscriptionSpecSource: redhat-operators
:CNVSubscriptionSpecName: kubevirt-hyperconverged
:delete: image:delete.png[title="Delete"]
//distributed tracing
:DTProductName: Red Hat OpenShift distributed tracing platform
:DTShortName: distributed tracing platform
:DTProductVersion: 2.9
:JaegerName: Red Hat OpenShift distributed tracing platform (Jaeger)
:JaegerShortName: distributed tracing platform (Jaeger)
:JaegerVersion: 1.47.0
:OTELName: Red Hat OpenShift distributed tracing data collection
:OTELShortName: distributed tracing data collection
:OTELOperator: Red Hat OpenShift distributed tracing data collection Operator
:OTELVersion: 0.81.0
:TempoName: Red Hat OpenShift distributed tracing platform (Tempo)
:TempoShortName: distributed tracing platform (Tempo)
:TempoOperator: Tempo Operator
:TempoVersion: 2.1.1
//logging
:logging-title: logging subsystem for Red Hat OpenShift
:logging-title-uc: Logging subsystem for Red Hat OpenShift
:logging: logging subsystem
:logging-uc: Logging subsystem
//serverless
:ServerlessProductName: OpenShift Serverless
:ServerlessProductShortName: Serverless
:ServerlessOperatorName: OpenShift Serverless Operator
:FunctionsProductName: OpenShift Serverless Functions
//service mesh v2
:product-dedicated: Red Hat OpenShift Dedicated
:product-rosa: Red Hat OpenShift Service on AWS
:SMProductName: Red Hat OpenShift Service Mesh
:SMProductShortName: Service Mesh
:SMProductVersion: 2.4.4
:MaistraVersion: 2.4
//Service Mesh v1
:SMProductVersion1x: 1.1.18.2
//Windows containers
:productwinc: Red Hat OpenShift support for Windows Containers
// Red Hat Quay Container Security Operator
:rhq-cso: Red Hat Quay Container Security Operator
// Red Hat Quay
:quay: Red Hat Quay
:sno: single-node OpenShift
:sno-caps: Single-node OpenShift
//TALO and Redfish events Operators
:cgu-operator-first: Topology Aware Lifecycle Manager (TALM)
:cgu-operator-full: Topology Aware Lifecycle Manager
:cgu-operator: TALM
:redfish-operator: Bare Metal Event Relay
//Formerly known as CodeReady Containers and CodeReady Workspaces
:openshift-local-productname: Red Hat OpenShift Local
:openshift-dev-spaces-productname: Red Hat OpenShift Dev Spaces
// Factory-precaching-cli tool
:factory-prestaging-tool: factory-precaching-cli tool
:factory-prestaging-tool-caps: Factory-precaching-cli tool
:openshift-networking: Red Hat OpenShift Networking
// TODO - this probably needs to be different for OKD
//ifdef::openshift-origin[]
//:openshift-networking: OKD Networking
//endif::[]
// logical volume manager storage
:lvms-first: Logical volume manager storage (LVM Storage)
:lvms: LVM Storage
//Operator SDK version
:osdk_ver: 1.31.0
//Operator SDK version that shipped with the previous OCP 4.x release
:osdk_ver_n1: 1.28.0
//Next-gen (OCP 4.14+) Operator Lifecycle Manager, aka "v1"
:olmv1: OLM 1.0
:olmv1-first: Operator Lifecycle Manager (OLM) 1.0
:ztp-first: GitOps Zero Touch Provisioning (ZTP)
:ztp: GitOps ZTP
:3no: three-node OpenShift
:3no-caps: Three-node OpenShift
:run-once-operator: Run Once Duration Override Operator
// Web terminal
:web-terminal-op: Web Terminal Operator
:devworkspace-op: DevWorkspace Operator
:secrets-store-driver: Secrets Store CSI driver
:secrets-store-operator: Secrets Store CSI Driver Operator
//AWS STS
:sts-first: Security Token Service (STS)
:sts-full: Security Token Service
:sts-short: STS
//Cloud provider names
//AWS
:aws-first: Amazon Web Services (AWS)
:aws-full: Amazon Web Services
:aws-short: AWS
//GCP
:gcp-first: Google Cloud Platform (GCP)
:gcp-full: Google Cloud Platform
:gcp-short: GCP
//alibaba cloud
:alibaba: Alibaba Cloud
// IBM Cloud VPC
:ibmcloudVPCProductName: IBM Cloud VPC
:ibmcloudVPCRegProductName: IBM(R) Cloud VPC
// IBM Cloud
:ibm-cloud-bm: IBM Cloud Bare Metal (Classic)
:ibm-cloud-bm-reg: IBM Cloud(R) Bare Metal (Classic)
// IBM Power
:ibmpowerProductName: IBM Power
:ibmpowerRegProductName: IBM(R) Power
// IBM zSystems
:ibmzProductName: IBM Z
:ibmzRegProductName: IBM(R) Z
:linuxoneProductName: IBM(R) LinuxONE
//Azure
:azure-full: Microsoft Azure
:azure-short: Azure
//vSphere
:vmw-full: VMware vSphere
:vmw-short: vSphere
//Oracle
:oci-first: Oracle(R) Cloud Infrastructure
:oci: OCI
:ocvs-first: Oracle(R) Cloud VMware Solution (OCVS)
:ocvs: OCVS
:context: nodes-pods-secrets-store

toc::[]

Some applications need sensitive information, such as passwords and user names, that you do not want developers to have.

As an alternative to using Kubernetes `Secret` objects to provide sensitive information, you can use an external secrets store to store the sensitive information. You can use the {secrets-store-operator} to integrate with an external secrets store and mount the secret content as a pod volume.

:FeatureName: The {secrets-store-operator}
:leveloffset: +1

// When including this file, ensure that {FeatureName} is set immediately before
// the include. Otherwise it will result in an incorrect replacement.

[IMPORTANT]
====
[subs="attributes+"]
{FeatureName} is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.

For more information about the support scope of Red Hat Technology Preview features, see link:https://access.redhat.com/support/offerings/techpreview/[Technology Preview Features Support Scope].
====
// Undefine {FeatureName} attribute, so that any mistakes are easily spotted
:!FeatureName:

:leveloffset!:

// About the {secrets-store-operator}
:leveloffset: +1

// Module included in the following assemblies:
//
// * storage/container_storage_interface/persistent-storage-csi-secrets-store.adoc
// * nodes/pods/nodes-pods-secrets-store.adoc

:nodes:

:_mod-docs-content-type: CONCEPT
[id="persistent-storage-csi-secrets-store-driver-overview_{context}"]
= About the {secrets-store-operator}

Kubernetes secrets are stored with Base64 encoding. etcd provides encryption at rest for these secrets, but when secrets are retrieved, they are decrypted and presented to the user. If role-based access control is not configured properly on your cluster, anyone with API or etcd access can retrieve or modify a secret. Additionally, anyone who is authorized to create a pod in a namespace can use that access to read any secret in that namespace.

To store and manage your secrets securely, you can configure the {product-title} Secrets Store Container Storage Interface (CSI) Driver Operator to mount secrets from an external secret management system, such as Azure Key Vault, by using a provider plugin. Applications can then use the secret, but the secret does not persist on the system after the application pod is destroyed.

The {secrets-store-operator}, `secrets-store.csi.k8s.io`, enables {product-title} to mount multiple secrets, keys, and certificates stored in enterprise-grade external secrets stores into pods as a volume. The {secrets-store-operator} communicates with the provider using gRPC to fetch the mount contents from the specified external secrets store. After the volume is attached, the data in it is mounted into the container's file system. Secrets store volumes are mounted in-line.

:!nodes:

:leveloffset!:

// Secrets store providers
:leveloffset: +2

// Module included in the following assemblies:
//
// * nodes/pods/nodes-pods-secrets-store.adoc

:_mod-docs-content-type: CONCEPT
[id="secrets-store-providers_{context}"]
= Secrets store providers

The following secrets store providers are available for use with the {secrets-store-operator}:

* AWS Secrets Manager
* AWS Systems Manager Parameter Store
* Azure Key Vault

:leveloffset!:

// Automatic rotation
:leveloffset: +2

// Module included in the following assemblies:
//
// * nodes/pods/nodes-pods-secrets-store.adoc

:_mod-docs-content-type: CONCEPT
[id="secrets-store-auto-rotation_{context}"]
= Automatic rotation

The {secrets-store-driver} periodically rotates the content in the mounted volume with the content from the external secrets store. If a secret is updated in the external secrets store, the secret will be updated in the mounted volume. The {secrets-store-operator} polls for updates every 2 minutes.

If you enabled synchronization of mounted content as Kubernetes secrets, the Kubernetes secrets are also rotated.

Applications consuming the secret data must watch for updates to the secrets.

:leveloffset!:

// Installing the {secrets-store-driver}
:leveloffset: +1

// Module included in the following assemblies:
//
// * storage/container_storage_interface/persistent-storage-csi-secrets-store.adoc
//

:_mod-docs-content-type: PROCEDURE
[id="persistent-storage-csi-secrets-store-driver-install_{context}"]
= Installing the {secrets-store-driver}

.Prerequisites
* Access to the {product-title} web console.

* Administrator access to the cluster.

.Procedure

To install the {secrets-store-driver}:

. Install the {secrets-store-operator}:
.. Log in to the web console.
.. Click *Operators* â†’ *OperatorHub*.
.. Locate the {secrets-store-operator} by typing "Secrets Store CSI" in the filter box.
.. Click the *Secrets Store CSI Driver Operator* button.
.. On the *Secrets Store CSI Driver Operator* page, click *Install*.
.. On the *Install Operator* page, ensure that:
+
* *All namespaces on the cluster (default)* is selected.

* *Installed Namespace* is set to *openshift-cluster-csi-drivers*.
.. Click *Install*.
+
After the installation finishes, the {secrets-store-operator} is listed in the *Installed Operators* section of the web console.

. Create the `ClusterCSIDriver` instance for the driver (`secrets-store.csi.k8s.io`):
.. Click *Administration* -> *CustomResourceDefinitions* -> *ClusterCSIDriver*.
.. On the *Instances* tab, click *Create ClusterCSIDriver*.
+
Use the following YAML file:
+
[source,yaml]
----
apiVersion: operator.openshift.io/v1
kind: ClusterCSIDriver
metadata:
    name: secrets-store.csi.k8s.io
spec:
  managementState: Managed
----
.. Click *Create*.

:leveloffset!:

[id="mounting-secrets-external-secrets-store"]
== Mounting secrets from an external secrets store to a CSI volume

After installing the {secrets-store-operator}, you can mount secrets from one of the following external secrets stores to a CSI volume:

* xref:../../nodes/pods/nodes-pods-secrets-store.adoc#secrets-store-aws_nodes-pods-secrets-store[AWS Secrets Manager]
* xref:../../nodes/pods/nodes-pods-secrets-store.adoc#secrets-store-aws_nodes-pods-secrets-store-parameter-store[AWS Systems Manager Parameter Store]
* xref:../../nodes/pods/nodes-pods-secrets-store.adoc#secrets-store-azure_nodes-pods-secrets-store[Azure Key Vault]

// Mounting secrets from AWS Secrets Manager
:secrets-store-provider: AWS Secrets Manager
:leveloffset: +2

// Module included in the following assemblies:
//
// * nodes/pods/nodes-pods-secrets-store.adoc
//
// IMPORTANT: This file requires you to define :secrets-store-provider: before including this module.

:aws-secrets-manager:

:_mod-docs-content-type: PROCEDURE
[id="secrets-store-aws_{context}"]
= Mounting secrets from {secrets-store-provider}

You can use the {secrets-store-operator} to mount secrets from {secrets-store-provider} to a CSI volume in {product-title}. To mount secrets from {secrets-store-provider}, your cluster must be installed on AWS and use AWS Security Token Service (STS).

[IMPORTANT]
====
It is not supported to use the {secrets-store-operator} with {secrets-store-provider} in a hosted control plane cluster.
====

.Prerequisites

* Your cluster is installed on AWS and uses AWS Security Token Service (STS).
* You have installed the {secrets-store-operator}. See _Installing the {secrets-store-driver}_ for instructions.
* You have configured {secrets-store-provider} to store the required secrets.
* You have extracted and prepared the `ccoctl` binary.
* You have installed the `jq` CLI tool.
* You have access to the cluster as a user with the `cluster-admin` role.

.Procedure

. Install the {secrets-store-provider} provider:

.. Create a YAML file with the following configuration for the provider resources:
+
[IMPORTANT]
====
The {secrets-store-provider} provider for the {secrets-store-driver} is an upstream provider.

This configuration is modified from the configuration provided in the upstream link:https://github.com/aws/secrets-store-csi-driver-provider-aws#installing-the-aws-provider[AWS documentation] so that it works properly with {product-title}. Changes to this configuration might impact functionality.
====
+
.Example `aws-provider.yaml` file
[source,yaml]
----
apiVersion: v1
kind: ServiceAccount
metadata:
  name: csi-secrets-store-provider-aws
  namespace: openshift-cluster-csi-drivers
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: csi-secrets-store-provider-aws-cluster-role
rules:
- apiGroups: [""]
  resources: ["serviceaccounts/token"]
  verbs: ["create"]
- apiGroups: [""]
  resources: ["serviceaccounts"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: csi-secrets-store-provider-aws-cluster-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: csi-secrets-store-provider-aws-cluster-role
subjects:
- kind: ServiceAccount
  name: csi-secrets-store-provider-aws
  namespace: openshift-cluster-csi-drivers
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  namespace: openshift-cluster-csi-drivers
  name: csi-secrets-store-provider-aws
  labels:
    app: csi-secrets-store-provider-aws
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: csi-secrets-store-provider-aws
  template:
    metadata:
      labels:
        app: csi-secrets-store-provider-aws
    spec:
      serviceAccountName: csi-secrets-store-provider-aws
      hostNetwork: false
      containers:
        - name: provider-aws-installer
          image: public.ecr.aws/aws-secrets-manager/secrets-store-csi-driver-provider-aws:1.0.r2-50-g5b4aca1-2023.06.09.21.19
          imagePullPolicy: Always
          args:
              - --provider-volume=/etc/kubernetes/secrets-store-csi-providers
          resources:
            requests:
              cpu: 50m
              memory: 100Mi
            limits:
              cpu: 50m
              memory: 100Mi
          securityContext:
            privileged: true
          volumeMounts:
            - mountPath: "/etc/kubernetes/secrets-store-csi-providers"
              name: providervol
            - name: mountpoint-dir
              mountPath: /var/lib/kubelet/pods
              mountPropagation: HostToContainer
      tolerations:
      - operator: Exists
      volumes:
        - name: providervol
          hostPath:
            path: "/etc/kubernetes/secrets-store-csi-providers"
        - name: mountpoint-dir
          hostPath:
            path: /var/lib/kubelet/pods
            type: DirectoryOrCreate
      nodeSelector:
        kubernetes.io/os: linux
----

.. Grant privileged access to the `csi-secrets-store-provider-aws` service account by running the following command:
+
[source,terminal]
----
$ oc adm policy add-scc-to-user privileged -z csi-secrets-store-provider-aws -n openshift-cluster-csi-drivers
----

.. Create the provider resources by running the following command:
+
[source,terminal]
----
$ oc apply -f aws-provider.yaml
----

. Grant permission to allow the service account to read the AWS secret object:

.. Create a directory to contain the credentials request by running the following command:
+
[source,terminal]
----
$ mkdir credentialsrequest-dir-aws
----

.. Create a YAML file with the following configuration for the credentials request:
+
.Example `credentialsrequest.yaml` file
[source,yaml]
----
apiVersion: cloudcredential.openshift.io/v1
kind: CredentialsRequest
metadata:
  name: aws-provider-test
  namespace: openshift-cloud-credential-operator
spec:
  providerSpec:
    apiVersion: cloudcredential.openshift.io/v1
    kind: AWSProviderSpec
    statementEntries:
    - action:
      - "secretsmanager:GetSecretValue"
      - "secretsmanager:DescribeSecret"
      effect: Allow
      resource: "arn:*:secretsmanager:*:*:secret:testSecret-??????"
  secretRef:
    name: aws-creds
    namespace: my-namespace
  serviceAccountNames:
  - aws-provider
----

.. Retrieve the OIDC provider by running the following command:
+
[source,terminal]
----
$ oc get --raw=/.well-known/openid-configuration | jq -r '.issuer'
----
+
.Example output
[source,terminal]
----
https://<oidc_provider_name>
----
Copy the OIDC provider name `<oidc_provider_name>` from the output to use in the next step.

.. Use the `ccoctl` tool to process the credentials request by running the following command:
+
[source,terminal]
----
$ ccoctl aws create-iam-roles \
    --name my-role --region=<aws_region> \
    --credentials-requests-dir=credentialsrequest-dir-aws \
    --identity-provider-arn arn:aws:iam::<aws_account>:oidc-provider/<oidc_provider_name> --output-dir=credrequests-ccoctl-output
----
+
.Example output
[source,terminal]
----
2023/05/15 18:10:34 Role arn:aws:iam::<aws_account_id>:role/my-role-my-namespace-aws-creds created
2023/05/15 18:10:34 Saved credentials configuration to: credrequests-ccoctl-output/manifests/my-namespace-aws-creds-credentials.yaml
2023/05/15 18:10:35 Updated Role policy for Role my-role-my-namespace-aws-creds
----
+
Copy the `<aws_role_arn>` from the output to use in the next step. For example, `arn:aws:iam::<aws_account_id>:role/my-role-my-namespace-aws-creds`.

.. Bind the service account with the role ARN by running the following command:
+
[source,terminal]
----
$ oc annotate -n my-namespace sa/aws-provider eks.amazonaws.com/role-arn="<aws_role_arn>"
----

. Create a secret provider class to define your secrets store provider:

.. Create a YAML file that defines the `SecretProviderClass` object:
+
.Example `secret-provider-class-aws.yaml`
[source,yaml]
----
apiVersion: secrets-store.csi.x-k8s.io/v1
kind: SecretProviderClass
metadata:
  name: my-aws-provider                   <1>
  namespace: my-namespace                 <2>
spec:
  provider: aws                           <3>
  parameters:                             <4>
    objects: |
      - objectName: "testSecret"
        objectType: "secretsmanager"
----
<1> Specify the name for the secret provider class.
<2> Specify the namespace for the secret provider class.
<3> Specify the provider as `aws`.
<4> Specify the provider-specific configuration parameters.

.. Create the `SecretProviderClass` object by running the following command:
+
[source,terminal]
----
$ oc create -f secret-provider-class-aws.yaml
----

. Create a deployment to use this secret provider class:

.. Create a YAML file that defines the `Deployment` object:
+
.Example `deployment.yaml`
[source,yaml]
----
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-aws-deployment                              <1>
  namespace: my-namespace                              <2>
spec:
  replicas: 1
  selector:
    matchLabels:
      app: my-storage
  template:
    metadata:
      labels:
        app: my-storage
    spec:
      containers:
      - name: busybox
        image: k8s.gcr.io/e2e-test-images/busybox:1.29
        command:
          - "/bin/sleep"
          - "10000"
        volumeMounts:
        - name: secrets-store-inline
          mountPath: "/mnt/secrets-store"
          readOnly: true
      volumes:
        - name: secrets-store-inline
          csi:
            driver: secrets-store.csi.k8s.io
            readOnly: true
            volumeAttributes:
              secretProviderClass: "my-aws-provider" <3>
----
<1> Specify the name for the deployment.
<2> Specify the namespace for the deployment. This must be the same namespace as the secret provider class.
<3> Specify the name of the secret provider class.

.. Create the `Deployment` object by running the following command:
+
[source,terminal]
----
$ oc create -f deployment.yaml
----

.Verification

* Verify that you can access the secrets from {secrets-store-provider} in the pod volume mount:

.. List the secrets in the pod mount:
+
[source,terminal]
----
$ oc exec busybox-<hash> -n my-namespace -- ls /mnt/secrets-store/
----
+
.Example output
[source,terminal]
----
testSecret
----

.. View a secret in the pod mount:
+
[source,terminal]
----
$ oc exec busybox-<hash> -n my-namespace -- cat /mnt/secrets-store/testSecret
----
+
.Example output
[source,terminal]
----
<secret_value>
----

:!aws-secrets-manager:

:leveloffset!:
:!secrets-store-provider:

[role="_additional-resources"]
.Additional resources
* xref:../../installing/installing_aws/installing-aws-customizations.adoc#cco-ccoctl-configuring_installing-aws-customizations[Configuring the Cloud Credential Operator utility]

// --- START OF CONTEXT CHANGE ---
// Setting a unique context for including the secrets-store-aws.adoc module a second time in this assembly
:context: nodes-pods-secrets-store-parameter-store

// Mounting secrets from AWS Systems Manager Parameter Store
:secrets-store-provider: AWS Systems Manager Parameter Store
:leveloffset: +2

// Module included in the following assemblies:
//
// * nodes/pods/nodes-pods-secrets-store.adoc
//
// IMPORTANT: This file requires you to define :secrets-store-provider: before including this module.

:aws-systems-manager-parameter-store:

:_mod-docs-content-type: PROCEDURE
[id="secrets-store-aws_{context}"]
= Mounting secrets from {secrets-store-provider}

You can use the {secrets-store-operator} to mount secrets from {secrets-store-provider} to a CSI volume in {product-title}. To mount secrets from {secrets-store-provider}, your cluster must be installed on AWS and use AWS Security Token Service (STS).

[IMPORTANT]
====
It is not supported to use the {secrets-store-operator} with {secrets-store-provider} in a hosted control plane cluster.
====

.Prerequisites

* Your cluster is installed on AWS and uses AWS Security Token Service (STS).
* You have installed the {secrets-store-operator}. See _Installing the {secrets-store-driver}_ for instructions.
* You have configured {secrets-store-provider} to store the required secrets.
* You have extracted and prepared the `ccoctl` binary.
* You have installed the `jq` CLI tool.
* You have access to the cluster as a user with the `cluster-admin` role.

.Procedure

. Install the {secrets-store-provider} provider:

.. Create a YAML file with the following configuration for the provider resources:
+
[IMPORTANT]
====
The {secrets-store-provider} provider for the {secrets-store-driver} is an upstream provider.

This configuration is modified from the configuration provided in the upstream link:https://github.com/aws/secrets-store-csi-driver-provider-aws#installing-the-aws-provider[AWS documentation] so that it works properly with {product-title}. Changes to this configuration might impact functionality.
====
+
.Example `aws-provider.yaml` file
[source,yaml]
----
apiVersion: v1
kind: ServiceAccount
metadata:
  name: csi-secrets-store-provider-aws
  namespace: openshift-cluster-csi-drivers
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: csi-secrets-store-provider-aws-cluster-role
rules:
- apiGroups: [""]
  resources: ["serviceaccounts/token"]
  verbs: ["create"]
- apiGroups: [""]
  resources: ["serviceaccounts"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: csi-secrets-store-provider-aws-cluster-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: csi-secrets-store-provider-aws-cluster-role
subjects:
- kind: ServiceAccount
  name: csi-secrets-store-provider-aws
  namespace: openshift-cluster-csi-drivers
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  namespace: openshift-cluster-csi-drivers
  name: csi-secrets-store-provider-aws
  labels:
    app: csi-secrets-store-provider-aws
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: csi-secrets-store-provider-aws
  template:
    metadata:
      labels:
        app: csi-secrets-store-provider-aws
    spec:
      serviceAccountName: csi-secrets-store-provider-aws
      hostNetwork: false
      containers:
        - name: provider-aws-installer
          image: public.ecr.aws/aws-secrets-manager/secrets-store-csi-driver-provider-aws:1.0.r2-50-g5b4aca1-2023.06.09.21.19
          imagePullPolicy: Always
          args:
              - --provider-volume=/etc/kubernetes/secrets-store-csi-providers
          resources:
            requests:
              cpu: 50m
              memory: 100Mi
            limits:
              cpu: 50m
              memory: 100Mi
          securityContext:
            privileged: true
          volumeMounts:
            - mountPath: "/etc/kubernetes/secrets-store-csi-providers"
              name: providervol
            - name: mountpoint-dir
              mountPath: /var/lib/kubelet/pods
              mountPropagation: HostToContainer
      tolerations:
      - operator: Exists
      volumes:
        - name: providervol
          hostPath:
            path: "/etc/kubernetes/secrets-store-csi-providers"
        - name: mountpoint-dir
          hostPath:
            path: /var/lib/kubelet/pods
            type: DirectoryOrCreate
      nodeSelector:
        kubernetes.io/os: linux
----

.. Grant privileged access to the `csi-secrets-store-provider-aws` service account by running the following command:
+
[source,terminal]
----
$ oc adm policy add-scc-to-user privileged -z csi-secrets-store-provider-aws -n openshift-cluster-csi-drivers
----

.. Create the provider resources by running the following command:
+
[source,terminal]
----
$ oc apply -f aws-provider.yaml
----

. Grant permission to allow the service account to read the AWS secret object:

.. Create a directory to contain the credentials request by running the following command:
+
[source,terminal]
----
$ mkdir credentialsrequest-dir-aws
----

.. Create a YAML file with the following configuration for the credentials request:
+
.Example `credentialsrequest.yaml` file
[source,yaml]
----
apiVersion: cloudcredential.openshift.io/v1
kind: CredentialsRequest
metadata:
  name: aws-provider-test
  namespace: openshift-cloud-credential-operator
spec:
  providerSpec:
    apiVersion: cloudcredential.openshift.io/v1
    kind: AWSProviderSpec
    statementEntries:
    - action:
      - "ssm:GetParameter"
      - "ssm:GetParameters"
      effect: Allow
      resource: "arn:*:ssm:*:*:parameter/testParameter*"
  secretRef:
    name: aws-creds
    namespace: my-namespace
  serviceAccountNames:
  - aws-provider
----

.. Retrieve the OIDC provider by running the following command:
+
[source,terminal]
----
$ oc get --raw=/.well-known/openid-configuration | jq -r '.issuer'
----
+
.Example output
[source,terminal]
----
https://<oidc_provider_name>
----
Copy the OIDC provider name `<oidc_provider_name>` from the output to use in the next step.

.. Use the `ccoctl` tool to process the credentials request by running the following command:
+
[source,terminal]
----
$ ccoctl aws create-iam-roles \
    --name my-role --region=<aws_region> \
    --credentials-requests-dir=credentialsrequest-dir-aws \
    --identity-provider-arn arn:aws:iam::<aws_account>:oidc-provider/<oidc_provider_name> --output-dir=credrequests-ccoctl-output
----
+
.Example output
[source,terminal]
----
2023/05/15 18:10:34 Role arn:aws:iam::<aws_account_id>:role/my-role-my-namespace-aws-creds created
2023/05/15 18:10:34 Saved credentials configuration to: credrequests-ccoctl-output/manifests/my-namespace-aws-creds-credentials.yaml
2023/05/15 18:10:35 Updated Role policy for Role my-role-my-namespace-aws-creds
----
+
Copy the `<aws_role_arn>` from the output to use in the next step. For example, `arn:aws:iam::<aws_account_id>:role/my-role-my-namespace-aws-creds`.

.. Bind the service account with the role ARN by running the following command:
+
[source,terminal]
----
$ oc annotate -n my-namespace sa/aws-provider eks.amazonaws.com/role-arn="<aws_role_arn>"
----

. Create a secret provider class to define your secrets store provider:

.. Create a YAML file that defines the `SecretProviderClass` object:
+
.Example `secret-provider-class-aws.yaml`
[source,yaml]
----
apiVersion: secrets-store.csi.x-k8s.io/v1
kind: SecretProviderClass
metadata:
  name: my-aws-provider                   <1>
  namespace: my-namespace                 <2>
spec:
  provider: aws                           <3>
  parameters:                             <4>
    objects: |
      - objectName: "testParameter"
        objectType: "ssmparameter"
----
<1> Specify the name for the secret provider class.
<2> Specify the namespace for the secret provider class.
<3> Specify the provider as `aws`.
<4> Specify the provider-specific configuration parameters.

.. Create the `SecretProviderClass` object by running the following command:
+
[source,terminal]
----
$ oc create -f secret-provider-class-aws.yaml
----

. Create a deployment to use this secret provider class:

.. Create a YAML file that defines the `Deployment` object:
+
.Example `deployment.yaml`
[source,yaml]
----
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-aws-deployment                              <1>
  namespace: my-namespace                              <2>
spec:
  replicas: 1
  selector:
    matchLabels:
      app: my-storage
  template:
    metadata:
      labels:
        app: my-storage
    spec:
      containers:
      - name: busybox
        image: k8s.gcr.io/e2e-test-images/busybox:1.29
        command:
          - "/bin/sleep"
          - "10000"
        volumeMounts:
        - name: secrets-store-inline
          mountPath: "/mnt/secrets-store"
          readOnly: true
      volumes:
        - name: secrets-store-inline
          csi:
            driver: secrets-store.csi.k8s.io
            readOnly: true
            volumeAttributes:
              secretProviderClass: "my-aws-provider" <3>
----
<1> Specify the name for the deployment.
<2> Specify the namespace for the deployment. This must be the same namespace as the secret provider class.
<3> Specify the name of the secret provider class.

.. Create the `Deployment` object by running the following command:
+
[source,terminal]
----
$ oc create -f deployment.yaml
----

.Verification

* Verify that you can access the secrets from {secrets-store-provider} in the pod volume mount:

.. List the secrets in the pod mount:
+
[source,terminal]
----
$ oc exec busybox-<hash> -n my-namespace -- ls /mnt/secrets-store/
----
+
.Example output
[source,terminal]
----
testParameter
----

.. View a secret in the pod mount:
+
[source,terminal]
----
$ oc exec busybox-<hash> -n my-namespace -- cat /mnt/secrets-store/testSecret
----
+
.Example output
[source,terminal]
----
<secret_value>
----

:!aws-systems-manager-parameter-store:

:leveloffset!:
:!secrets-store-provider:

// Resetting the context back to original context
:context: nodes-pods-secrets-store
// --- END OF CONTEXT CHANGE ---

[role="_additional-resources"]
.Additional resources
* xref:../../installing/installing_aws/installing-aws-customizations.adoc#cco-ccoctl-configuring_installing-aws-customizations[Configuring the Cloud Credential Operator utility]

// Mounting secrets from Azure Key Vault
:leveloffset: +2

// Module included in the following assemblies:
//
// * nodes/pods/nodes-pods-secrets-store.adoc

:_mod-docs-content-type: PROCEDURE
[id="secrets-store-azure_{context}"]
= Mounting secrets from Azure Key Vault

You can use the {secrets-store-operator} to mount secrets from Azure Key Vault to a CSI volume in {product-title}. To mount secrets from Azure Key Vault, your cluster must be installed on Microsoft Azure.

.Prerequisites

* Your cluster is installed on Azure.
* You have installed the {secrets-store-operator}. See _Installing the {secrets-store-driver}_ for instructions.
* You have configured Azure Key Vault to store the required secrets.
* You have installed the Azure CLI (`az`).
* You have access to the cluster as a user with the `cluster-admin` role.

.Procedure

. Install the Azure Key Vault provider:

.. Create a YAML file with the following configuration for the provider resources:
+
[IMPORTANT]
====
The Azure Key Vault provider for the {secrets-store-driver} is an upstream provider.

This configuration is modified from the configuration provided in the upstream link:https://azure.github.io/secrets-store-csi-driver-provider-azure/docs/getting-started/installation/[Azure documentation] so that it works properly with {product-title}. Changes to this configuration might impact functionality.
====
+
.Example `azure-provider.yaml` file
[source,yaml]
----
apiVersion: v1
kind: ServiceAccount
metadata:
  name: csi-secrets-store-provider-azure
  namespace: openshift-cluster-csi-drivers
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: csi-secrets-store-provider-azure-cluster-role
rules:
- apiGroups: [""]
  resources: ["serviceaccounts/token"]
  verbs: ["create"]
- apiGroups: [""]
  resources: ["serviceaccounts"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: csi-secrets-store-provider-azure-cluster-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: csi-secrets-store-provider-azure-cluster-role
subjects:
- kind: ServiceAccount
  name: csi-secrets-store-provider-azure
  namespace: openshift-cluster-csi-drivers
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  namespace: openshift-cluster-csi-drivers
  name: csi-secrets-store-provider-azure
  labels:
    app: csi-secrets-store-provider-azure
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: csi-secrets-store-provider-azure
  template:
    metadata:
      labels:
        app: csi-secrets-store-provider-azure
    spec:
      serviceAccountName: csi-secrets-store-provider-azure
      hostNetwork: true
      containers:
        - name: provider-azure-installer
          image: mcr.microsoft.com/oss/azure/secrets-store/provider-azure:v1.4.1
          imagePullPolicy: IfNotPresent
          args:
            - --endpoint=unix:///provider/azure.sock
            - --construct-pem-chain=true
            - --healthz-port=8989
            - --healthz-path=/healthz
            - --healthz-timeout=5s
          livenessProbe:
            httpGet:
              path: /healthz
              port: 8989
            failureThreshold: 3
            initialDelaySeconds: 5
            timeoutSeconds: 10
            periodSeconds: 30
          resources:
            requests:
              cpu: 50m
              memory: 100Mi
            limits:
              cpu: 50m
              memory: 100Mi
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 0
            capabilities:
              drop:
              - ALL
          volumeMounts:
            - mountPath: "/provider"
              name: providervol
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: type
                operator: NotIn
                values:
                - virtual-kubelet
      volumes:
        - name: providervol
          hostPath:
            path: "/var/run/secrets-store-csi-providers"
      tolerations:
      - operator: Exists
      nodeSelector:
        kubernetes.io/os: linux
----

.. Grant privileged access to the `csi-secrets-store-provider-azure` service account by running the following command:
+
[source,terminal]
----
$ oc adm policy add-scc-to-user privileged -z csi-secrets-store-provider-azure -n openshift-cluster-csi-drivers
----

.. Create the provider resources by running the following command:
+
[source,terminal]
----
$ oc apply -f azure-provider.yaml
----

. Create a service principal to access the key vault:

.. Set the service principal client secret as an environment variable by running the following command:
+
[source,terminal]
----
$ SERVICE_PRINCIPAL_CLIENT_SECRET="$(az ad sp create-for-rbac --name https://$KEYVAULT_NAME --query 'password' -otsv)"
----

.. Set the service principal client ID as an environment variable by running the following command:
+
[source,terminal]
----
$ SERVICE_PRINCIPAL_CLIENT_ID="$(az ad sp list --display-name https://$KEYVAULT_NAME --query '[0].appId' -otsv)"
----

.. Create a generic secret with the service principal client secret and ID by running the following command:
+
[source,terminal]
----
$ oc create secret generic secrets-store-creds -n my-namespace --from-literal clientid=${SERVICE_PRINCIPAL_CLIENT_ID} --from-literal clientsecret=${SERVICE_PRINCIPAL_CLIENT_SECRET}
----

.. Apply the `secrets-store.csi.k8s.io/used=true` label to allow the provider to find this `nodePublishSecretRef` secret:
+
[source,terminal]
----
$ oc -n my-namespace label secret secrets-store-creds secrets-store.csi.k8s.io/used=true
----

. Create a secret provider class to define your secrets store provider:

.. Create a YAML file that defines the `SecretProviderClass` object:
+
.Example `secret-provider-class-azure.yaml`
[source,yaml]
----
apiVersion: secrets-store.csi.x-k8s.io/v1
kind: SecretProviderClass
metadata:
  name: my-azure-provider                 <1>
  namespace: my-namespace                 <2>
spec:
  provider: azure                         <3>
  parameters:                             <4>
    usePodIdentity: "false"
    useVMManagedIdentity: "false"
    userAssignedIdentityID: ""
    keyvaultName: "kvname"
    objects: |
      array:
        - |
          objectName: secret1
          objectType: secret
    tenantId: "tid"
----
<1> Specify the name for the secret provider class.
<2> Specify the namespace for the secret provider class.
<3> Specify the provider as `azure`.
<4> Specify the provider-specific configuration parameters.

.. Create the `SecretProviderClass` object by running the following command:
+
[source,terminal]
----
$ oc create -f secret-provider-class-azure.yaml
----

. Create a deployment to use this secret provider class:

.. Create a YAML file that defines the `Deployment` object:
+
.Example `deployment.yaml`
[source,yaml]
----
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-azure-deployment                            <1>
  namespace: my-namespace                              <2>
spec:
  replicas: 1
  selector:
    matchLabels:
      app: my-storage
  template:
    metadata:
      labels:
        app: my-storage
    spec:
      containers:
      - name: busybox
        image: k8s.gcr.io/e2e-test-images/busybox:1.29
        command:
          - "/bin/sleep"
          - "10000"
        volumeMounts:
        - name: secrets-store-inline
          mountPath: "/mnt/secrets-store"
          readOnly: true
      volumes:
        - name: secrets-store-inline
          csi:
            driver: secrets-store.csi.k8s.io
            readOnly: true
            volumeAttributes:
              secretProviderClass: "my-azure-provider" <3>
            nodePublishSecretRef:
              name: secrets-store-creds                <4>
----
<1> Specify the name for the deployment.
<2> Specify the namespace for the deployment. This must be the same namespace as the secret provider class.
<3> Specify the name of the secret provider class.
<4> Specify the name of the Kubernetes secret that contains the service principal credentials to access Azure Key Vault.

.. Create the `Deployment` object by running the following command:
+
[source,terminal]
----
$ oc create -f deployment.yaml
----

.Verification

* Verify that you can access the secrets from Azure Key Vault in the pod volume mount:

.. List the secrets in the pod mount:
+
[source,terminal]
----
$ oc exec busybox-<hash> -n my-namespace -- ls /mnt/secrets-store/
----
+
.Example output
[source,terminal]
----
secret1
----

.. View a secret in the pod mount:
+
[source,terminal]
----
$ oc exec busybox-<hash> -n my-namespace -- cat /mnt/secrets-store/secret1
----
+
.Example output
[source,terminal]
----
my-secret-value
----

:leveloffset!:

// Enabling synchronization of mounted content as Kubernetes secrets
:leveloffset: +1

// Module included in the following assemblies:
//
// * nodes/pods/nodes-pods-secrets-store.adoc

:_mod-docs-content-type: PROCEDURE
[id="secrets-store-sync-secrets_{context}"]
= Enabling synchronization of mounted content as Kubernetes secrets

You can enable synchronization to create Kubernetes secrets from the content on a mounted volume. An example where you might want to enable synchronization is to use an environment variable in your deployment to reference the Kubernetes secret.

[WARNING]
====
Do not enable synchronization if you do not want to store your secrets on your {product-title} cluster and in etcd. Enable this functionality only if you require it, such as when you want to use environment variables to refer to the secret.
====

If you enable synchronization, the secrets from the mounted volume are synchronized as Kubernetes secrets after you start a pod that mounts the secrets.

The synchronized Kubernetes secret is deleted when all pods that mounted the content are deleted.

.Prerequisites

* You have installed the {secrets-store-operator}.
* You have installed a secrets store provider.
* You have created the secret provider class.
* You have access to the cluster as a user with the `cluster-admin` role.

.Procedure

. Edit the `SecretProviderClass` resource by running the following command:
+
[source,terminal]
----
$ oc edit secretproviderclass my-azure-provider <1>
----
<1> Replace `my-azure-provider` with the name of your secret provider class.

. Add the `secretsObjects` section with the configuration for the synchronized Kubernetes secrets:
+
[source,yaml]
----
apiVersion: secrets-store.csi.x-k8s.io/v1
kind: SecretProviderClass
metadata:
  name: my-azure-provider
  namespace: my-namespace
spec:
  provider: azure
  secretObjects:                                   <1>
    - secretName: tlssecret                        <2>
      type: kubernetes.io/tls                      <3>
      labels:
        environment: "test"
      data:
        - objectName: tlskey                       <4>
          key: tls.key                             <5>
        - objectName: tlscrt
          key: tls.crt
  parameters:
    usePodIdentity: "false"
    keyvaultName: "kvname"
    objects:  |
      array:
        - |
          objectName: tlskey
          objectType: secret
        - |
          objectName: tlscrt
          objectType: secret
    tenantId: "tid"
----
<1> Specify the configuration for synchronized Kubernetes secrets.
<2> Specify the name of the Kubernetes `Secret` object to create.
<3> Specify the type of Kubernetes `Secret` object to create. For example, `Opaque` or `kubernetes.io/tls`.
<4> Specify the object name or alias of the mounted content to synchronize.
<5> Specify the data field from the specified `objectName` to populate the Kubernetes secret with.

. Save the file to apply the changes.

:leveloffset!:

// Viewing the status of secrets in the pod volume mount
:leveloffset: +1

// Module included in the following assemblies:
//
// * nodes/pods/nodes-pods-secrets-store.adoc

:_mod-docs-content-type: PROCEDURE
[id="secrets-store-viewing-secret-versions_{context}"]
= Viewing the status of secrets in the pod volume mount

You can view detailed information, including the versions, of the secrets in the pod volume mount.

The {secrets-store-operator} creates a `SecretProviderClassPodStatus` resource in the same namespace as the pod. You can review this resource to see detailed information, including versions, about the secrets in the pod volume mount.

.Prerequisites

* You have installed the {secrets-store-operator}.
* You have installed a secrets store provider.
* You have created the secret provider class.
* You have deployed a pod that mounts a volume from the {secrets-store-operator}.
* You have access to the cluster as a user with the `cluster-admin` role.

.Procedure

* View detailed information about the secrets in a pod volume mount by running the following command:
+
[source,terminal]
----
$ oc get secretproviderclasspodstatus <secret_provider_class_pod_status_name> -o yaml <1>
----
<1> The name of the secret provider class pod status object is in the format of `<pod_name>-<namespace>-<secret_provider_class_name>`.
+
.Example output
[source,terminal]
----
...
status:
  mounted: true
  objects:
  - id: secret/tlscrt
    version: f352293b97da4fa18d96a9528534cb33
  - id: secret/tlskey
    version: 02534bc3d5df481cb138f8b2a13951ef
  podName: busybox-<hash>
  secretProviderClassName: my-azure-provider
  targetPath: /var/lib/kubelet/pods/f0d49c1e-c87a-4beb-888f-37798456a3e7/volumes/kubernetes.io~csi/secrets-store-inline/mount
----

:leveloffset!:

// Uninstalling the {secrets-store-operator}
:leveloffset: +1

// Module included in the following assemblies:
//
// * storage/container_storage_interface/persistent-storage-csi-secrets-store.adoc
//

:_mod-docs-content-type: PROCEDURE
[id="persistent-storage-csi-secrets-store-driver-uninstall_{context}"]
= Uninstalling the {secrets-store-operator}

.Prerequisites
* Access to the {product-title} web console.

* Administrator access to the cluster.

.Procedure

To uninstall the {secrets-store-operator}:

. Stop all application pods that use the `secrets-store.csi.k8s.io` provider.
. Remove any third-party provider plug-in for your chosen secret store.
. Remove the Container Storage Interface (CSI) driver and associated manifests:
.. Click *Administration* â†’ *CustomResourceDefinitions* â†’ *ClusterCSIDriver*.
.. On the *Instances* tab, for *secrets-store.csi.k8s.io*, on the far left side, click the drop-down menu, and then click *Delete ClusterCSIDriver*.
.. When prompted, click *Delete*.
. Verify that the CSI driver pods are no longer running.
. Uninstall the {secrets-store-operator}:
+
[NOTE]
====
Before you can uninstall the Operator, you must remove the CSI driver first.
====
+
.. Click *Operators* â†’ *Installed Operators*.
.. On the *Installed Operators* page, scroll or type "Secrets Store CSI" into the *Search by name* box to find the Operator, and then click it.
.. On the upper, right of the *Installed Operators* > *Operator details* page, click *Actions* â†’ *Uninstall Operator*.
.. When prompted on the *Uninstall Operator* window, click the *Uninstall* button to remove the Operator from the namespace. Any applications deployed by the Operator on the cluster need to be cleaned up manually.
+
After uninstalling, the {secrets-store-operator} is no longer listed in the *Installed Operators* section of the web console.

:leveloffset!:

//# includes=_attributes/common-attributes,snippets/technology-preview,modules/persistent-storage-csi-secrets-store-driver-overview,modules/secrets-store-providers,modules/secrets-store-auto-rotation,modules/persistent-storage-csi-secrets-store-driver-install,modules/secrets-store-aws,modules/secrets-store-azure,modules/secrets-store-sync-secrets,modules/secrets-store-viewing-secret-versions,modules/persistent-storage-csi-secrets-store-driver-uninstall
