:_mod-docs-content-type: ASSEMBLY
:context: nodes-cluster-limit-ranges
[id="nodes-cluster-limit-ranges"]
= Restrict resource consumption with limit ranges
// The {product-title} attribute provides the context-sensitive name of the relevant OpenShift distribution, for example, "OpenShift Container Platform" or "OKD". The {product-version} attribute provides the product version relative to the distribution, for example "4.9".
// {product-title} and {product-version} are parsed when AsciiBinder queries the _distro_map.yml file in relation to the base branch of a pull request.
// See https://github.com/openshift/openshift-docs/blob/main/contributing_to_docs/doc_guidelines.adoc#product-name-and-version for more information on this topic.
// Other common attributes are defined in the following lines:
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:imagesdir: images
:prewrap!:
:op-system-first: Red Hat Enterprise Linux CoreOS (RHCOS)
:op-system: RHCOS
:op-system-lowercase: rhcos
:op-system-base: RHEL
:op-system-base-full: Red Hat Enterprise Linux (RHEL)
:op-system-version: 8.x
:tsb-name: Template Service Broker
:kebab: image:kebab.png[title="Options menu"]
:rh-openstack-first: Red Hat OpenStack Platform (RHOSP)
:rh-openstack: RHOSP
:ai-full: Assisted Installer
:ai-version: 2.3
:cluster-manager-first: Red Hat OpenShift Cluster Manager
:cluster-manager: OpenShift Cluster Manager
:cluster-manager-url: link:https://console.redhat.com/openshift[OpenShift Cluster Manager Hybrid Cloud Console]
:cluster-manager-url-pull: link:https://console.redhat.com/openshift/install/pull-secret[pull secret from the Red Hat OpenShift Cluster Manager]
:insights-advisor-url: link:https://console.redhat.com/openshift/insights/advisor/[Insights Advisor]
:hybrid-console: Red Hat Hybrid Cloud Console
:hybrid-console-second: Hybrid Cloud Console
:oadp-first: OpenShift API for Data Protection (OADP)
:oadp-full: OpenShift API for Data Protection
:oc-first: pass:quotes[OpenShift CLI (`oc`)]
:product-registry: OpenShift image registry
:rh-storage-first: Red Hat OpenShift Data Foundation
:rh-storage: OpenShift Data Foundation
:rh-rhacm-first: Red Hat Advanced Cluster Management (RHACM)
:rh-rhacm: RHACM
:rh-rhacm-version: 2.8
:sandboxed-containers-first: OpenShift sandboxed containers
:sandboxed-containers-operator: OpenShift sandboxed containers Operator
:sandboxed-containers-version: 1.3
:sandboxed-containers-version-z: 1.3.3
:sandboxed-containers-legacy-version: 1.3.2
:cert-manager-operator: cert-manager Operator for Red Hat OpenShift
:secondary-scheduler-operator-full: Secondary Scheduler Operator for Red Hat OpenShift
:secondary-scheduler-operator: Secondary Scheduler Operator
// Backup and restore
:velero-domain: velero.io
:velero-version: 1.11
:launch: image:app-launcher.png[title="Application Launcher"]
:mtc-short: MTC
:mtc-full: Migration Toolkit for Containers
:mtc-version: 1.8
:mtc-version-z: 1.8.0
// builds (Valid only in 4.11 and later)
:builds-v2title: Builds for Red Hat OpenShift
:builds-v2shortname: OpenShift Builds v2
:builds-v1shortname: OpenShift Builds v1
//gitops
:gitops-title: Red Hat OpenShift GitOps
:gitops-shortname: GitOps
:gitops-ver: 1.1
:rh-app-icon: image:red-hat-applications-menu-icon.jpg[title="Red Hat applications"]
//pipelines
:pipelines-title: Red Hat OpenShift Pipelines
:pipelines-shortname: OpenShift Pipelines
:pipelines-ver: pipelines-1.12
:pipelines-version-number: 1.12
:tekton-chains: Tekton Chains
:tekton-hub: Tekton Hub
:artifact-hub: Artifact Hub
:pac: Pipelines as Code
//odo
:odo-title: odo
//OpenShift Kubernetes Engine
:oke: OpenShift Kubernetes Engine
//OpenShift Platform Plus
:opp: OpenShift Platform Plus
//openshift virtualization (cnv)
:VirtProductName: OpenShift Virtualization
:VirtVersion: 4.14
:KubeVirtVersion: v0.59.0
:HCOVersion: 4.14.0
:CNVNamespace: openshift-cnv
:CNVOperatorDisplayName: OpenShift Virtualization Operator
:CNVSubscriptionSpecSource: redhat-operators
:CNVSubscriptionSpecName: kubevirt-hyperconverged
:delete: image:delete.png[title="Delete"]
//distributed tracing
:DTProductName: Red Hat OpenShift distributed tracing platform
:DTShortName: distributed tracing platform
:DTProductVersion: 2.9
:JaegerName: Red Hat OpenShift distributed tracing platform (Jaeger)
:JaegerShortName: distributed tracing platform (Jaeger)
:JaegerVersion: 1.47.0
:OTELName: Red Hat OpenShift distributed tracing data collection
:OTELShortName: distributed tracing data collection
:OTELOperator: Red Hat OpenShift distributed tracing data collection Operator
:OTELVersion: 0.81.0
:TempoName: Red Hat OpenShift distributed tracing platform (Tempo)
:TempoShortName: distributed tracing platform (Tempo)
:TempoOperator: Tempo Operator
:TempoVersion: 2.1.1
//logging
:logging-title: logging subsystem for Red Hat OpenShift
:logging-title-uc: Logging subsystem for Red Hat OpenShift
:logging: logging subsystem
:logging-uc: Logging subsystem
//serverless
:ServerlessProductName: OpenShift Serverless
:ServerlessProductShortName: Serverless
:ServerlessOperatorName: OpenShift Serverless Operator
:FunctionsProductName: OpenShift Serverless Functions
//service mesh v2
:product-dedicated: Red Hat OpenShift Dedicated
:product-rosa: Red Hat OpenShift Service on AWS
:SMProductName: Red Hat OpenShift Service Mesh
:SMProductShortName: Service Mesh
:SMProductVersion: 2.4.4
:MaistraVersion: 2.4
//Service Mesh v1
:SMProductVersion1x: 1.1.18.2
//Windows containers
:productwinc: Red Hat OpenShift support for Windows Containers
// Red Hat Quay Container Security Operator
:rhq-cso: Red Hat Quay Container Security Operator
// Red Hat Quay
:quay: Red Hat Quay
:sno: single-node OpenShift
:sno-caps: Single-node OpenShift
//TALO and Redfish events Operators
:cgu-operator-first: Topology Aware Lifecycle Manager (TALM)
:cgu-operator-full: Topology Aware Lifecycle Manager
:cgu-operator: TALM
:redfish-operator: Bare Metal Event Relay
//Formerly known as CodeReady Containers and CodeReady Workspaces
:openshift-local-productname: Red Hat OpenShift Local
:openshift-dev-spaces-productname: Red Hat OpenShift Dev Spaces
// Factory-precaching-cli tool
:factory-prestaging-tool: factory-precaching-cli tool
:factory-prestaging-tool-caps: Factory-precaching-cli tool
:openshift-networking: Red Hat OpenShift Networking
// TODO - this probably needs to be different for OKD
//ifdef::openshift-origin[]
//:openshift-networking: OKD Networking
//endif::[]
// logical volume manager storage
:lvms-first: Logical volume manager storage (LVM Storage)
:lvms: LVM Storage
//Operator SDK version
:osdk_ver: 1.31.0
//Operator SDK version that shipped with the previous OCP 4.x release
:osdk_ver_n1: 1.28.0
//Next-gen (OCP 4.14+) Operator Lifecycle Manager, aka "v1"
:olmv1: OLM 1.0
:olmv1-first: Operator Lifecycle Manager (OLM) 1.0
:ztp-first: GitOps Zero Touch Provisioning (ZTP)
:ztp: GitOps ZTP
:3no: three-node OpenShift
:3no-caps: Three-node OpenShift
:run-once-operator: Run Once Duration Override Operator
// Web terminal
:web-terminal-op: Web Terminal Operator
:devworkspace-op: DevWorkspace Operator
:secrets-store-driver: Secrets Store CSI driver
:secrets-store-operator: Secrets Store CSI Driver Operator
//AWS STS
:sts-first: Security Token Service (STS)
:sts-full: Security Token Service
:sts-short: STS
//Cloud provider names
//AWS
:aws-first: Amazon Web Services (AWS)
:aws-full: Amazon Web Services
:aws-short: AWS
//GCP
:gcp-first: Google Cloud Platform (GCP)
:gcp-full: Google Cloud Platform
:gcp-short: GCP
//alibaba cloud
:alibaba: Alibaba Cloud
// IBM Cloud VPC
:ibmcloudVPCProductName: IBM Cloud VPC
:ibmcloudVPCRegProductName: IBM(R) Cloud VPC
// IBM Cloud
:ibm-cloud-bm: IBM Cloud Bare Metal (Classic)
:ibm-cloud-bm-reg: IBM Cloud(R) Bare Metal (Classic)
// IBM Power
:ibmpowerProductName: IBM Power
:ibmpowerRegProductName: IBM(R) Power
// IBM zSystems
:ibmzProductName: IBM Z
:ibmzRegProductName: IBM(R) Z
:linuxoneProductName: IBM(R) LinuxONE
//Azure
:azure-full: Microsoft Azure
:azure-short: Azure
//vSphere
:vmw-full: VMware vSphere
:vmw-short: vSphere
//Oracle
:oci-first: Oracle(R) Cloud Infrastructure
:oci: OCI
:ocvs-first: Oracle(R) Cloud VMware Solution (OCVS)
:ocvs: OCVS

toc::[]


By default, containers run with unbounded compute resources on an {product-title}
cluster. With limit ranges, you can restrict resource consumption for specific
objects in a project:

* pods and containers: You can set minimum and maximum requirements for CPU and
memory for pods and their containers.
* Image streams: You can set limits on the number of images and tags in an
`ImageStream` object.
* Images: You can limit the size of images that can be pushed to an internal
registry.
* Persistent volume claims (PVC): You can restrict the size of the PVCs that can
be requested.

If a pod does not meet the constraints imposed by the limit
range, the pod cannot be created in the namespace.

// The following include statements pull in the module files that comprise
// the assembly. Include any combination of concept, procedure, or reference
// modules required to cover the user story. You can also include other
// assemblies.


:leveloffset: +1

// Module included in the following assemblies:
//
// * nodes/cluster/limit-ranges.adoc

:_mod-docs-content-type: CONCEPT
[id="nodes-cluster-limit-ranges-about_{context}"]
= About limit ranges

A limit range, defined by a `LimitRange` object, restricts resource
consumption in a project. In the project you can set specific resource
limits for a pod, container, image, image stream, or
persistent volume claim (PVC).

All requests to create and modify resources are evaluated against each
`LimitRange` object in the project. If the resource violates any of the
enumerated constraints, the resource is rejected.


The following shows a limit range object for all components: pod, container,
image, image stream, or PVC. You can configure limits for any or all of these
components in the same object. You create a different limit range object for
each project where you want to control resources.

.Sample limit range object for a container

[source,yaml]
----
apiVersion: "v1"
kind: "LimitRange"
metadata:
  name: "resource-limits"
spec:
  limits:
    - type: "Container"
      max:
        cpu: "2"
        memory: "1Gi"
      min:
        cpu: "100m"
        memory: "4Mi"
      default:
        cpu: "300m"
        memory: "200Mi"
      defaultRequest:
        cpu: "200m"
        memory: "100Mi"
      maxLimitRequestRatio:
        cpu: "10"
----

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
//
// * nodes/cluster/limit-ranges.adoc

:_mod-docs-content-type: CONCEPT
[id="nodes-cluster-limit-ranges-limits_{context}"]
= About component limits

The following examples show limit range parameters for each component. The
examples are broken out for clarity. You can create a single `LimitRange` object
for any or all components as necessary.

[id="nodes-cluster-limit-container-limits"]
== Container limits

A limit range allows you to specify the minimum and maximum CPU and memory that each container
in a pod can request for a specific project. If a container is created in the project,
the container CPU and memory requests in the `Pod` spec must comply with the values set in the
`LimitRange` object. If not, the pod does not get created.

* The container CPU or memory request and limit must be greater than or equal to the
`min` resource constraint for containers that are specified in the `LimitRange` object.

* The container CPU or memory request and limit must be less than or equal to the
`max` resource constraint for containers that are specified in the `LimitRange` object.
+
If the `LimitRange` object defines a `max` CPU, you do not need to define a CPU
`request` value in the `Pod` spec. But you must specify a CPU `limit` value that
satisfies the maximum CPU constraint specified in the limit range.

* The ratio of the container limits to requests must be
less than or equal to the `maxLimitRequestRatio` value for containers that
is specified in the `LimitRange` object.
+
If the `LimitRange` object defines a `maxLimitRequestRatio` constraint, any new
containers must have both a `request` and a `limit` value. {product-title}
calculates the limit-to-request ratio by dividing the `limit` by the
`request`. This value should be a non-negative integer greater than 1.
+
For example, if a container has `cpu: 500` in the `limit` value, and
`cpu: 100` in the `request` value, the limit-to-request ratio for `cpu` is
`5`. This ratio must be less than or equal to the `maxLimitRequestRatio`.

If the `Pod` spec does not specify a container resource memory or limit,
the `default` or `defaultRequest` CPU and memory values for containers
specified in the limit range object are assigned to the container.

.Container `LimitRange` object definition

[source,yaml]
----
apiVersion: "v1"
kind: "LimitRange"
metadata:
  name: "resource-limits" <1>
spec:
  limits:
    - type: "Container"
      max:
        cpu: "2" <2>
        memory: "1Gi" <3>
      min:
        cpu: "100m" <4>
        memory: "4Mi" <5>
      default:
        cpu: "300m" <6>
        memory: "200Mi" <7>
      defaultRequest:
        cpu: "200m" <8>
        memory: "100Mi" <9>
      maxLimitRequestRatio:
        cpu: "10" <10>
----
<1> The name of the LimitRange object.
<2> The maximum amount of CPU that a single container in a pod can request.
<3> The maximum amount of memory that a single container in a pod can request.
<4> The minimum amount of CPU that a single container in a pod can request.
<5> The minimum amount of memory that a single container in a pod can request.
<6> The default amount of CPU that a container can use if not specified in the `Pod` spec.
<7> The default amount of memory that a container can use if not specified in the `Pod` spec.
<8> The default amount of CPU that a container can request if not specified in the `Pod` spec.
<9> The default amount of memory that a container can request if not specified in the `Pod` spec.
<10> The maximum limit-to-request ratio for a container.


[id="nodes-cluster-limit-pod-limits"]
== Pod limits

A limit range allows you to specify the minimum and maximum CPU and memory limits for all containers
across a pod in a given project. To create a container in the project, the container CPU and memory
requests in the `Pod` spec must comply with the values set in the `LimitRange` object. If not,
the pod does not get created.

If the `Pod` spec does not specify a container resource memory or limit,
the `default` or `defaultRequest` CPU and memory values for containers
specified in the limit range object are assigned to the container.

Across all containers in a pod, the following must hold true:

* The container CPU or memory request and limit must be greater than or equal to the
`min` resource constraints for pods that are specified in the `LimitRange` object.

* The container CPU or memory request and limit must be less than or equal to the
`max` resource constraints for pods that are specified in the `LimitRange` object.

* The ratio of the container limits to requests must be less than or equal to
the `maxLimitRequestRatio` constraint specified in the `LimitRange` object.

.Pod `LimitRange` object definition

[source,yaml]
----
apiVersion: "v1"
kind: "LimitRange"
metadata:
  name: "resource-limits" <1>
spec:
  limits:
    - type: "Pod"
      max:
        cpu: "2" <2>
        memory: "1Gi" <3>
      min:
        cpu: "200m" <4>
        memory: "6Mi" <5>
      maxLimitRequestRatio:
        cpu: "10" <6>
----
<1> The name of the limit range object.
<2> The maximum amount of CPU that a pod can request across all containers.
<3> The maximum amount of memory that a pod can request across all containers.
<4> The minimum amount of CPU that a pod can request across all containers.
<5> The minimum amount of memory that a pod can request across all containers.
<6> The maximum limit-to-request ratio for a container.

[id="nodes-cluster-limit-image-limits"]
== Image limits

A `LimitRange` object allows you to specify the maximum size of an image
that can be pushed to an {product-registry}.

When pushing images to an {product-registry}, the following must hold true:

* The size of the image must be less than or equal to the `max` size for
images that is specified in the `LimitRange` object.

.Image `LimitRange` object definition

[source,yaml]
----
apiVersion: "v1"
kind: "LimitRange"
metadata:
  name: "resource-limits" <1>
spec:
  limits:
    - type: openshift.io/Image
      max:
        storage: 1Gi <2>
----
<1> The name of the `LimitRange` object.
<2> The maximum size of an image that can be pushed to an {product-registry}.


[WARNING]
====
The image size is not always available in the manifest of an uploaded image.
This is especially the case for images built with Docker 1.10 or higher and
pushed to a v2 registry. If such an image is pulled with an older Docker daemon,
the image manifest is converted by the registry to schema v1 lacking all
the size information. No storage limit set on images prevent it from being
uploaded.

link:https://github.com/openshift/origin/issues/7706[The issue] is being
addressed.
====

[id="nodes-cluster-limit-stream-limits"]
== Image stream limits

A `LimitRange` object allows you to specify limits for image streams.

For each image stream, the following must hold true:

* The number of image tags in an `ImageStream` specification must be less
than or equal to the `openshift.io/image-tags` constraint in the `LimitRange` object.

* The number of unique references to images in an `ImageStream` specification
must be less than or equal to the `openshift.io/images` constraint in the limit
range object.

.Imagestream `LimitRange` object definition

[source,yaml]
----
apiVersion: "v1"
kind: "LimitRange"
metadata:
  name: "resource-limits" <1>
spec:
  limits:
    - type: openshift.io/ImageStream
      max:
        openshift.io/image-tags: 20 <2>
        openshift.io/images: 30 <3>
----
<1> The name of the `LimitRange` object.
<2> The maximum number of unique image tags in the `imagestream.spec.tags`
parameter in imagestream spec.
<3> The maximum number of unique image references in the `imagestream.status.tags`
parameter in the `imagestream` spec.

The `openshift.io/image-tags` resource represents unique image
references. Possible references are an `*ImageStreamTag*`, an
`*ImageStreamImage*` and a `*DockerImage*`. Tags can be created using
the `oc tag` and `oc import-image` commands. No distinction
is made between internal and external references. However, each unique reference
tagged in an `ImageStream` specification is counted just once. It does not
restrict pushes to an internal container image registry in any way, but is useful for tag
restriction.

The `openshift.io/images` resource represents unique image names recorded in
image stream status. It allows for restriction of a number of images that can be
pushed to the {product-registry}. Internal and external references are not
distinguished.

[id="nodes-cluster-limit-pvc-limits"]
== Persistent volume claim limits

A `LimitRange` object allows you to restrict the storage requested in a persistent volume claim (PVC).

Across all persistent volume claims in a project, the following must hold true:

* The resource request in a persistent volume claim (PVC) must be greater than or equal
the `min` constraint for PVCs that is specified in the `LimitRange` object.

* The resource request in a persistent volume claim (PVC) must be less than or equal
the `max` constraint for PVCs that is specified in the `LimitRange` object.

.PVC `LimitRange` object definition

[source,yaml]
----
apiVersion: "v1"
kind: "LimitRange"
metadata:
  name: "resource-limits" <1>
spec:
  limits:
    - type: "PersistentVolumeClaim"
      min:
        storage: "2Gi" <2>
      max:
        storage: "50Gi" <3>
----
<1> The name of the `LimitRange` object.
<2> The minimum amount of storage that can be requested in a persistent volume claim.
<3> The maximum amount of storage that can be requested in a persistent volume claim.

:leveloffset!:

:leveloffset: +1

// Module included in the following assemblies:
//
// * nodes/cluster/limit-ranges.adoc

[id="nodes-cluster-limit-creating_{context}"]
= Creating a Limit Range

To apply a limit range to a project:

. Create a `LimitRange` object with your required specifications:
+
[source,yaml]
----
apiVersion: "v1"
kind: "LimitRange"
metadata:
  name: "resource-limits" <1>
spec:
  limits:
    - type: "Pod" <2>
      max:
        cpu: "2"
        memory: "1Gi"
      min:
        cpu: "200m"
        memory: "6Mi"
    - type: "Container" <3>
      max:
        cpu: "2"
        memory: "1Gi"
      min:
        cpu: "100m"
        memory: "4Mi"
      default: <4>
        cpu: "300m"
        memory: "200Mi"
      defaultRequest: <5>
        cpu: "200m"
        memory: "100Mi"
      maxLimitRequestRatio: <6>
        cpu: "10"
    - type: openshift.io/Image <7>
      max:
        storage: 1Gi
    - type: openshift.io/ImageStream <8>
      max:
        openshift.io/image-tags: 20
        openshift.io/images: 30
    - type: "PersistentVolumeClaim" <9>
      min:
        storage: "2Gi"
      max:
        storage: "50Gi"
----
<1> Specify a name for the `LimitRange` object.
<2> To set limits for a pod, specify the minimum and maximum CPU and memory requests as needed.
<3> To set limits for a container, specify the minimum and maximum CPU and memory requests as needed.
<4> Optional. For a container, specify the default amount of CPU or memory that a container can use, if not specified in the `Pod` spec.
<5> Optional. For a container, specify the default amount of CPU or memory that a container can request, if not specified in the `Pod` spec.
<6> Optional. For a container, specify the maximum limit-to-request ratio that can be specified in the `Pod` spec.
<7> To set limits for an Image object, set the maximum size of an image that can be pushed to an {product-registry}.
<8> To set limits for an image stream, set the maximum number of image tags and references that can be in the `ImageStream` object file, as needed.
<9> To set limits for a persistent volume claim, set the minimum and maximum amount of storage that can be requested.

. Create the object:
+
[source,terminal]
----
$ oc create -f <limit_range_file> -n <project> <1>
----
<1> Specify the name of the YAML file you created and the project where you want the limits to apply.

:leveloffset!:

:leveloffset: +1

// Module included in the following assemblies:
//
// * nodes/cluster/limit-ranges.adoc

[id="nodes-cluster-limit-viewing_{context}"]
= Viewing a limit

You can view any limits defined in a project by navigating in the web
console to the project's *Quota* page.

You can also use the CLI to view limit range details:

. Get the list of `LimitRange` object defined in the project. For example, for a
project called *demoproject*:
+
[source,terminal]
----
$ oc get limits -n demoproject
----
+
[source,terminal]
----
NAME              CREATED AT
resource-limits   2020-07-15T17:14:23Z
----

. Describe the `LimitRange` object you are interested in, for example the
`resource-limits` limit range:
+

[source,terminal]
----
$ oc describe limits resource-limits -n demoproject
----
+

[source,terminal]
----
Name:                           resource-limits
Namespace:                      demoproject
Type                            Resource                Min     Max     Default Request Default Limit   Max Limit/Request Ratio
----                            --------                ---     ---     --------------- -------------   -----------------------
Pod                             cpu                     200m    2       -               -               -
Pod                             memory                  6Mi     1Gi     -               -               -
Container                       cpu                     100m    2       200m            300m            10
Container                       memory                  4Mi     1Gi     100Mi           200Mi           -
openshift.io/Image              storage                 -       1Gi     -               -               -
openshift.io/ImageStream        openshift.io/image      -       12      -               -               -
openshift.io/ImageStream        openshift.io/image-tags -       10      -               -               -
PersistentVolumeClaim           storage                 -       50Gi    -               -               -
----


:leveloffset!:

:leveloffset: +1

// Module included in the following assemblies:
//
// * nodes/cluster/limit-ranges.adoc

[id="nodes-cluster-limit-ranges-deleting_{context}"]
= Deleting a Limit Range


To remove any active `LimitRange` object to no longer enforce the limits in a project:

* Run the following command:
+
[source,terminal]
----
$ oc delete limits <limit_name>
----

:leveloffset!:

//# includes=_attributes/common-attributes,modules/nodes-cluster-limit-ranges-about,modules/nodes-cluster-limit-ranges-limits,modules/nodes-cluster-limit-ranges-creating,modules/nodes-cluster-limit-ranges-viewing,modules/nodes-cluster-limit-ranges-deleting
