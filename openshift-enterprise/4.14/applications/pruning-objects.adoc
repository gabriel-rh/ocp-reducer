:_mod-docs-content-type: ASSEMBLY
[id="pruning-objects"]
= Pruning objects to reclaim resources
// The {product-title} attribute provides the context-sensitive name of the relevant OpenShift distribution, for example, "OpenShift Container Platform" or "OKD". The {product-version} attribute provides the product version relative to the distribution, for example "4.9".
// {product-title} and {product-version} are parsed when AsciiBinder queries the _distro_map.yml file in relation to the base branch of a pull request.
// See https://github.com/openshift/openshift-docs/blob/main/contributing_to_docs/doc_guidelines.adoc#product-name-and-version for more information on this topic.
// Other common attributes are defined in the following lines:
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:imagesdir: images
:prewrap!:
:op-system-first: Red Hat Enterprise Linux CoreOS (RHCOS)
:op-system: RHCOS
:op-system-lowercase: rhcos
:op-system-base: RHEL
:op-system-base-full: Red Hat Enterprise Linux (RHEL)
:op-system-version: 8.x
:tsb-name: Template Service Broker
:kebab: image:kebab.png[title="Options menu"]
:rh-openstack-first: Red Hat OpenStack Platform (RHOSP)
:rh-openstack: RHOSP
:ai-full: Assisted Installer
:ai-version: 2.3
:cluster-manager-first: Red Hat OpenShift Cluster Manager
:cluster-manager: OpenShift Cluster Manager
:cluster-manager-url: link:https://console.redhat.com/openshift[OpenShift Cluster Manager Hybrid Cloud Console]
:cluster-manager-url-pull: link:https://console.redhat.com/openshift/install/pull-secret[pull secret from the Red Hat OpenShift Cluster Manager]
:insights-advisor-url: link:https://console.redhat.com/openshift/insights/advisor/[Insights Advisor]
:hybrid-console: Red Hat Hybrid Cloud Console
:hybrid-console-second: Hybrid Cloud Console
:oadp-first: OpenShift API for Data Protection (OADP)
:oadp-full: OpenShift API for Data Protection
:oc-first: pass:quotes[OpenShift CLI (`oc`)]
:product-registry: OpenShift image registry
:rh-storage-first: Red Hat OpenShift Data Foundation
:rh-storage: OpenShift Data Foundation
:rh-rhacm-first: Red Hat Advanced Cluster Management (RHACM)
:rh-rhacm: RHACM
:rh-rhacm-version: 2.8
:sandboxed-containers-first: OpenShift sandboxed containers
:sandboxed-containers-operator: OpenShift sandboxed containers Operator
:sandboxed-containers-version: 1.3
:sandboxed-containers-version-z: 1.3.3
:sandboxed-containers-legacy-version: 1.3.2
:cert-manager-operator: cert-manager Operator for Red Hat OpenShift
:secondary-scheduler-operator-full: Secondary Scheduler Operator for Red Hat OpenShift
:secondary-scheduler-operator: Secondary Scheduler Operator
// Backup and restore
:velero-domain: velero.io
:velero-version: 1.11
:launch: image:app-launcher.png[title="Application Launcher"]
:mtc-short: MTC
:mtc-full: Migration Toolkit for Containers
:mtc-version: 1.8
:mtc-version-z: 1.8.0
// builds (Valid only in 4.11 and later)
:builds-v2title: Builds for Red Hat OpenShift
:builds-v2shortname: OpenShift Builds v2
:builds-v1shortname: OpenShift Builds v1
//gitops
:gitops-title: Red Hat OpenShift GitOps
:gitops-shortname: GitOps
:gitops-ver: 1.1
:rh-app-icon: image:red-hat-applications-menu-icon.jpg[title="Red Hat applications"]
//pipelines
:pipelines-title: Red Hat OpenShift Pipelines
:pipelines-shortname: OpenShift Pipelines
:pipelines-ver: pipelines-1.12
:pipelines-version-number: 1.12
:tekton-chains: Tekton Chains
:tekton-hub: Tekton Hub
:artifact-hub: Artifact Hub
:pac: Pipelines as Code
//odo
:odo-title: odo
//OpenShift Kubernetes Engine
:oke: OpenShift Kubernetes Engine
//OpenShift Platform Plus
:opp: OpenShift Platform Plus
//openshift virtualization (cnv)
:VirtProductName: OpenShift Virtualization
:VirtVersion: 4.14
:KubeVirtVersion: v0.59.0
:HCOVersion: 4.14.0
:CNVNamespace: openshift-cnv
:CNVOperatorDisplayName: OpenShift Virtualization Operator
:CNVSubscriptionSpecSource: redhat-operators
:CNVSubscriptionSpecName: kubevirt-hyperconverged
:delete: image:delete.png[title="Delete"]
//distributed tracing
:DTProductName: Red Hat OpenShift distributed tracing platform
:DTShortName: distributed tracing platform
:DTProductVersion: 2.9
:JaegerName: Red Hat OpenShift distributed tracing platform (Jaeger)
:JaegerShortName: distributed tracing platform (Jaeger)
:JaegerVersion: 1.47.0
:OTELName: Red Hat OpenShift distributed tracing data collection
:OTELShortName: distributed tracing data collection
:OTELOperator: Red Hat OpenShift distributed tracing data collection Operator
:OTELVersion: 0.81.0
:TempoName: Red Hat OpenShift distributed tracing platform (Tempo)
:TempoShortName: distributed tracing platform (Tempo)
:TempoOperator: Tempo Operator
:TempoVersion: 2.1.1
//logging
:logging-title: logging subsystem for Red Hat OpenShift
:logging-title-uc: Logging subsystem for Red Hat OpenShift
:logging: logging subsystem
:logging-uc: Logging subsystem
//serverless
:ServerlessProductName: OpenShift Serverless
:ServerlessProductShortName: Serverless
:ServerlessOperatorName: OpenShift Serverless Operator
:FunctionsProductName: OpenShift Serverless Functions
//service mesh v2
:product-dedicated: Red Hat OpenShift Dedicated
:product-rosa: Red Hat OpenShift Service on AWS
:SMProductName: Red Hat OpenShift Service Mesh
:SMProductShortName: Service Mesh
:SMProductVersion: 2.4.4
:MaistraVersion: 2.4
//Service Mesh v1
:SMProductVersion1x: 1.1.18.2
//Windows containers
:productwinc: Red Hat OpenShift support for Windows Containers
// Red Hat Quay Container Security Operator
:rhq-cso: Red Hat Quay Container Security Operator
// Red Hat Quay
:quay: Red Hat Quay
:sno: single-node OpenShift
:sno-caps: Single-node OpenShift
//TALO and Redfish events Operators
:cgu-operator-first: Topology Aware Lifecycle Manager (TALM)
:cgu-operator-full: Topology Aware Lifecycle Manager
:cgu-operator: TALM
:redfish-operator: Bare Metal Event Relay
//Formerly known as CodeReady Containers and CodeReady Workspaces
:openshift-local-productname: Red Hat OpenShift Local
:openshift-dev-spaces-productname: Red Hat OpenShift Dev Spaces
// Factory-precaching-cli tool
:factory-prestaging-tool: factory-precaching-cli tool
:factory-prestaging-tool-caps: Factory-precaching-cli tool
:openshift-networking: Red Hat OpenShift Networking
// TODO - this probably needs to be different for OKD
//ifdef::openshift-origin[]
//:openshift-networking: OKD Networking
//endif::[]
// logical volume manager storage
:lvms-first: Logical volume manager storage (LVM Storage)
:lvms: LVM Storage
//Operator SDK version
:osdk_ver: 1.31.0
//Operator SDK version that shipped with the previous OCP 4.x release
:osdk_ver_n1: 1.28.0
//Next-gen (OCP 4.14+) Operator Lifecycle Manager, aka "v1"
:olmv1: OLM 1.0
:olmv1-first: Operator Lifecycle Manager (OLM) 1.0
:ztp-first: GitOps Zero Touch Provisioning (ZTP)
:ztp: GitOps ZTP
:3no: three-node OpenShift
:3no-caps: Three-node OpenShift
:run-once-operator: Run Once Duration Override Operator
// Web terminal
:web-terminal-op: Web Terminal Operator
:devworkspace-op: DevWorkspace Operator
:secrets-store-driver: Secrets Store CSI driver
:secrets-store-operator: Secrets Store CSI Driver Operator
//AWS STS
:sts-first: Security Token Service (STS)
:sts-full: Security Token Service
:sts-short: STS
//Cloud provider names
//AWS
:aws-first: Amazon Web Services (AWS)
:aws-full: Amazon Web Services
:aws-short: AWS
//GCP
:gcp-first: Google Cloud Platform (GCP)
:gcp-full: Google Cloud Platform
:gcp-short: GCP
//alibaba cloud
:alibaba: Alibaba Cloud
// IBM Cloud VPC
:ibmcloudVPCProductName: IBM Cloud VPC
:ibmcloudVPCRegProductName: IBM(R) Cloud VPC
// IBM Cloud
:ibm-cloud-bm: IBM Cloud Bare Metal (Classic)
:ibm-cloud-bm-reg: IBM Cloud(R) Bare Metal (Classic)
// IBM Power
:ibmpowerProductName: IBM Power
:ibmpowerRegProductName: IBM(R) Power
// IBM zSystems
:ibmzProductName: IBM Z
:ibmzRegProductName: IBM(R) Z
:linuxoneProductName: IBM(R) LinuxONE
//Azure
:azure-full: Microsoft Azure
:azure-short: Azure
//vSphere
:vmw-full: VMware vSphere
:vmw-short: vSphere
//Oracle
:oci-first: Oracle(R) Cloud Infrastructure
:oci: OCI
:ocvs-first: Oracle(R) Cloud VMware Solution (OCVS)
:ocvs: OCVS
:context: pruning-objects

toc::[]

Over time, API objects created in {product-title} can accumulate in the
cluster's etcd data store through normal user operations, such as when building
and deploying applications.

Cluster administrators can periodically prune older versions of objects from the
cluster that are no longer required. For example, by pruning images you can delete
older images and layers that are no longer in use, but are still taking up disk
space.

:leveloffset: +1

// Module included in the following assemblies:
//
// * applications/pruning-objects.adoc

[id="pruning-basic-operations_{context}"]
= Basic pruning operations

The CLI groups prune operations under a common parent command:

[source,terminal]
----
$ oc adm prune <object_type> <options>
----

This specifies:

- The `<object_type>` to perform the action on, such as `groups`, `builds`,
`deployments`, or `images`.
- The `<options>` supported to prune that object type.

:leveloffset!:
:leveloffset: +1

// Module included in the following assemblies:
//
// * applications/pruning-objects.adoc

:_mod-docs-content-type: PROCEDURE
[id="pruning-groups_{context}"]
= Pruning groups

To prune groups records from an external provider, administrators can run the
following command:

[source,terminal]
----
$ oc adm prune groups \
    --sync-config=path/to/sync/config [<options>]
----

.`oc adm prune groups` flags
[cols="4,8",options="header"]
|===

|Options |Description

.^|`--confirm`
|Indicate that pruning should occur, instead of performing a dry-run.

.^|`--blacklist`
|Path to the group blacklist file.

.^|`--whitelist`
|Path to the group whitelist file.

.^|`--sync-config`
|Path to the synchronization configuration file.
|===

.Procedure

. To see the groups that the prune command deletes, run the following command:
+
[source,terminal]
----
$ oc adm prune groups --sync-config=ldap-sync-config.yaml
----

. To perform the prune operation, add the `--confirm` flag:
+
[source,terminal]
----
$ oc adm prune groups --sync-config=ldap-sync-config.yaml --confirm
----

////
Needs "Additional resources" links when converted:

//Future xref:../install_config/syncing_groups_with_ldap.adoc#configuring-ldap-sync[Configuring LDAP Sync]
//Future xref:../install_config/syncing_groups_with_ldap.adoc#overview[Syncing Groups With LDAP]
////

:leveloffset!:
:leveloffset: +1

// Module included in the following assemblies:
//
// * applications/pruning-objects.adoc

:_mod-docs-content-type: PROCEDURE
[id="pruning-deployments_{context}"]
= Pruning deployment resources

You can prune resources associated with deployments that are no longer required by the system, due to age and status.

The following command prunes replication controllers associated with `DeploymentConfig` objects:

[source,terminal]
----
$ oc adm prune deployments [<options>]
----

[NOTE]
====
To also prune replica sets associated with `Deployment` objects, use the `--replica-sets` flag. This flag is currently a Technology Preview feature.
====

.`oc adm prune deployments` flags
[cols="4,8a",options="header"]
|===

|Option |Description

.^|`--confirm`
|Indicate that pruning should occur, instead of performing a dry-run.

.^|`--keep-complete=<N>`
|Per the `DeploymentConfig` object, keep the last `N` replication controllers that have a status of `Complete` and replica count of zero. The default is `5`.

.^|`--keep-failed=<N>`
|Per the `DeploymentConfig` object, keep the last `N` replication controllers that have a status of `Failed` and replica count of zero. The default is `1`.

.^|`--keep-younger-than=<duration>`
|Do not prune any replication controller that is younger than `<duration>` relative to the current time. Valid units of measurement include nanoseconds (`ns`), microseconds (`us`), milliseconds (`ms`), seconds (`s`), minutes (`m`), and hours (`h`). The default is `60m`.

.^|`--orphans`
|Prune all replication controllers that no longer have a `DeploymentConfig` object, has status of `Complete` or `Failed`, and has a replica count of zero.

.^|`--replica-sets=true\|false`
|If `true`, replica sets are included in the pruning process. The default is `false`.

[IMPORTANT]
====
This flag is a Technology Preview feature.
====
|===

.Procedure

. To see what a pruning operation would delete, run the following command:
+
[source,terminal]
----
$ oc adm prune deployments --orphans --keep-complete=5 --keep-failed=1 \
    --keep-younger-than=60m
----

. To actually perform the prune operation, add the `--confirm` flag:
+
[source,terminal]
----
$ oc adm prune deployments --orphans --keep-complete=5 --keep-failed=1 \
    --keep-younger-than=60m --confirm
----

:leveloffset!:
:leveloffset: +1

// Module included in the following assemblies:
//
// * applications/pruning-objects.adoc

:_mod-docs-content-type: PROCEDURE
[id="pruning-builds_{context}"]
= Pruning builds

To prune builds that are no longer required by the system due to age and status, administrators can run the following command:

[source,terminal]
----
$ oc adm prune builds [<options>]
----

.`oc adm prune builds` flags
[cols="4,8",options="header"]
|===

|Option |Description

.^|`--confirm`
|Indicate that pruning should occur, instead of performing a dry-run.

.^|`--orphans`
|Prune all builds whose build configuration no longer exists, status is complete, failed, error, or canceled.

.^|`--keep-complete=<N>`
|Per build configuration, keep the last `N` builds whose status is complete. The default is `5`.

.^|`--keep-failed=<N>`
|Per build configuration, keep the last `N` builds whose status is failed, error, or canceled. The default is `1`.

.^|`--keep-younger-than=<duration>`
|Do not prune any object that is younger than `<duration>` relative to the current time. The default is `60m`.
|===

.Procedure

. To see what a pruning operation would delete, run the following command:
+
[source,terminal]
----
$ oc adm prune builds --orphans --keep-complete=5 --keep-failed=1 \
    --keep-younger-than=60m
----

. To actually perform the prune operation, add the `--confirm` flag:
+
[source,terminal]
----
$ oc adm prune builds --orphans --keep-complete=5 --keep-failed=1 \
    --keep-younger-than=60m --confirm
----

[NOTE]
====
Developers can enable automatic build pruning by modifying their build configuration.
====

:leveloffset!:

[role="_additional-resources"]
.Additional resources
* xref:../cicd/builds/advanced-build-operations.adoc#builds-build-pruning-advanced-build-operations[Performing advanced builds -> Pruning builds]

:leveloffset: +1

// Module included in the following assemblies:
//
// * applications/pruning-objects.adoc

:_mod-docs-content-type: PROCEDURE
[id="pruning-images_{context}"]
= Automatically pruning images

Images from the {product-registry} that are no longer required by the system due to age, status, or exceed limits are automatically pruned. Cluster administrators can configure the Pruning Custom Resource, or suspend it.

.Prerequisites

* Cluster administrator permissions.
* Install the `oc` CLI.

.Procedure

* Verify that the object named `imagepruners.imageregistry.operator.openshift.io/cluster` contains the following `spec` and `status` fields:

[source,yaml]
----
spec:
  schedule: 0 0 * * * <1>
  suspend: false <2>
  keepTagRevisions: 3 <3>
  keepYoungerThanDuration: 60m <4>
  keepYoungerThan: 3600000000000 <5>
  resources: {} <6>
  affinity: {} <7>
  nodeSelector: {} <8>
  tolerations: [] <9>
  successfulJobsHistoryLimit: 3 <10>
  failedJobsHistoryLimit: 3 <11>
status:
  observedGeneration: 2 <12>
  conditions: <13>
  - type: Available
    status: "True"
    lastTransitionTime: 2019-10-09T03:13:45
    reason: Ready
    message: "Periodic image pruner has been created."
  - type: Scheduled
    status: "True"
    lastTransitionTime: 2019-10-09T03:13:45
    reason: Scheduled
    message: "Image pruner job has been scheduled."
  - type: Failed
    staus: "False"
    lastTransitionTime: 2019-10-09T03:13:45
    reason: Succeeded
    message: "Most recent image pruning job succeeded."
----
<1> `schedule`: `CronJob` formatted schedule. This is an optional field, default is daily at midnight.
<2> `suspend`: If set to `true`, the `CronJob` running pruning is suspended. This is an optional field, default is `false`. The initial value on new clusters is `false`.
<3> `keepTagRevisions`: The number of revisions per tag to keep. This is an optional field, default is `3`. The initial value is `3`.
<4> `keepYoungerThanDuration`: Retain images younger than this duration. This is an optional field. If a value is not specified, either `keepYoungerThan` or the default value `60m` (60 minutes) is used.
<5> `keepYoungerThan`: Deprecated. The same as `keepYoungerThanDuration`, but the duration is specified as an integer in nanoseconds. This is an optional field. When `keepYoungerThanDuration` is set, this field is ignored.
<6> `resources`: Standard pod resource requests and limits. This is an optional field.
<7> `affinity`: Standard pod affinity. This is an optional field.
<8> `nodeSelector`: Standard pod node selector. This is an optional field.
<9> `tolerations`: Standard pod tolerations. This is an optional field.
<10> `successfulJobsHistoryLimit`: The maximum number of successful jobs to retain. Must be `>= 1` to ensure metrics are reported. This is an optional field, default is `3`. The initial value is `3`.
<11> `failedJobsHistoryLimit`: The maximum number of failed jobs to retain. Must be `>= 1` to ensure metrics are reported. This is an optional field, default is `3`. The initial value is `3`.
<12> `observedGeneration`: The generation observed by the Operator.
<13> `conditions`: The standard condition objects with the following types:
* `Available`: Indicates if the pruning job has been created. Reasons can be Ready or Error.
* `Scheduled`: Indicates if the next pruning job has been scheduled. Reasons can be Scheduled, Suspended, or Error.
* `Failed`: Indicates if the most recent pruning job failed.


[IMPORTANT]
====
The Image Registry Operator's behavior for managing the pruner is orthogonal to the `managementState` specified on the Image Registry Operator's `ClusterOperator` object. If the Image Registry Operator is not in the `Managed` state, the image pruner can still be configured and managed by the Pruning Custom Resource.

However, the `managementState` of the Image Registry Operator alters the behavior of the deployed image pruner job:

* `Managed`: the `--prune-registry` flag for the image pruner is set to `true`.
* `Removed`: the `--prune-registry` flag for the image pruner is set to `false`, meaning it only prunes image metatdata in etcd.
====

:leveloffset!:
:leveloffset: +1

// Module included in the following assemblies:
//
// * applications/pruning-objects.adoc

:_mod-docs-content-type: PROCEDURE
[id="pruning-images-manual_{context}"]
= Manually pruning images

The pruning custom resource enables automatic image pruning for the images from the {product-registry}. However, administrators can manually prune images that are no longer required by the system due to age, status, or exceed limits. There are two methods to manually prune images:

* Running image pruning as a `Job` or `CronJob` on the cluster.
* Running the `oc adm prune images` command.

.Prerequisites

* To prune images, you must first log in to the CLI as a user with an access token. The user must also have the `system:image-pruner` cluster role or greater (for example, `cluster-admin`).
* Expose the image registry.

.Procedure

To manually prune images that are no longer required by the system due to age, status, or exceed limits, use one of the following methods:

* Run image pruning as a `Job` or `CronJob` on the cluster by creating a YAML file for the `pruner` service account, for example:
+
[source,terminal]
----
$ oc create -f <filename>.yaml
----
+
.Example output
+
[source,yaml]
----
kind: List
apiVersion: v1
items:
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: pruner
    namespace: openshift-image-registry
- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    name: openshift-image-registry-pruner
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:image-pruner
  subjects:
  - kind: ServiceAccount
    name: pruner
    namespace: openshift-image-registry
- apiVersion: batch/v1
  kind: CronJob
  metadata:
    name: image-pruner
    namespace: openshift-image-registry
  spec:
    schedule: "0 0 * * *"
    concurrencyPolicy: Forbid
    successfulJobsHistoryLimit: 1
    failedJobsHistoryLimit: 3
    jobTemplate:
      spec:
        template:
          spec:
            restartPolicy: OnFailure
            containers:
            - image: "quay.io/openshift/origin-cli:4.1"
              resources:
                requests:
                  cpu: 1
                  memory: 1Gi
              terminationMessagePolicy: FallbackToLogsOnError
              command:
              - oc
              args:
              - adm
              - prune
              - images
              - --certificate-authority=/var/run/secrets/kubernetes.io/serviceaccount/service-ca.crt
              - --keep-tag-revisions=5
              - --keep-younger-than=96h
              - --confirm=true
              name: image-pruner
            serviceAccountName: pruner
----

* Run the `oc adm prune images [<options>]` command:
+
[source,terminal]
----
$ oc adm prune images [<options>]
----
+
Pruning images removes data from the integrated registry unless `--prune-registry=false` is used.
+
Pruning images with the `--namespace` flag does not remove images, only image streams. Images are non-namespaced resources. Therefore, limiting pruning to a particular namespace makes it impossible to calculate its current usage.
+
By default, the integrated registry caches metadata of blobs to reduce the number of requests to storage, and to increase the request-processing speed. Pruning does not update the integrated registry cache. Images that still contain pruned layers after pruning will be broken because the pruned layers that have metadata in the cache will not be pushed. Therefore, you must redeploy the registry to clear the cache after pruning:
+
[source,terminal]
----
$ oc rollout restart deployment/image-registry -n openshift-image-registry
----
+
If the integrated registry uses a Redis cache, you must clean the database manually.
+
If redeploying the registry after pruning is not an option, then you must permanently disable the cache.
+
`oc adm prune images` operations require a route for your registry. Registry routes are not created by default.
+
The *Prune images CLI configuration options* table describes the options you can use with the `oc adm prune images <options>` command.
+
.Prune images CLI configuration options
[cols="4,8",options="header"]
|===

|Option |Description

.^|`--all`
|Include images that were not pushed to the registry, but have been mirrored by
pullthrough. This is on by default. To limit the pruning to images that were
pushed to the integrated registry, pass `--all=false`.

.^|`--certificate-authority`
|The path to a certificate authority file to use when communicating with the
{product-title}-managed registries. Defaults to the certificate authority data
from the current user's configuration file. If provided, a secure connection is
initiated.

.^|`--confirm`
|Indicate that pruning should occur, instead of performing a test-run. This
requires a valid route to the integrated container image registry. If this
command is run outside of the cluster network, the route must be provided
using `--registry-url`.

.^|`--force-insecure`
|Use caution with this option. Allow an insecure connection to the container
registry that is hosted via HTTP or has an invalid HTTPS certificate.

.^|`--keep-tag-revisions=<N>`
|For each imagestream, keep up to at most `N` image revisions per tag (default
`3`).

.^|`--keep-younger-than=<duration>`
|Do not prune any image that is younger than `<duration>` relative to the
current time. Alternately, do not prune any image that is referenced by any other object that
is younger than `<duration>` relative to the current time (default `60m`).

.^|`--prune-over-size-limit`
|Prune each image that exceeds the smallest limit defined in the same project.
This flag cannot be combined with `--keep-tag-revisions` nor
`--keep-younger-than`.

.^|`--registry-url`
|The address to use when contacting the registry. The command attempts to use a
cluster-internal URL determined from managed images and image streams. In case
it fails (the registry cannot be resolved or reached), an alternative route that
works needs to be provided using this flag. The registry hostname can be
prefixed by `https://` or `http://`, which enforces particular connection
protocol.

.^|`--prune-registry`
|In conjunction with the conditions stipulated by the other options, this option
controls whether the data in the registry corresponding to the {product-title}
image API object is pruned. By default, image pruning processes both the image
API objects and corresponding data in the registry.

This option is useful when you are only concerned with removing etcd content, to reduce the number of image objects but are not concerned with cleaning up registry storage, or if you intend to do that separately by hard pruning the registry during an appropriate maintenance window for the registry.
|===

[id="pruning-images-conditions_{context}"]
== Image prune conditions

You can apply conditions to your manually pruned images.

* To remove any image managed by {product-title}, or images with the annotation `openshift.io/image.managed`:
** Created at least `--keep-younger-than` minutes ago and are not currently referenced by any:
*** Pods created less than `--keep-younger-than` minutes ago
*** Image streams created less than `--keep-younger-than` minutes ago
*** Running pods
*** Pending pods
*** Replication controllers
*** Deployments
*** Deployment configs
*** Replica sets
*** Build configurations
*** Builds
*** `--keep-tag-revisions` most recent items in `stream.status.tags[].items`
** That are exceeding the smallest limit defined in the same project and are not currently referenced by any:
*** Running pods
*** Pending pods
*** Replication controllers
*** Deployments
*** Deployment configs
*** Replica sets
*** Build configurations
*** Builds
* There is no support for pruning from external registries.
* When an image is pruned, all references to the image are removed from all
image streams that have a reference to the image in `status.tags`.
* Image layers that are no longer referenced by any images are removed.

[NOTE]
====
The `--prune-over-size-limit` flag cannot be combined with the `--keep-tag-revisions` flag nor the `--keep-younger-than` flags. Doing so returns
information that this operation is not allowed.
====

Separating the removal of {product-title} image API objects and image data from the registry by using `--prune-registry=false`, followed by hard pruning the registry, can narrow timing windows and is safer when compared to trying to prune both through one command. However, timing windows are not completely removed.

For example, you can still create a pod referencing an image as pruning identifies that image for pruning. You should still keep track of an API object created during the pruning operations that might reference images so that you can mitigate any references to deleted content.

Re-doing the pruning without the `--prune-registry` option or with `--prune-registry=true` does not lead to pruning the associated storage in the image registry for images previously pruned by `--prune-registry=false`. Any images that were pruned with `--prune-registry=false` can only be deleted from registry storage by hard pruning the registry.

[id="pruning-images-running-operation_{context}"]
== Running the image prune operation

.Procedure

. To see what a pruning operation would delete:

.. Keeping up to three tag revisions, and keeping resources (images, image streams, and pods) younger than 60 minutes:
+
[source,terminal]
----
$ oc adm prune images --keep-tag-revisions=3 --keep-younger-than=60m
----

.. Pruning every image that exceeds defined limits:
+
[source,terminal]
----
$ oc adm prune images --prune-over-size-limit
----

. To perform the prune operation with the options from the previous step:
+
[source,terminal]
----
$ oc adm prune images --keep-tag-revisions=3 --keep-younger-than=60m --confirm
----
+
[source,terminal]
----
$ oc adm prune images --prune-over-size-limit --confirm
----

[id="pruning-images-secure-insecure_{context}"]
== Using secure or insecure connections

The secure connection is the preferred and recommended approach. It is done over
HTTPS protocol with a mandatory certificate verification. The `prune` command
always attempts to use it if possible. If it is not possible, in some cases it
can fall-back to insecure connection, which is dangerous. In this case, either
certificate verification is skipped or plain HTTP protocol is used.

The fall-back to insecure connection is allowed in the following cases unless
`--certificate-authority` is specified:

. The `prune` command is run with the `--force-insecure` option.
. The provided `registry-url` is prefixed with the `http://` scheme.
. The provided `registry-url` is a local-link address or `localhost`.
. The configuration of the current user allows for an insecure connection. This
can be caused by the user either logging in using `--insecure-skip-tls-verify`
or choosing the insecure connection when prompted.

[IMPORTANT]
====
If the registry is secured by a certificate authority different from the one used by {product-title}, it must be specified using the
`--certificate-authority` flag. Otherwise, the `prune` command fails with an error.
====

[id="pruning-images-problems_{context}"]
== Image pruning problems

[discrete]
[id="pruning-images-not-being-pruned_{context}"]
==== Images not being pruned

If your images keep accumulating and the `prune` command removes just a small
portion of what you expect, ensure that you understand the image prune
conditions that must apply for an image to be considered a candidate for
pruning.

Ensure that images you want removed occur at higher positions in each tag
history than your chosen tag revisions threshold. For example, consider an old
and obsolete image named `sha256:abz`. By running the following command in your
namespace, where the image is tagged, the image is tagged three times in a
single image stream named `myapp`:

[source,terminal]
----
$ oc get is -n <namespace> -o go-template='{{range $isi, $is := .items}}{{range $ti, $tag := $is.status.tags}}'\
'{{range $ii, $item := $tag.items}}{{if eq $item.image "sha256:<hash>"}}{{$is.metadata.name}}:{{$tag.tag}} at position {{$ii}} out of {{len $tag.items}}\n'\
'{{end}}{{end}}{{end}}{{end}}'
----

.Example output
[source,terminal]
----
myapp:v2 at position 4 out of 5
myapp:v2.1 at position 2 out of 2
myapp:v2.1-may-2016 at position 0 out of 1
----

When default options are used, the image is never pruned because it occurs at
position `0` in a history of `myapp:v2.1-may-2016` tag. For an image to be
considered for pruning, the administrator must either:

* Specify `--keep-tag-revisions=0` with the `oc adm prune images` command.
+
[WARNING]
====
This action removes all the tags from all the namespaces with underlying images, unless they are younger or they are referenced by objects younger than the specified threshold.
====

* Delete all the `istags` where the position is below the revision threshold,
which means `myapp:v2.1` and `myapp:v2.1-may-2016`.

* Move the image further in the history, either by running new builds pushing to
the same `istag`, or by tagging other image. This is not always
desirable for old release tags.

Tags having a date or time of a particular image's build in their names should
be avoided, unless the image must be preserved for an undefined amount of time.
Such tags tend to have just one image in their history, which prevents
them from ever being pruned.

[discrete]
[id="pruning-images-secure-against-insecure_{context}"]
==== Using a secure connection against insecure registry

If you see a message similar to the following in the output of the `oc adm prune images`
command, then your registry is not secured and the `oc adm prune images`
client attempts to use a secure connection:

[source,terminal]
----
error: error communicating with registry: Get https://172.30.30.30:5000/healthz: http: server gave HTTP response to HTTPS client
----

* The recommended solution is to secure the registry. Otherwise, you can force the
client to use an insecure connection by appending `--force-insecure`  to the
command; however, this is not recommended.

[discrete]
[id="pruning-images-insecure-against-secure_{context}"]
==== Using an insecure connection against a secured registry

If you see one of the following errors in the output of the `oc adm prune images`
command, it means that your registry is secured using a certificate signed by a
certificate authority other than the one used by `oc adm prune images` client for
connection verification:

[source,terminal]
----
error: error communicating with registry: Get http://172.30.30.30:5000/healthz: malformed HTTP response "\x15\x03\x01\x00\x02\x02"
error: error communicating with registry: [Get https://172.30.30.30:5000/healthz: x509: certificate signed by unknown authority, Get http://172.30.30.30:5000/healthz: malformed HTTP response "\x15\x03\x01\x00\x02\x02"]
----

By default, the certificate authority data stored in the user's configuration files is used; the same is true for communication with the master API.

Use the `--certificate-authority` option to provide the right certificate authority for the container image registry server.

[discrete]
[id="pruning-images-wrong-ca_{context}"]
==== Using the wrong certificate authority

The following error means that the certificate authority used to sign the certificate of the secured container image registry is different from the authority used by the client:

[source,terminal]
----
error: error communicating with registry: Get https://172.30.30.30:5000/: x509: certificate signed by unknown authority
----

Make sure to provide the right one with the flag `--certificate-authority`.

As a workaround, the `--force-insecure` flag can be added instead. However, this is not recommended.

:leveloffset!:

[role="_additional-resources"]
.Additional resources
* xref:../registry/accessing-the-registry.adoc#accessing-the-registry[Accessing the registry]
* xref:../registry/securing-exposing-registry.adoc#securing-exposing-registry[Exposing the registry]
* See
xref:../registry/configuring-registry-operator.adoc#configuring-registry-operator[Image
Registry Operator in {product-title}] for information on how to create a
registry route.

:leveloffset: +1

// Module included in the following assemblies:
//
// * applications/pruning-objects.adoc

:_mod-docs-content-type: PROCEDURE
[id="pruning-hard-pruning-registry_{context}"]
= Hard pruning the registry

The OpenShift Container Registry can accumulate blobs that are not referenced by
the {product-title} cluster's etcd. The basic pruning images procedure,
therefore, is unable to operate on them. These are called _orphaned blobs_.

Orphaned blobs can occur from the following scenarios:

- Manually deleting an image with `oc delete image <sha256:image-id>` command,
which only removes the image from etcd, but not from the registry's storage.

- Pushing to the registry initiated by daemon failures, which causes some blobs to
get uploaded, but the image manifest (which is uploaded as the very last
component) does not. All unique image blobs become orphans.

- {product-title} refusing an image because of quota restrictions.

- The standard image pruner deleting an image manifest, but is interrupted before
it deletes the related blobs.

- A bug in the registry pruner, which fails to remove the intended blobs, causing
the image objects referencing them to be removed and the blobs becoming orphans.
// Find this BZ

_Hard pruning_ the registry, a separate procedure from basic image pruning,
allows cluster administrators to remove orphaned blobs. You should hard prune if
you are running out of storage space in your OpenShift Container Registry and
believe you have orphaned blobs.

This should be an infrequent operation and is necessary only when you have
evidence that significant numbers of new orphans have been created. Otherwise,
you can perform standard image pruning at regular intervals, for example, once a
day (depending on the number of images being created).

.Procedure

To hard prune orphaned blobs from the registry:

. *Log in.*
+
Log in to the cluster with the CLI as `kubeadmin` or another privileged user that
has access to the `openshift-image-registry` namespace.

. *Run a basic image prune*.
+
Basic image pruning removes additional images that are no longer needed. The
hard prune does not remove images on its own. It only removes blobs stored in
the registry storage. Therefore, you should run this just before the hard prune.

. *Switch the registry to read-only mode.*
+
If the registry is not running in read-only mode, any pushes happening at the
same time as the prune will either:
+
--
- fail and cause new orphans, or
- succeed although the images cannot be pulled (because some of the
referenced blobs were deleted).
--
+
Pushes will not succeed until the registry is switched back to read-write mode.
Therefore, the hard prune must be carefully scheduled.
+
To switch the registry to read-only mode:

.. In `configs.imageregistry.operator.openshift.io/cluster`, set `spec.readOnly` to `true`:
+
[source,terminal]
----
$ oc patch configs.imageregistry.operator.openshift.io/cluster -p '{"spec":{"readOnly":true}}' --type=merge
----

. *Add the `system:image-pruner` role.*
+
The service account used to run the registry instances requires additional
permissions to list some resources.

.. Get the service account name:
+
[source,terminal]
----
$ service_account=$(oc get -n openshift-image-registry \
    -o jsonpath='{.spec.template.spec.serviceAccountName}' deploy/image-registry)
----

.. Add the `system:image-pruner` cluster role to the service account:
+
[source,terminal]
----
$ oc adm policy add-cluster-role-to-user \
    system:image-pruner -z \
    ${service_account} -n openshift-image-registry
----

. *Optional: Run the pruner in dry-run mode.*
+
To see how many blobs would be removed, run the hard pruner in dry-run mode. No changes are actually made. The following example references an image registry pod called `image-registry-3-vhndw`:
+
[source,terminal]
----
$ oc -n openshift-image-registry exec pod/image-registry-3-vhndw -- /bin/sh -c '/usr/bin/dockerregistry -prune=check'
----
+
Alternatively, to get the exact paths for the prune candidates, increase the
logging level:
+
[source,terminal]
----
$ oc -n openshift-image-registry exec pod/image-registry-3-vhndw -- /bin/sh -c 'REGISTRY_LOG_LEVEL=info /usr/bin/dockerregistry -prune=check'
----
+
.Example output
[source,terminal]
----
time="2017-06-22T11:50:25.066156047Z" level=info msg="start prune (dry-run mode)" distribution_version="v2.4.1+unknown" kubernetes_version=v1.6.1+$Format:%h$ openshift_version=unknown
time="2017-06-22T11:50:25.092257421Z" level=info msg="Would delete blob: sha256:00043a2a5e384f6b59ab17e2c3d3a3d0a7de01b2cabeb606243e468acc663fa5" go.version=go1.7.5 instance.id=b097121c-a864-4e0c-ad6c-cc25f8fdf5a6
time="2017-06-22T11:50:25.092395621Z" level=info msg="Would delete blob: sha256:0022d49612807cb348cabc562c072ef34d756adfe0100a61952cbcb87ee6578a" go.version=go1.7.5 instance.id=b097121c-a864-4e0c-ad6c-cc25f8fdf5a6
time="2017-06-22T11:50:25.092492183Z" level=info msg="Would delete blob: sha256:0029dd4228961086707e53b881e25eba0564fa80033fbbb2e27847a28d16a37c" go.version=go1.7.5 instance.id=b097121c-a864-4e0c-ad6c-cc25f8fdf5a6
time="2017-06-22T11:50:26.673946639Z" level=info msg="Would delete blob: sha256:ff7664dfc213d6cc60fd5c5f5bb00a7bf4a687e18e1df12d349a1d07b2cf7663" go.version=go1.7.5 instance.id=b097121c-a864-4e0c-ad6c-cc25f8fdf5a6
time="2017-06-22T11:50:26.674024531Z" level=info msg="Would delete blob: sha256:ff7a933178ccd931f4b5f40f9f19a65be5eeeec207e4fad2a5bafd28afbef57e" go.version=go1.7.5 instance.id=b097121c-a864-4e0c-ad6c-cc25f8fdf5a6
time="2017-06-22T11:50:26.674675469Z" level=info msg="Would delete blob: sha256:ff9b8956794b426cc80bb49a604a0b24a1553aae96b930c6919a6675db3d5e06" go.version=go1.7.5 instance.id=b097121c-a864-4e0c-ad6c-cc25f8fdf5a6
...
Would delete 13374 blobs
Would free up 2.835 GiB of disk space
Use -prune=delete to actually delete the data
----

. *Run the hard prune.*
+
Execute the following command inside one running instance of a `image-registry` pod to run the hard prune. The following example references an image registry pod called `image-registry-3-vhndw`:
+
[source,terminal]
----
$ oc -n openshift-image-registry exec pod/image-registry-3-vhndw -- /bin/sh -c '/usr/bin/dockerregistry -prune=delete'
----
+
.Example output
[source,terminal]
----
Deleted 13374 blobs
Freed up 2.835 GiB of disk space
----

. *Switch the registry back to read-write mode.*
+
After the prune is finished, the registry can be switched back to read-write
mode. In `configs.imageregistry.operator.openshift.io/cluster`, set
`spec.readOnly` to `false`:
+
[source,terminal]
----
$ oc patch configs.imageregistry.operator.openshift.io/cluster -p '{"spec":{"readOnly":false}}' --type=merge
----

:leveloffset!:
:leveloffset: +1

// Module included in the following assemblies:
//
// * applications/pruning-objects.adoc

[id="pruning-cronjobs_{context}"]
= Pruning cron jobs

Cron jobs can perform pruning of successful jobs, but might not properly handle
failed jobs. Therefore, the cluster administrator should perform regular cleanup of
jobs manually. They should also restrict the access to cron jobs to a small
group of trusted users and set appropriate quota to prevent the cron job from
creating too many jobs and pods.

:leveloffset!:

[role="_additional-resources"]
.Additional resources
* xref:../nodes/jobs/nodes-nodes-jobs.adoc#nodes-nodes-jobs_nodes-nodes-jobs[Running tasks in pods using jobs]
* xref:../applications/quotas/quotas-setting-across-multiple-projects.adoc#setting-quotas-across-multiple-projects[Resource quotas across multiple projects]
* xref:../authentication/using-rbac.adoc#using-rbac[Using RBAC to define and apply permissions]

//# includes=_attributes/common-attributes,modules/pruning-basic-operations,modules/pruning-groups,modules/pruning-deployments,modules/pruning-builds,modules/pruning-images,modules/pruning-images-manual,modules/pruning-hard-pruning-registry,modules/pruning-cronjobs
