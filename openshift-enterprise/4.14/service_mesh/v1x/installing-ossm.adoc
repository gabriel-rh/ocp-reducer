:_mod-docs-content-type: ASSEMBLY
[id="installing-ossm-v1x"]
= Installing Service Mesh
// The {product-title} attribute provides the context-sensitive name of the relevant OpenShift distribution, for example, "OpenShift Container Platform" or "OKD". The {product-version} attribute provides the product version relative to the distribution, for example "4.9".
// {product-title} and {product-version} are parsed when AsciiBinder queries the _distro_map.yml file in relation to the base branch of a pull request.
// See https://github.com/openshift/openshift-docs/blob/main/contributing_to_docs/doc_guidelines.adoc#product-name-and-version for more information on this topic.
// Other common attributes are defined in the following lines:
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:imagesdir: images
:prewrap!:
:op-system-first: Red Hat Enterprise Linux CoreOS (RHCOS)
:op-system: RHCOS
:op-system-lowercase: rhcos
:op-system-base: RHEL
:op-system-base-full: Red Hat Enterprise Linux (RHEL)
:op-system-version: 8.x
:tsb-name: Template Service Broker
:kebab: image:kebab.png[title="Options menu"]
:rh-openstack-first: Red Hat OpenStack Platform (RHOSP)
:rh-openstack: RHOSP
:ai-full: Assisted Installer
:ai-version: 2.3
:cluster-manager-first: Red Hat OpenShift Cluster Manager
:cluster-manager: OpenShift Cluster Manager
:cluster-manager-url: link:https://console.redhat.com/openshift[OpenShift Cluster Manager Hybrid Cloud Console]
:cluster-manager-url-pull: link:https://console.redhat.com/openshift/install/pull-secret[pull secret from the Red Hat OpenShift Cluster Manager]
:insights-advisor-url: link:https://console.redhat.com/openshift/insights/advisor/[Insights Advisor]
:hybrid-console: Red Hat Hybrid Cloud Console
:hybrid-console-second: Hybrid Cloud Console
:oadp-first: OpenShift API for Data Protection (OADP)
:oadp-full: OpenShift API for Data Protection
:oc-first: pass:quotes[OpenShift CLI (`oc`)]
:product-registry: OpenShift image registry
:rh-storage-first: Red Hat OpenShift Data Foundation
:rh-storage: OpenShift Data Foundation
:rh-rhacm-first: Red Hat Advanced Cluster Management (RHACM)
:rh-rhacm: RHACM
:rh-rhacm-version: 2.8
:sandboxed-containers-first: OpenShift sandboxed containers
:sandboxed-containers-operator: OpenShift sandboxed containers Operator
:sandboxed-containers-version: 1.3
:sandboxed-containers-version-z: 1.3.3
:sandboxed-containers-legacy-version: 1.3.2
:cert-manager-operator: cert-manager Operator for Red Hat OpenShift
:secondary-scheduler-operator-full: Secondary Scheduler Operator for Red Hat OpenShift
:secondary-scheduler-operator: Secondary Scheduler Operator
// Backup and restore
:velero-domain: velero.io
:velero-version: 1.11
:launch: image:app-launcher.png[title="Application Launcher"]
:mtc-short: MTC
:mtc-full: Migration Toolkit for Containers
:mtc-version: 1.8
:mtc-version-z: 1.8.0
// builds (Valid only in 4.11 and later)
:builds-v2title: Builds for Red Hat OpenShift
:builds-v2shortname: OpenShift Builds v2
:builds-v1shortname: OpenShift Builds v1
//gitops
:gitops-title: Red Hat OpenShift GitOps
:gitops-shortname: GitOps
:gitops-ver: 1.1
:rh-app-icon: image:red-hat-applications-menu-icon.jpg[title="Red Hat applications"]
//pipelines
:pipelines-title: Red Hat OpenShift Pipelines
:pipelines-shortname: OpenShift Pipelines
:pipelines-ver: pipelines-1.12
:pipelines-version-number: 1.12
:tekton-chains: Tekton Chains
:tekton-hub: Tekton Hub
:artifact-hub: Artifact Hub
:pac: Pipelines as Code
//odo
:odo-title: odo
//OpenShift Kubernetes Engine
:oke: OpenShift Kubernetes Engine
//OpenShift Platform Plus
:opp: OpenShift Platform Plus
//openshift virtualization (cnv)
:VirtProductName: OpenShift Virtualization
:VirtVersion: 4.14
:KubeVirtVersion: v0.59.0
:HCOVersion: 4.14.0
:CNVNamespace: openshift-cnv
:CNVOperatorDisplayName: OpenShift Virtualization Operator
:CNVSubscriptionSpecSource: redhat-operators
:CNVSubscriptionSpecName: kubevirt-hyperconverged
:delete: image:delete.png[title="Delete"]
//distributed tracing
:DTProductName: Red Hat OpenShift distributed tracing platform
:DTShortName: distributed tracing platform
:DTProductVersion: 2.9
:JaegerName: Red Hat OpenShift distributed tracing platform (Jaeger)
:JaegerShortName: distributed tracing platform (Jaeger)
:JaegerVersion: 1.47.0
:OTELName: Red Hat OpenShift distributed tracing data collection
:OTELShortName: distributed tracing data collection
:OTELOperator: Red Hat OpenShift distributed tracing data collection Operator
:OTELVersion: 0.81.0
:TempoName: Red Hat OpenShift distributed tracing platform (Tempo)
:TempoShortName: distributed tracing platform (Tempo)
:TempoOperator: Tempo Operator
:TempoVersion: 2.1.1
//logging
:logging-title: logging subsystem for Red Hat OpenShift
:logging-title-uc: Logging subsystem for Red Hat OpenShift
:logging: logging subsystem
:logging-uc: Logging subsystem
//serverless
:ServerlessProductName: OpenShift Serverless
:ServerlessProductShortName: Serverless
:ServerlessOperatorName: OpenShift Serverless Operator
:FunctionsProductName: OpenShift Serverless Functions
//service mesh v2
:product-dedicated: Red Hat OpenShift Dedicated
:product-rosa: Red Hat OpenShift Service on AWS
:SMProductName: Red Hat OpenShift Service Mesh
:SMProductShortName: Service Mesh
:SMProductVersion: 2.4.4
:MaistraVersion: 2.4
//Service Mesh v1
:SMProductVersion1x: 1.1.18.2
//Windows containers
:productwinc: Red Hat OpenShift support for Windows Containers
// Red Hat Quay Container Security Operator
:rhq-cso: Red Hat Quay Container Security Operator
// Red Hat Quay
:quay: Red Hat Quay
:sno: single-node OpenShift
:sno-caps: Single-node OpenShift
//TALO and Redfish events Operators
:cgu-operator-first: Topology Aware Lifecycle Manager (TALM)
:cgu-operator-full: Topology Aware Lifecycle Manager
:cgu-operator: TALM
:redfish-operator: Bare Metal Event Relay
//Formerly known as CodeReady Containers and CodeReady Workspaces
:openshift-local-productname: Red Hat OpenShift Local
:openshift-dev-spaces-productname: Red Hat OpenShift Dev Spaces
// Factory-precaching-cli tool
:factory-prestaging-tool: factory-precaching-cli tool
:factory-prestaging-tool-caps: Factory-precaching-cli tool
:openshift-networking: Red Hat OpenShift Networking
// TODO - this probably needs to be different for OKD
//ifdef::openshift-origin[]
//:openshift-networking: OKD Networking
//endif::[]
// logical volume manager storage
:lvms-first: Logical volume manager storage (LVM Storage)
:lvms: LVM Storage
//Operator SDK version
:osdk_ver: 1.31.0
//Operator SDK version that shipped with the previous OCP 4.x release
:osdk_ver_n1: 1.28.0
//Next-gen (OCP 4.14+) Operator Lifecycle Manager, aka "v1"
:olmv1: OLM 1.0
:olmv1-first: Operator Lifecycle Manager (OLM) 1.0
:ztp-first: GitOps Zero Touch Provisioning (ZTP)
:ztp: GitOps ZTP
:3no: three-node OpenShift
:3no-caps: Three-node OpenShift
:run-once-operator: Run Once Duration Override Operator
// Web terminal
:web-terminal-op: Web Terminal Operator
:devworkspace-op: DevWorkspace Operator
:secrets-store-driver: Secrets Store CSI driver
:secrets-store-operator: Secrets Store CSI Driver Operator
//AWS STS
:sts-first: Security Token Service (STS)
:sts-full: Security Token Service
:sts-short: STS
//Cloud provider names
//AWS
:aws-first: Amazon Web Services (AWS)
:aws-full: Amazon Web Services
:aws-short: AWS
//GCP
:gcp-first: Google Cloud Platform (GCP)
:gcp-full: Google Cloud Platform
:gcp-short: GCP
//alibaba cloud
:alibaba: Alibaba Cloud
// IBM Cloud VPC
:ibmcloudVPCProductName: IBM Cloud VPC
:ibmcloudVPCRegProductName: IBM(R) Cloud VPC
// IBM Cloud
:ibm-cloud-bm: IBM Cloud Bare Metal (Classic)
:ibm-cloud-bm-reg: IBM Cloud(R) Bare Metal (Classic)
// IBM Power
:ibmpowerProductName: IBM Power
:ibmpowerRegProductName: IBM(R) Power
// IBM zSystems
:ibmzProductName: IBM Z
:ibmzRegProductName: IBM(R) Z
:linuxoneProductName: IBM(R) LinuxONE
//Azure
:azure-full: Microsoft Azure
:azure-short: Azure
//vSphere
:vmw-full: VMware vSphere
:vmw-short: vSphere
//Oracle
:oci-first: Oracle(R) Cloud Infrastructure
:oci: OCI
:ocvs-first: Oracle(R) Cloud VMware Solution (OCVS)
:ocvs: OCVS
:context: installing-ossm-v1x

toc::[]

// Text snippet included in all Service Mesh v1 assemblies.
// NOTE: The OpenShift docs standards state that snippets should NOT contain xrefs.   https://github.com/openshift/openshift-docs/blob/main/contributing_to_docs/doc_guidelines.adoc#writing-text-snippets
//Because this snippet contains two xrefs it should ONLY be used in the v1 assemblies and never in a module.

:_mod-docs-content-type: SNIPPET

[WARNING]
====
*You are viewing documentation for a {SMProductName} release that is no longer supported.*

Service Mesh version 1.0 and 1.1 control planes are no longer supported. For information about upgrading your service mesh control plane, see xref:../../service_mesh/v2x/upgrading-ossm.adoc#ossm-versions_ossm-upgrade[Upgrading Service Mesh].

For information about the support status of a particular {SMProductName} release, see the https://access.redhat.com/support/policy/updates/openshift#ossm[Product lifecycle page].
====

Installing the {SMProductShortName} involves installing the OpenShift Elasticsearch, Jaeger, Kiali and {SMProductShortName} Operators, creating and managing a `ServiceMeshControlPlane` resource to deploy the control plane, and creating a `ServiceMeshMemberRoll` resource to specify the namespaces associated with the {SMProductShortName}.

[NOTE]
====
Mixer's policy enforcement is disabled by default. You must enable it to run policy tasks. See xref:../../service_mesh/v1x/prepare-to-deploy-applications-ossm.adoc#ossm-mixer-policy-1x_deploying-applications-ossm-v1x[Update Mixer policy enforcement] for instructions on enabling Mixer policy enforcement.
====

[NOTE]
====
Multi-tenant control plane installations are the default configuration.
====

[NOTE]
====
The {SMProductShortName} documentation uses `istio-system` as the example project, but you can deploy the service mesh to any project.
====

== Prerequisites
* Follow the xref:../../service_mesh/v1x/preparing-ossm-installation.adoc#preparing-ossm-installation-v1x[Preparing to install {SMProductName}] process.
* An account with the `cluster-admin` role.

The {SMProductShortName} installation process uses the link:https://operatorhub.io/[OperatorHub] to install the `ServiceMeshControlPlane` custom resource definition within the `openshift-operators` project. The {SMProductName} defines and monitors the `ServiceMeshControlPlane` related to the deployment, update, and deletion of the control plane.

Starting with {SMProductName} {SMProductVersion1x}, you must install the OpenShift Elasticsearch Operator, the Jaeger Operator, and the Kiali Operator before the {SMProductName} Operator can install the control plane.

:leveloffset: +1

////
This module included in the following assemblies:
- distr_tracing_jaeger/distr-tracing-jaeger-installing.adoc
////

:_mod-docs-content-type: PROCEDURE
[id="distr-tracing-operator-install-elasticsearch_{context}"]
= Installing the OpenShift Elasticsearch Operator

The default {JaegerName} deployment uses in-memory storage because it is designed to be installed quickly for those evaluating {DTProductName}, giving demonstrations, or using {JaegerName} in a test environment. If you plan to use {JaegerName} in production, you must install and configure a persistent storage option, in this case, Elasticsearch.

.Prerequisites
* You have access to the {product-title} web console.
* You have access to the cluster as a user with the `cluster-admin` role. If you use {product-dedicated}, you must have an account with the `dedicated-admin` role.

[WARNING]
====
Do not install Community versions of the Operators. Community Operators are not supported.
====

[NOTE]
====
If you have already installed the OpenShift Elasticsearch Operator as part of OpenShift Logging, you do not need to install the OpenShift Elasticsearch Operator again. The {JaegerName} Operator creates the Elasticsearch instance using the installed OpenShift Elasticsearch Operator.
====

.Procedure

. Log in to the {product-title} web console as a user with the `cluster-admin` role. If you use {product-dedicated}, you must have an account with the `dedicated-admin` role.

. Navigate to *Operators* -> *OperatorHub*.

. Type *Elasticsearch* into the filter box to locate the OpenShift Elasticsearch Operator.

. Click the *OpenShift Elasticsearch Operator* provided by Red Hat to display information about the Operator.

. Click *Install*.

. On the *Install Operator* page, select the *stable* Update Channel. This automatically updates your Operator as new versions are released.

. Accept the default *All namespaces on the cluster (default)*. This installs the Operator in the default `openshift-operators-redhat` project and makes the Operator available to all projects in the cluster.
+
[NOTE]
====
The Elasticsearch installation requires the *openshift-operators-redhat* namespace for the OpenShift Elasticsearch Operator. The other {DTProductName} Operators are installed in the `openshift-operators` namespace.
====
+

. Accept the default *Automatic* approval strategy. By accepting the default, when a new version of this Operator is available, Operator Lifecycle Manager (OLM) automatically upgrades the running instance of your Operator without human intervention. If you select *Manual* updates, when a newer version of an Operator is available, OLM creates an update request. As a cluster administrator, you must then manually approve that update request to have the Operator updated to the new version.
+
[NOTE]
====
The *Manual* approval strategy requires a user with appropriate credentials to approve the Operator install and subscription process.
====

. Click *Install*.

. On the *Installed Operators* page, select the `openshift-operators-redhat` project. Wait until you see that the OpenShift Elasticsearch Operator shows a status of "InstallSucceeded" before continuing.

:leveloffset!:

:leveloffset: +1

////
This module included in the following assemblies:
- distr_tracing_jaeger/distr-tracing-jaeger-installing.adoc
////

:_mod-docs-content-type: PROCEDURE
[id="distr-tracing-jaeger-operator-install_{context}"]
= Installing the {JaegerName} Operator

To install {JaegerName}, you use the link:https://operatorhub.io/[OperatorHub] to install the {JaegerName} Operator.

By default, the Operator is installed in the `openshift-operators` project.

.Prerequisites
* You have access to the {product-title} web console.
* You have access to the cluster as a user with the `cluster-admin` role. If you use {product-dedicated}, you must have an account with the `dedicated-admin` role.
* If you require persistent storage, you must also install the OpenShift Elasticsearch Operator before installing the {JaegerName} Operator.

[WARNING]
====
Do not install Community versions of the Operators. Community Operators are not supported.
====

.Procedure

. Log in to the {product-title} web console as a user with the `cluster-admin` role. If you use {product-dedicated}, you must have an account with the `dedicated-admin` role.

. Navigate to *Operators* -> *OperatorHub*.

. Type *distributed tracing platform* into the filter to locate the {JaegerName} Operator.

. Click the *{JaegerName} Operator* provided by Red Hat to display information about the Operator.

. Click *Install*.

. On the *Install Operator* page, select the *stable* Update Channel. This automatically updates your Operator as new versions are released.
//If you select a maintenance channel, for example, *Stable*, you will receive bug fixes and security patches for the length of the support cycle for that version.

. Accept the default *All namespaces on the cluster (default)*. This installs the Operator in the default `openshift-operators` project and makes the Operator available to all projects in the cluster.

* Accept the default *Automatic* approval strategy. By accepting the default, when a new version of this Operator is available, Operator Lifecycle Manager (OLM) automatically upgrades the running instance of your Operator without human intervention. If you select *Manual* updates, when a newer version of an Operator is available, OLM creates an update request. As a cluster administrator, you must then manually approve that update request to have the Operator updated to the new version.
+
[NOTE]
====
The *Manual* approval strategy requires a user with appropriate credentials to approve the Operator install and subscription process.
====

. Click *Install*.

. Navigate to *Operators* -> *Installed Operators*.

. On the *Installed Operators* page, select the `openshift-operators` project. Wait until you see that the {JaegerName} Operator shows a status of "Succeeded" before continuing.

:leveloffset!:

:leveloffset: +1

// Module included in the following assemblies:
//
// * service_mesh/v1x/installing-ossm.adoc
// * service_mesh/v2x/installing-ossm.adoc

:_mod-docs-content-type: PROCEDURE
[id="ossm-install-kiali_{context}"]
= Installing the Kiali Operator

You must install the Kiali Operator for the {SMProductName} Operator to install the {SMProductShortName} control plane.

[WARNING]
====
Do not install Community versions of the Operators. Community Operators are not supported.
====


.Prerequisites

* Access to the {product-title} web console.

.Procedure

. Log in to the {product-title} web console.

. Navigate to *Operators* -> *OperatorHub*.

. Type *Kiali* into the filter box to find the Kiali Operator.

. Click the *Kiali Operator* provided by Red Hat to display information about the Operator.

. Click *Install*.

. On the *Operator Installation* page, select the *stable* Update Channel.

. Select *All namespaces on the cluster (default)*. This installs the Operator in the default `openshift-operators` project and makes the Operator available to all projects in the cluster.

. Select the *Automatic* Approval Strategy.
+
[NOTE]
====
The Manual approval strategy requires a user with appropriate credentials to approve the Operator install and subscription process.
====

. Click *Install*.

. The *Installed Operators* page displays the Kiali Operator's installation progress.

:leveloffset!:

:leveloffset: +1

// Module included in the following assemblies:
//
// - service_mesh/v1x/installing-ossm.adoc
// - service_mesh/v2x/installing-ossm.adoc

:_mod-docs-content-type: PROCEDURE
[id="ossm-install-ossm-operator_{context}"]
= Installing the Operators

To install {SMProductName}, install the following Operators in this order. Repeat the procedure for each Operator.

* OpenShift Elasticsearch
* {JaegerName}
* Kiali Operator provided by Red Hat
* {SMProductName}

[NOTE]
====
If you have already installed the OpenShift Elasticsearch Operator as part of OpenShift Logging, you do not need to install the OpenShift Elasticsearch Operator again. The {JaegerName} Operator will create the Elasticsearch instance using the installed OpenShift Elasticsearch Operator.
====

.Procedure

. Log in to the {product-title} web console as a user with the `cluster-admin` role. If you use {product-dedicated}, you must have an account with the `dedicated-admin` role.

. In the {product-title} web console, click *Operators* -> *OperatorHub*.

. Type the name of the Operator into the filter box and select the Red Hat version of the Operator. Community versions of the Operators are not supported.

. Click *Install*.

. On the *Install Operator* page for each Operator, accept  the default settings.

. Click *Install*. Wait until the Operator has installed before repeating the steps for the next Operator in the list.
+
* The OpenShift Elasticsearch Operator is installed in the `openshift-operators-redhat` namespace and is available for all namespaces in the cluster.
* The {JaegerName} is installed in the `openshift-distributed-tracing` namespace and is available for all namespaces in the cluster.
* The Kiali Operator provided by Red Hat and the {SMProductName} Operator are installed in the `openshift-operators` namespace and are available for all namespaces in the cluster.

. After all you have installed all four Operators, click *Operators* -> *Installed Operators* to verify that your Operators installed.

:leveloffset!:

:leveloffset: +1

// Module included in the following assemblies:
//
// * service_mesh/v1x/installing-ossm.adoc

:_mod-docs-content-type: PROCEDURE
[id="ossm-control-plane-deploy-1x_{context}"]
= Deploying the {SMProductName} control plane

////
TODO - Flesh out how multitenancy affects this, link to control plate template topic.
////

The `ServiceMeshControlPlane` resource defines the configuration to be used during installation. You can deploy the default configuration provided by Red Hat or customize the `ServiceMeshControlPlane` file to fit your business needs.

You can deploy the {SMProductShortName} control plane by using the {product-title} web console or from the command line using the `oc` client tool.

[id="ossm-control-plane-deploy-operatorhub_{context}"]
== Deploying the control plane from the web console

Follow this procedure to deploy the {SMProductName} control plane by using the web console.  In this example, `istio-system` is the name of the control plane project.

.Prerequisites

* The {SMProductName} Operator must be installed.
* Review the instructions for how to customize the {SMProductName} installation.
* An account with the `cluster-admin` role.

.Procedure

. Log in to the {product-title} web console as a user with the `cluster-admin` role.

. Create a project named `istio-system`.

.. Navigate to *Home* -> *Projects*.

.. Click *Create Project*.

.. Enter `istio-system` in the *Name* field.

.. Click *Create*.

. Navigate to *Operators* -> *Installed Operators*.

. If necessary, select `istio-system` from the Project menu.  You may have to wait a few moments for the Operators to be copied to the new project.

. Click the {SMProductName} Operator.  Under *Provided APIs*, the Operator provides links to create two resource types:
** A `ServiceMeshControlPlane` resource
** A `ServiceMeshMemberRoll` resource

. Under *Istio Service Mesh Control Plane* click *Create ServiceMeshControlPlane*.

. On the *Create Service Mesh Control Plane* page, modify the YAML for the default `ServiceMeshControlPlane` template as needed.
+
[NOTE]
====
For additional information about customizing the control plane, see customizing the {SMProductName} installation. For production, you _must_ change the default Jaeger template.
====

. Click *Create* to create the control plane.  The Operator creates pods, services, and {SMProductShortName} control plane components based on your configuration parameters.

. Click the *Istio Service Mesh Control Plane* tab.

. Click the name of the new control plane.

. Click the *Resources* tab to see the {SMProductName} control plane resources the Operator created and configured.


[id="ossm-control-plane-deploy-cli_{context}"]
== Deploying the control plane from the CLI

Follow this procedure to deploy the {SMProductName} control plane the command line.

.Prerequisites

* The {SMProductName} Operator must be installed.
* Review the instructions for how to customize the {SMProductName} installation.
* An account with the `cluster-admin` role.
* Access to the OpenShift CLI (`oc`).

.Procedure

. Log in to the {product-title} CLI as a user with the `cluster-admin` role.
+
[source,terminal]
----
$ oc login --username=<NAMEOFUSER> https://<HOSTNAME>:6443
----

. Create a project named `istio-system`.
+
[source,terminal]
----
$ oc new-project istio-system
----

. Create a `ServiceMeshControlPlane` file named `istio-installation.yaml` using the example found in "Customize the {SMProductName} installation". You can customize the values as needed to match your use case.  For production deployments you _must_ change the default Jaeger template.

. Run the following command to deploy the control plane:
+
[source,terminal]
----
$ oc create -n istio-system -f istio-installation.yaml
----
+
. Execute the following command to see the status of the control plane installation.
+
[source,terminal]
----
$ oc get smcp -n istio-system
----
+
The installation has finished successfully when the STATUS column is `ComponentsReady`.
+
----
NAME            READY   STATUS            PROFILES      VERSION   AGE
basic-install   11/11   ComponentsReady   ["default"]   v1.1.18   4m25s
----
+
. Run the following command to watch the progress of the Pods during the installation process:
+
----
$ oc get pods -n istio-system -w
----
+
You should see output similar to the following:
+
.Example output
[source,terminal]
----
NAME                                     READY   STATUS             RESTARTS   AGE
grafana-7bf5764d9d-2b2f6                 2/2     Running            0          28h
istio-citadel-576b9c5bbd-z84z4           1/1     Running            0          28h
istio-egressgateway-5476bc4656-r4zdv     1/1     Running            0          28h
istio-galley-7d57b47bb7-lqdxv            1/1     Running            0          28h
istio-ingressgateway-dbb8f7f46-ct6n5     1/1     Running            0          28h
istio-pilot-546bf69578-ccg5x             2/2     Running            0          28h
istio-policy-77fd498655-7pvjw            2/2     Running            0          28h
istio-sidecar-injector-df45bd899-ctxdt   1/1     Running            0          28h
istio-telemetry-66f697d6d5-cj28l         2/2     Running            0          28h
jaeger-896945cbc-7lqrr                   2/2     Running            0          11h
kiali-78d9c5b87c-snjzh                   1/1     Running            0          22h
prometheus-6dff867c97-gr2n5              2/2     Running            0          28h
----

:leveloffset!:

For a multitenant installation, {SMProductName} supports multiple independent control planes within the cluster.  You can create reusable configurations with `ServiceMeshControlPlane` templates.  For more information, see xref:../../service_mesh/v1x/prepare-to-deploy-applications-ossm.adoc#ossm-control-plane-templates-1x_deploying-applications-ossm-v1x[Creating control plane templates].

:leveloffset: +1

// Module included in the following assemblies:
//
// * service_mesh/v1x/installing-ossm.adoc
// * service_mesh/v2x/installing-ossm.adoc

:_mod-docs-content-type: PROCEDURE
[id="ossm-member-roll-create_{context}"]
= Creating the {SMProductName} member roll

The `ServiceMeshMemberRoll` lists the projects that belong to the {SMProductShortName} control plane. Only projects listed in the `ServiceMeshMemberRoll` are affected by the control plane. A project does not belong to a service mesh until you add it to the member roll for a particular control plane deployment.

You must create a `ServiceMeshMemberRoll` resource named `default` in the same project as the `ServiceMeshControlPlane`, for example `istio-system`.

[id="ossm-member-roll-create-console_{context}"]
== Creating the member roll from the web console

You can add one or more projects to the {SMProductShortName} member roll from the web console. In this example, `istio-system` is the name of the {SMProductShortName} control plane project.

.Prerequisites
* An installed, verified {SMProductName} Operator.
* List of existing projects to add to the service mesh.

.Procedure

. Log in to the {product-title} web console.

. If you do not already have services for your mesh, or you are starting from scratch, create a project for your applications. It must be different from the project where you installed the {SMProductShortName} control plane.

.. Navigate to *Home* -> *Projects*.

.. Enter a name in the *Name* field.

.. Click *Create*.

. Navigate to *Operators* -> *Installed Operators*.

. Click the *Project* menu and choose the project where your `ServiceMeshControlPlane` resource is deployed from the list, for example `istio-system`.

. Click the {SMProductName} Operator.

. Click the *Istio Service Mesh Member Roll* tab.

. Click *Create ServiceMeshMemberRoll*

. Click *Members*, then enter the name of your project in the *Value* field. You can add any number of projects, but a project can only belong to *one* `ServiceMeshMemberRoll` resource.

. Click *Create*.

[id="ossm-member-roll-create-cli_{context}"]
== Creating the member roll from the CLI

You can add a project to the `ServiceMeshMemberRoll` from the command line.

.Prerequisites

* An installed, verified {SMProductName} Operator.
* List of projects to add to the service mesh.
* Access to the OpenShift CLI (`oc`).

.Procedure

. Log in to the {product-title} CLI.
+
[source,terminal]
----
$ oc login --username=<NAMEOFUSER> https://<HOSTNAME>:6443
----

. If you do not already have services for your mesh, or you are starting from scratch, create a project for your applications. It must be different from the project where you installed the {SMProductShortName} control plane.
+
[source,terminal]
----
$ oc new-project <your-project>
----

. To add your projects as members, modify the following example YAML. You can add any number of projects, but a project can only belong to *one* `ServiceMeshMemberRoll` resource. In this example, `istio-system` is the name of the {SMProductShortName} control plane project.
+
.Example servicemeshmemberroll-default.yaml
[source,yaml]
----
apiVersion: maistra.io/v1
kind: ServiceMeshMemberRoll
metadata:
  name: default
  namespace: istio-system
spec:
  members:
    # a list of projects joined into the service mesh
    - your-project-name
    - another-project-name
----

. Run the following command to upload and create the `ServiceMeshMemberRoll` resource in the `istio-system` namespace.
+
[source,terminal]
----
$ oc create -n istio-system -f servicemeshmemberroll-default.yaml
----

. Run the following command to verify the `ServiceMeshMemberRoll` was created successfully.
+
[source,terminal]
----
$ oc get smmr -n istio-system default
----
+
The installation has finished successfully when the `STATUS` column is `Configured`.

:leveloffset!:

:leveloffset: +1

// Module included in the following assemblies:
//
// * service_mesh/v1x/installing-ossm.adoc
// * service_mesh/v2x/installing-ossm.adoc

:_mod-docs-content-type: PROCEDURE
[id="ossm-member-roll-modify_{context}"]
= Adding or removing projects from the service mesh

You can add or remove projects from an existing {SMProductShortName} `ServiceMeshMemberRoll` resource using the web console.

* You can add any number of projects, but a project can only belong to *one* `ServiceMeshMemberRoll` resource.

* The `ServiceMeshMemberRoll` resource is deleted when its corresponding `ServiceMeshControlPlane` resource is deleted.

[id="ossm-member-roll-modify-console_{context}"]
== Adding or removing projects from the member roll using the web console

.Prerequisites
* An installed, verified {SMProductName} Operator.
* An existing `ServiceMeshMemberRoll` resource.
* Name of the project with the `ServiceMeshMemberRoll` resource.
* Names of the projects you want to add or remove from the mesh.

.Procedure

. Log in to the {product-title} web console.

. Navigate to *Operators* -> *Installed Operators*.

. Click the *Project* menu and choose the project where your `ServiceMeshControlPlane` resource is deployed from the list, for example `istio-system`.

. Click the {SMProductName} Operator.

. Click the *Istio Service Mesh Member Roll* tab.

. Click the `default` link.

. Click the YAML tab.

. Modify the YAML to add or remove projects as members.  You can add any number of projects, but a project can only belong to *one* `ServiceMeshMemberRoll` resource.

. Click *Save*.

. Click *Reload*.

[id="ossm-member-roll-modify-cli_{context}"]
== Adding or removing projects from the member roll using the CLI

You can modify an existing {SMProductShortName} member roll using the command line.

.Prerequisites

* An installed, verified {SMProductName} Operator.
* An existing `ServiceMeshMemberRoll` resource.
* Name of the project with the `ServiceMeshMemberRoll` resource.
* Names of the projects you want to add or remove from the mesh.
* Access to the OpenShift CLI (`oc`).


.Procedure

. Log in to the {product-title} CLI.

. Edit the `ServiceMeshMemberRoll` resource.
+
[source,terminal]
----
$ oc edit smmr -n <controlplane-namespace>
----
+

. Modify the YAML to add or remove projects as members.  You can add any number of projects, but a project can only belong to *one* `ServiceMeshMemberRoll` resource.

+
.Example servicemeshmemberroll-default.yaml

[source,yaml]
----
apiVersion: maistra.io/v1
kind: ServiceMeshMemberRoll
metadata:
  name: default
  namespace: istio-system #control plane project
spec:
  members:
    # a list of projects joined into the service mesh
    - your-project-name
    - another-project-name
----

:leveloffset!:

== Manual updates

If you choose to update manually, the Operator Lifecycle Manager (OLM) controls the installation, upgrade, and role-based access control (RBAC) of Operators in a cluster. OLM runs by default in {product-title}.
OLM uses CatalogSources, which use the Operator Registry API, to query for available Operators as well as upgrades for installed Operators.


:leveloffset: +2

// Module included in the following assemblies:
//
// * service_mesh/v1x/prepare-to-deploy-applications-ossm.adoc
// * service_mesh/v2x/prepare-to-deploy-applications-ossm.adoc

:_mod-docs-content-type: PROCEDURE
[id="ossm-update-app-sidecar_{context}"]
= Updating sidecar proxies

In order to update the configuration for sidecar proxies the application administrator must restart the application pods.

If your deployment uses automatic sidecar injection, you can update the pod template in the deployment by adding or modifying an annotation. Run the following command to redeploy the pods:

[source,terminal]
----
$ oc patch deployment/<deployment> -p '{"spec":{"template":{"metadata":{"annotations":{"kubectl.kubernetes.io/restartedAt": "'`date -Iseconds`'"}}}}}'
----

If your deployment does not use automatic sidecar injection, you must manually update the sidecars by modifying the sidecar container image specified in the deployment or pod, and then restart the pods.

:leveloffset!:

== Next steps

* xref:../../service_mesh/v1x/prepare-to-deploy-applications-ossm.adoc#deploying-applications-ossm-v1x[Prepare to deploy applications] on {SMProductName}.

//# includes=_attributes/common-attributes,snippets/ossm-out-of-support,modules/distr-tracing-install-elasticsearch,modules/distr-tracing-install-jaeger-operator,modules/ossm-install-kiali,modules/ossm-install-ossm-operator,modules/ossm-control-plane-deploy-1x,modules/ossm-member-roll-create,modules/ossm-member-roll-modify,modules/ossm-update-app-sidecar
