:_mod-docs-content-type: ASSEMBLY
[id="jaeger-config-ref"]
= Jaeger configuration reference
// The {product-title} attribute provides the context-sensitive name of the relevant OpenShift distribution, for example, "OpenShift Container Platform" or "OKD". The {product-version} attribute provides the product version relative to the distribution, for example "4.9".
// {product-title} and {product-version} are parsed when AsciiBinder queries the _distro_map.yml file in relation to the base branch of a pull request.
// See https://github.com/openshift/openshift-docs/blob/main/contributing_to_docs/doc_guidelines.adoc#product-name-and-version for more information on this topic.
// Other common attributes are defined in the following lines:
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:imagesdir: images
:prewrap!:
:op-system-first: Red Hat Enterprise Linux CoreOS (RHCOS)
:op-system: RHCOS
:op-system-lowercase: rhcos
:op-system-base: RHEL
:op-system-base-full: Red Hat Enterprise Linux (RHEL)
:op-system-version: 8.x
:tsb-name: Template Service Broker
:kebab: image:kebab.png[title="Options menu"]
:rh-openstack-first: Red Hat OpenStack Platform (RHOSP)
:rh-openstack: RHOSP
:ai-full: Assisted Installer
:ai-version: 2.3
:cluster-manager-first: Red Hat OpenShift Cluster Manager
:cluster-manager: OpenShift Cluster Manager
:cluster-manager-url: link:https://console.redhat.com/openshift[OpenShift Cluster Manager Hybrid Cloud Console]
:cluster-manager-url-pull: link:https://console.redhat.com/openshift/install/pull-secret[pull secret from the Red Hat OpenShift Cluster Manager]
:insights-advisor-url: link:https://console.redhat.com/openshift/insights/advisor/[Insights Advisor]
:hybrid-console: Red Hat Hybrid Cloud Console
:hybrid-console-second: Hybrid Cloud Console
:oadp-first: OpenShift API for Data Protection (OADP)
:oadp-full: OpenShift API for Data Protection
:oc-first: pass:quotes[OpenShift CLI (`oc`)]
:product-registry: OpenShift image registry
:rh-storage-first: Red Hat OpenShift Data Foundation
:rh-storage: OpenShift Data Foundation
:rh-rhacm-first: Red Hat Advanced Cluster Management (RHACM)
:rh-rhacm: RHACM
:rh-rhacm-version: 2.8
:sandboxed-containers-first: OpenShift sandboxed containers
:sandboxed-containers-operator: OpenShift sandboxed containers Operator
:sandboxed-containers-version: 1.3
:sandboxed-containers-version-z: 1.3.3
:sandboxed-containers-legacy-version: 1.3.2
:cert-manager-operator: cert-manager Operator for Red Hat OpenShift
:secondary-scheduler-operator-full: Secondary Scheduler Operator for Red Hat OpenShift
:secondary-scheduler-operator: Secondary Scheduler Operator
// Backup and restore
:velero-domain: velero.io
:velero-version: 1.11
:launch: image:app-launcher.png[title="Application Launcher"]
:mtc-short: MTC
:mtc-full: Migration Toolkit for Containers
:mtc-version: 1.8
:mtc-version-z: 1.8.0
// builds (Valid only in 4.11 and later)
:builds-v2title: Builds for Red Hat OpenShift
:builds-v2shortname: OpenShift Builds v2
:builds-v1shortname: OpenShift Builds v1
//gitops
:gitops-title: Red Hat OpenShift GitOps
:gitops-shortname: GitOps
:gitops-ver: 1.1
:rh-app-icon: image:red-hat-applications-menu-icon.jpg[title="Red Hat applications"]
//pipelines
:pipelines-title: Red Hat OpenShift Pipelines
:pipelines-shortname: OpenShift Pipelines
:pipelines-ver: pipelines-1.12
:pipelines-version-number: 1.12
:tekton-chains: Tekton Chains
:tekton-hub: Tekton Hub
:artifact-hub: Artifact Hub
:pac: Pipelines as Code
//odo
:odo-title: odo
//OpenShift Kubernetes Engine
:oke: OpenShift Kubernetes Engine
//OpenShift Platform Plus
:opp: OpenShift Platform Plus
//openshift virtualization (cnv)
:VirtProductName: OpenShift Virtualization
:VirtVersion: 4.14
:KubeVirtVersion: v0.59.0
:HCOVersion: 4.14.0
:CNVNamespace: openshift-cnv
:CNVOperatorDisplayName: OpenShift Virtualization Operator
:CNVSubscriptionSpecSource: redhat-operators
:CNVSubscriptionSpecName: kubevirt-hyperconverged
:delete: image:delete.png[title="Delete"]
//distributed tracing
:DTProductName: Red Hat OpenShift distributed tracing platform
:DTShortName: distributed tracing platform
:DTProductVersion: 2.9
:JaegerName: Red Hat OpenShift distributed tracing platform (Jaeger)
:JaegerShortName: distributed tracing platform (Jaeger)
:JaegerVersion: 1.47.0
:OTELName: Red Hat OpenShift distributed tracing data collection
:OTELShortName: distributed tracing data collection
:OTELOperator: Red Hat OpenShift distributed tracing data collection Operator
:OTELVersion: 0.81.0
:TempoName: Red Hat OpenShift distributed tracing platform (Tempo)
:TempoShortName: distributed tracing platform (Tempo)
:TempoOperator: Tempo Operator
:TempoVersion: 2.1.1
//logging
:logging-title: logging subsystem for Red Hat OpenShift
:logging-title-uc: Logging subsystem for Red Hat OpenShift
:logging: logging subsystem
:logging-uc: Logging subsystem
//serverless
:ServerlessProductName: OpenShift Serverless
:ServerlessProductShortName: Serverless
:ServerlessOperatorName: OpenShift Serverless Operator
:FunctionsProductName: OpenShift Serverless Functions
//service mesh v2
:product-dedicated: Red Hat OpenShift Dedicated
:product-rosa: Red Hat OpenShift Service on AWS
:SMProductName: Red Hat OpenShift Service Mesh
:SMProductShortName: Service Mesh
:SMProductVersion: 2.4.4
:MaistraVersion: 2.4
//Service Mesh v1
:SMProductVersion1x: 1.1.18.2
//Windows containers
:productwinc: Red Hat OpenShift support for Windows Containers
// Red Hat Quay Container Security Operator
:rhq-cso: Red Hat Quay Container Security Operator
// Red Hat Quay
:quay: Red Hat Quay
:sno: single-node OpenShift
:sno-caps: Single-node OpenShift
//TALO and Redfish events Operators
:cgu-operator-first: Topology Aware Lifecycle Manager (TALM)
:cgu-operator-full: Topology Aware Lifecycle Manager
:cgu-operator: TALM
:redfish-operator: Bare Metal Event Relay
//Formerly known as CodeReady Containers and CodeReady Workspaces
:openshift-local-productname: Red Hat OpenShift Local
:openshift-dev-spaces-productname: Red Hat OpenShift Dev Spaces
// Factory-precaching-cli tool
:factory-prestaging-tool: factory-precaching-cli tool
:factory-prestaging-tool-caps: Factory-precaching-cli tool
:openshift-networking: Red Hat OpenShift Networking
// TODO - this probably needs to be different for OKD
//ifdef::openshift-origin[]
//:openshift-networking: OKD Networking
//endif::[]
// logical volume manager storage
:lvms-first: Logical volume manager storage (LVM Storage)
:lvms: LVM Storage
//Operator SDK version
:osdk_ver: 1.31.0
//Operator SDK version that shipped with the previous OCP 4.x release
:osdk_ver_n1: 1.28.0
//Next-gen (OCP 4.14+) Operator Lifecycle Manager, aka "v1"
:olmv1: OLM 1.0
:olmv1-first: Operator Lifecycle Manager (OLM) 1.0
:ztp-first: GitOps Zero Touch Provisioning (ZTP)
:ztp: GitOps ZTP
:3no: three-node OpenShift
:3no-caps: Three-node OpenShift
:run-once-operator: Run Once Duration Override Operator
// Web terminal
:web-terminal-op: Web Terminal Operator
:devworkspace-op: DevWorkspace Operator
:secrets-store-driver: Secrets Store CSI driver
:secrets-store-operator: Secrets Store CSI Driver Operator
//AWS STS
:sts-first: Security Token Service (STS)
:sts-full: Security Token Service
:sts-short: STS
//Cloud provider names
//AWS
:aws-first: Amazon Web Services (AWS)
:aws-full: Amazon Web Services
:aws-short: AWS
//GCP
:gcp-first: Google Cloud Platform (GCP)
:gcp-full: Google Cloud Platform
:gcp-short: GCP
//alibaba cloud
:alibaba: Alibaba Cloud
// IBM Cloud VPC
:ibmcloudVPCProductName: IBM Cloud VPC
:ibmcloudVPCRegProductName: IBM(R) Cloud VPC
// IBM Cloud
:ibm-cloud-bm: IBM Cloud Bare Metal (Classic)
:ibm-cloud-bm-reg: IBM Cloud(R) Bare Metal (Classic)
// IBM Power
:ibmpowerProductName: IBM Power
:ibmpowerRegProductName: IBM(R) Power
// IBM zSystems
:ibmzProductName: IBM Z
:ibmzRegProductName: IBM(R) Z
:linuxoneProductName: IBM(R) LinuxONE
//Azure
:azure-full: Microsoft Azure
:azure-short: Azure
//vSphere
:vmw-full: VMware vSphere
:vmw-short: vSphere
//Oracle
:oci-first: Oracle(R) Cloud Infrastructure
:oci: OCI
:ocvs-first: Oracle(R) Cloud VMware Solution (OCVS)
:ocvs: OCVS
:context: jaeger-config-reference

toc::[]

When the {SMProductShortName} Operator deploys the `ServiceMeshControlPlane` resource, it can also create the resources for distributed tracing. {SMProductShortName} uses Jaeger for distributed tracing.

[IMPORTANT]
====
Jaeger does not use FIPS validated cryptographic modules.
====

:leveloffset: +1

// Module included in the following assemblies:
//
// * service_mesh/v2x/customizing-installation-ossm.adoc


[id="ossm-enabling-tracing_{context}"]
= Enabling and disabling tracing

You enable distributed tracing by specifying a tracing type and a sampling rate in the `ServiceMeshControlPlane` resource.

.Default `all-in-one` Jaeger parameters
[source,yaml, subs="attributes,verbatim"]
----
apiVersion: maistra.io/v2
kind: ServiceMeshControlPlane
metadata:
  name: basic
spec:
  version: v{MaistraVersion}
  tracing:
    sampling: 100
    type: Jaeger
----

Currently, the only tracing type that is supported is `Jaeger`.

Jaeger is enabled by default. To disable tracing, set `type` to `None`.

The sampling rate determines how often the Envoy proxy generates a trace. You can use the sampling rate option to control what percentage of requests get reported to your tracing system. You can configure this setting based upon your traffic in the mesh and the amount of tracing data you want to collect. You configure `sampling` as a scaled integer representing 0.01% increments. For example, setting the value to `10` samples 0.1% of traces, setting the value to `500` samples 5% of traces, and a setting of `10000` samples 100% of traces.

[NOTE]
====
The SMCP sampling configuration option controls the Envoy sampling rate. You configure the Jaeger trace sampling rate in the Jaeger custom resource.
====

:leveloffset!:

:leveloffset: +1

// Module included in the following assemblies:
//
// * service_mesh/v2x/customizing-installation-ossm.adoc

:_mod-docs-content-type: CONCEPT
[id="ossm-specifying-jaeger-configuration_{context}"]
= Specifying Jaeger configuration in the SMCP

You configure Jaeger under the `addons` section of the `ServiceMeshControlPlane` resource. However, there are some limitations to what you can configure in the SMCP.

When the SMCP passes configuration information to the {JaegerName} Operator, it triggers one of three deployment strategies: `allInOne`, `production`, or `streaming`.

:leveloffset!:

:leveloffset: +1

// Module included in the following assemblies:
//
// * service_mesh/v2x/ossm-custom-resources.adoc

[id="ossm-deploying-jaeger_{context}"]
= Deploying the distributed tracing platform

The {JaegerShortName} has predefined deployment strategies. You specify a deployment strategy in the Jaeger custom resource (CR) file. When you create an instance of the {JaegerShortName}, the {JaegerName} Operator uses this configuration file to create the objects necessary for the deployment.

The {JaegerName} Operator currently supports the following deployment strategies:

* *allInOne* (default) - This strategy is intended for development, testing, and demo purposes and it is not for production use. The main back-end components, Agent, Collector, and Query service, are all packaged into a single executable, which is configured (by default) to use in-memory storage. You can configure this deployment strategy in the SMCP.
+
[NOTE]
====
In-memory storage is not persistent, which means that if the Jaeger instance shuts down, restarts, or is replaced, your trace data will be lost. And in-memory storage cannot be scaled, since each pod has its own memory. For persistent storage, you must use the `production` or `streaming` strategies, which use Elasticsearch as the default storage.
====

* *production* - The production strategy is intended for production environments, where long term storage of trace data is important, and a more scalable and highly available architecture is required. Each back-end component is therefore deployed separately. The Agent can be injected as a sidecar on the instrumented application. The Query and Collector services are configured with a supported storage type, which is currently Elasticsearch. Multiple instances of each of these components can be provisioned as required for performance and resilience purposes. You can configure this deployment strategy in the SMCP, but in order to be fully customized, you must specify your configuration in the Jaeger CR and link that to the SMCP.

* *streaming* - The streaming strategy is designed to augment the production strategy by providing a streaming capability that sits between the Collector and the Elasticsearch back-end storage. This provides the benefit of reducing the pressure on the back-end storage, under high load situations, and enables other trace post-processing capabilities to tap into the real-time span data directly from the streaming platform (https://access.redhat.com/documentation/en-us/red_hat_amq/7.6/html/using_amq_streams_on_openshift/index[AMQ Streams]/ https://kafka.apache.org/documentation/[Kafka]). You cannot configure this deployment strategy in the SMCP; you must configure a Jaeger CR and link that to the SMCP.

[NOTE]
====
The streaming strategy requires an additional Red Hat subscription for AMQ Streams.
====

[id="ossm-deploying-jaeger-default_{context}"]
== Default {JaegerShortName} deployment

If you do not specify Jaeger configuration options, the `ServiceMeshControlPlane` resource will use the `allInOne` Jaeger deployment strategy by default. When using the default `allInOne` deployment strategy, set `spec.addons.jaeger.install.storage.type` to `Memory`. You can accept the defaults or specify additional configuration options under `install`.

.Control plane default Jaeger parameters (Memory)
[source,yaml, subs="attributes,verbatim"]
----
apiVersion: maistra.io/v2
kind: ServiceMeshControlPlane
metadata:
  name: basic
spec:
  version: v{MaistraVersion}
  tracing:
    sampling: 10000
    type: Jaeger
  addons:
    jaeger:
      name: jaeger
      install:
        storage:
          type: Memory
----

[id="ossm-deploying-jaeger-production-min_{context}"]
== Production {JaegerShortName} deployment (minimal)

To use the default settings for the `production` deployment strategy, set `spec.addons.jaeger.install.storage.type` to `Elasticsearch` and specify additional configuration options under `install`. Note that the SMCP only supports configuring Elasticsearch resources and image name.

.Control plane default Jaeger parameters (Elasticsearch)
[source,yaml, subs="attributes"]
----
apiVersion: maistra.io/v2
kind: ServiceMeshControlPlane
metadata:
  name: basic
spec:
  version: v{MaistraVersion}
  tracing:
    sampling: 10000
    type: Jaeger
  addons:
    jaeger:
      name: jaeger  #name of Jaeger CR
      install:
        storage:
          type: Elasticsearch
        ingress:
          enabled: true
  runtime:
    components:
      tracing.jaeger.elasticsearch: # only supports resources and image name
        container:
          resources: {}
----


[id="ossm-deploying-jaeger-production_{context}"]
== Production {JaegerShortName} deployment (fully customized)

The SMCP supports only minimal Elasticsearch parameters. To fully customize your production environment and access all of the Elasticsearch configuration parameters, use the Jaeger custom resource (CR) to configure Jaeger.

Create and configure your Jaeger instance and set `spec.addons.jaeger.name` to the name of the Jaeger instance, in this example: `MyJaegerInstance`.

.Control plane with linked Jaeger production CR
[source,yaml, subs="attributes"]
----
apiVersion: maistra.io/v2
kind: ServiceMeshControlPlane
metadata:
  name: basic
spec:
  version: v{MaistraVersion}
  tracing:
    sampling: 1000
    type: Jaeger
  addons:
    jaeger:
      name: MyJaegerInstance #name of Jaeger CR
      install:
        storage:
          type: Elasticsearch
        ingress:
          enabled: true
----

[id="ossm-deploying-jaeger-streaming_{context}"]
== Streaming Jaeger deployment

To use the `streaming` deployment strategy, you create and configure your Jaeger instance first, then set `spec.addons.jaeger.name` to the name of the Jaeger instance, in this example: `MyJaegerInstance`.

.Control plane with linked Jaeger streaming CR
[source,yaml, subs="attributes"]
----
apiVersion: maistra.io/v2
kind: ServiceMeshControlPlane
metadata:
  name: basic
spec:
  version: v{MaistraVersion}
  tracing:
    sampling: 1000
    type: Jaeger
  addons:
    jaeger:
      name: MyJaegerInstance  #name of Jaeger CR
----

:leveloffset!:

:leveloffset: +1

// Module included in the following assemblies:
//
// * service_mesh/v2x/customizing-installation-ossm.adoc

:_mod-docs-content-type: CONCEPT
[id="ossm-specifying-external-jaeger_{context}"]
= Specifying Jaeger configuration in a Jaeger custom resource

You can fully customize your Jaeger deployment by configuring Jaeger in the Jaeger custom resource (CR) rather than in the `ServiceMeshControlPlane` (SMCP) resource. This configuration is sometimes referred to as an "external Jaeger" since the configuration is specified outside of the SMCP.

[NOTE]
====
You must deploy the SMCP and Jaeger CR in the same namespace. For example, `istio-system`.
====

You can configure and deploy a standalone Jaeger instance and then specify the `name` of the Jaeger resource as the value for `spec.addons.jaeger.name` in the SMCP resource. If a Jaeger CR matching the value of `name` exists, the {SMProductShortName} control plane will use the existing installation. This approach lets you fully customize your Jaeger configuration.

:leveloffset!:

:leveloffset: +2

////
This module included in the following assemblies:
- distr_tracing_jaeger/distr-tracing-jaeger-configuring.adoc
////
:_mod-docs-content-type: CONCEPT
[id="distr-tracing-deployment-best-practices_{context}"]
= Deployment best practices

* {DTProductName} instance names must be unique. If you want to have multiple {JaegerName} instances and are using sidecar injected agents, then the {JaegerName} instances should have unique names, and the injection annotation should explicitly specify the {JaegerName} instance name the tracing data should be reported to.

* If you have a multitenant implementation and tenants are separated by namespaces, deploy a {JaegerName} instance to each tenant namespace.

:leveloffset!:


:leveloffset: +2

////
This module included in the following assemblies:
service_mesh/v2x/ossm-reference-jaeger.adoc
////
:_mod-docs-content-type: CONCEPT
[id="distr-tracing-config-security-ossm_{context}"]
= Configuring distributed tracing security for service mesh

The {JaegerShortName} uses OAuth for default authentication. However {SMProductName} uses a secret called `htpasswd` to facilitate communication between dependent services such as Grafana, Kiali, and the {JaegerShortName}. When you configure your {JaegerShortName} in the `ServiceMeshControlPlane` the {SMProductShortName} automatically configures security settings to use `htpasswd`.

If you are specifying your {JaegerShortName} configuration in a Jaeger custom resource, you must manually configure the `htpasswd` settings and ensure the `htpasswd` secret is mounted into your Jaeger instance so that Kiali can communicate with it.

:leveloffset!:

:leveloffset: +3

////
This module included in the following assemblies:
service_mesh/v2x/ossm-reference-jaeger.adoc
////
:_mod-docs-content-type: PROCEDURE
[id="distr-tracing-config-security-ossm-web_{context}"]
= Configuring distributed tracing security for service mesh from the web console

You can modify the Jaeger resource to configure {JaegerShortName} security for use with {SMproductShortName} in the web console.

.Prerequisites

* You have access to the cluster as a user with the `cluster-admin` role. If you use {product-dedicated}, you must have an account with the `dedicated-admin` role.
* The {SMProductName} Operator must be installed.
* The `ServiceMeshControlPlane` deployed to the cluster.
* You have access to the {product-title} web console.

.Procedure

. Log in to the {product-title} web console as a user with the `cluster-admin` role.

. Navigate to Operators → Installed Operators.

. Click the *Project* menu and select the project where your `ServiceMeshControlPlane` resource is deployed from the list, for example `istio-system`.

. Click the *{JaegerName} Operator*.

. On the *Operator Details* page, click the *Jaeger* tab.

. Click the name of your Jaeger instance.

. On the Jaeger details page, click the *YAML* tab to modify your configuration.

. Edit the `Jaeger` custom resource file to add the `htpasswd` configuration as shown in the following example.

* `spec.ingress.openshift.htpasswdFile`
* `spec.volumes`
* `spec.volumeMounts`
+
.Example Jaeger resource showing `htpasswd` configuration
[source,yaml]
----
apiVersion: jaegertracing.io/v1
kind: Jaeger
spec:
  ingress:
    enabled: true
    openshift:
      htpasswdFile: /etc/proxy/htpasswd/auth
      sar: '{"namespace": "istio-system", "resource": "pods", "verb": "get"}'
    options: {}
    resources: {}
    security: oauth-proxy
  volumes:
    - name: secret-htpasswd
      secret:
        secretName: htpasswd
    - configMap:
        defaultMode: 420
        items:
          - key: ca-bundle.crt
            path: tls-ca-bundle.pem
        name: trusted-ca-bundle
        optional: true
      name: trusted-ca-bundle
  volumeMounts:
    - mountPath: /etc/proxy/htpasswd
      name: secret-htpasswd
    - mountPath: /etc/pki/ca-trust/extracted/pem/
      name: trusted-ca-bundle
      readOnly: true
----
+
. Click *Save*.

:leveloffset!:

:leveloffset: +3

////
This module included in the following assemblies:
service_mesh/v2x/ossm-reference-jaeger.adoc
////
:_mod-docs-content-type: PROCEDURE
[id="distr-tracing-config-security-ossm-cli_{context}"]
= Configuring distributed tracing security for service mesh from the command line

You can modify the Jaeger resource to configure {JaegerShortName} security for use with {SMproductShortName} from the command line by running the {oc-first}.

.Prerequisites

* You have access to the cluster as a user with the `cluster-admin` role. If you use {product-dedicated}, you must have an account with the `dedicated-admin` role.
* The {SMProductName} Operator must be installed.
* The `ServiceMeshControlPlane` deployed to the cluster.
* You have access to the {oc-first} that matches your {product-title} version.

.Procedure

. Log in to the {oc-first} as a user with the `cluster-admin` role by running the following command. If you use {product-dedicated}, you must have an account with the `dedicated-admin` role.
+
[source,terminal]
----
$ oc login https://<HOSTNAME>:6443
----
+
. Change to the project where you installed the control plane, for example `istio-system`, by entering the following command:
+
[source,terminal]
----
$ oc project istio-system
----
+
. Run the following command to edit the Jaeger custom resource file, where `jaeger.yaml` is the name of your Jaeger custom resource.
+
[source,terminal]
----
$ oc edit -n tracing-system -f jaeger.yaml
----
+
. Edit the `Jaeger` custom resource file to add the `htpasswd` configuration as shown in the following example.

* `spec.ingress.openshift.htpasswdFile`
* `spec.volumes`
* `spec.volumeMounts`
+
.Example Jaeger resource showing `htpasswd` configuration
[source,yaml]
----
apiVersion: jaegertracing.io/v1
kind: Jaeger
spec:
  ingress:
    enabled: true
    openshift:
      htpasswdFile: /etc/proxy/htpasswd/auth
      sar: '{"namespace": "istio-system", "resource": "pods", "verb": "get"}'
    options: {}
    resources: {}
    security: oauth-proxy
  volumes:
    - name: secret-htpasswd
      secret:
        secretName: htpasswd
    - configMap:
        defaultMode: 420
        items:
          - key: ca-bundle.crt
            path: tls-ca-bundle.pem
        name: trusted-ca-bundle
        optional: true
      name: trusted-ca-bundle
  volumeMounts:
    - mountPath: /etc/proxy/htpasswd
      name: secret-htpasswd
    - mountPath: /etc/pki/ca-trust/extracted/pem/
      name: trusted-ca-bundle
      readOnly: true
----
+
. Run the following command to apply your changes, where <jaeger.yaml> is the name of your Jaeger custom resource.
+
[source,terminal]
----
$ oc apply -n tracing-system -f <jaeger.yaml>
----
+
. Run the following command to watch the progress of the pod deployment:
+
[source,terminal]
----
$ oc get pods -n tracing-system -w
----

:leveloffset!:

:leveloffset: +2

////
This module included in the following assemblies:
- distr_tracing_jaeger/distr-tracing-jaeger-configuring.adoc
////
:_mod-docs-content-type: REFERENCE
[id="distr-tracing-config-default_{context}"]
= Distributed tracing default configuration options

The Jaeger custom resource (CR) defines the architecture and settings to be used when creating the {JaegerShortName} resources. You can modify these parameters to customize your {JaegerShortName} implementation to your business needs.

.Generic YAML example of the Jaeger CR
[source,yaml]
----
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: name
spec:
  strategy: <deployment_strategy>
  allInOne:
    options: {}
    resources: {}
  agent:
    options: {}
    resources: {}
  collector:
    options: {}
    resources: {}
  sampling:
    options: {}
  storage:
    type:
    options: {}
  query:
    options: {}
    resources: {}
  ingester:
    options: {}
    resources: {}
  options: {}
----

.Jaeger parameters
[options="header"]
|===
|Parameter |Description |Values |Default value

|`apiVersion:`
|API version to use when creating the object.
|`jaegertracing.io/v1`
|`jaegertracing.io/v1`

|`kind:`
|Defines the kind of Kubernetes object to create.
|`jaeger`
|

|`metadata:`
|Data that helps uniquely identify the object, including a `name` string, `UID`, and optional `namespace`.
|
|{product-title} automatically generates the `UID` and completes the `namespace` with the name of the project where the object is created.

|`name:`
|Name for the object.
|The name of your {JaegerShortName} instance.
|`jaeger-all-in-one-inmemory`

|`spec:`
|Specification for the object to be created.
|Contains all of the configuration parameters for your {JaegerShortName} instance. When a common definition for all Jaeger components is required, it is defined under the `spec` node. When the definition relates to an individual component, it is placed under the `spec/<component>` node.
|N/A

|`strategy:`
|Jaeger deployment strategy
|`allInOne`, `production`, or `streaming`
|`allInOne`

|`allInOne:`
|Because the `allInOne` image deploys the Agent, Collector, Query, Ingester, and Jaeger UI in a single pod, configuration for this deployment must nest component configuration under the `allInOne` parameter.
|
|

|`agent:`
|Configuration options that define the Agent.
|
|

|`collector:`
|Configuration options that define the Jaeger Collector.
|
|

|`sampling:`
|Configuration options that define the sampling strategies for tracing.
|
|

|`storage:`
|Configuration options that define the storage. All storage-related options must be placed under `storage`, rather than under the `allInOne` or other component options.
|
|

|`query:`
|Configuration options that define the Query service.
|
|

|`ingester:`
|Configuration options that define the Ingester service.
|
|
|===

The following example YAML is the minimum required to create a {JaegerName} deployment using the default settings.

.Example minimum required dist-tracing-all-in-one.yaml
[source,yaml]
----
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: jaeger-all-in-one-inmemory
----

:leveloffset!:

:leveloffset: +2

////
This module included in the following assemblies:
- distr_tracing_jaeger/distr-tracing-jaeger-configuring.adoc
////
:_mod-docs-content-type: REFERENCE
[id="distr-tracing-config-jaeger-collector_{context}"]
= Jaeger Collector configuration options

The Jaeger Collector is the component responsible for receiving the spans that were captured by the tracer and writing them to persistent Elasticsearch storage when using the `production` strategy, or to AMQ Streams when using the `streaming` strategy.

The Collectors are stateless and thus many instances of Jaeger Collector can be run in parallel. Collectors require almost no configuration, except for the location of the Elasticsearch cluster.

.Parameters used by the Operator to define the Jaeger Collector
[options="header"]
[cols="l, a, a"]
|===
|Parameter |Description |Values
|collector:
  replicas:
|Specifies the number of Collector replicas to create.
|Integer, for example, `5`
|===


.Configuration parameters passed to the Collector
[options="header"]
[cols="l, a, a"]
|===
|Parameter |Description |Values
|spec:
 collector:
  options: {}
|Configuration options that define the Jaeger Collector.
|

|options:
  collector:
    num-workers:
|The number of workers pulling from the queue.
|Integer, for example, `50`

|options:
  collector:
    queue-size:
|The size of the Collector queue.
|Integer, for example, `2000`

|options:
  kafka:
    producer:
      topic: jaeger-spans
|The `topic` parameter identifies the Kafka configuration used by the Collector to produce the messages, and the Ingester to consume the messages.
|Label for the producer.

|options:
  kafka:
    producer:
      brokers: my-cluster-kafka-brokers.kafka:9092
|Identifies the Kafka configuration used by the Collector to produce the messages. If brokers are not specified, and you have AMQ Streams 1.4.0+ installed, the {JaegerName} Operator will self-provision Kafka.
|

|options:
  log-level:
|Logging level for the Collector.
|Possible values: `debug`, `info`, `warn`, `error`, `fatal`, `panic`.
|===

:leveloffset!:

:leveloffset: +2

////
This module included in the following assemblies:
- distr_tracing_jaeger/distr-tracing-jaeger-configuring.adoc
////
:_mod-docs-content-type: REFERENCE
[id="distr-tracing-config-sampling_{context}"]
= Distributed tracing sampling configuration options

The {JaegerName} Operator can be used to define sampling strategies that will be supplied to tracers that have been configured to use a remote sampler.

While all traces are generated, only a few are sampled. Sampling a trace marks the trace for further processing and storage.

[NOTE]
====
This is not relevant if a trace was started by the Envoy proxy, as the sampling decision is made there. The Jaeger sampling decision is only relevant when the trace is started by an application using the client.
====

When a service receives a request that contains no trace context, the client starts a new trace, assigns it a random trace ID, and makes a sampling decision based on the currently installed sampling strategy. The sampling decision propagates to all subsequent requests in the trace so that other services are not making the sampling decision again.

{JaegerShortName} libraries support the following samplers:

* *Probabilistic* - The sampler makes a random sampling decision with the probability of sampling equal to the value of the `sampling.param` property. For example, using `sampling.param=0.1` samples approximately 1 in 10 traces.

* *Rate Limiting* - The sampler uses a leaky bucket rate limiter to ensure that traces are sampled with a certain constant rate. For example, using `sampling.param=2.0` samples requests with the rate of 2 traces per second.

.Jaeger sampling options
[options="header"]
[cols="l, a, a, a"]
|===
|Parameter |Description |Values |Default value
|spec:
 sampling:
  options: {}
    default_strategy:
    service_strategy:
|Configuration options that define the sampling strategies for tracing.
|
|If you do not provide configuration, the Collectors will return the default probabilistic sampling policy with 0.001 (0.1%) probability for all services.

|default_strategy:
  type:
service_strategy:
  type:
|Sampling strategy to use. See descriptions above.
|Valid values are `probabilistic`, and `ratelimiting`.
|`probabilistic`

|default_strategy:
  param:
service_strategy:
  param:
|Parameters for the selected sampling strategy.
|Decimal and integer values (0, .1, 1, 10)
|1
|===

This example defines a default sampling strategy that is probabilistic, with a 50% chance of the trace instances being sampled.

.Probabilistic sampling example
[source,yaml]
----
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: with-sampling
spec:
  sampling:
    options:
      default_strategy:
        type: probabilistic
        param: 0.5
      service_strategies:
        - service: alpha
          type: probabilistic
          param: 0.8
          operation_strategies:
            - operation: op1
              type: probabilistic
              param: 0.2
            - operation: op2
              type: probabilistic
              param: 0.4
        - service: beta
          type: ratelimiting
          param: 5
----

If there are no user-supplied configurations, the {JaegerShortName} uses the following settings:

.Default sampling
[source,yaml]
----
spec:
  sampling:
    options:
      default_strategy:
        type: probabilistic
        param: 1
----

:leveloffset!:

:leveloffset: +2

////
This module included in the following assemblies:
- distr_tracing_jaeger/distr-tracing-jaeger-configuring.adoc
////
:_mod-docs-content-type: REFERENCE
[id="distr-tracing-config-storage_{context}"]
= Distributed tracing storage configuration options

You configure storage for the Collector, Ingester, and Query services under `spec.storage`. Multiple instances of each of these components can be provisioned as required for performance and resilience purposes.

.General storage parameters used by the {JaegerName} Operator to define distributed tracing storage

[options="header"]
[cols="l, a, a, a"]
|===
|Parameter |Description |Values |Default value
|spec:
  storage:
    type:
|Type of storage to use for the deployment.
|`memory` or `elasticsearch`.
Memory storage is only appropriate for development, testing, demonstrations, and proof of concept environments as the data does not persist if the pod is shut down. For production environments {JaegerShortName} supports Elasticsearch for persistent storage.
|`memory`

|storage:
  secretname:
|Name of the secret, for example `tracing-secret`.
|
|N/A

|storage:
  options: {}
|Configuration options that define the storage.
|
|
|===

.Elasticsearch index cleaner parameters
[options="header"]
[cols="l, a, a, a"]
|===
|Parameter |Description |Values |Default value
|storage:
  esIndexCleaner:
    enabled:
|When using Elasticsearch storage, by default a job is created to clean old traces from the index. This parameter enables or disables the index cleaner job.
|`true`/ `false`
|`true`

|storage:
  esIndexCleaner:
    numberOfDays:
|Number of days to wait before deleting an index.
|Integer value
|`7`

|storage:
  esIndexCleaner:
    schedule:
|Defines the schedule for how often to clean the Elasticsearch index.
|Cron expression
|"55 23 * * *"
|===

[id="distributed-tracing-config-auto-provisioning-es_{context}"]
== Auto-provisioning an Elasticsearch instance

When you deploy a Jaeger custom resource, the {JaegerName} Operator uses the OpenShift Elasticsearch Operator to create an Elasticsearch cluster based on the configuration provided in the `storage` section of the custom resource file. The {JaegerName} Operator will provision Elasticsearch if the following configurations are set:

* `spec.storage:type` is set to `elasticsearch`
* `spec.storage.elasticsearch.doNotProvision` set to `false`
* `spec.storage.options.es.server-urls` is not defined, that is, there is no connection to an Elasticsearch instance that was not provisioned by the Red Hat Elasticsearch Operator.

When provisioning Elasticsearch, the {JaegerName} Operator sets the Elasticsearch custom resource `name` to the value of `spec.storage.elasticsearch.name` from the Jaeger custom resource.  If you do not specify a value for `spec.storage.elasticsearch.name`, the Operator uses `elasticsearch`.

.Restrictions

* You can have only one {JaegerShortName} with self-provisioned Elasticsearch instance per namespace. The Elasticsearch cluster is meant to be dedicated for a single {JaegerShortName} instance.
* There can be only one Elasticsearch per namespace.

[NOTE]
====
If you already have installed Elasticsearch as part of OpenShift Logging, the {JaegerName} Operator can use the installed OpenShift Elasticsearch Operator to provision storage.
====

The following configuration parameters are for a _self-provisioned_ Elasticsearch instance, that is an instance created by the {JaegerName} Operator using the OpenShift Elasticsearch Operator. You specify configuration options for self-provisioned Elasticsearch under `spec:storage:elasticsearch` in your configuration file.

.Elasticsearch resource configuration parameters
[options="header"]
[cols="l, a, a, a"]
|===
|Parameter |Description |Values |Default value
|elasticsearch:
  properties:
    doNotProvision:
|Use to specify whether or not an Elasticsearch instance should be provisioned by the {JaegerName} Operator.
|`true`/`false`
|`true`

|elasticsearch:
  properties:
    name:
|Name of the Elasticsearch instance. The {JaegerName} Operator uses the Elasticsearch instance specified in this parameter to connect to Elasticsearch.
|string
|`elasticsearch`

|elasticsearch:
  nodeCount:
|Number of Elasticsearch nodes. For high availability use at least 3 nodes. Do not use 2 nodes as “split brain” problem can happen.
|Integer value. For example, Proof of concept = 1,
Minimum deployment =3
|3

|elasticsearch:
  resources:
    requests:
      cpu:
|Number of central processing units for requests, based on your environment's configuration.
|Specified in cores or millicores, for example, 200m, 0.5, 1. For example, Proof of concept = 500m,
Minimum deployment =1
|1

|elasticsearch:
  resources:
    requests:
      memory:
|Available memory for requests, based on your environment's configuration.
|Specified in bytes, for example, 200Ki, 50Mi, 5Gi. For example, Proof of concept = 1Gi,
Minimum deployment = 16Gi*
|16Gi

|elasticsearch:
  resources:
    limits:
      cpu:
|Limit on number of central processing units, based on your environment's configuration.
|Specified in cores or millicores, for example, 200m, 0.5, 1. For example, Proof of concept = 500m,
Minimum deployment =1
|

|elasticsearch:
  resources:
    limits:
      memory:
|Available memory limit based on your environment's configuration.
|Specified in bytes, for example, 200Ki, 50Mi, 5Gi. For example, Proof of concept = 1Gi,
Minimum deployment = 16Gi*
|

|elasticsearch:
  redundancyPolicy:
|Data replication policy defines how Elasticsearch shards are replicated across data nodes in the cluster. If not specified, the {JaegerName} Operator automatically determines the most appropriate replication based on number of nodes.
|`ZeroRedundancy`(no replica shards), `SingleRedundancy`(one replica shard), `MultipleRedundancy`(each index is spread over half of the Data nodes), `FullRedundancy` (each index is fully replicated on every Data node in the cluster).
|

|elasticsearch:
  useCertManagement:
|Use to specify whether or not {JaegerShortName} should use the certificate management feature of the Red Hat Elasticsearch Operator.  This feature was added to {logging-title} 5.2 in {product-title} 4.7 and is the preferred setting for new Jaeger deployments.
|`true`/`false`
|`true`

|
3+|*Each Elasticsearch node can operate with a lower memory setting though this is NOT recommended for production deployments. For production use, you should have no less than 16Gi allocated to each pod by default, but preferably allocate as much as you can, up to 64Gi per pod.
|===

.Production storage example
[source,yaml]
----
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: simple-prod
spec:
  strategy: production
  storage:
    type: elasticsearch
    elasticsearch:
      nodeCount: 3
      resources:
        requests:
          cpu: 1
          memory: 16Gi
        limits:
          memory: 16Gi
----

.Storage example with persistent storage:
[source,yaml]
----
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: simple-prod
spec:
  strategy: production
  storage:
    type: elasticsearch
    elasticsearch:
      nodeCount: 1
      storage: # <1>
        storageClassName: gp2
        size: 5Gi
      resources:
        requests:
          cpu: 200m
          memory: 4Gi
        limits:
          memory: 4Gi
      redundancyPolicy: ZeroRedundancy
----

<1> Persistent storage configuration. In this case AWS `gp2` with `5Gi` size. When no value is specified, {JaegerShortName} uses `emptyDir`. The OpenShift Elasticsearch Operator provisions `PersistentVolumeClaim` and `PersistentVolume` which are not removed with {JaegerShortName} instance. You can mount the same volumes if you create a {JaegerShortName} instance with the same name and namespace.


[id="distributed-tracing-config-external-es_{context}"]
== Connecting to an existing Elasticsearch instance

You can use an existing Elasticsearch cluster for storage with {DTShortName}. An existing Elasticsearch cluster, also known as an _external_ Elasticsearch instance, is an instance that was not installed by the {JaegerName} Operator or by the Red Hat Elasticsearch Operator.

When you deploy a Jaeger custom resource, the {JaegerName} Operator will not provision Elasticsearch if the following configurations are set:

* `spec.storage.elasticsearch.doNotProvision` set to `true`
* `spec.storage.options.es.server-urls` has a value
* `spec.storage.elasticsearch.name` has a value, or if the Elasticsearch instance name is `elasticsearch`.

The {JaegerName} Operator uses the Elasticsearch instance specified in `spec.storage.elasticsearch.name` to connect to Elasticsearch.

.Restrictions

* You cannot share or reuse a {product-title} logging Elasticsearch instance with {JaegerShortName}. The Elasticsearch cluster is meant to be dedicated for a single {JaegerShortName} instance.

[NOTE]
====
Red Hat does not provide support for your external Elasticsearch instance. You can review the tested integrations matrix on the link:https://access.redhat.com/articles/5381021[Customer Portal].
====

The following configuration parameters are for an already existing Elasticsearch instance, also known as an _external_ Elasticsearch instance. In this case, you specify configuration options for Elasticsearch under `spec:storage:options:es` in your custom resource file.

.General ES configuration parameters
[options="header"]
[cols="l, a, a, a"]
|===
|Parameter |Description |Values |Default value
|es:
  server-urls:
|URL of the Elasticsearch instance.
|The fully-qualified domain name of the Elasticsearch server.
|`http://elasticsearch.<namespace>.svc:9200`

|es:
  max-doc-count:
|The maximum document count to return from an Elasticsearch query. This will also apply to aggregations. If you set both `es.max-doc-count` and `es.max-num-spans`, Elasticsearch will use the smaller value of the two.
|
|10000

|es:
  max-num-spans:
|[*Deprecated* - Will be removed in a future release, use `es.max-doc-count` instead.] The maximum number of spans to fetch at a time, per query, in Elasticsearch. If you set both `es.max-num-spans` and `es.max-doc-count`, Elasticsearch will use the smaller value of the two.
|
|10000

|es:
  max-span-age:
|The maximum lookback for spans in Elasticsearch.
|
|72h0m0s

|es:
  sniffer:
|The sniffer configuration for Elasticsearch. The client uses the sniffing process to find all nodes automatically. Disabled by default.
|`true`/ `false`
|`false`

|es:
  sniffer-tls-enabled:
|Option to enable TLS when sniffing an Elasticsearch Cluster. The client uses the sniffing process to find all nodes automatically. Disabled by default
|`true`/ `false`
|`false`

|es:
  timeout:
|Timeout used for queries. When set to zero there is no timeout.
|
|0s

|es:
  username:
|The username required by Elasticsearch. The basic authentication also loads CA if it is specified. See also `es.password`.
|
|

|es:
  password:
|The password required by Elasticsearch. See also, `es.username`.
|
|

|es:
  version:
|The major Elasticsearch version. If not specified, the value will be auto-detected from Elasticsearch.
|
|0
|===

.ES data replication parameters
[options="header"]
[cols="l, a, a, a"]
|===
|Parameter |Description |Values |Default value
|es:
  num-replicas:
|The number of replicas per index in Elasticsearch.
|
|1

|es:
  num-shards:
|The number of shards per index in Elasticsearch.
|
|5
|===

.ES index configuration parameters
[options="header"]
[cols="l, a, a, a"]
|===
|Parameter |Description |Values |Default value
|es:
  create-index-templates:
|Automatically create index templates at application startup when set to `true`. When templates are installed manually, set to `false`.
|`true`/ `false`
|`true`

|es:
  index-prefix:
|Optional prefix for {JaegerShortName} indices. For example, setting this to "production" creates indices named "production-tracing-*".
|
|
|===

.ES bulk processor configuration parameters
[options="header"]
[cols="l, a, a, a"]
|===
|Parameter |Description |Values |Default value
|es:
  bulk:
    actions:
|The number of requests that can be added to the queue before the bulk processor decides to commit updates to disk.
|
|1000

//What is the default here? The original text said "Set to zero to disable. By default, this is disabled."
|es:
  bulk:
    flush-interval:
|A `time.Duration` after which bulk requests are committed, regardless of other thresholds. To disable the bulk processor flush interval, set this to zero.
|
|200ms

|es:
  bulk:
    size:
|The number of bytes that the bulk requests can take up before the bulk processor decides to commit updates to disk.
|
|5000000

|es:
  bulk:
    workers:
|The number of workers that are able to receive and commit bulk requests to Elasticsearch.
|
|1
|===

.ES TLS configuration parameters
[options="header"]
[cols="l, a, a, a"]
|===
|Parameter |Description |Values |Default value
|es:
  tls:
    ca:
|Path to a TLS Certification Authority (CA) file used to verify the remote servers.
|
|Will use the system truststore by default.

|es:
  tls:
    cert:
|Path to a TLS Certificate file, used to identify this process to the remote servers.
|
|

|es:
  tls:
    enabled:
|Enable transport layer security (TLS) when talking to the remote servers. Disabled by default.
|`true`/ `false`
|`false`

|es:
  tls:
    key:
|Path to a TLS Private Key file, used to identify this process to the remote servers.
|
|

|es:
  tls:
    server-name:
|Override the expected TLS server name in the certificate of the remote servers.
|
|
//Clarification of "if specified" for `token-file` and `username`, does that mean if this is set? Or that it only loads the CA if one is specified (that is, if es.tls.ca has a value?)
|es:
  token-file:
|Path to a file containing the bearer token. This flag also loads the Certification Authority (CA) file if it is specified.
|
|
|===

.ES archive configuration parameters
[options="header"]
[cols="l, a, a, a"]
|===
|Parameter |Description |Values |Default value
|es-archive:
  bulk:
    actions:
|The number of requests that can be added to the queue before the bulk processor decides to commit updates to disk.
|
|0

//What is the default here? The original text said "Set to zero to disable. By default, this is disabled."
|es-archive:
  bulk:
    flush-interval:
|A `time.Duration` after which bulk requests are committed, regardless of other thresholds. To disable the bulk processor flush interval, set this to zero.
|
|0s

|es-archive:
  bulk:
    size:
|The number of bytes that the bulk requests can take up before the bulk processor decides to commit updates to disk.
|
|0

|es-archive:
  bulk:
    workers:
|The number of workers that are able to receive and commit bulk requests to Elasticsearch.
|
|0

|es-archive:
  create-index-templates:
|Automatically create index templates at application startup when set to `true`. When templates are installed manually, set to `false`.
|`true`/ `false`
|`false`

|es-archive:
  enabled:
|Enable extra storage.
|`true`/ `false`
|`false`

|es-archive:
  index-prefix:
|Optional prefix for {JaegerShortName} indices. For example, setting this to "production" creates indices named "production-tracing-*".
|
|

|es-archive:
  max-doc-count:
|The maximum document count to return from an Elasticsearch query. This will also apply to aggregations.
|
|0

|es-archive:
  max-num-spans:
|[*Deprecated* - Will be removed in a future release, use `es-archive.max-doc-count` instead.] The maximum number of spans to fetch at a time, per query, in Elasticsearch.
|
|0

|es-archive:
  max-span-age:
|The maximum lookback for spans in Elasticsearch.
|
|0s

|es-archive:
  num-replicas:
|The number of replicas per index in Elasticsearch.
|
|0

|es-archive:
  num-shards:
|The number of shards per index in Elasticsearch.
|
|0

|es-archive:
  password:
|The password required by Elasticsearch. See also, `es.username`.
|
|

|es-archive:
  server-urls:
|The comma-separated list of Elasticsearch servers. Must be specified as fully qualified URLs, for example, `\http://localhost:9200`.
|
|

|es-archive:
  sniffer:
|The sniffer configuration for Elasticsearch. The client uses the sniffing process to find all nodes automatically. Disabled by default.
|`true`/ `false`
|`false`

|es-archive:
  sniffer-tls-enabled:
|Option to enable TLS when sniffing an Elasticsearch Cluster. The client uses the sniffing process to find all nodes automatically. Disabled by default.
|`true`/ `false`
|`false`

|es-archive:
  timeout:
|Timeout used for queries. When set to zero there is no timeout.
|
|0s

|es-archive:
  tls:
    ca:
|Path to a TLS Certification Authority (CA) file used to verify the remote servers.
|
|Will use the system truststore by default.

|es-archive:
  tls:
    cert:
|Path to a TLS Certificate file, used to identify this process to the remote servers.
|
|

|es-archive:
  tls:
    enabled:
|Enable transport layer security (TLS) when talking to the remote servers. Disabled by default.
|`true`/ `false`
|`false`

|es-archive:
  tls:
    key:
|Path to a TLS Private Key file, used to identify this process to the remote servers.
|
|

|es-archive:
  tls:
    server-name:
|Override the expected TLS server name in the certificate of the remote servers.
|
|

//Clarification of "if specified" for next two rows, does that mean if this is set? Or that it only loads the CA if one is specified (that is, if es-archive.tls.ca has a value?)
|es-archive:
  token-file:
|Path to a file containing the bearer token. This flag also loads the Certification Authority (CA) file if it is specified.
|
|

|es-archive:
  username:
|The username required by Elasticsearch. The basic authentication also loads CA if it is specified. See also `es-archive.password`.
|
|

|es-archive:
  version:
|The major Elasticsearch version. If not specified, the value will be auto-detected from Elasticsearch.
|
|0
|===


.Storage example with volume mounts
[source,yaml]
----
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: simple-prod
spec:
  strategy: production
  storage:
    type: elasticsearch
    options:
      es:
        server-urls: https://quickstart-es-http.default.svc:9200
        index-prefix: my-prefix
        tls:
          ca: /es/certificates/ca.crt
    secretName: tracing-secret
  volumeMounts:
    - name: certificates
      mountPath: /es/certificates/
      readOnly: true
  volumes:
    - name: certificates
      secret:
        secretName: quickstart-es-http-certs-public
----

The following example shows a Jaeger CR using an external Elasticsearch cluster with TLS CA certificate mounted from a volume and user/password stored in a secret.

.External Elasticsearch example
[source,yaml]
----
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: simple-prod
spec:
  strategy: production
  storage:
    type: elasticsearch
    options:
      es:
        server-urls: https://quickstart-es-http.default.svc:9200 # <1>
        index-prefix: my-prefix
        tls: # <2>
          ca: /es/certificates/ca.crt
    secretName: tracing-secret # <3>
  volumeMounts: # <4>
    - name: certificates
      mountPath: /es/certificates/
      readOnly: true
  volumes:
    - name: certificates
      secret:
        secretName: quickstart-es-http-certs-public
----
<1> URL to Elasticsearch service running in default namespace.
<2> TLS configuration. In this case only CA certificate, but it can also contain es.tls.key and es.tls.cert when using mutual TLS.
<3> Secret which defines environment variables ES_PASSWORD and ES_USERNAME. Created by kubectl create secret generic tracing-secret --from-literal=ES_PASSWORD=changeme --from-literal=ES_USERNAME=elastic
<4> Volume mounts and volumes which are mounted into all storage components.

[id="distr-tracing-manage-es-certificates_{context}"]
= Managing certificates with Elasticsearch

You can create and manage certificates using the Red Hat Elasticsearch Operator. Managing certificates using the Red Hat Elasticsearch Operator also lets you use a single Elasticsearch cluster with multiple Jaeger Collectors.

:FeatureName: Managing certificates with Elasticsearch
:leveloffset: +1

// When including this file, ensure that {FeatureName} is set immediately before
// the include. Otherwise it will result in an incorrect replacement.

[IMPORTANT]
====
[subs="attributes+"]
{FeatureName} is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.

For more information about the support scope of Red Hat Technology Preview features, see link:https://access.redhat.com/support/offerings/techpreview/[Technology Preview Features Support Scope].
====
// Undefine {FeatureName} attribute, so that any mistakes are easily spotted
:!FeatureName:

:leveloffset: 2

Starting with version 2.4, the {JaegerName} Operator delegates certificate creation to the Red Hat Elasticsearch Operator by using the following annotations in the Elasticsearch custom resource:

* `logging.openshift.io/elasticsearch-cert-management: "true"`
* `logging.openshift.io/elasticsearch-cert.jaeger-<shared-es-node-name>: "user.jaeger"`
* `logging.openshift.io/elasticsearch-cert.curator-<shared-es-node-name>: "system.logging.curator"`

Where the `<shared-es-node-name>` is the name of the Elasticsearch node. For example, if you create an Elasticsearch node named `custom-es`, your custom resource might look like the following example.

.Example Elasticsearch CR showing annotations
[source,yaml]
----
apiVersion: logging.openshift.io/v1
kind: Elasticsearch
metadata:
  annotations:
    logging.openshift.io/elasticsearch-cert-management: "true"
    logging.openshift.io/elasticsearch-cert.jaeger-custom-es: "user.jaeger"
    logging.openshift.io/elasticsearch-cert.curator-custom-es: "system.logging.curator"
  name: custom-es
spec:
  managementState: Managed
  nodeSpec:
    resources:
      limits:
        memory: 16Gi
      requests:
        cpu: 1
        memory: 16Gi
  nodes:
    - nodeCount: 3
      proxyResources: {}
      resources: {}
      roles:
        - master
        - client
        - data
      storage: {}
  redundancyPolicy: ZeroRedundancy
----

.Prerequisites

* {product-title} 4.7
* {logging-title} 5.2
* The Elasticsearch node and the Jaeger instances must be deployed in the same namespace.  For example, `tracing-system`.

You enable certificate management by setting `spec.storage.elasticsearch.useCertManagement` to `true` in the Jaeger custom resource.

.Example showing `useCertManagement`
[source,yaml]
----
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: jaeger-prod
spec:
  strategy: production
  storage:
    type: elasticsearch
    elasticsearch:
      name: custom-es
      doNotProvision: true
      useCertManagement: true
----

The {JaegerName} Operator sets the Elasticsearch custom resource `name` to the value of `spec.storage.elasticsearch.name` from the Jaeger custom resource when provisioning Elasticsearch.

The certificates are provisioned by the Red Hat Elasticsearch Operator and the {JaegerName} Operator injects the certificates.

:leveloffset!:


:leveloffset: +2

////
This module included in the following assemblies:
- distr_tracing_jaeger/distr-tracing-jaeger-configuring.adoc
////
:_mod-docs-content-type: REFERENCE
[id="distr-tracing-config-query_{context}"]
= Query configuration options

Query is a service that retrieves traces from storage and hosts the user interface to display them.

.Parameters used by the {JaegerName} Operator to define Query
[options="header"]
[cols="l, a, a, a"]
|===
|Parameter |Description |Values |Default value

|spec:
  query:
    replicas:
|Specifies the number of Query replicas to create.
|Integer, for example, `2`
|
|===


.Configuration parameters passed to Query
[options="header"]
[cols="l, a, a, a"]
|===
|Parameter |Description |Values |Default value

|spec:
  query:
    options: {}
|Configuration options that define the Query service.
|
|

|options:
  log-level:
|Logging level for Query.
|Possible values: `debug`, `info`, `warn`, `error`, `fatal`, `panic`.
|

|options:
  query:
    base-path:
|The base path for all jaeger-query HTTP routes can be set to a non-root value, for example, `/jaeger` would cause all UI URLs to start with `/jaeger`. This can be useful when running jaeger-query behind a reverse proxy.
|/<path>
|
|===

.Sample Query configuration
[source,yaml]
----
apiVersion: jaegertracing.io/v1
kind: "Jaeger"
metadata:
  name: "my-jaeger"
spec:
  strategy: allInOne
  allInOne:
    options:
      log-level: debug
      query:
        base-path: /jaeger
----

:leveloffset!:

:leveloffset: +2

////
This module included in the following assemblies:
- distr_tracing_jaeger/distr-tracing-jaeger-configuring.adoc
////
:_mod-docs-content-type: REFERENCE
[id="distr-tracing-config-ingester_{context}"]
= Ingester configuration options

Ingester is a service that reads from a Kafka topic and writes to the Elasticsearch storage backend. If you are using the `allInOne` or `production` deployment strategies, you do not need to configure the Ingester service.

.Jaeger parameters passed to the Ingester
[options="header"]
[cols="l, a, a"]
|===
|Parameter |Description |Values
|spec:
  ingester:
    options: {}
|Configuration options that define the Ingester service.
|

|options:
  deadlockInterval:
|Specifies the interval, in seconds or minutes, that the Ingester must wait for a message before terminating.
The deadlock interval is disabled by default (set to `0`), to avoid terminating the Ingester when no messages arrive during system initialization.
|Minutes and seconds, for example, `1m0s`. Default value is `0`.

|options:
  kafka:
    consumer:
      topic:
|The `topic` parameter identifies the Kafka configuration used by the collector to produce the messages, and the Ingester to consume the messages.
|Label for the consumer. For example, `jaeger-spans`.

|options:
  kafka:
    consumer:
      brokers:
|Identifies the Kafka configuration used by the Ingester to consume the messages.
|Label for the broker, for example, `my-cluster-kafka-brokers.kafka:9092`.

|options:
  log-level:
|Logging level for the Ingester.
|Possible values: `debug`, `info`, `warn`, `error`, `fatal`, `dpanic`, `panic`.
|===

.Streaming Collector and Ingester example
[source,yaml]
----
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: simple-streaming
spec:
  strategy: streaming
  collector:
    options:
      kafka:
        producer:
          topic: jaeger-spans
          brokers: my-cluster-kafka-brokers.kafka:9092
  ingester:
    options:
      kafka:
        consumer:
          topic: jaeger-spans
          brokers: my-cluster-kafka-brokers.kafka:9092
      ingester:
        deadlockInterval: 5
  storage:
    type: elasticsearch
    options:
      es:
        server-urls: http://elasticsearch:9200
----

:leveloffset!:

//# includes=_attributes/common-attributes,modules/ossm-enabling-jaeger,modules/ossm-config-smcp-jaeger,modules/ossm-deploying-jaeger,modules/ossm-configuring-external-jaeger,modules/distr-tracing-deployment-best-practices,modules/distr-tracing-config-security-ossm,modules/distr-tracing-config-security-ossm-web,modules/distr-tracing-config-security-ossm-cli,modules/distr-tracing-config-default,modules/distr-tracing-config-jaeger-collector,modules/distr-tracing-config-sampling,modules/distr-tracing-config-storage,modules/snippets/technology-preview,modules/distr-tracing-config-query,modules/distr-tracing-config-ingester
