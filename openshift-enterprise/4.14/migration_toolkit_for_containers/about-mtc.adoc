:_mod-docs-content-type: ASSEMBLY
[id="about-mtc"]
= About the Migration Toolkit for Containers
// The {product-title} attribute provides the context-sensitive name of the relevant OpenShift distribution, for example, "OpenShift Container Platform" or "OKD". The {product-version} attribute provides the product version relative to the distribution, for example "4.9".
// {product-title} and {product-version} are parsed when AsciiBinder queries the _distro_map.yml file in relation to the base branch of a pull request.
// See https://github.com/openshift/openshift-docs/blob/main/contributing_to_docs/doc_guidelines.adoc#product-name-and-version for more information on this topic.
// Other common attributes are defined in the following lines:
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:imagesdir: images
:prewrap!:
:op-system-first: Red Hat Enterprise Linux CoreOS (RHCOS)
:op-system: RHCOS
:op-system-lowercase: rhcos
:op-system-base: RHEL
:op-system-base-full: Red Hat Enterprise Linux (RHEL)
:op-system-version: 8.x
:tsb-name: Template Service Broker
:kebab: image:kebab.png[title="Options menu"]
:rh-openstack-first: Red Hat OpenStack Platform (RHOSP)
:rh-openstack: RHOSP
:ai-full: Assisted Installer
:ai-version: 2.3
:cluster-manager-first: Red Hat OpenShift Cluster Manager
:cluster-manager: OpenShift Cluster Manager
:cluster-manager-url: link:https://console.redhat.com/openshift[OpenShift Cluster Manager Hybrid Cloud Console]
:cluster-manager-url-pull: link:https://console.redhat.com/openshift/install/pull-secret[pull secret from the Red Hat OpenShift Cluster Manager]
:insights-advisor-url: link:https://console.redhat.com/openshift/insights/advisor/[Insights Advisor]
:hybrid-console: Red Hat Hybrid Cloud Console
:hybrid-console-second: Hybrid Cloud Console
:oadp-first: OpenShift API for Data Protection (OADP)
:oadp-full: OpenShift API for Data Protection
:oc-first: pass:quotes[OpenShift CLI (`oc`)]
:product-registry: OpenShift image registry
:rh-storage-first: Red Hat OpenShift Data Foundation
:rh-storage: OpenShift Data Foundation
:rh-rhacm-first: Red Hat Advanced Cluster Management (RHACM)
:rh-rhacm: RHACM
:rh-rhacm-version: 2.8
:sandboxed-containers-first: OpenShift sandboxed containers
:sandboxed-containers-operator: OpenShift sandboxed containers Operator
:sandboxed-containers-version: 1.3
:sandboxed-containers-version-z: 1.3.3
:sandboxed-containers-legacy-version: 1.3.2
:cert-manager-operator: cert-manager Operator for Red Hat OpenShift
:secondary-scheduler-operator-full: Secondary Scheduler Operator for Red Hat OpenShift
:secondary-scheduler-operator: Secondary Scheduler Operator
// Backup and restore
:velero-domain: velero.io
:velero-version: 1.11
:launch: image:app-launcher.png[title="Application Launcher"]
:mtc-short: MTC
:mtc-full: Migration Toolkit for Containers
:mtc-version: 1.8
:mtc-version-z: 1.8.0
// builds (Valid only in 4.11 and later)
:builds-v2title: Builds for Red Hat OpenShift
:builds-v2shortname: OpenShift Builds v2
:builds-v1shortname: OpenShift Builds v1
//gitops
:gitops-title: Red Hat OpenShift GitOps
:gitops-shortname: GitOps
:gitops-ver: 1.1
:rh-app-icon: image:red-hat-applications-menu-icon.jpg[title="Red Hat applications"]
//pipelines
:pipelines-title: Red Hat OpenShift Pipelines
:pipelines-shortname: OpenShift Pipelines
:pipelines-ver: pipelines-1.12
:pipelines-version-number: 1.12
:tekton-chains: Tekton Chains
:tekton-hub: Tekton Hub
:artifact-hub: Artifact Hub
:pac: Pipelines as Code
//odo
:odo-title: odo
//OpenShift Kubernetes Engine
:oke: OpenShift Kubernetes Engine
//OpenShift Platform Plus
:opp: OpenShift Platform Plus
//openshift virtualization (cnv)
:VirtProductName: OpenShift Virtualization
:VirtVersion: 4.14
:KubeVirtVersion: v0.59.0
:HCOVersion: 4.14.0
:CNVNamespace: openshift-cnv
:CNVOperatorDisplayName: OpenShift Virtualization Operator
:CNVSubscriptionSpecSource: redhat-operators
:CNVSubscriptionSpecName: kubevirt-hyperconverged
:delete: image:delete.png[title="Delete"]
//distributed tracing
:DTProductName: Red Hat OpenShift distributed tracing platform
:DTShortName: distributed tracing platform
:DTProductVersion: 2.9
:JaegerName: Red Hat OpenShift distributed tracing platform (Jaeger)
:JaegerShortName: distributed tracing platform (Jaeger)
:JaegerVersion: 1.47.0
:OTELName: Red Hat OpenShift distributed tracing data collection
:OTELShortName: distributed tracing data collection
:OTELOperator: Red Hat OpenShift distributed tracing data collection Operator
:OTELVersion: 0.81.0
:TempoName: Red Hat OpenShift distributed tracing platform (Tempo)
:TempoShortName: distributed tracing platform (Tempo)
:TempoOperator: Tempo Operator
:TempoVersion: 2.1.1
//logging
:logging-title: logging subsystem for Red Hat OpenShift
:logging-title-uc: Logging subsystem for Red Hat OpenShift
:logging: logging subsystem
:logging-uc: Logging subsystem
//serverless
:ServerlessProductName: OpenShift Serverless
:ServerlessProductShortName: Serverless
:ServerlessOperatorName: OpenShift Serverless Operator
:FunctionsProductName: OpenShift Serverless Functions
//service mesh v2
:product-dedicated: Red Hat OpenShift Dedicated
:product-rosa: Red Hat OpenShift Service on AWS
:SMProductName: Red Hat OpenShift Service Mesh
:SMProductShortName: Service Mesh
:SMProductVersion: 2.4.4
:MaistraVersion: 2.4
//Service Mesh v1
:SMProductVersion1x: 1.1.18.2
//Windows containers
:productwinc: Red Hat OpenShift support for Windows Containers
// Red Hat Quay Container Security Operator
:rhq-cso: Red Hat Quay Container Security Operator
// Red Hat Quay
:quay: Red Hat Quay
:sno: single-node OpenShift
:sno-caps: Single-node OpenShift
//TALO and Redfish events Operators
:cgu-operator-first: Topology Aware Lifecycle Manager (TALM)
:cgu-operator-full: Topology Aware Lifecycle Manager
:cgu-operator: TALM
:redfish-operator: Bare Metal Event Relay
//Formerly known as CodeReady Containers and CodeReady Workspaces
:openshift-local-productname: Red Hat OpenShift Local
:openshift-dev-spaces-productname: Red Hat OpenShift Dev Spaces
// Factory-precaching-cli tool
:factory-prestaging-tool: factory-precaching-cli tool
:factory-prestaging-tool-caps: Factory-precaching-cli tool
:openshift-networking: Red Hat OpenShift Networking
// TODO - this probably needs to be different for OKD
//ifdef::openshift-origin[]
//:openshift-networking: OKD Networking
//endif::[]
// logical volume manager storage
:lvms-first: Logical volume manager storage (LVM Storage)
:lvms: LVM Storage
//Operator SDK version
:osdk_ver: 1.31.0
//Operator SDK version that shipped with the previous OCP 4.x release
:osdk_ver_n1: 1.28.0
//Next-gen (OCP 4.14+) Operator Lifecycle Manager, aka "v1"
:olmv1: OLM 1.0
:olmv1-first: Operator Lifecycle Manager (OLM) 1.0
:ztp-first: GitOps Zero Touch Provisioning (ZTP)
:ztp: GitOps ZTP
:3no: three-node OpenShift
:3no-caps: Three-node OpenShift
:run-once-operator: Run Once Duration Override Operator
// Web terminal
:web-terminal-op: Web Terminal Operator
:devworkspace-op: DevWorkspace Operator
:secrets-store-driver: Secrets Store CSI driver
:secrets-store-operator: Secrets Store CSI Driver Operator
//AWS STS
:sts-first: Security Token Service (STS)
:sts-full: Security Token Service
:sts-short: STS
//Cloud provider names
//AWS
:aws-first: Amazon Web Services (AWS)
:aws-full: Amazon Web Services
:aws-short: AWS
//GCP
:gcp-first: Google Cloud Platform (GCP)
:gcp-full: Google Cloud Platform
:gcp-short: GCP
//alibaba cloud
:alibaba: Alibaba Cloud
// IBM Cloud VPC
:ibmcloudVPCProductName: IBM Cloud VPC
:ibmcloudVPCRegProductName: IBM(R) Cloud VPC
// IBM Cloud
:ibm-cloud-bm: IBM Cloud Bare Metal (Classic)
:ibm-cloud-bm-reg: IBM Cloud(R) Bare Metal (Classic)
// IBM Power
:ibmpowerProductName: IBM Power
:ibmpowerRegProductName: IBM(R) Power
// IBM zSystems
:ibmzProductName: IBM Z
:ibmzRegProductName: IBM(R) Z
:linuxoneProductName: IBM(R) LinuxONE
//Azure
:azure-full: Microsoft Azure
:azure-short: Azure
//vSphere
:vmw-full: VMware vSphere
:vmw-short: vSphere
//Oracle
:oci-first: Oracle(R) Cloud Infrastructure
:oci: OCI
:ocvs-first: Oracle(R) Cloud VMware Solution (OCVS)
:ocvs: OCVS
:context: about-mtc

toc::[]

The {mtc-full} ({mtc-short}) enables you to migrate stateful application workloads between {product-title} 4 clusters at the granularity of a namespace.

[NOTE]
====
If you are migrating from {product-title} 3, see xref:../migrating_from_ocp_3_to_4/about-migrating-from-3-to-4.adoc#about-migrating-from-3-to-4[About migrating from {product-title} 3 to 4] and xref:../migrating_from_ocp_3_to_4/installing-3-4.adoc#migration-installing-legacy-operator_installing-3-4[Installing the legacy {mtc-full} Operator on {product-title} 3].
====

You can migrate applications within the same cluster or between clusters by using state migration.

{mtc-short} provides a web console and an API, based on Kubernetes custom resources, to help you control the migration and minimize application downtime.

The {mtc-short} console is installed on the target cluster by default. You can configure the {mtc-full} Operator to install the console on a link:https://access.redhat.com/articles/5064151[remote cluster].

See xref:../migration_toolkit_for_containers/advanced-migration-options-mtc.adoc#advanced-migration-options-mtc[Advanced migration options] for information about the following topics:

* Automating your migration with migration hooks and the {mtc-short} API.
* Configuring your migration plan to exclude resources, support large-scale migrations, and enable automatic PV resizing for direct volume migration.

:leveloffset: +1

// Module included in the following assemblies:
//
// * migrating_from_ocp_3_to_4/about-mtc-3-4.adoc
// * migrating_from_ocp_3_to_4/advanced-migration-options-3-4.adoc
// * migration_toolkit_for_containers/about-mtc.adoc
// * migration_toolkit_for_containers/advanced-migration-options-mtc.adoc

[id="migration-terminology_{context}"]
= Terminology

[cols="1,3a", options="header"]
.{mtc-short} terminology
|===
|Term |Definition
|Source cluster |Cluster from which the applications are migrated.
|Destination cluster^[1]^ |Cluster to which the applications are migrated.
|Replication repository |Object storage used for copying images, volumes, and Kubernetes objects during indirect migration or for Kubernetes objects during direct volume migration or direct image migration.

The replication repository must be accessible to all clusters.

|Host cluster |Cluster on which the `migration-controller` pod and the web console are running. The host cluster is usually the destination cluster but this is not required.

The host cluster does not require an exposed registry route for direct image migration.
|Remote cluster |A remote cluster is usually the source cluster but this is not required.

A remote cluster requires a `Secret` custom resource that contains the `migration-controller` service account token.

A remote cluster requires an exposed secure registry route for direct image migration.

|Indirect migration |Images, volumes, and Kubernetes objects are copied from the source cluster to the replication repository and then from the replication repository to the destination cluster.
|Direct volume migration |Persistent volumes are copied directly from the source cluster to the destination cluster.
|Direct image migration |Images are copied directly from the source cluster to the destination cluster.
|Stage migration |Data is copied to the destination cluster without stopping the application.

Running a stage migration multiple times reduces the duration of the cutover migration.
|Cutover migration |The application is stopped on the source cluster and its resources are migrated to the destination cluster.
|State migration |Application state is migrated by copying specific persistent volume claims to the destination cluster.
|Rollback migration |Rollback migration rolls back a completed migration.
|===
^1^  Called the _target_ cluster in the {mtc-short} web console.

:leveloffset!:
:leveloffset: +1

// Module included in the following assemblies:
//
// * migrating_from_ocp_3_to_4/about-mtc-3-4.adoc
// * migrating_from_ocp_3_to_4/advanced-migration-options-3-4.adoc
// * migration_toolkit_for_containers/about-mtc.adoc
// * migration_toolkit_for_containers/advanced-migration-options-mtc.adoc

[id="migration-mtc-workflow_{context}"]
= {mtc-short} workflow

You can migrate Kubernetes resources, persistent volume data, and internal container images to {product-title} {product-version} by using the {mtc-full} ({mtc-short}) web console or the Kubernetes API.

{mtc-short} migrates the following resources:

* A namespace specified in a migration plan.
* Namespace-scoped resources: When the {mtc-short} migrates a namespace, it migrates all the objects and resources associated with that namespace, such as services or pods. Additionally, if a resource that exists in the namespace but not at the cluster level depends on a resource that exists at the cluster level, the {mtc-short} migrates both resources.
+
For example, a security context constraint (SCC) is a resource that exists at the cluster level and a service account (SA) is a resource that exists at the namespace level. If an SA exists in a namespace that the {mtc-short} migrates, the {mtc-short} automatically locates any SCCs that are linked to the SA and also migrates those SCCs. Similarly, the {mtc-short} migrates persistent volumes that are linked to the persistent volume claims of the namespace.
+
[NOTE]
====
Cluster-scoped resources might have to be migrated manually, depending on the resource.
====

* Custom resources (CRs) and custom resource definitions (CRDs): {mtc-short} automatically migrates CRs and CRDs at the namespace level.

Migrating an application with the {mtc-short} web console involves the following steps:

. Install the {mtc-full} Operator on all clusters.
+
You can install the {mtc-full} Operator in a restricted environment with limited or no internet access. The source and target clusters must have network access to each other and to a mirror registry.

. Configure the replication repository, an intermediate object storage that {mtc-short} uses to migrate data.
+
The source and target clusters must have network access to the replication repository during migration. If you are using a proxy server, you must configure it to allow network traffic between the replication repository and the clusters.

. Add the source cluster to the {mtc-short} web console.
. Add the replication repository to the {mtc-short} web console.
. Create a migration plan, with one of the following data migration options:

* *Copy*: {mtc-short} copies the data from the source cluster to the replication repository, and from the replication repository to the target cluster.
+
[NOTE]
====
If you are using direct image migration or direct volume migration, the images or volumes are copied directly from the source cluster to the target cluster.
====
+
image::migration-PV-copy.png[]

* *Move*: {mtc-short} unmounts a remote volume, for example, NFS, from the source cluster, creates a PV resource on the target cluster pointing to the remote volume, and then mounts the remote volume on the target cluster. Applications running on the target cluster use the same remote volume that the source cluster was using. The remote volume must be accessible to the source and target clusters.
+
[NOTE]
====
Although the replication repository does not appear in this diagram, it is required for migration.
====
+
image::migration-PV-move.png[]

. Run the migration plan, with one of the following options:

* *Stage* copies data to the target cluster without stopping the application.
+
A stage migration can be run multiple times so that most of the data is copied to the target before migration. Running one or more stage migrations reduces the duration of the cutover migration.

* *Cutover* stops the application on the source cluster and moves the resources to the target cluster.
+
Optional: You can clear the *Halt transactions on the source cluster during migration* checkbox.

image::OCP_3_to_4_App_migration.png[]

:leveloffset!:
:leveloffset: +1

// Module included in the following assemblies:
//
// * migrating_from_ocp_3_to_4/migrating-applications-3-4.adoc
// * migration_toolkit_for_containers/migrating-applications-with-mtc.adoc

:_mod-docs-content-type: CONCEPT
[id="migration-understanding-data-copy-methods_{context}"]
= About data copy methods

The {mtc-full} ({mtc-short}) supports the file system and snapshot data copy methods for migrating data from the source cluster to the target cluster. You can select a method that is suited for your environment and is supported by your storage provider.

[id="file-system-copy-method_{context}"]
== File system copy method

{mtc-short} copies data files from the source cluster to the replication repository, and from there to the target cluster.

The file system copy method uses Restic for indirect migration or Rsync for direct volume migration.

[cols="1,1", options="header"]
.File system copy method summary
|===
|Benefits |Limitations
a|* Clusters can have different storage classes.
* Supported for all S3 storage providers.
* Optional data verification with checksum.
* Supports direct volume migration, which significantly increases performance.
a|* Slower than the snapshot copy method.
* Optional data verification significantly reduces performance.
|===

[NOTE]
====
The Restic and Rsync PV migration assumes that the PVs supported are only `volumeMode=filesystem`. Using `volumeMode=Block` for file system migration is _not_
supported.
====


[id="snapshot-copy-method_{context}"]
== Snapshot copy method

{mtc-short} copies a snapshot of the source cluster data to the replication repository of a cloud provider. The data is restored on the target cluster.

The snapshot copy method can be used with Amazon Web Services, Google Cloud Provider, and Microsoft Azure.

[cols="1,1", options="header"]
.Snapshot copy method summary
|===
|Benefits |Limitations
a|* Faster than the file system copy method.
a|* Cloud provider must support snapshots.
* Clusters must be on the same cloud provider.
* Clusters must be in the same location or region.
* Clusters must have the same storage class.
* Storage class must be compatible with snapshots.
* Does not support direct volume migration.
|===

:leveloffset!:
:leveloffset: +1

// Module included in the following assemblies:
//
// * migrating_from_ocp_3_to_4/migrating-applications-3-4.adoc
// * migration_toolkit_for_containers/migrating-applications-with-mtc.adoc

[id="migration-direct-volume-migration-and-direct-image-migration_{context}"]
= Direct volume migration and direct image migration

You can use direct image migration (DIM) and direct volume migration (DVM) to migrate images and data directly from the source cluster to the target cluster.

If you run DVM with nodes that are in different availability zones, the migration might fail because the migrated pods cannot access the persistent volume claim.

DIM and DVM have significant performance benefits because the intermediate steps of backing up files from the source cluster to the replication repository and restoring files from the replication repository to the target cluster are skipped. The data is transferred with link:https://rsync.samba.org/[Rsync].

DIM and DVM have additional prerequisites.

:leveloffset!:

//# includes=_attributes/common-attributes,modules/migration-terminology,modules/migration-mtc-workflow,modules/migration-understanding-data-copy-methods,modules/migration-direct-volume-migration-and-direct-image-migration
