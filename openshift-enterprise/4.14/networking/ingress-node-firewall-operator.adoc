:_mod-docs-content-type: ASSEMBLY
[id="ingress-node-firewall-operator"]
= Ingress Node Firewall Operator in {product-title}
// The {product-title} attribute provides the context-sensitive name of the relevant OpenShift distribution, for example, "OpenShift Container Platform" or "OKD". The {product-version} attribute provides the product version relative to the distribution, for example "4.9".
// {product-title} and {product-version} are parsed when AsciiBinder queries the _distro_map.yml file in relation to the base branch of a pull request.
// See https://github.com/openshift/openshift-docs/blob/main/contributing_to_docs/doc_guidelines.adoc#product-name-and-version for more information on this topic.
// Other common attributes are defined in the following lines:
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:imagesdir: images
:prewrap!:
:op-system-first: Red Hat Enterprise Linux CoreOS (RHCOS)
:op-system: RHCOS
:op-system-lowercase: rhcos
:op-system-base: RHEL
:op-system-base-full: Red Hat Enterprise Linux (RHEL)
:op-system-version: 8.x
:tsb-name: Template Service Broker
:kebab: image:kebab.png[title="Options menu"]
:rh-openstack-first: Red Hat OpenStack Platform (RHOSP)
:rh-openstack: RHOSP
:ai-full: Assisted Installer
:ai-version: 2.3
:cluster-manager-first: Red Hat OpenShift Cluster Manager
:cluster-manager: OpenShift Cluster Manager
:cluster-manager-url: link:https://console.redhat.com/openshift[OpenShift Cluster Manager Hybrid Cloud Console]
:cluster-manager-url-pull: link:https://console.redhat.com/openshift/install/pull-secret[pull secret from the Red Hat OpenShift Cluster Manager]
:insights-advisor-url: link:https://console.redhat.com/openshift/insights/advisor/[Insights Advisor]
:hybrid-console: Red Hat Hybrid Cloud Console
:hybrid-console-second: Hybrid Cloud Console
:oadp-first: OpenShift API for Data Protection (OADP)
:oadp-full: OpenShift API for Data Protection
:oc-first: pass:quotes[OpenShift CLI (`oc`)]
:product-registry: OpenShift image registry
:rh-storage-first: Red Hat OpenShift Data Foundation
:rh-storage: OpenShift Data Foundation
:rh-rhacm-first: Red Hat Advanced Cluster Management (RHACM)
:rh-rhacm: RHACM
:rh-rhacm-version: 2.8
:sandboxed-containers-first: OpenShift sandboxed containers
:sandboxed-containers-operator: OpenShift sandboxed containers Operator
:sandboxed-containers-version: 1.3
:sandboxed-containers-version-z: 1.3.3
:sandboxed-containers-legacy-version: 1.3.2
:cert-manager-operator: cert-manager Operator for Red Hat OpenShift
:secondary-scheduler-operator-full: Secondary Scheduler Operator for Red Hat OpenShift
:secondary-scheduler-operator: Secondary Scheduler Operator
// Backup and restore
:velero-domain: velero.io
:velero-version: 1.11
:launch: image:app-launcher.png[title="Application Launcher"]
:mtc-short: MTC
:mtc-full: Migration Toolkit for Containers
:mtc-version: 1.8
:mtc-version-z: 1.8.0
// builds (Valid only in 4.11 and later)
:builds-v2title: Builds for Red Hat OpenShift
:builds-v2shortname: OpenShift Builds v2
:builds-v1shortname: OpenShift Builds v1
//gitops
:gitops-title: Red Hat OpenShift GitOps
:gitops-shortname: GitOps
:gitops-ver: 1.1
:rh-app-icon: image:red-hat-applications-menu-icon.jpg[title="Red Hat applications"]
//pipelines
:pipelines-title: Red Hat OpenShift Pipelines
:pipelines-shortname: OpenShift Pipelines
:pipelines-ver: pipelines-1.12
:pipelines-version-number: 1.12
:tekton-chains: Tekton Chains
:tekton-hub: Tekton Hub
:artifact-hub: Artifact Hub
:pac: Pipelines as Code
//odo
:odo-title: odo
//OpenShift Kubernetes Engine
:oke: OpenShift Kubernetes Engine
//OpenShift Platform Plus
:opp: OpenShift Platform Plus
//openshift virtualization (cnv)
:VirtProductName: OpenShift Virtualization
:VirtVersion: 4.14
:KubeVirtVersion: v0.59.0
:HCOVersion: 4.14.0
:CNVNamespace: openshift-cnv
:CNVOperatorDisplayName: OpenShift Virtualization Operator
:CNVSubscriptionSpecSource: redhat-operators
:CNVSubscriptionSpecName: kubevirt-hyperconverged
:delete: image:delete.png[title="Delete"]
//distributed tracing
:DTProductName: Red Hat OpenShift distributed tracing platform
:DTShortName: distributed tracing platform
:DTProductVersion: 2.9
:JaegerName: Red Hat OpenShift distributed tracing platform (Jaeger)
:JaegerShortName: distributed tracing platform (Jaeger)
:JaegerVersion: 1.47.0
:OTELName: Red Hat OpenShift distributed tracing data collection
:OTELShortName: distributed tracing data collection
:OTELOperator: Red Hat OpenShift distributed tracing data collection Operator
:OTELVersion: 0.81.0
:TempoName: Red Hat OpenShift distributed tracing platform (Tempo)
:TempoShortName: distributed tracing platform (Tempo)
:TempoOperator: Tempo Operator
:TempoVersion: 2.1.1
//logging
:logging-title: logging subsystem for Red Hat OpenShift
:logging-title-uc: Logging subsystem for Red Hat OpenShift
:logging: logging subsystem
:logging-uc: Logging subsystem
//serverless
:ServerlessProductName: OpenShift Serverless
:ServerlessProductShortName: Serverless
:ServerlessOperatorName: OpenShift Serverless Operator
:FunctionsProductName: OpenShift Serverless Functions
//service mesh v2
:product-dedicated: Red Hat OpenShift Dedicated
:product-rosa: Red Hat OpenShift Service on AWS
:SMProductName: Red Hat OpenShift Service Mesh
:SMProductShortName: Service Mesh
:SMProductVersion: 2.4.4
:MaistraVersion: 2.4
//Service Mesh v1
:SMProductVersion1x: 1.1.18.2
//Windows containers
:productwinc: Red Hat OpenShift support for Windows Containers
// Red Hat Quay Container Security Operator
:rhq-cso: Red Hat Quay Container Security Operator
// Red Hat Quay
:quay: Red Hat Quay
:sno: single-node OpenShift
:sno-caps: Single-node OpenShift
//TALO and Redfish events Operators
:cgu-operator-first: Topology Aware Lifecycle Manager (TALM)
:cgu-operator-full: Topology Aware Lifecycle Manager
:cgu-operator: TALM
:redfish-operator: Bare Metal Event Relay
//Formerly known as CodeReady Containers and CodeReady Workspaces
:openshift-local-productname: Red Hat OpenShift Local
:openshift-dev-spaces-productname: Red Hat OpenShift Dev Spaces
// Factory-precaching-cli tool
:factory-prestaging-tool: factory-precaching-cli tool
:factory-prestaging-tool-caps: Factory-precaching-cli tool
:openshift-networking: Red Hat OpenShift Networking
// TODO - this probably needs to be different for OKD
//ifdef::openshift-origin[]
//:openshift-networking: OKD Networking
//endif::[]
// logical volume manager storage
:lvms-first: Logical volume manager storage (LVM Storage)
:lvms: LVM Storage
//Operator SDK version
:osdk_ver: 1.31.0
//Operator SDK version that shipped with the previous OCP 4.x release
:osdk_ver_n1: 1.28.0
//Next-gen (OCP 4.14+) Operator Lifecycle Manager, aka "v1"
:olmv1: OLM 1.0
:olmv1-first: Operator Lifecycle Manager (OLM) 1.0
:ztp-first: GitOps Zero Touch Provisioning (ZTP)
:ztp: GitOps ZTP
:3no: three-node OpenShift
:3no-caps: Three-node OpenShift
:run-once-operator: Run Once Duration Override Operator
// Web terminal
:web-terminal-op: Web Terminal Operator
:devworkspace-op: DevWorkspace Operator
:secrets-store-driver: Secrets Store CSI driver
:secrets-store-operator: Secrets Store CSI Driver Operator
//AWS STS
:sts-first: Security Token Service (STS)
:sts-full: Security Token Service
:sts-short: STS
//Cloud provider names
//AWS
:aws-first: Amazon Web Services (AWS)
:aws-full: Amazon Web Services
:aws-short: AWS
//GCP
:gcp-first: Google Cloud Platform (GCP)
:gcp-full: Google Cloud Platform
:gcp-short: GCP
//alibaba cloud
:alibaba: Alibaba Cloud
// IBM Cloud VPC
:ibmcloudVPCProductName: IBM Cloud VPC
:ibmcloudVPCRegProductName: IBM(R) Cloud VPC
// IBM Cloud
:ibm-cloud-bm: IBM Cloud Bare Metal (Classic)
:ibm-cloud-bm-reg: IBM Cloud(R) Bare Metal (Classic)
// IBM Power
:ibmpowerProductName: IBM Power
:ibmpowerRegProductName: IBM(R) Power
// IBM zSystems
:ibmzProductName: IBM Z
:ibmzRegProductName: IBM(R) Z
:linuxoneProductName: IBM(R) LinuxONE
//Azure
:azure-full: Microsoft Azure
:azure-short: Azure
//vSphere
:vmw-full: VMware vSphere
:vmw-short: vSphere
//Oracle
:oci-first: Oracle(R) Cloud Infrastructure
:oci: OCI
:ocvs-first: Oracle(R) Cloud VMware Solution (OCVS)
:ocvs: OCVS
:context: ingress-node-firewall-operator

toc::[]

The Ingress Node Firewall Operator allows administrators to manage firewall configurations at the node level.

:leveloffset: +1

// Module included in the following assemblies:
//
// * networking/ingress-node-firewall-operator.adoc

:_mod-docs-content-type: PROCEDURE
[id="installing-infw-operator_{context}"]
= Installing the Ingress Node Firewall Operator

As a cluster administrator, you can install the Ingress Node Firewall Operator by using the {product-title} CLI or the web console.

[id="install-operator-cli_{context}"]
== Installing the Ingress Node Firewall Operator using the CLI

As a cluster administrator, you can install the Operator using the CLI.

.Prerequisites

* You have installed the OpenShift CLI (`oc`).
* You have an account with administrator privileges.

.Procedure

. To create the `openshift-ingress-node-firewall` namespace, enter the following command:
+
[source,terminal]
----
$ cat << EOF| oc create -f -
apiVersion: v1
kind: Namespace
metadata:
  labels:
    pod-security.kubernetes.io/enforce: privileged
    pod-security.kubernetes.io/enforce-version: v1.24
  name: openshift-ingress-node-firewall
EOF
----

. To create an `OperatorGroup` CR, enter the following command:
+
[source,terminal]
----
$ cat << EOF| oc create -f -
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: ingress-node-firewall-operators
  namespace: openshift-ingress-node-firewall
EOF
----

. Subscribe to the Ingress Node Firewall Operator.

.. To create a `Subscription` CR for the Ingress Node Firewall Operator, enter the following command:
+
[source,terminal]
----
$ cat << EOF| oc create -f -
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: ingress-node-firewall-sub
  namespace: openshift-ingress-node-firewall
spec:
  name: ingress-node-firewall
  channel: stable
  source: redhat-operators
  sourceNamespace: openshift-marketplace
EOF
----

. To verify that the Operator is installed, enter the following command:
+
[source,terminal]
----
$ oc get ip -n openshift-ingress-node-firewall
----
+
.Example output
[source,terminal,subs="attributes+"]
----
NAME            CSV                                         APPROVAL    APPROVED
install-5cvnz   ingress-node-firewall.{product-version}.0-202211122336   Automatic   true
----

. To verify the version of the Operator, enter the following command:

+
[source,terminal]
----
$ oc get csv -n openshift-ingress-node-firewall
----
+
.Example output
[source,terminal,subs="attributes+"]
----
NAME                                        DISPLAY                          VERSION               REPLACES                                    PHASE
ingress-node-firewall.{product-version}.0-202211122336   Ingress Node Firewall Operator   {product-version}.0-202211122336   ingress-node-firewall.{product-version}.0-202211102047   Succeeded
----

[id="install-operator-web-console_{context}"]
== Installing the Ingress Node Firewall Operator using the web console

As a cluster administrator, you can install the Operator using the web console.

.Prerequisites

* You have installed the OpenShift CLI (`oc`).
* You have an account with administrator privileges.

.Procedure


. Install the Ingress Node Firewall Operator:

.. In the {product-title} web console, click *Operators* -> *OperatorHub*.

.. Select *Ingress Node Firewall Operator* from the list of available Operators, and then click *Install*.

.. On the *Install Operator* page, under *Installed Namespace*, select *Operator recommended Namespace*.

.. Click *Install*.

. Verify that the Ingress Node Firewall Operator is installed successfully:

.. Navigate to the *Operators* -> *Installed Operators* page.

.. Ensure that *Ingress Node Firewall Operator* is listed in the *openshift-ingress-node-firewall* project with a *Status* of *InstallSucceeded*.
+
[NOTE]
====
During installation an Operator might display a *Failed* status.
If the installation later succeeds with an *InstallSucceeded* message, you can ignore the *Failed* message.
====

+
If the Operator does not have a *Status* of *InstallSucceeded*, troubleshoot using the following steps:

+
* Inspect the *Operator Subscriptions* and *Install Plans* tabs for any failures or errors under *Status*.
* Navigate to the *Workloads* -> *Pods* page and check the logs for pods in the `openshift-ingress-node-firewall` project.
* Check the namespace of the YAML file. If the annotation is missing, you can add the annotation `workload.openshift.io/allowed=management` to the Operator namespace with the following command:
+
[source,terminal]
----
$ oc annotate ns/openshift-ingress-node-firewall workload.openshift.io/allowed=management
----
+
[NOTE]
====
For {sno} clusters, the `openshift-ingress-node-firewall` namespace requires the `workload.openshift.io/allowed=management` annotation.
====

:leveloffset!:

:leveloffset: +1

// Module included in the following assemblies:
//
// * networking/ingress-node-firewall-operator.adoc

:_mod-docs-content-type: CONCEPT
[id="nw-infw-operator-cr_{context}"]
= Ingress Node Firewall Operator

The Ingress Node Firewall Operator provides ingress firewall rules at a node level by deploying the daemon set to nodes you specify and manage in the firewall configurations. To deploy the daemon set, you create an `IngressNodeFirewallConfig` custom resource (CR). The Operator applies the `IngressNodeFirewallConfig` CR to create ingress node firewall daemon set `daemon`, which run on all nodes that match the `nodeSelector`.

You configure `rules` of the `IngressNodeFirewall` CR and apply them to clusters using the `nodeSelector` and setting values to "true".

[IMPORTANT]
====
The Ingress Node Firewall Operator supports only stateless firewall rules.

Network interface controllers (NICs) that do not support native XDP drivers will run at a lower performance.

For {product-title} 4.14, you must run Ingress Node Firewall Operator on {op-system-base} 9.0 or later.
====

:leveloffset!:

:leveloffset: +1

// Module included in the following assemblies:
//
// * networking/ingress-node-firewall-operator.adoc

:_mod-docs-content-type: PROCEDURE
[id="nw-infw-operator-deploying_{context}"]
= Deploying Ingress Node Firewall Operator

.Prerequisite
* The Ingress Node Firewall Operator is installed.

.Procedure

To deploy the Ingress Node Firewall Operator, create a `IngressNodeFirewallConfig` custom resource that will deploy the Operator's daemon set. You can deploy one or multiple `IngressNodeFirewall` CRDs to nodes by applying firewall rules.

. Create the `IngressNodeFirewallConfig` inside the `openshift-ingress-node-firewall` namespace named `ingressnodefirewallconfig`.

. Run the following command to deploy Ingress Node Firewall Operator rules:
+
[source,terminal]
----
$ oc apply -f rule.yaml
----

:leveloffset!:

:leveloffset: +1

// Module included in the following assemblies:
//
// * networking/ingress-node-firewall-operator.adoc

:_mod-docs-content-type: CONCEPT
[id="nw-infw-operator-config-object_{context}"]
== Ingress Node Firewall configuration object

The fields for the Ingress Node Firewall configuration object are described in the following table:

.Ingress Node Firewall Configuration object
[cols=".^2,.^2,.^6a",options="header"]
|====
|Field|Type|Description

|`metadata.name`
|`string`
|The name of the CR object. The name of the firewall rules object must be `ingressnodefirewallconfig`.

|`metadata.namespace`
|`string`
|Namespace for the Ingress Firewall Operator CR object. The `IngressNodeFirewallConfig` CR must be created inside the `openshift-ingress-node-firewall` namespace.

|`spec.nodeSelector`
|`string`
|
A node selection constraint used to target nodes through specified node labels. For example:

[source,yaml]
----
spec:
  nodeSelector:
    node-role.kubernetes.io/worker: ""
----

[NOTE]
====
One label used in `nodeSelector` must match a label on the nodes in order for the daemon set to start. For example, if the node labels `node-role.kubernetes.io/worker` and `node-type.kubernetes.io/vm` are applied to a node, then at least one label must be set using `nodeSelector` for the daemon set to start.
====

|====

[NOTE]
====
The Operator consumes the CR and creates an ingress node firewall daemon set on all the nodes that match the `nodeSelector`.
====

[discrete]
[id="nw-ingress-node-firewall-example-cr-2_{context}"]
== Ingress Node Firewall Operator example configuration

A complete Ingress Node Firewall Configuration is specified in the following example:

.Example Ingress Node Firewall Configuration object
[source,yaml]
----
apiVersion: ingressnodefirewall.openshift.io/v1alpha1
kind: IngressNodeFirewallConfig
metadata:
  name: ingressnodefirewallconfig
  namespace: openshift-ingress-node-firewall
spec:
  nodeSelector:
    node-role.kubernetes.io/worker: ""
----

[NOTE]
====
The Operator consumes the CR and creates an ingress node firewall daemon set on all the nodes that match the `nodeSelector`.
====

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
//
// * networking/ingress-node-firewall-operator.adoc

:_mod-docs-content-type: CONCEPT
[id="nw-ingress-node-firewall-operator-rules-object_{context}"]
= Ingress Node Firewall rules object

The fields for the Ingress Node Firewall rules object are described in the following table:

.Ingress Node Firewall rules object
[cols=".^2,.^2,.^6a",options="header"]
|====
|Field|Type|Description

|`metadata.name`
|`string`
|The name of the CR object.

|`interfaces`
|`array`
|The fields for this object specify the interfaces to apply the firewall rules to. For example, `- en0` and
`- en1`.

|`nodeSelector`
|`array`
|You can use `nodeSelector` to select the nodes to apply the firewall rules to. Set the value of your named `nodeselector` labels to `true` to apply the rule.

|`ingress`
|`object`
|`ingress` allows you to configure the rules that allow outside access to the services on your cluster.
|====

[discrete]
[id="nw-infw-ingress-rules-object_{context}"]
=== Ingress object configuration

The values for the `ingress` object are defined in the following table:

.`ingress` object
[cols=".^3,.^2,.^5a",options="header"]
|====
|Field|Type|Description

|`sourceCIDRs`
|`array`
|Allows you to set the CIDR block. You can configure multiple CIDRs from different address families.

[NOTE]
====
Different CIDRs allow you to use the same order rule. In the case that there are multiple `IngressNodeFirewall` objects for the same nodes and interfaces with overlapping CIDRs, the `order` field will specify which rule is applied first. Rules are applied in ascending order.
====

|`rules`
|`array`
|Ingress firewall `rules.order` objects are ordered starting at `1` for each `source.CIDR` with up to 100 rules per CIDR. Lower order rules are executed first.

`rules.protocolConfig.protocol` supports the following protocols: TCP, UDP, SCTP, ICMP and ICMPv6. ICMP and ICMPv6 rules can match against ICMP and ICMPv6 types or codes. TCP, UDP, and SCTP rules can match against a single destination port or a range of ports using `<start : end-1>` format.

Set `rules.action` to `allow` to apply the rule or `deny` to disallow the rule.

[NOTE]
====
Ingress firewall rules are verified using a verification webhook that blocks any invalid configuration. The verification webhook prevents you from blocking any critical cluster services such as the API server or SSH.
====
|====

[discrete]
[id="nw-ingress-node-firewall-example-cr_{context}"]
== Ingress Node Firewall rules object example

A complete Ingress Node Firewall configuration is specified in the following example:

.Example Ingress Node Firewall configuration
[source,yaml]
----
apiVersion: ingressnodefirewall.openshift.io/v1alpha1
kind: IngressNodeFirewall
metadata:
  name: ingressnodefirewall
spec:
  interfaces:
  - eth0
  nodeSelector:
    matchLabels:
      <do_node_ingress_firewall>: 'true'
  ingress:
  - sourceCIDRs:
       - 172.16.0.0/12
    rules:
    - order: 10
      protocolConfig:
        protocol: ICMP
        icmp:
          icmpType: 8 #ICMP Echo request
      action: Deny
    - order: 20
      protocolConfig:
        protocol: TCP
        tcp:
          ports: "8000-9000"
      action: Deny
  - sourceCIDRs:
       - fc00:f853:ccd:e793::0/64
    rules:
    - order: 10
      protocolConfig:
        protocol: ICMPv6
        icmpv6:
          icmpType: 128 #ICMPV6 Echo request
      action: Deny
----

[discrete]
[id="nw-ingress-node-firewall-zero-trust-example-cr_{context}"]
== Zero trust Ingress Node Firewall rules object example

Zero trust Ingress Node Firewall rules can provide additional security to multi-interface clusters. For example, you can use zero trust Ingress Node Firewall rules to drop all traffic on a specific interface except for SSH.

A complete configuration of a zero trust Ingress Node Firewall rule set is specified in the following example:

[IMPORTANT]
====
Users need to add all ports their application will use to their allowlist in the following case to ensure proper functionality.
====

.Example zero trust Ingress Node Firewall rules
[source,yaml]
----
apiVersion: ingressnodefirewall.openshift.io/v1alpha1
kind: IngressNodeFirewall
metadata:
 name: ingressnodefirewall-zero-trust
spec:
 interfaces:
 - eth1 <1>
 nodeSelector:
   matchLabels:
     <do_node_ingress_firewall>: 'true'
 ingress:
 - sourceCIDRs:
      - 0.0.0.0/0 <2>
   rules:
   - order: 10
     protocolConfig:
       protocol: TCP
       tcp:
         ports: 22
     action: Allow
   - order: 20
     action: Deny <3>
----
<1> Multi-interface cluster
<2> `0.0.0.0/0` set to match any CIDR
<3> `action` set to `deny`

:leveloffset!:

:leveloffset: +1

// Module included in the following assemblies:
//
// * networking/ingress-node-firewall-operator.adoc

:_mod-docs-content-type: PROCEDURE
[id="nw-infw-operator-viewing_{context}"]
= Viewing Ingress Node Firewall Operator rules

.Procedure

. Run the following command to view all current rules :
+
[source,terminal]
----
$ oc get ingressnodefirewall
----

. Choose one of the returned `<resource>` names and run the following command to view the rules or configs:
+
[source,terminal]
----
$ oc get <resource> <name> -o yaml
----

:leveloffset!:

:leveloffset: +1

// Module included in the following assemblies:
//
// * networking/ingress-node-firewall-operator.adoc

:_mod-docs-content-type: PROCEDURE
[id="nw-infw-operator-troubleshooting_{context}"]
= Troubleshooting the Ingress Node Firewall Operator

* Run the following command to list installed Ingress Node Firewall custom resource definitions (CRD):
+
[source,terminal]
----
$ oc get crds | grep ingressnodefirewall
----
+
.Example output
[source,terminal]
----
NAME               READY   UP-TO-DATE   AVAILABLE   AGE
ingressnodefirewallconfigs.ingressnodefirewall.openshift.io       2022-08-25T10:03:01Z
ingressnodefirewallnodestates.ingressnodefirewall.openshift.io    2022-08-25T10:03:00Z
ingressnodefirewalls.ingressnodefirewall.openshift.io             2022-08-25T10:03:00Z
----

* Run the following command to view the state of the Ingress Node Firewall Operator:
+
[source,terminal]
----
$ oc get pods -n openshift-ingress-node-firewall
----
+
.Example output
[source,terminal]
----
NAME                                       READY  STATUS         RESTARTS  AGE
ingress-node-firewall-controller-manager   2/2    Running        0         5d21h
ingress-node-firewall-daemon-pqx56         3/3    Running        0         5d21h
----
+
The following fields provide information about the status of the Operator:
`READY`, `STATUS`, `AGE`, and `RESTARTS`. The `STATUS` field is `Running` when the Ingress Node Firewall Operator is deploying a daemon set to the assigned nodes.

* Run the following command to collect all ingress firewall node pods' logs:
+
[source,terminal]
----
$ oc adm must-gather â€“ gather_ingress_node_firewall
----
+
The logs are available in the sos node's report containing eBPF `bpftool` outputs at `/sos_commands/ebpf`. These reports include lookup tables used or updated as the ingress firewall XDP handles packet processing, updates statistics, and emits events.

:leveloffset!:

//# includes=_attributes/common-attributes,modules/nw-infw-operator-installing,modules/nw-infw-operator-cr,modules/nw-infw-operator-deploying,modules/nw-infw-operator-config-object,modules/nw-infw-operator-rules-object,modules/nw-infw-operator-viewing,modules/nw-infw-operator-troubleshooting
