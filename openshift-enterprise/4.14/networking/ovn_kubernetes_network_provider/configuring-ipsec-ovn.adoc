:_mod-docs-content-type: ASSEMBLY
[id="configuring-ipsec-ovn"]
= Configuring IPsec encryption
// The {product-title} attribute provides the context-sensitive name of the relevant OpenShift distribution, for example, "OpenShift Container Platform" or "OKD". The {product-version} attribute provides the product version relative to the distribution, for example "4.9".
// {product-title} and {product-version} are parsed when AsciiBinder queries the _distro_map.yml file in relation to the base branch of a pull request.
// See https://github.com/openshift/openshift-docs/blob/main/contributing_to_docs/doc_guidelines.adoc#product-name-and-version for more information on this topic.
// Other common attributes are defined in the following lines:
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:imagesdir: images
:prewrap!:
:op-system-first: Red Hat Enterprise Linux CoreOS (RHCOS)
:op-system: RHCOS
:op-system-lowercase: rhcos
:op-system-base: RHEL
:op-system-base-full: Red Hat Enterprise Linux (RHEL)
:op-system-version: 8.x
:tsb-name: Template Service Broker
:kebab: image:kebab.png[title="Options menu"]
:rh-openstack-first: Red Hat OpenStack Platform (RHOSP)
:rh-openstack: RHOSP
:ai-full: Assisted Installer
:ai-version: 2.3
:cluster-manager-first: Red Hat OpenShift Cluster Manager
:cluster-manager: OpenShift Cluster Manager
:cluster-manager-url: link:https://console.redhat.com/openshift[OpenShift Cluster Manager Hybrid Cloud Console]
:cluster-manager-url-pull: link:https://console.redhat.com/openshift/install/pull-secret[pull secret from the Red Hat OpenShift Cluster Manager]
:insights-advisor-url: link:https://console.redhat.com/openshift/insights/advisor/[Insights Advisor]
:hybrid-console: Red Hat Hybrid Cloud Console
:hybrid-console-second: Hybrid Cloud Console
:oadp-first: OpenShift API for Data Protection (OADP)
:oadp-full: OpenShift API for Data Protection
:oc-first: pass:quotes[OpenShift CLI (`oc`)]
:product-registry: OpenShift image registry
:rh-storage-first: Red Hat OpenShift Data Foundation
:rh-storage: OpenShift Data Foundation
:rh-rhacm-first: Red Hat Advanced Cluster Management (RHACM)
:rh-rhacm: RHACM
:rh-rhacm-version: 2.8
:sandboxed-containers-first: OpenShift sandboxed containers
:sandboxed-containers-operator: OpenShift sandboxed containers Operator
:sandboxed-containers-version: 1.3
:sandboxed-containers-version-z: 1.3.3
:sandboxed-containers-legacy-version: 1.3.2
:cert-manager-operator: cert-manager Operator for Red Hat OpenShift
:secondary-scheduler-operator-full: Secondary Scheduler Operator for Red Hat OpenShift
:secondary-scheduler-operator: Secondary Scheduler Operator
// Backup and restore
:velero-domain: velero.io
:velero-version: 1.11
:launch: image:app-launcher.png[title="Application Launcher"]
:mtc-short: MTC
:mtc-full: Migration Toolkit for Containers
:mtc-version: 1.8
:mtc-version-z: 1.8.0
// builds (Valid only in 4.11 and later)
:builds-v2title: Builds for Red Hat OpenShift
:builds-v2shortname: OpenShift Builds v2
:builds-v1shortname: OpenShift Builds v1
//gitops
:gitops-title: Red Hat OpenShift GitOps
:gitops-shortname: GitOps
:gitops-ver: 1.1
:rh-app-icon: image:red-hat-applications-menu-icon.jpg[title="Red Hat applications"]
//pipelines
:pipelines-title: Red Hat OpenShift Pipelines
:pipelines-shortname: OpenShift Pipelines
:pipelines-ver: pipelines-1.12
:pipelines-version-number: 1.12
:tekton-chains: Tekton Chains
:tekton-hub: Tekton Hub
:artifact-hub: Artifact Hub
:pac: Pipelines as Code
//odo
:odo-title: odo
//OpenShift Kubernetes Engine
:oke: OpenShift Kubernetes Engine
//OpenShift Platform Plus
:opp: OpenShift Platform Plus
//openshift virtualization (cnv)
:VirtProductName: OpenShift Virtualization
:VirtVersion: 4.14
:KubeVirtVersion: v0.59.0
:HCOVersion: 4.14.0
:CNVNamespace: openshift-cnv
:CNVOperatorDisplayName: OpenShift Virtualization Operator
:CNVSubscriptionSpecSource: redhat-operators
:CNVSubscriptionSpecName: kubevirt-hyperconverged
:delete: image:delete.png[title="Delete"]
//distributed tracing
:DTProductName: Red Hat OpenShift distributed tracing platform
:DTShortName: distributed tracing platform
:DTProductVersion: 2.9
:JaegerName: Red Hat OpenShift distributed tracing platform (Jaeger)
:JaegerShortName: distributed tracing platform (Jaeger)
:JaegerVersion: 1.47.0
:OTELName: Red Hat OpenShift distributed tracing data collection
:OTELShortName: distributed tracing data collection
:OTELOperator: Red Hat OpenShift distributed tracing data collection Operator
:OTELVersion: 0.81.0
:TempoName: Red Hat OpenShift distributed tracing platform (Tempo)
:TempoShortName: distributed tracing platform (Tempo)
:TempoOperator: Tempo Operator
:TempoVersion: 2.1.1
//logging
:logging-title: logging subsystem for Red Hat OpenShift
:logging-title-uc: Logging subsystem for Red Hat OpenShift
:logging: logging subsystem
:logging-uc: Logging subsystem
//serverless
:ServerlessProductName: OpenShift Serverless
:ServerlessProductShortName: Serverless
:ServerlessOperatorName: OpenShift Serverless Operator
:FunctionsProductName: OpenShift Serverless Functions
//service mesh v2
:product-dedicated: Red Hat OpenShift Dedicated
:product-rosa: Red Hat OpenShift Service on AWS
:SMProductName: Red Hat OpenShift Service Mesh
:SMProductShortName: Service Mesh
:SMProductVersion: 2.4.4
:MaistraVersion: 2.4
//Service Mesh v1
:SMProductVersion1x: 1.1.18.2
//Windows containers
:productwinc: Red Hat OpenShift support for Windows Containers
// Red Hat Quay Container Security Operator
:rhq-cso: Red Hat Quay Container Security Operator
// Red Hat Quay
:quay: Red Hat Quay
:sno: single-node OpenShift
:sno-caps: Single-node OpenShift
//TALO and Redfish events Operators
:cgu-operator-first: Topology Aware Lifecycle Manager (TALM)
:cgu-operator-full: Topology Aware Lifecycle Manager
:cgu-operator: TALM
:redfish-operator: Bare Metal Event Relay
//Formerly known as CodeReady Containers and CodeReady Workspaces
:openshift-local-productname: Red Hat OpenShift Local
:openshift-dev-spaces-productname: Red Hat OpenShift Dev Spaces
// Factory-precaching-cli tool
:factory-prestaging-tool: factory-precaching-cli tool
:factory-prestaging-tool-caps: Factory-precaching-cli tool
:openshift-networking: Red Hat OpenShift Networking
// TODO - this probably needs to be different for OKD
//ifdef::openshift-origin[]
//:openshift-networking: OKD Networking
//endif::[]
// logical volume manager storage
:lvms-first: Logical volume manager storage (LVM Storage)
:lvms: LVM Storage
//Operator SDK version
:osdk_ver: 1.31.0
//Operator SDK version that shipped with the previous OCP 4.x release
:osdk_ver_n1: 1.28.0
//Next-gen (OCP 4.14+) Operator Lifecycle Manager, aka "v1"
:olmv1: OLM 1.0
:olmv1-first: Operator Lifecycle Manager (OLM) 1.0
:ztp-first: GitOps Zero Touch Provisioning (ZTP)
:ztp: GitOps ZTP
:3no: three-node OpenShift
:3no-caps: Three-node OpenShift
:run-once-operator: Run Once Duration Override Operator
// Web terminal
:web-terminal-op: Web Terminal Operator
:devworkspace-op: DevWorkspace Operator
:secrets-store-driver: Secrets Store CSI driver
:secrets-store-operator: Secrets Store CSI Driver Operator
//AWS STS
:sts-first: Security Token Service (STS)
:sts-full: Security Token Service
:sts-short: STS
//Cloud provider names
//AWS
:aws-first: Amazon Web Services (AWS)
:aws-full: Amazon Web Services
:aws-short: AWS
//GCP
:gcp-first: Google Cloud Platform (GCP)
:gcp-full: Google Cloud Platform
:gcp-short: GCP
//alibaba cloud
:alibaba: Alibaba Cloud
// IBM Cloud VPC
:ibmcloudVPCProductName: IBM Cloud VPC
:ibmcloudVPCRegProductName: IBM(R) Cloud VPC
// IBM Cloud
:ibm-cloud-bm: IBM Cloud Bare Metal (Classic)
:ibm-cloud-bm-reg: IBM Cloud(R) Bare Metal (Classic)
// IBM Power
:ibmpowerProductName: IBM Power
:ibmpowerRegProductName: IBM(R) Power
// IBM zSystems
:ibmzProductName: IBM Z
:ibmzRegProductName: IBM(R) Z
:linuxoneProductName: IBM(R) LinuxONE
//Azure
:azure-full: Microsoft Azure
:azure-short: Azure
//vSphere
:vmw-full: VMware vSphere
:vmw-short: vSphere
//Oracle
:oci-first: Oracle(R) Cloud Infrastructure
:oci: OCI
:ocvs-first: Oracle(R) Cloud VMware Solution (OCVS)
:ocvs: OCVS
:context: configuring-ipsec-ovn

toc::[]

With IPsec enabled, you can encrypt both internal pod-to-pod cluster traffic between nodes and external traffic between pods and IPsec endpoints external to your cluster. All pod-to-pod network traffic between nodes on the OVN-Kubernetes cluster network is encrypted with IPsec _Transport mode_.

IPsec is disabled by default. It can be enabled either during or after installing the cluster. For information about cluster installation, see xref:../../installing/index.adoc#ocp-installation-overview[{product-title} installation overview]. If you need to enable IPsec after cluster installation, you must first resize your cluster MTU to account for the overhead of the IPsec ESP IP header.

[NOTE]
====
IPsec on IBM Cloud VPC supports only NAT-T. Using ESP is not supported.
====

Use the procedures in the following documentation to:

* Enable and disable IPSec after cluster installation
* Configure support for external IPsec endpoints outside the cluster
* Verify that IPsec encrypts traffic between pods on different nodes

[id="{context}-prerequisites"]
== Prerequisites

* You have decreased the size of the cluster MTU by `46` bytes to allow for the additional overhead of the IPsec ESP header. For more information on resizing the MTU that your cluster uses, see xref:../../networking/changing-cluster-network-mtu.adoc#changing-cluster-network-mtu[Changing the MTU for the cluster network].

:leveloffset: +1

// Module included in the following assemblies:
//
// * networking/ovn_kubernetes_network_provider/about-ipsec-ovn.adoc

:_mod-docs-content-type: CONCEPT
[id="network-connectivity-requirements-ipsec_{context}"]
= Network connectivity requirements when IPsec is enabled

You must configure the network connectivity between machines to allow {product-title} cluster components to communicate. Each machine must be able to resolve the hostnames of all other machines in the cluster.

.Ports used for all-machine to all-machine communications
[cols="2a,2a,5a",options="header"]
|===

|Protocol
|Port
|Description

.2+|UDP
|`500`
|IPsec IKE packets

|`4500`
|IPsec NAT-T packets

|ESP
|N/A
|IPsec Encapsulating Security Payload (ESP)

|===

:leveloffset!:

[id="{context}-pod-to-pod-ipsec"]
== IPsec encryption for pod-to-pod traffic

{product-title} supports IPsec encryption for network traffic between pods.

:leveloffset: +2

// Module included in the following assemblies:
//
// * networking/ovn_kubernetes_network_provider/about-ipsec-ovn.adoc

:_mod-docs-content-type: CONCEPT
[id="nw-ovn-ipsec-traffic_{context}"]
= Types of network traffic flows encrypted by pod-to-pod IPsec

With IPsec enabled, only the following network traffic flows between pods are encrypted:

* Traffic between pods on different nodes on the cluster network
* Traffic from a pod on the host network to a pod on the cluster network

The following traffic flows are not encrypted:

* Traffic between pods on the same node on the cluster network
* Traffic between pods on the host network
* Traffic from a pod on the cluster network to a pod on the host network

The encrypted and unencrypted flows are illustrated in the following diagram:

image::nw-ipsec-encryption.png[IPsec encrypted and unencrypted traffic flows]

:leveloffset!:
:leveloffset: +2

// Module included in the following assemblies:
//
// * networking/ovn_kubernetes_network_provider/about-ipsec-ovn.adoc

:_mod-docs-content-type: CONCEPT
[id="nw-ovn-ipsec-encryption_{context}"]
= Encryption protocol and IPsec mode

The encrypt cipher used is `AES-GCM-16-256`. The integrity check value (ICV) is `16` bytes. The key length is `256` bits.

The IPsec mode used is _Transport mode_, a mode that encrypts end-to-end communication by adding an Encapsulated Security Payload (ESP) header to the IP header of the original packet and encrypts the packet data. {product-title} does not currently use or support IPsec _Tunnel mode_ for pod-to-pod communication.

:leveloffset!:
:leveloffset: +2

// Module included in the following assemblies:
//
// * networking/ovn_kubernetes_network_provider/about-ipsec-ovn.adoc

:_mod-docs-content-type: CONCEPT
[id="nw-ovn-ipsec-certificates_{context}"]
= Security certificate generation and rotation

The Cluster Network Operator (CNO) generates a self-signed X.509 certificate authority (CA) that is used by IPsec for encryption. Certificate signing requests (CSRs) from each node are automatically fulfilled by the CNO.

The CA is valid for 10 years. The individual node certificates are valid for 5 years and are automatically rotated after 4 1/2 years elapse.

:leveloffset!:
:leveloffset: +2

// Module included in the following assemblies:
//
// * networking/ovn_kubernetes_network_provider/configuring-ipsec-ovn.adoc

:_mod-docs-content-type: PROCEDURE
[id="nw-ovn-ipsec-enable_{context}"]
= Enabling pod-to-pod IPsec encryption

As a cluster administrator, you can enable pod-to-pod IPsec encryption after cluster installation.

.Prerequisites

* Install the {oc-first}.
* You are logged in to the cluster as a user with `cluster-admin` privileges.
* You have reduced the size of your cluster MTU by `46` bytes to allow for the overhead of the IPsec ESP header.

.Procedure

* To enable IPsec encryption, enter the following command:
+
[source,terminal]
----
$ oc patch networks.operator.openshift.io cluster --type=merge \
-p '{"spec":{"defaultNetwork":{"ovnKubernetesConfig":{"ipsecConfig":{ }}}}}'
----

:leveloffset!:
:leveloffset: +2

// Module included in the following assemblies:
//
// * networking/ovn_kubernetes_network_provider/about-ipsec-ovn.adoc

:_mod-docs-content-type: PROCEDURE
[id="nw-ovn-ipsec-verification_{context}"]
= Verifying that IPsec is enabled

As a cluster administrator, you can verify that IPsec is enabled.

.Verification

. To find the names of the OVN-Kubernetes data plane pods, enter the following command:
+
[source,terminal]
----
$ oc get pods -n openshift-ovn-kubernetes -l=app=ovnkube-node
----
+
.Example output
[source,terminal]
----
ovnkube-node-5xqbf                       8/8     Running   0              28m
ovnkube-node-6mwcx                       8/8     Running   0              29m
ovnkube-node-ck5fr                       8/8     Running   0              31m
ovnkube-node-fr4ld                       8/8     Running   0              26m
ovnkube-node-wgs4l                       8/8     Running   0              33m
ovnkube-node-zfvcl                       8/8     Running   0              34m
----

. Verify that IPsec is enabled on your cluster:
+
[source,terminal]
----
$ oc -n openshift-ovn-kubernetes -c nbdb rsh ovnkube-node-<XXXXX> ovn-nbctl --no-leader-only get nb_global . ipsec
----
+
--
where:

`<XXXXX>`:: Specifies the random sequence of letters for a pod from the previous step.
--
+
.Example output
[source,text]
----
true
----

:leveloffset!:
:leveloffset: +2

// Module included in the following assemblies:
//
// * networking/ovn_kubernetes_network_provider/configuring-ipsec-ovn.adoc

:_mod-docs-content-type: PROCEDURE
[id="nw-ovn-ipsec-disable_{context}"]
= Disabling IPsec encryption

As a cluster administrator, you can disable IPsec encryption only if you enabled IPsec after cluster installation.

[NOTE]
====
If you enabled IPsec when you installed your cluster, you cannot disable IPsec with this procedure.
====

.Prerequisites

* Install the OpenShift CLI (`oc`).
* Log in to the cluster with a user with `cluster-admin` privileges.

.Procedure

. To disable IPsec encryption, enter the following command:
+
[source,terminal]
----
$ oc patch networks.operator.openshift.io/cluster --type=json \
  -p='[{"op":"remove", "path":"/spec/defaultNetwork/ovnKubernetesConfig/ipsecConfig"}]'
----

. Optional: You can increase the size of your cluster MTU by `46` bytes because there is no longer any overhead from the IPsec ESP header in IP packets.

:leveloffset!:

[id="{context}-external-traffic-ipsec"]
== IPsec encryption for external traffic

{product-title} supports IPsec encryption for traffic to external hosts.

You must supply a custom IPsec configuration, which includes the IPsec configuration file itself and TLS certificates.

Ensure that the following prohibitions are observed:

* The custom IPsec configuration must not include any connection specifications that might interfere with the cluster's pod-to-pod IPsec configuration.
* Certificate common names (CN) in the provided certificate bundle must not begin with the `ovs_` prefix, because this naming can collide with pod-to-pod IPsec CN names in the Network Security Services (NSS) database of each node.

// Tech Preview
:FeatureName: IPsec support for external endpoints
// When including this file, ensure that {FeatureName} is set immediately before
// the include. Otherwise it will result in an incorrect replacement.

[IMPORTANT]
====
[subs="attributes+"]
{FeatureName} is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.

For more information about the support scope of Red Hat Technology Preview features, see link:https://access.redhat.com/support/offerings/techpreview/[Technology Preview Features Support Scope].
====
// Undefine {FeatureName} attribute, so that any mistakes are easily spotted
:!FeatureName:

:leveloffset: +2

// Module included in the following assemblies:
//
// * networking/ovn_kubernetes_network_provider/configuring-ipsec-ovn.adoc

:_mod-docs-content-type: PROCEDURE
[id="nw-ovn-ipsec-north-south-enable_{context}"]
= Enabling IPsec encryption for external IPsec endpoints

// This procedure requests installing Butane to prepare the machine config

As a cluster administrator, you can enable IPsec encryption between the cluster and external IPsec endpoints. Because this procedure uses Butane to create machine configs, you must have the `butane` command installed.

[NOTE]
====
After you apply the machine config, the Machine Config Operator reboots affected nodes in your cluster to rollout the new machine config.
====

.Prerequisites

* Install the {oc-first}.
* You are logged in to the cluster as a user with `cluster-admin` privileges.
* You have reduced the size of your cluster MTU by `46` bytes to allow for the overhead of the IPsec ESP header.
* You have installed the `butane` utility.
* You have an existing PKCS#12 certificate for the IPsec endpoint and a CA cert in PEM format.

.Procedure

As a cluster administrator, you can enable IPsec support for external IPsec endpoints.

. Create an IPsec configuration file named `ipsec-endpoint-config.conf`. The configuration is consumed in the next step. For more information, see link:https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/securing_networks/configuring-a-vpn-with-ipsec_securing-networks#configuring-a-vpn-with-ipsec_securing-networks[Libreswan as an IPsec VPN implementation].

. Provide the following certificate files to add to the Network Security Services (NSS) database on each host. These files are imported as part of the Butane configuration in subsequent steps.
+
--
* `left_server.p12`: The certificate bundle for the IPsec endpoints
* `ca.pem`: The certificate authority that you signed your certificates with
--

. Create a machine config to apply the IPsec configuration to your cluster by using the following two steps:

.. To add the IPsec configuration, create Butane config files for the control plane and worker nodes with the following contents:
+
[source,terminal,subs="attributes+"]
----
$ for role in master worker; do
  cat >> "99-ipsec-$\{role}-endpoint-config.bu" <<-EOF
  variant: openshift
  version: {product-version}.0
  metadata:
    name: 99-$\{role}-import-certs-enable-svc-os-ext
    labels:
      machineconfiguration.openshift.io/role: $role
  openshift:
    extensions:
      - ipsec
  systemd:
    units:
    - name: ipsec-import.service
      enabled: true
      contents: |
        [Unit]
        Description=Import external certs into ipsec NSS
        Before=ipsec.service

        [Service]
        Type=oneshot
        ExecStart=/usr/local/bin/ipsec-addcert.sh
        RemainAfterExit=false
        StandardOutput=journal

        [Install]
        WantedBy=multi-user.target
    - name: ipsecenabler.service
      enabled: true
      contents: |
        [Service]
        Type=oneshot
        ExecStart=systemctl enable --now ipsec.service

        [Install]
        WantedBy=multi-user.target
  storage:
    files:
    - path: /etc/pki/certs/ca.pem
      mode: 0400
      overwrite: true
      contents:
        local: ca.pem
    - path: /etc/pki/certs/left_server.p12
      mode: 0400
      overwrite: true
      contents:
        local: left_server.p12
    - path: /usr/local/bin/ipsec-addcert.sh
      mode: 0740
      overwrite: true
      contents:
        inline: |
          #!/bin/bash -e
          echo "importing cert to NSS"
          certutil -A -n "CA" -t "CT,C,C" -d /var/lib/ipsec/nss/ -i /etc/pki/certs/ca.pem
          pk12util -W "" -i /etc/pki/certs/left_server.p12 -d /var/lib/ipsec/nss/
          certutil -M -n "left_server" -t "u,u,u" -d /var/lib/ipsec/nss/
EOF
done
----

.. To transform the Butane files that you created in the previous step into machine configs, enter the following command:
+
[source,terminal]
----
$ for role in master worker; do
  butane 99-ipsec-${role}-endpoint-config.bu -o ./99-ipsec-$role-endpoint-config.yaml
done
----

. To apply the machine configs to your cluster, enter the following command:
+
[source,terminal]
----
$ for role in master worker; do
  oc apply -f 99-ipsec-${role}-endpoint-config.yaml
done
----
+
[IMPORTANT]
====
As the Machine Config Operator (MCO) updates machines in each machine config pool, it reboots each node one by one. You must wait until all the nodes are updated before external IPsec connectivity is available.
====

. Check the machine config pool status by entering the following command:
+
[source,terminal]
----
$ oc get mcp
----
+
A successfully updated node has the following status: `UPDATED=true`, `UPDATING=false`, `DEGRADED=false`.
+
[NOTE]
====
By default, the MCO updates one machine per pool at a time, causing the total time the migration takes to increase with the size of the cluster.
====

:leveloffset!:

[id="{context}_additional-resources"]
== Additional resources

* xref:../../networking/ovn_kubernetes_network_provider/about-ovn-kubernetes.adoc#about-ovn-kubernetes[About the OVN-Kubernetes Container Network Interface (CNI) network plugin]
* xref:../../networking/changing-cluster-network-mtu.adoc#changing-cluster-network-mtu[Changing the MTU for the cluster network]
* xref:../../installing/install_config/installing-customizing.adoc#installation-special-config-butane-install_installing-customizing[Installing Butane]
* xref:../../rest_api/operator_apis/network-operator-openshift-io-v1.adoc#network-operator-openshift-io-v1[Network [operator.openshift.io/v1]] API

//# includes=_attributes/common-attributes,modules/nw-own-ipsec-required-ports,modules/nw-ovn-ipsec-traffic,modules/nw-ovn-ipsec-encryption,modules/nw-ovn-ipsec-certificates,modules/nw-ovn-ipsec-enable,modules/nw-ovn-ipsec-verification,modules/nw-ovn-ipsec-disable,snippets/technology-preview,modules/nw-ovn-ipsec-north-south-enable
