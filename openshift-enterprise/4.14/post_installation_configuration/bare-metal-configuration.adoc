:_mod-docs-content-type: ASSEMBLY
:context: post-install-bare-metal-configuration
[id="post-install-bare-metal-configuration"]
= Bare metal configuration
// The {product-title} attribute provides the context-sensitive name of the relevant OpenShift distribution, for example, "OpenShift Container Platform" or "OKD". The {product-version} attribute provides the product version relative to the distribution, for example "4.9".
// {product-title} and {product-version} are parsed when AsciiBinder queries the _distro_map.yml file in relation to the base branch of a pull request.
// See https://github.com/openshift/openshift-docs/blob/main/contributing_to_docs/doc_guidelines.adoc#product-name-and-version for more information on this topic.
// Other common attributes are defined in the following lines:
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:imagesdir: images
:prewrap!:
:op-system-first: Red Hat Enterprise Linux CoreOS (RHCOS)
:op-system: RHCOS
:op-system-lowercase: rhcos
:op-system-base: RHEL
:op-system-base-full: Red Hat Enterprise Linux (RHEL)
:op-system-version: 8.x
:tsb-name: Template Service Broker
:kebab: image:kebab.png[title="Options menu"]
:rh-openstack-first: Red Hat OpenStack Platform (RHOSP)
:rh-openstack: RHOSP
:ai-full: Assisted Installer
:ai-version: 2.3
:cluster-manager-first: Red Hat OpenShift Cluster Manager
:cluster-manager: OpenShift Cluster Manager
:cluster-manager-url: link:https://console.redhat.com/openshift[OpenShift Cluster Manager Hybrid Cloud Console]
:cluster-manager-url-pull: link:https://console.redhat.com/openshift/install/pull-secret[pull secret from the Red Hat OpenShift Cluster Manager]
:insights-advisor-url: link:https://console.redhat.com/openshift/insights/advisor/[Insights Advisor]
:hybrid-console: Red Hat Hybrid Cloud Console
:hybrid-console-second: Hybrid Cloud Console
:oadp-first: OpenShift API for Data Protection (OADP)
:oadp-full: OpenShift API for Data Protection
:oc-first: pass:quotes[OpenShift CLI (`oc`)]
:product-registry: OpenShift image registry
:rh-storage-first: Red Hat OpenShift Data Foundation
:rh-storage: OpenShift Data Foundation
:rh-rhacm-first: Red Hat Advanced Cluster Management (RHACM)
:rh-rhacm: RHACM
:rh-rhacm-version: 2.8
:sandboxed-containers-first: OpenShift sandboxed containers
:sandboxed-containers-operator: OpenShift sandboxed containers Operator
:sandboxed-containers-version: 1.3
:sandboxed-containers-version-z: 1.3.3
:sandboxed-containers-legacy-version: 1.3.2
:cert-manager-operator: cert-manager Operator for Red Hat OpenShift
:secondary-scheduler-operator-full: Secondary Scheduler Operator for Red Hat OpenShift
:secondary-scheduler-operator: Secondary Scheduler Operator
// Backup and restore
:velero-domain: velero.io
:velero-version: 1.11
:launch: image:app-launcher.png[title="Application Launcher"]
:mtc-short: MTC
:mtc-full: Migration Toolkit for Containers
:mtc-version: 1.8
:mtc-version-z: 1.8.0
// builds (Valid only in 4.11 and later)
:builds-v2title: Builds for Red Hat OpenShift
:builds-v2shortname: OpenShift Builds v2
:builds-v1shortname: OpenShift Builds v1
//gitops
:gitops-title: Red Hat OpenShift GitOps
:gitops-shortname: GitOps
:gitops-ver: 1.1
:rh-app-icon: image:red-hat-applications-menu-icon.jpg[title="Red Hat applications"]
//pipelines
:pipelines-title: Red Hat OpenShift Pipelines
:pipelines-shortname: OpenShift Pipelines
:pipelines-ver: pipelines-1.12
:pipelines-version-number: 1.12
:tekton-chains: Tekton Chains
:tekton-hub: Tekton Hub
:artifact-hub: Artifact Hub
:pac: Pipelines as Code
//odo
:odo-title: odo
//OpenShift Kubernetes Engine
:oke: OpenShift Kubernetes Engine
//OpenShift Platform Plus
:opp: OpenShift Platform Plus
//openshift virtualization (cnv)
:VirtProductName: OpenShift Virtualization
:VirtVersion: 4.14
:KubeVirtVersion: v0.59.0
:HCOVersion: 4.14.0
:CNVNamespace: openshift-cnv
:CNVOperatorDisplayName: OpenShift Virtualization Operator
:CNVSubscriptionSpecSource: redhat-operators
:CNVSubscriptionSpecName: kubevirt-hyperconverged
:delete: image:delete.png[title="Delete"]
//distributed tracing
:DTProductName: Red Hat OpenShift distributed tracing platform
:DTShortName: distributed tracing platform
:DTProductVersion: 2.9
:JaegerName: Red Hat OpenShift distributed tracing platform (Jaeger)
:JaegerShortName: distributed tracing platform (Jaeger)
:JaegerVersion: 1.47.0
:OTELName: Red Hat OpenShift distributed tracing data collection
:OTELShortName: distributed tracing data collection
:OTELOperator: Red Hat OpenShift distributed tracing data collection Operator
:OTELVersion: 0.81.0
:TempoName: Red Hat OpenShift distributed tracing platform (Tempo)
:TempoShortName: distributed tracing platform (Tempo)
:TempoOperator: Tempo Operator
:TempoVersion: 2.1.1
//logging
:logging-title: logging subsystem for Red Hat OpenShift
:logging-title-uc: Logging subsystem for Red Hat OpenShift
:logging: logging subsystem
:logging-uc: Logging subsystem
//serverless
:ServerlessProductName: OpenShift Serverless
:ServerlessProductShortName: Serverless
:ServerlessOperatorName: OpenShift Serverless Operator
:FunctionsProductName: OpenShift Serverless Functions
//service mesh v2
:product-dedicated: Red Hat OpenShift Dedicated
:product-rosa: Red Hat OpenShift Service on AWS
:SMProductName: Red Hat OpenShift Service Mesh
:SMProductShortName: Service Mesh
:SMProductVersion: 2.4.4
:MaistraVersion: 2.4
//Service Mesh v1
:SMProductVersion1x: 1.1.18.2
//Windows containers
:productwinc: Red Hat OpenShift support for Windows Containers
// Red Hat Quay Container Security Operator
:rhq-cso: Red Hat Quay Container Security Operator
// Red Hat Quay
:quay: Red Hat Quay
:sno: single-node OpenShift
:sno-caps: Single-node OpenShift
//TALO and Redfish events Operators
:cgu-operator-first: Topology Aware Lifecycle Manager (TALM)
:cgu-operator-full: Topology Aware Lifecycle Manager
:cgu-operator: TALM
:redfish-operator: Bare Metal Event Relay
//Formerly known as CodeReady Containers and CodeReady Workspaces
:openshift-local-productname: Red Hat OpenShift Local
:openshift-dev-spaces-productname: Red Hat OpenShift Dev Spaces
// Factory-precaching-cli tool
:factory-prestaging-tool: factory-precaching-cli tool
:factory-prestaging-tool-caps: Factory-precaching-cli tool
:openshift-networking: Red Hat OpenShift Networking
// TODO - this probably needs to be different for OKD
//ifdef::openshift-origin[]
//:openshift-networking: OKD Networking
//endif::[]
// logical volume manager storage
:lvms-first: Logical volume manager storage (LVM Storage)
:lvms: LVM Storage
//Operator SDK version
:osdk_ver: 1.31.0
//Operator SDK version that shipped with the previous OCP 4.x release
:osdk_ver_n1: 1.28.0
//Next-gen (OCP 4.14+) Operator Lifecycle Manager, aka "v1"
:olmv1: OLM 1.0
:olmv1-first: Operator Lifecycle Manager (OLM) 1.0
:ztp-first: GitOps Zero Touch Provisioning (ZTP)
:ztp: GitOps ZTP
:3no: three-node OpenShift
:3no-caps: Three-node OpenShift
:run-once-operator: Run Once Duration Override Operator
// Web terminal
:web-terminal-op: Web Terminal Operator
:devworkspace-op: DevWorkspace Operator
:secrets-store-driver: Secrets Store CSI driver
:secrets-store-operator: Secrets Store CSI Driver Operator
//AWS STS
:sts-first: Security Token Service (STS)
:sts-full: Security Token Service
:sts-short: STS
//Cloud provider names
//AWS
:aws-first: Amazon Web Services (AWS)
:aws-full: Amazon Web Services
:aws-short: AWS
//GCP
:gcp-first: Google Cloud Platform (GCP)
:gcp-full: Google Cloud Platform
:gcp-short: GCP
//alibaba cloud
:alibaba: Alibaba Cloud
// IBM Cloud VPC
:ibmcloudVPCProductName: IBM Cloud VPC
:ibmcloudVPCRegProductName: IBM(R) Cloud VPC
// IBM Cloud
:ibm-cloud-bm: IBM Cloud Bare Metal (Classic)
:ibm-cloud-bm-reg: IBM Cloud(R) Bare Metal (Classic)
// IBM Power
:ibmpowerProductName: IBM Power
:ibmpowerRegProductName: IBM(R) Power
// IBM zSystems
:ibmzProductName: IBM Z
:ibmzRegProductName: IBM(R) Z
:linuxoneProductName: IBM(R) LinuxONE
//Azure
:azure-full: Microsoft Azure
:azure-short: Azure
//vSphere
:vmw-full: VMware vSphere
:vmw-short: vSphere
//Oracle
:oci-first: Oracle(R) Cloud Infrastructure
:oci: OCI
:ocvs-first: Oracle(R) Cloud VMware Solution (OCVS)
:ocvs: OCVS

toc::[]

When deploying {product-title} on bare metal hosts, there are times when you need to make changes to the host either before or after provisioning. This can include inspecting the host's hardware, firmware, and firmware details. It can also include formatting disks or changing modifiable firmware settings.

:leveloffset: +1

// This is included in the following assemblies:
//
// post_installation_configuration/bare-metal-configuration.adoc

:_module-type: CONCEPT
[id="bmo-about-the-bare-metal-operator_{context}"]
= About the Bare Metal Operator

Use the Bare Metal Operator (BMO) to provision, manage, and inspect bare-metal hosts in your cluster.

The BMO uses three resources to complete these tasks:

* `BareMetalHost`
* `HostFirmwareSettings`
* `FirmwareSchema`

The BMO maintains an inventory of the physical hosts in the cluster by mapping each bare-metal host to an instance of the `BareMetalHost` custom resource definition. Each `BareMetalHost` resource features hardware, software, and firmware details. The BMO continually inspects the bare-metal hosts in the cluster to ensure each `BareMetalHost` resource accurately details the components of the corresponding host.

The BMO also uses the `HostFirmwareSettings` resource and the `FirmwareSchema` resource to detail firmware specifications for the bare-metal host.

The BMO interfaces with bare-metal hosts in the cluster by using the Ironic API service. The Ironic service uses the Baseboard Management Controller (BMC) on the host to interface with the machine.

Some common tasks you can complete by using the BMO include the following:

* Provision bare-metal hosts to the cluster with a specific image
* Format a host's disk contents before provisioning or after deprovisioning
* Turn on or off a host
* Change firmware settings
* View the host's hardware details

:leveloffset!:
:leveloffset: +2

// This is included in the following assemblies:
//
// post_installation_configuration/bare-metal-configuration.adoc
:_mod-docs-content-type: CONCEPT
[id="bmo-bare-metal-operator-architecture_{context}"]
= Bare Metal Operator architecture

The Bare Metal Operator (BMO) uses three resources to provision, manage, and inspect bare-metal hosts in your cluster. The following diagram illustrates the architecture of these resources:

image::302_OpenShift_Bare_Metal_Operator_0223.png[BMO architecture overview]

.BareMetalHost

The `BareMetalHost` resource defines a physical host and its properties. When you provision a bare-metal host to the cluster, you must define a `BareMetalHost` resource for that host. For ongoing management of the host, you can inspect the information in the `BareMetalHost` or update this information.

The `BareMetalHost` resource features provisioning information such as the following:

* Deployment specifications such as the operating system boot image or the custom RAM disk
* Provisioning state
* Baseboard Management Controller (BMC) address
* Desired power state

The `BareMetalHost` resource features hardware information such as the following:

* Number of CPUs
* MAC address of a NIC
* Size of the host's storage device
* Current power state

.HostFirmwareSettings
You can use the `HostFirmwareSettings` resource to retrieve and manage the firmware settings for a host. When a host moves to the `Available` state, the Ironic service reads the host's firmware settings and creates the `HostFirmwareSettings` resource. There is a one-to-one mapping between the `BareMetalHost` resource and the `HostFirmwareSettings` resource.

You can use the `HostFirmwareSettings` resource to inspect the firmware specifications for a host or to update a host's firmware specifications.

[NOTE]
====
You must adhere to the schema specific to the vendor firmware when you edit the `spec` field of the `HostFirmwareSettings` resource. This schema is defined in the read-only `FirmwareSchema` resource.
====

.FirmwareSchema
Firmware settings vary among hardware vendors and host models. A `FirmwareSchema` resource is a read-only resource that contains the types and limits for each firmware setting on each host model. The data comes directly from the BMC by using the Ironic service. The `FirmwareSchema` resource enables you to identify valid values you can specify in the `spec` field of the `HostFirmwareSettings` resource.

A `FirmwareSchema` resource can apply to many `BareMetalHost` resources if the schema is the same.

[role="_additional-resources"]
.Additional resources
* link:https://metal3.io/[Metal³ API service for provisioning bare-metal hosts]
* link:https://ironicbaremetal.org/[Ironic API service for managing bare-metal infrastructure]

:leveloffset!:
:leveloffset: +1

// This is included in the following assemblies:
//
// post_installation_configuration/bare-metal-configuration.adoc

:_mod-docs-content-type: REFERENCE
[id="about-the-baremetalhost-resource_{context}"]
= About the BareMetalHost resource

Metal^3^ introduces the concept of the `BareMetalHost` resource, which defines a physical host and its properties. The `BareMetalHost` resource contains two sections:

. The `BareMetalHost` spec
. The `BareMetalHost` status

== The BareMetalHost spec

The `spec` section of the `BareMetalHost` resource defines the desired state of the host.

.BareMetalHost spec
[options="header"]
|====
|Parameters |Description

| `automatedCleaningMode`
| An interface to enable or disable automated cleaning during provisioning and de-provisioning. When set to `disabled`, it skips automated cleaning. When set to `metadata`, automated cleaning is enabled. The default setting is `metadata`.

a|
----
bmc:
  address:
  credentialsName:
  disableCertificateVerification:
----
a| The `bmc` configuration setting contains the connection information for the baseboard management controller (BMC) on the host. The fields are:

* `address`: The URL for communicating with the host's BMC controller.

* `credentialsName`: A reference to a secret containing the username and password for the BMC.

* `disableCertificateVerification`: A boolean to skip certificate validation when set to `true`.

| `bootMACAddress`
| The MAC address of the NIC used for provisioning the host.

| `bootMode`
| The boot mode of the host. It defaults to `UEFI`, but it can also be set to `legacy` for BIOS boot, or `UEFISecureBoot`.

| `consumerRef`
| A reference to another resource that is using the host. It could be empty if another resource is not currently using the host. For example, a `Machine` resource might use the host when the `machine-api` is using the host.

| `description`
| A human-provided string to help identify the host.

| `externallyProvisioned`
a| A boolean indicating whether the host provisioning and deprovisioning are managed externally. When set:

* Power status can still be managed using the online field.
* Hardware inventory will be monitored, but no provisioning or deprovisioning operations are performed on the host.

| `firmware`
a| Contains information about the BIOS configuration of bare metal hosts. Currently, `firmware` is only supported by iRMC, iDRAC, iLO4 and iLO5 BMCs. The sub fields are:

** `simultaneousMultithreadingEnabled`: Allows a single physical processor core to appear as several logical processors. Valid settings are `true` or `false`.
** `sriovEnabled`: SR-IOV support enables a hypervisor to create virtual instances of a PCI-express device, potentially increasing performance. Valid settings are `true` or `false`.
** `virtualizationEnabled`: Supports the virtualization of platform hardware. Valid settings are `true` or `false`.

a|
----
image:
  url:
  checksum:
  checksumType:
  format:
----
a| The `image` configuration setting holds the details for the image to be deployed on the host. Ironic requires the image fields. However, when the `externallyProvisioned` configuration setting is set to `true` and the external management doesn't require power control, the fields can be empty. The fields are:

* `url`: The URL of an image to deploy to the host.
* `checksum`: The actual checksum or a URL to a file containing the checksum for the image at `image.url`.
* `checksumType`: You can specify checksum algorithms. Currently `image.checksumType` only supports `md5`, `sha256`, and `sha512`. The default checksum type is `md5`.
* `format`: This is the disk format of the image. It can be one of `raw`, `qcow2`, `vdi`, `vmdk`, `live-iso` or be left unset. Setting it to `raw` enables raw image streaming in the Ironic agent for that image. Setting it to `live-iso` enables iso images to live boot without deploying to disk, and it ignores the `checksum` fields.

| `networkData`
| A reference to the secret containing the network configuration data and its namespace, so that it can be attached to the host before the host boots to set up the network.

| `online`
| A boolean indicating whether the host should be powered on (`true`) or off (`false`). Changing this value will trigger a change in the power state of the physical host.

a|
----
raid:
  hardwareRAIDVolumes:
  softwareRAIDVolumes:
----
a|  (Optional) Contains the information about the RAID configuration for bare metal hosts. If not specified, it retains the current configuration.

[NOTE]
====
{product-title} {product-version} supports hardware RAID for BMCs using the iRMC protocol only. {product-title} {product-version} does not support software RAID.
====

See the following configuration settings:

* `hardwareRAIDVolumes`: Contains the list of logical drives for hardware RAID, and defines the desired volume configuration in the hardware RAID. If you don't specify `rootDeviceHints`, the first volume is the root volume. The sub-fields are:

** `level`: The RAID level for the logical drive. The following levels are supported: `0`,`1`,`2`,`5`,`6`,`1+0`,`5+0`,`6+0`.
** `name`: The name of the volume as a string. It should be unique within the server. If not specified, the volume name will be auto-generated.
** `numberOfPhysicalDisks`: The number of physical drives as an integer to use for the logical drove. Defaults to the minimum number of disk drives required for the particular RAID level.
** `physicalDisks`: The list of names of physical disk drives as a string. This is an optional field. If specified, the controller field must be specified too.
** `controller`: (Optional) The name of the RAID controller as a string to use in the hardware RAID volume.
** `rotational`: If set to `true`, it will only select rotational disk drives. If set to `false`, it will only select solid-state and NVMe drives. If not set, it selects any drive types, which is the default behavior.
** `sizeGibibytes`: The size of the logical drive as an integer to create in GiB. If unspecified or set to `0`, it will use the maximum capacity of physical drive for the logical drive.

* `softwareRAIDVolumes`: {product-title} {product-version} does not support software RAID. The following information is for reference only. This configuration contains the list of logical disks for software RAID. If you don't specify `rootDeviceHints`, the first volume is the root volume. If you set `HardwareRAIDVolumes`, this item will be invalid. Software RAIDs will always be deleted. The number of created software RAID devices must be `1` or `2`. If there is only one software RAID device, it must be `RAID-1`. If there are two RAID devices, the first device must be `RAID-1`, while the RAID level for the second device can be `0`, `1`, or `1+0`. The first RAID device will be the deployment device. Therefore, enforcing `RAID-1` reduces the risk of a non-booting node in case of a device failure. The `softwareRAIDVolume` field defines the desired configuration of the volume in the software RAID. The sub-fields are:

** `level`: The RAID level for the logical drive. The following levels are supported: `0`,`1`,`1+0`.
** `physicalDisks`: A list of device hints. The number of items should be greater than or equal to `2`.
** `sizeGibibytes`: The size of the logical disk drive as an integer to be created in GiB. If unspecified or set to `0`, it will use the maximum capacity of physical drive for logical drive.

You can set the `hardwareRAIDVolume` as an empty slice to clear the hardware RAID configuration. For example:

----
spec:
   raid:
     hardwareRAIDVolume: []
----

If you receive an error message indicating that the driver does not support RAID, set the `raid`, `hardwareRAIDVolumes` or `softwareRAIDVolumes` to nil. You might need to ensure the host has a RAID controller.

a|
----
rootDeviceHints:
  deviceName:
  hctl:
  model:
  vendor:
  serialNumber:
  minSizeGigabytes:
  wwn:
  wwnWithExtension:
  wwnVendorExtension:
  rotational:
----
a| The `rootDeviceHints` parameter enables provisioning of the {op-system} image to a particular device. It examines the devices in the order it discovers them, and compares the discovered values with the hint values. It uses the first discovered device that matches the hint value. The configuration can combine multiple hints, but a device must match all hints to get selected. The fields are:

* `deviceName`: A string containing a Linux device name like `/dev/vda`. The hint must match the actual value exactly.

* `hctl`: A string containing a SCSI bus address like `0:0:0:0`. The hint must match the actual value exactly.

* `model`: A string containing a vendor-specific device identifier. The hint can be a substring of the actual value.

* `vendor`: A string containing the name of the vendor or manufacturer of the device. The hint can be a sub-string of the actual value.

* `serialNumber`: A string containing the device serial number. The hint must match the actual value exactly.

* `minSizeGigabytes`: An integer representing the minimum size of the device in gigabytes.

* `wwn`: A string containing the unique storage identifier. The hint must match the actual value exactly.

* `wwnWithExtension`: A string containing the unique storage identifier with the vendor extension appended. The hint must match the actual value exactly.

* `wwnVendorExtension`: A string containing the unique vendor storage identifier. The hint must match the actual value exactly.

* `rotational`: A boolean indicating whether the device should be a rotating disk (true) or not (false).

|====

== The BareMetalHost status

The `BareMetalHost` status represents the host's current state, and includes tested credentials, current hardware details, and other information.


.BareMetalHost status
[options="header"]
|====
|Parameters |Description

| `goodCredentials`
| A reference to the secret and its namespace holding the last set of baseboard management controller (BMC) credentials the system was able to validate as working.

| `errorMessage`
| Details of the last error reported by the provisioning backend, if any.

| `errorType`
a| Indicates the class of problem that has caused the host to enter an error state. The error types are:

* `provisioned registration error`: Occurs when the controller is unable to re-register an already provisioned host.
* `registration error`: Occurs when the controller is unable to connect to the host's baseboard management controller.
* `inspection error`: Occurs when an attempt to obtain hardware details from the host fails.
* `preparation error`: Occurs when cleaning fails.
* `provisioning error`: Occurs when the controller fails to provision or deprovision the host.
* `power management error`: Occurs when the controller is unable to modify the power state of the host.
* `detach error`: Occurs when the controller is unable to detatch the host from the provisioner.

a|
----
hardware:
  cpu
    arch:
    model:
    clockMegahertz:
    flags:
    count:
----
a| The `hardware.cpu` field details of the CPU(s) in the system. The fields include:

* `arch`: The architecture of the CPU.
* `model`: The CPU model as a string.
* `clockMegahertz`: The speed in MHz of the CPU.
* `flags`: The list of CPU flags. For example, `'mmx','sse','sse2','vmx'` etc.
* `count`: The number of CPUs available in the system.

a|
----
hardware:
  firmware:
----
| Contains BIOS firmware information. For example, the hardware vendor and version.

a|
----
hardware:
  nics:
  - ip:
    name:
    mac:
    speedGbps:
    vlans:
    vlanId:
    pxe:
----
a| The `hardware.nics` field contains a list of network interfaces for the host. The fields include:

* `ip`: The IP address of the NIC, if one was assigned when the discovery agent ran.
* `name`: A string identifying the network device. For example, `nic-1`.
* `mac`: The MAC address of the NIC.
* `speedGbps`: The speed of the device in Gbps.
* `vlans`: A list holding all the VLANs available for this NIC.
* `vlanId`: The untagged VLAN ID.
* `pxe`: Whether the NIC is able to boot using PXE.

a|
----
hardware:
  ramMebibytes:
----
| The host's amount of memory in Mebibytes (MiB).

a|
----
hardware:
  storage:
  - name:
    rotational:
    sizeBytes:
    serialNumber:
----
a| The `hardware.storage` field contains a list of storage devices available to the host. The fields include:

* `name`: A string identifying the storage device. For example, `disk 1 (boot)`.
* `rotational`: Indicates whether the disk is rotational, and returns either `true` or `false`.
* `sizeBytes`: The size of the storage device.
* `serialNumber`: The device's serial number.

a|
----
hardware:
  systemVendor:
    manufacturer:
    productName:
    serialNumber:
----
| Contains information about the host's `manufacturer`, the `productName`, and the `serialNumber`.


| `lastUpdated`
| The timestamp of the last time the status of the host was updated.

| `operationalStatus`
a| The status of the server. The status is one of the following:

* `OK`: Indicates all the details for the host are known, correctly configured, working, and manageable.
* `discovered`: Implies some of the host's details are either not working correctly or missing. For example, the BMC address is known but the login credentials are not.
* `error`: Indicates the system found some sort of irrecoverable error. Refer to the `errorMessage` field in the status section for more details.
* `delayed`: Indicates that provisioning is delayed to limit simultaneous provisioning of multiple hosts.
* `detached`: Indicates the host is marked `unmanaged`.

| `poweredOn`
| Boolean indicating whether the host is powered on.

a|
----
provisioning:
  state:
  id:
  image:
  raid:
  firmware:
  rootDeviceHints:
----
a| The `provisioning` field contains values related to deploying an image to the host. The sub-fields include:

* `state`: The current state of any ongoing provisioning operation. The states include:
** `<empty string>`: There is no provisioning happening at the moment.
** `unmanaged`: There is insufficient information available to register the host.
** `registering`: The agent is checking the host's BMC details.
** `match profile`: The agent is comparing the discovered hardware details on the host against known profiles.
** `available`: The host is available for provisioning. This state was previously known as `ready`.
** `preparing`: The existing configuration will be removed, and the new configuration will be set on the host.
** `provisioning`: The provisioner is writing an image to the host's storage.
** `provisioned`: The provisioner wrote an image to the host's storage.
** `externally provisioned`: Metal^3^ does not manage the image on the host.
** `deprovisioning`: The provisioner is wiping the image from the host's storage.
** `inspecting`: The agent is collecting hardware details for the host.
** `deleting`: The agent is deleting the from the cluster.
* `id`: The unique identifier for the service in the underlying provisioning tool.
* `image`: The image most recently provisioned to the host.
* `raid`: The list of hardware or software RAID volumes recently set.
* `firmware`: The BIOS configuration for the bare metal server.
* `rootDeviceHints`: The root device selection instructions used for the most recent provisioning operation.

| `triedCredentials`
| A reference to the secret and its namespace holding the last set of BMC credentials that were sent to the provisioning backend.

|====

:leveloffset!:
:leveloffset: +1

// This is included in the following assemblies:
//
// post_installation_configuration/bare-metal-configuration.adoc
:_mod-docs-content-type: PROCEDURE
[id="getting-the-baremetalhost-resource_{context}"]
= Getting the BareMetalHost resource

The `BareMetalHost` resource contains the properties of a physical host. You must get the `BareMetalHost` resource for a physical host to review its properties.

.Procedure

. Get the list of `BareMetalHost` resources:
+
[source,terminal]
----
$ oc get bmh -n openshift-machine-api -o yaml
----
+
[NOTE]
====
You can use `baremetalhost` as the long form of `bmh` with `oc get` command.
====

. Get the list of hosts:
+
[source,terminal]
----
$ oc get bmh -n openshift-machine-api
----

. Get the `BareMetalHost` resource for a specific host:
+
[source,terminal]
----
$ oc get bmh <host_name> -n openshift-machine-api -o yaml
----
+
Where `<host_name>` is the name of the host.
+
.Example output
[source,yaml]
----
apiVersion: metal3.io/v1alpha1
kind: BareMetalHost
metadata:
  creationTimestamp: "2022-06-16T10:48:33Z"
  finalizers:
  - baremetalhost.metal3.io
  generation: 2
  name: openshift-worker-0
  namespace: openshift-machine-api
  resourceVersion: "30099"
  uid: 1513ae9b-e092-409d-be1b-ad08edeb1271
spec:
  automatedCleaningMode: metadata
  bmc:
    address: redfish://10.46.61.19:443/redfish/v1/Systems/1
    credentialsName: openshift-worker-0-bmc-secret
    disableCertificateVerification: true
  bootMACAddress: 48:df:37:c7:f7:b0
  bootMode: UEFI
  consumerRef:
    apiVersion: machine.openshift.io/v1beta1
    kind: Machine
    name: ocp-edge-958fk-worker-0-nrfcg
    namespace: openshift-machine-api
  customDeploy:
    method: install_coreos
  hardwareProfile: unknown
  online: true
  rootDeviceHints:
    deviceName: /dev/disk/by-id/scsi-<serial_number>
  userData:
    name: worker-user-data-managed
    namespace: openshift-machine-api
status:
  errorCount: 0
  errorMessage: ""
  goodCredentials:
    credentials:
      name: openshift-worker-0-bmc-secret
      namespace: openshift-machine-api
    credentialsVersion: "16120"
  hardware:
    cpu:
      arch: x86_64
      clockMegahertz: 2300
      count: 64
      flags:
      - 3dnowprefetch
      - abm
      - acpi
      - adx
      - aes
      model: Intel(R) Xeon(R) Gold 5218 CPU @ 2.30GHz
    firmware:
      bios:
        date: 10/26/2020
        vendor: HPE
        version: U30
    hostname: openshift-worker-0
    nics:
    - mac: 48:df:37:c7:f7:b3
      model: 0x8086 0x1572
      name: ens1f3
    ramMebibytes: 262144
    storage:
    - hctl: "0:0:0:0"
      model: VK000960GWTTB
      name: /dev/disk/by-id/scsi-<serial_number>
      sizeBytes: 960197124096
      type: SSD
      vendor: ATA
    systemVendor:
      manufacturer: HPE
      productName: ProLiant DL380 Gen10 (868703-B21)
      serialNumber: CZ200606M3
  hardwareProfile: unknown
  lastUpdated: "2022-06-16T11:41:42Z"
  operationalStatus: OK
  poweredOn: true
  provisioning:
    ID: 217baa14-cfcf-4196-b764-744e184a3413
    bootMode: UEFI
    customDeploy:
      method: install_coreos
    image:
      url: ""
    raid:
      hardwareRAIDVolumes: null
      softwareRAIDVolumes: []
    rootDeviceHints:
      deviceName: /dev/disk/by-id/scsi-<serial_number>
    state: provisioned
  triedCredentials:
    credentials:
      name: openshift-worker-0-bmc-secret
      namespace: openshift-machine-api
    credentialsVersion: "16120"

----

:leveloffset!:

:leveloffset: +1

// This is included in the following assemblies:
//
// post_installation_configuration/bare-metal-configuration.adoc

:_mod-docs-content-type: REFERENCE
[id="about-the-hostfirmwaresettings-resource_{context}"]
= About the HostFirmwareSettings resource

You can use the `HostFirmwareSettings` resource to retrieve and manage the BIOS settings for a host. When a host moves to the `Available` state, Ironic reads the host's BIOS settings and creates the `HostFirmwareSettings` resource. The resource contains the complete BIOS configuration returned from the baseboard management controller (BMC). Whereas, the `firmware` field in the `BareMetalHost` resource returns three vendor-independent fields, the `HostFirmwareSettings` resource typically comprises many BIOS settings of vendor-specific fields per host.

The `HostFirmwareSettings` resource contains two sections:

. The `HostFirmwareSettings` spec.
. The `HostFirmwareSettings` status.

== The `HostFirmwareSettings` spec

The `spec` section of the `HostFirmwareSettings` resource defines the desired state of the host's BIOS, and it is empty by default. Ironic uses the settings in the `spec.settings` section to update the baseboard management controller (BMC) when the host is in the `Preparing` state. Use the `FirmwareSchema` resource to ensure that you do not send invalid name/value pairs to hosts. See "About the FirmwareSchema resource" for additional details.

.Example
[source,terminal]
----
spec:
  settings:
    ProcTurboMode: Disabled<1>
----
<1> In the foregoing example, the `spec.settings` section contains a name/value pair that will set the `ProcTurboMode` BIOS setting to `Disabled`.

[NOTE]
====
Integer parameters listed in the `status` section appear as strings. For example, `"1"`. When setting integers in the `spec.settings` section, the values should be set as integers without quotes. For example, `1`.
====

== The `HostFirmwareSettings` status

The `status` represents the current state of the host's BIOS.

.HostFirmwareSettings
[options="header"]
|====
|Parameters|Description
a|
----
status:
  conditions:
  - lastTransitionTime:
    message:
    observedGeneration:
    reason:
    status:
    type:
----
a| The `conditions` field contains a list of state changes. The sub-fields include:

* `lastTransitionTime`: The last time the state changed.
* `message`: A description of the state change.
* `observedGeneration`: The current generation of the `status`. If `metadata.generation` and this field are not the same, the `status.conditions` might be out of date.
* `reason`: The reason for the state change.
* `status`: The status of the state change. The status can be `True`, `False` or `Unknown`.
* `type`: The type of state change. The types are `Valid` and `ChangeDetected`.

a|
----
status:
  schema:
    name:
    namespace:
    lastUpdated:
----
a| The `FirmwareSchema` for the firmware settings. The fields include:

* `name`: The name or unique identifier referencing the schema.
* `namespace`: The namespace where the schema is stored.
* `lastUpdated`: The last time the resource was updated.

a|
----
status:
  settings:
----
| The `settings` field contains a list of name/value pairs of a host's current BIOS settings.

|====

:leveloffset!:
:leveloffset: +1

// This is included in the following assemblies:
//
// post_installation_configuration/bare-metal-configuration.adoc

[id="getting-the-hostfirmwaresettings-resource_{context}"]
= Getting the HostFirmwareSettings resource

The `HostFirmwareSettings` resource contains the vendor-specific BIOS properties of a physical host. You must get the `HostFirmwareSettings` resource for a physical host to review its BIOS properties.

.Procedure

. Get the detailed list of `HostFirmwareSettings` resources:
+
[source,terminal]
----
$ oc get hfs -n openshift-machine-api -o yaml
----
+
[NOTE]
====
You can use `hostfirmwaresettings` as the long form of `hfs` with the `oc get` command.
====

. Get the list of `HostFirmwareSettings` resources:
+
[source,terminal]
----
$ oc get hfs -n openshift-machine-api
----

. Get the `HostFirmwareSettings` resource for a particular host
+
[source,terminal]
----
$ oc get hfs <host_name> -n openshift-machine-api -o yaml
----
+
Where `<host_name>` is the name of the host.

:leveloffset!:
:leveloffset: +1

// This is included in the following assemblies:
//
// post_installation_configuration/bare-metal-configuration.adoc

:_mod-docs-content-type: PROCEDURE
[id="editing-the-hostfirmwaresettings-resource_{context}"]
= Editing the HostFirmwareSettings resource

You can edit the `HostFirmwareSettings` of provisioned hosts.

[IMPORTANT]
====
You can only edit hosts when they are in the `provisioned` state, excluding read-only values. You cannot edit hosts in the `externally provisioned` state.

====

.Procedure

. Get the list of `HostFirmwareSettings` resources:
+
[source,terminal]
----
$ oc get hfs -n openshift-machine-api
----

. Edit a host's `HostFirmwareSettings` resource:
+
[source,terminal]
----
$ oc edit hfs <host_name> -n openshift-machine-api
----
+
Where `<host_name>` is the name of a provisioned host. The `HostFirmwareSettings` resource will open in the default editor for your terminal.

. Add name/value pairs to the `spec.settings` section:
+
.Example
[source,terminal]
----
spec:
  settings:
    name: value <1>
----
<1> Use the `FirmwareSchema` resource to identify the available settings for the host. You cannot set values that are read-only.

. Save the changes and exit the editor.

. Get the host's machine name:
+
[source,terminal]
----
 $ oc get bmh <host_name> -n openshift-machine name
----
+
Where `<host_name>` is the name of the host. The machine name appears under the `CONSUMER` field.

. Annotate the machine to delete it from the machineset:
+
[source,terminal]
----
$ oc annotate machine <machine_name> machine.openshift.io/delete-machine=true -n openshift-machine-api
----
+
Where `<machine_name>` is the name of the machine to delete.

. Get a list of nodes and count the number of worker nodes:
+
[source,terminal]
----
$ oc get nodes
----

. Get the machineset:
+
[source,terminal]
----
$ oc get machinesets -n openshift-machine-api
----

. Scale the machineset:
+
[source,terminal]
----
$ oc scale machineset <machineset_name> -n openshift-machine-api --replicas=<n-1>
----
+
Where `<machineset_name>` is the name of the machineset and `<n-1>` is the decremented number of worker nodes.

. When the host enters the `Available` state, scale up the machineset to make the `HostFirmwareSettings` resource changes take effect:
+
[source,terminal]
----
$ oc scale machineset <machineset_name> -n openshift-machine-api --replicas=<n>
----
+
Where `<machineset_name>` is the name of the machineset and `<n>` is the number of worker nodes.

:leveloffset!:
:leveloffset: +1

// This is included in the following assemblies:
//
// post_installation_configuration/bare-metal-configuration.adoc

:_mod-docs-content-type: PROCEDURE
[id="verifying-the-hostfirmware-settings-resource-is-valid_{context}"]
= Verifying the HostFirmware Settings resource is valid

When the user edits the `spec.settings` section to make a change to the `HostFirmwareSetting`(HFS) resource, the Bare Metal Operator (BMO) validates the change against the `FimwareSchema` resource, which is a read-only resource. If the setting is invalid, the BMO will set the `Type` value of the `status.Condition` setting to `False` and also generate an event and store it in the HFS resource. Use the following procedure to verify that the resource is valid.

.Procedure

. Get a list of `HostFirmwareSetting` resources:
+
[source,terminal]
----
$ oc get hfs -n openshift-machine-api
----

. Verify that the `HostFirmwareSettings` resource for a particular host is valid:
+
[source,terminal]
----
$ oc describe hfs <host_name> -n openshift-machine-api
----
+
Where `<host_name>` is the name of the host.
+
.Example output
[source,terminal]
----
Events:
  Type    Reason            Age    From                                    Message
  ----    ------            ----   ----                                    -------
  Normal  ValidationFailed  2m49s  metal3-hostfirmwaresettings-controller  Invalid BIOS setting: Setting ProcTurboMode is invalid, unknown enumeration value - Foo
----
+
[IMPORTANT]
====
If the response returns `ValidationFailed`, there is an error in the resource configuration and you must update the values to conform to the `FirmwareSchema` resource.
====

:leveloffset!:

:leveloffset: +1

// This is included in the following assemblies:
//
// post_installation_configuration/bare-metal-configuration.adoc

:_mod-docs-content-type: REFERENCE
[id="about-the-firmwareschema-resource_{context}"]
= About the FirmwareSchema resource

BIOS settings vary among hardware vendors and host models. A `FirmwareSchema` resource is a read-only resource that contains the types and limits for each BIOS setting on each host model. The data comes directly from the BMC through Ironic. The `FirmwareSchema` enables you to identify valid values you can specify in the `spec` field of the `HostFirmwareSettings` resource. The `FirmwareSchema` resource has a unique identifier derived from its settings and limits. Identical host models use the same `FirmwareSchema` identifier. It is likely that multiple instances of `HostFirmwareSettings` use the same `FirmwareSchema`.

.FirmwareSchema specification
[options="header"]
|====
|Parameters|Description

a|
----
<BIOS_setting_name>
  attribute_type:
  allowable_values:
  lower_bound:
  upper_bound:
  min_length:
  max_length:
  read_only:
  unique:
----

a| The `spec` is a simple map consisting of the BIOS setting name and the limits of the setting. The fields include:

* `attribute_type`: The type of setting. The supported types are:
** `Enumeration`
** `Integer`
** `String`
** `Boolean`
* `allowable_values`: A list of allowable values when the `attribute_type` is `Enumeration`.
* `lower_bound`: The lowest allowed value when `attribute_type` is `Integer`.
* `upper_bound`: The highest allowed value when `attribute_type` is `Integer`.
* `min_length`: The shortest string length that the value can have when `attribute_type` is `String`.
* `max_length`: The longest string length that the value can have when `attribute_type` is `String`.
* `read_only`: The setting is read only and cannot be modified.
* `unique`: The setting is specific to this host.

|====

:leveloffset!:
:leveloffset: +1

// This is included in the following assemblies:
//
// post_installation_configuration/bare-metal-configuration.adoc

:_mod-docs-content-type: PROCEDURE
[id="getting-the-firmwareschema-resource_{context}"]
= Getting the FirmwareSchema resource

Each host model from each vendor has different BIOS settings. When editing the `HostFirmwareSettings` resource's `spec` section, the name/value pairs you set must conform to that host's firmware schema. To ensure you are setting valid name/value pairs, get the `FirmwareSchema` for the host and review it.

.Procedure

. To get a list of `FirmwareSchema` resource instances, execute the following:
+
[source,terminal]
----
$ oc get firmwareschema -n openshift-machine-api
----

. To get a particular `FirmwareSchema` instance, execute:
+
[source,terminal]
----
$ oc get firmwareschema <instance_name> -n openshift-machine-api -o yaml
----
+
Where `<instance_name>` is the name of the schema instance stated in the `HostFirmwareSettings` resource (see Table 3).

:leveloffset!:

//# includes=_attributes/common-attributes,modules/bmo-about-the-bare-metal-operator,modules/con_bmo-bare-metal-operator-architecture,modules/bmo-about-the-baremetalhost-resource,modules/bmo-getting-the-baremetalhost-resource,modules/bmo-about-the-hostfirmwaresettings-resource,modules/bmo-getting-the-hostfirmwaresettings-resource,modules/bmo-editing-the-hostfirmwaresettings-resource,modules/bmo-verifying-the-hostfirmware-settings-resource-is-valid,modules/bmo-about-the-firmwareschema-resource,modules/bmo-getting-the-firmwareschema-resource
