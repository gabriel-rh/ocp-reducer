:_mod-docs-content-type: ASSEMBLY
[id="build-strategies"]
= Using build strategies
// The {product-title} attribute provides the context-sensitive name of the relevant OpenShift distribution, for example, "OpenShift Container Platform" or "OKD". The {product-version} attribute provides the product version relative to the distribution, for example "4.9".
// {product-title} and {product-version} are parsed when AsciiBinder queries the _distro_map.yml file in relation to the base branch of a pull request.
// See https://github.com/openshift/openshift-docs/blob/main/contributing_to_docs/doc_guidelines.adoc#product-name-and-version for more information on this topic.
// Other common attributes are defined in the following lines:
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:imagesdir: images
:prewrap!:
:op-system-first: Red Hat Enterprise Linux CoreOS (RHCOS)
:op-system: RHCOS
:op-system-lowercase: rhcos
:op-system-base: RHEL
:op-system-base-full: Red Hat Enterprise Linux (RHEL)
:op-system-version: 8.x
:tsb-name: Template Service Broker
:kebab: image:kebab.png[title="Options menu"]
:rh-openstack-first: Red Hat OpenStack Platform (RHOSP)
:rh-openstack: RHOSP
:ai-full: Assisted Installer
:ai-version: 2.3
:cluster-manager-first: Red Hat OpenShift Cluster Manager
:cluster-manager: OpenShift Cluster Manager
:cluster-manager-url: link:https://console.redhat.com/openshift[OpenShift Cluster Manager Hybrid Cloud Console]
:cluster-manager-url-pull: link:https://console.redhat.com/openshift/install/pull-secret[pull secret from the Red Hat OpenShift Cluster Manager]
:insights-advisor-url: link:https://console.redhat.com/openshift/insights/advisor/[Insights Advisor]
:hybrid-console: Red Hat Hybrid Cloud Console
:hybrid-console-second: Hybrid Cloud Console
:oadp-first: OpenShift API for Data Protection (OADP)
:oadp-full: OpenShift API for Data Protection
:oc-first: pass:quotes[OpenShift CLI (`oc`)]
:product-registry: OpenShift image registry
:rh-storage-first: Red Hat OpenShift Data Foundation
:rh-storage: OpenShift Data Foundation
:rh-rhacm-first: Red Hat Advanced Cluster Management (RHACM)
:rh-rhacm: RHACM
:rh-rhacm-version: 2.8
:sandboxed-containers-first: OpenShift sandboxed containers
:sandboxed-containers-operator: OpenShift sandboxed containers Operator
:sandboxed-containers-version: 1.3
:sandboxed-containers-version-z: 1.3.3
:sandboxed-containers-legacy-version: 1.3.2
:cert-manager-operator: cert-manager Operator for Red Hat OpenShift
:secondary-scheduler-operator-full: Secondary Scheduler Operator for Red Hat OpenShift
:secondary-scheduler-operator: Secondary Scheduler Operator
// Backup and restore
:velero-domain: velero.io
:velero-version: 1.11
:launch: image:app-launcher.png[title="Application Launcher"]
:mtc-short: MTC
:mtc-full: Migration Toolkit for Containers
:mtc-version: 1.8
:mtc-version-z: 1.8.0
// builds (Valid only in 4.11 and later)
:builds-v2title: Builds for Red Hat OpenShift
:builds-v2shortname: OpenShift Builds v2
:builds-v1shortname: OpenShift Builds v1
//gitops
:gitops-title: Red Hat OpenShift GitOps
:gitops-shortname: GitOps
:gitops-ver: 1.1
:rh-app-icon: image:red-hat-applications-menu-icon.jpg[title="Red Hat applications"]
//pipelines
:pipelines-title: Red Hat OpenShift Pipelines
:pipelines-shortname: OpenShift Pipelines
:pipelines-ver: pipelines-1.12
:pipelines-version-number: 1.12
:tekton-chains: Tekton Chains
:tekton-hub: Tekton Hub
:artifact-hub: Artifact Hub
:pac: Pipelines as Code
//odo
:odo-title: odo
//OpenShift Kubernetes Engine
:oke: OpenShift Kubernetes Engine
//OpenShift Platform Plus
:opp: OpenShift Platform Plus
//openshift virtualization (cnv)
:VirtProductName: OpenShift Virtualization
:VirtVersion: 4.14
:KubeVirtVersion: v0.59.0
:HCOVersion: 4.14.0
:CNVNamespace: openshift-cnv
:CNVOperatorDisplayName: OpenShift Virtualization Operator
:CNVSubscriptionSpecSource: redhat-operators
:CNVSubscriptionSpecName: kubevirt-hyperconverged
:delete: image:delete.png[title="Delete"]
//distributed tracing
:DTProductName: Red Hat OpenShift distributed tracing platform
:DTShortName: distributed tracing platform
:DTProductVersion: 2.9
:JaegerName: Red Hat OpenShift distributed tracing platform (Jaeger)
:JaegerShortName: distributed tracing platform (Jaeger)
:JaegerVersion: 1.47.0
:OTELName: Red Hat OpenShift distributed tracing data collection
:OTELShortName: distributed tracing data collection
:OTELOperator: Red Hat OpenShift distributed tracing data collection Operator
:OTELVersion: 0.81.0
:TempoName: Red Hat OpenShift distributed tracing platform (Tempo)
:TempoShortName: distributed tracing platform (Tempo)
:TempoOperator: Tempo Operator
:TempoVersion: 2.1.1
//logging
:logging-title: logging subsystem for Red Hat OpenShift
:logging-title-uc: Logging subsystem for Red Hat OpenShift
:logging: logging subsystem
:logging-uc: Logging subsystem
//serverless
:ServerlessProductName: OpenShift Serverless
:ServerlessProductShortName: Serverless
:ServerlessOperatorName: OpenShift Serverless Operator
:FunctionsProductName: OpenShift Serverless Functions
//service mesh v2
:product-dedicated: Red Hat OpenShift Dedicated
:product-rosa: Red Hat OpenShift Service on AWS
:SMProductName: Red Hat OpenShift Service Mesh
:SMProductShortName: Service Mesh
:SMProductVersion: 2.4.4
:MaistraVersion: 2.4
//Service Mesh v1
:SMProductVersion1x: 1.1.18.2
//Windows containers
:productwinc: Red Hat OpenShift support for Windows Containers
// Red Hat Quay Container Security Operator
:rhq-cso: Red Hat Quay Container Security Operator
// Red Hat Quay
:quay: Red Hat Quay
:sno: single-node OpenShift
:sno-caps: Single-node OpenShift
//TALO and Redfish events Operators
:cgu-operator-first: Topology Aware Lifecycle Manager (TALM)
:cgu-operator-full: Topology Aware Lifecycle Manager
:cgu-operator: TALM
:redfish-operator: Bare Metal Event Relay
//Formerly known as CodeReady Containers and CodeReady Workspaces
:openshift-local-productname: Red Hat OpenShift Local
:openshift-dev-spaces-productname: Red Hat OpenShift Dev Spaces
// Factory-precaching-cli tool
:factory-prestaging-tool: factory-precaching-cli tool
:factory-prestaging-tool-caps: Factory-precaching-cli tool
:openshift-networking: Red Hat OpenShift Networking
// TODO - this probably needs to be different for OKD
//ifdef::openshift-origin[]
//:openshift-networking: OKD Networking
//endif::[]
// logical volume manager storage
:lvms-first: Logical volume manager storage (LVM Storage)
:lvms: LVM Storage
//Operator SDK version
:osdk_ver: 1.31.0
//Operator SDK version that shipped with the previous OCP 4.x release
:osdk_ver_n1: 1.28.0
//Next-gen (OCP 4.14+) Operator Lifecycle Manager, aka "v1"
:olmv1: OLM 1.0
:olmv1-first: Operator Lifecycle Manager (OLM) 1.0
:ztp-first: GitOps Zero Touch Provisioning (ZTP)
:ztp: GitOps ZTP
:3no: three-node OpenShift
:3no-caps: Three-node OpenShift
:run-once-operator: Run Once Duration Override Operator
// Web terminal
:web-terminal-op: Web Terminal Operator
:devworkspace-op: DevWorkspace Operator
:secrets-store-driver: Secrets Store CSI driver
:secrets-store-operator: Secrets Store CSI Driver Operator
//AWS STS
:sts-first: Security Token Service (STS)
:sts-full: Security Token Service
:sts-short: STS
//Cloud provider names
//AWS
:aws-first: Amazon Web Services (AWS)
:aws-full: Amazon Web Services
:aws-short: AWS
//GCP
:gcp-first: Google Cloud Platform (GCP)
:gcp-full: Google Cloud Platform
:gcp-short: GCP
//alibaba cloud
:alibaba: Alibaba Cloud
// IBM Cloud VPC
:ibmcloudVPCProductName: IBM Cloud VPC
:ibmcloudVPCRegProductName: IBM(R) Cloud VPC
// IBM Cloud
:ibm-cloud-bm: IBM Cloud Bare Metal (Classic)
:ibm-cloud-bm-reg: IBM Cloud(R) Bare Metal (Classic)
// IBM Power
:ibmpowerProductName: IBM Power
:ibmpowerRegProductName: IBM(R) Power
// IBM zSystems
:ibmzProductName: IBM Z
:ibmzRegProductName: IBM(R) Z
:linuxoneProductName: IBM(R) LinuxONE
//Azure
:azure-full: Microsoft Azure
:azure-short: Azure
//vSphere
:vmw-full: VMware vSphere
:vmw-short: vSphere
//Oracle
:oci-first: Oracle(R) Cloud Infrastructure
:oci: OCI
:ocvs-first: Oracle(R) Cloud VMware Solution (OCVS)
:ocvs: OCVS
:context: build-strategies

toc::[]

The following sections define the primary supported build strategies, and how to
use them.

// Docker build strategy

:leveloffset: +1

// Module included in the following assemblies:
//
//*builds/build-strategies.adoc
//*builds/understanding-image-builds

[id="builds-strategy-docker-build_{context}"]
= Docker build

{product-title} uses Buildah to build a container image from a Dockerfile. For more information on building container images with Dockerfiles, see link:https://docs.docker.com/engine/reference/builder/[the Dockerfile reference documentation].

[TIP]
====
If you set Docker build arguments by using the `buildArgs` array, see link:https://docs.docker.com/engine/reference/builder/#understand-how-arg-and-from-interact[Understand how ARG and FROM interact] in the Dockerfile reference documentation.
====

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
// * builds/build-strategies.adoc

:_mod-docs-content-type: PROCEDURE
[id="builds-strategy-docker-from-image_{context}"]
= Replacing Dockerfile FROM image

You can replace the `FROM` instruction of the Dockerfile with the `from` of the `BuildConfig` object. If the Dockerfile uses multi-stage builds, the image in the last `FROM` instruction will be replaced.

.Procedure

To replace the `FROM` instruction of the Dockerfile with the `from` of the `BuildConfig`.

[source,yaml]
----
strategy:
  dockerStrategy:
    from:
      kind: "ImageStreamTag"
      name: "debian:latest"
----

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
// * builds/build-strategies.adoc

:_mod-docs-content-type: PROCEDURE
[id="builds-strategy-dockerfile-path_{context}"]
= Using Dockerfile path

By default, docker builds use a Dockerfile located at the root of the context specified in the `BuildConfig.spec.source.contextDir` field.

The `dockerfilePath` field allows the build to use a different path to locate your Dockerfile, relative to the `BuildConfig.spec.source.contextDir` field. It can be a different file name than the default Dockerfile, such as `MyDockerfile`, or a path to a Dockerfile in a subdirectory, such as `dockerfiles/app1/Dockerfile`.

.Procedure

To use the `dockerfilePath` field for the build to use a different path to locate your Dockerfile, set:

[source,yaml]
----
strategy:
  dockerStrategy:
    dockerfilePath: dockerfiles/app1/Dockerfile
----

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
// * builds/build-strategies.adoc

:_mod-docs-content-type: PROCEDURE
[id="builds-strategy-docker-environment-variables_{context}"]
= Using docker environment variables

To make environment variables available to the docker build process and resulting image, you can add environment variables to the `dockerStrategy` definition of the build configuration.

The environment variables defined there are inserted as a single `ENV` Dockerfile instruction right after the `FROM` instruction, so that it can be referenced later on within the Dockerfile.

.Procedure

The variables are defined during build and stay in the output image, therefore they will be present in any container that runs that image as well.

For example, defining a custom HTTP proxy to be used during build and runtime:

[source,yaml]
----
dockerStrategy:
...
  env:
    - name: "HTTP_PROXY"
      value: "http://myproxy.net:5187/"
----

You can also manage environment variables defined in the build configuration with the `oc set env` command.

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
// * builds/build-strategies.adoc

:_mod-docs-content-type: PROCEDURE
[id="builds-strategy-docker-build-arguments_{context}"]
= Adding docker build arguments

You can set link:http://docs.docker.com/v1.7/reference/api/hub_registry_spec/#docker-registry-1-0[docker build arguments] using the `buildArgs` array. The build arguments are passed to docker when a build is started.

[TIP]
====
See link:https://docs.docker.com/engine/reference/builder/#understand-how-arg-and-from-interact[Understand how ARG and FROM interact] in the Dockerfile reference documentation.
====

.Procedure

To set docker build arguments, add entries to the `buildArgs` array, which is located in the `dockerStrategy` definition of the `BuildConfig` object. For example:

[source,yaml]
----
dockerStrategy:
...
  buildArgs:
    - name: "foo"
      value: "bar"
----

[NOTE]
====
Only the `name` and `value` fields are supported. Any settings on the `valueFrom` field are ignored.
====

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
//* builds/running-entitled-builds.adoc

:_mod-docs-content-type: PROCEDURE
[id="builds-strategy-docker-squash-layers_{context}"]
= Squashing layers with docker builds

Docker builds normally create a layer representing each instruction in a Dockerfile. Setting the `imageOptimizationPolicy` to `SkipLayers` merges all instructions into a single layer on top of the base image.

.Procedure

* Set the `imageOptimizationPolicy` to `SkipLayers`:
+
[source,yaml]
----
strategy:
  dockerStrategy:
    imageOptimizationPolicy: SkipLayers
----

:leveloffset!:

:context: build-strategies-docker

:leveloffset: +2

:dockerstrategy:

:_mod-docs-content-type: PROCEDURE
[id="builds-using-build-volumes_{context}"]
= Using build volumes

You can mount build volumes to give running builds access to information that you don't want to persist in the output container image.

Build volumes provide sensitive information, such as repository credentials, that the build environment or configuration only needs at build time. Build volumes are different from xref:../../cicd/builds/creating-build-inputs.adoc#builds-define-build-inputs_creating-build-inputs[build inputs], whose data can persist in the output container image.

The mount points of build volumes, from which the running build reads data, are functionally similar to link:https://kubernetes.io/docs/concepts/storage/volumes/[pod volume mounts].

.Prerequisites
* You have xref:../../cicd/builds/creating-build-inputs.adoc#builds-input-secrets-configmaps_creating-build-inputs[added an input secret, config map, or both to a BuildConfig object].

.Procedure


* In the `dockerStrategy` definition of the `BuildConfig` object, add any build volumes to the `volumes` array. For example:
+
[source,yaml]
----
spec:
  dockerStrategy:
    volumes:
      - name: secret-mvn <1>
        mounts:
        - destinationPath: /opt/app-root/src/.ssh <2>
        source:
          type: Secret <3>
          secret:
            secretName: my-secret <4>
      - name: settings-mvn <1>
        mounts:
        - destinationPath: /opt/app-root/src/.m2  <2>
        source:
          type: ConfigMap <3>
          configMap:
            name: my-config <4>
      - name: my-csi-volume <1>
        mounts:
        - destinationPath: /opt/app-root/src/some_path  <2>
        source:
          type: CSI <3>
          csi:
            driver: csi.sharedresource.openshift.io <5>
            readOnly: true <6>
            volumeAttributes: <7>
              attribute: value
----
<1> Required. A unique name.
<2> Required. The absolute path of the mount point. It must not contain `..` or `:` and doesn't collide with the destination path generated by the builder. The `/opt/app-root/src` is the default home directory for many Red Hat S2I-enabled images.
<3> Required. The type of source, `ConfigMap`, `Secret`, or `CSI`.
<4> Required. The name of the source.
<5> Required. The driver that provides the ephemeral CSI volume.
<6> Required. This value must be set to `true`. Provides a read-only volume.
<7> Optional. The volume attributes of the ephemeral CSI volume. Consult the CSI driver's documentation for supported attribute keys and values.

[NOTE]
====
The Shared Resource CSI Driver is supported as a Technology Preview feature.
====



:!dockerstrategy:

:leveloffset!:


// S2I build strategy

:leveloffset: +1

// Module included in the following assemblies:
//
//* builds/build-strategies.adoc
//* builds/understanding-image-builds.adoc

[id="builds-strategy-s2i-build_{context}"]
= Source-to-image build

Source-to-image (S2I) is a tool for building reproducible container images. It produces ready-to-run images by injecting application source into a container image and assembling a new image. The new image incorporates the base image, the builder, and built source and is ready to use with the `buildah run` command. S2I supports incremental builds, which re-use previously downloaded dependencies, previously built artifacts, and so on.


////
The advantages of S2I include the following:

[horizontal]
Image flexibility:: S2I scripts can be written to inject application code into almost any existing Docker-formatted container image, taking advantage of the existing ecosystem. Note that, currently, S2I relies on `tar` to inject application source, so the image needs to be able to process tarred content.

Speed:: With S2I, the assemble process can perform a large number of complex operations without creating a new layer at each step, resulting in a fast process. In addition, S2I scripts can be written to re-use artifacts stored in a previous version of the application image, rather than having to download or build them each time the build is run.

Patchability:: S2I allows you to rebuild the application consistently if an underlying image needs a patch due to a security issue.

Operational efficiency:: By restricting build operations instead of allowing arbitrary actions, as a Dockerfile would allow, the PaaS operator can avoid accidental or intentional abuses of the build system.

Operational security:: Building an arbitrary Dockerfile exposes the host system to root privilege escalation. This can be exploited by a malicious user because the entire Docker build process is run as a user with Docker privileges. S2I restricts the operations performed as a root user and can run the scripts as a non-root user.

User efficiency:: S2I prevents developers from performing arbitrary `yum install` type operations, which could slow down development iteration, during their application build.

Ecosystem:: S2I encourages a shared ecosystem of images where you can leverage best practices for your applications.

Reproducibility:: Produced images can include all inputs including specific versions of build tools and dependencies. This ensures that the image can be reproduced precisely.
////

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
//* builds/build-strategies.adoc

:_mod-docs-content-type: PROCEDURE
[id="builds-strategy-s2i-incremental-builds_{context}"]
= Performing source-to-image incremental builds

Source-to-image (S2I) can perform incremental builds, which means it reuses artifacts from previously-built images.

.Procedure

* To create an incremental build, create a  with the following modification to the strategy definition:
+
[source,yaml]
----
strategy:
  sourceStrategy:
    from:
      kind: "ImageStreamTag"
      name: "incremental-image:latest" <1>
    incremental: true <2>
----
<1> Specify an image that supports incremental builds. Consult the documentation of the builder image to determine if it supports this behavior.
<2> This flag controls whether an incremental build is attempted. If the builder image does not support incremental builds, the build will still succeed, but you will get a log message stating the incremental build was not successful because of a missing `save-artifacts` script.

[role="_additional-resources"]
.Additional resources

* See S2I Requirements for information on how to create a builder image supporting incremental builds.

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
// * builds/build-strategies.adoc

:_mod-docs-content-type: PROCEDURE
[id="builds-strategy-s2i-override-builder-image-scripts_{context}"]
= Overriding source-to-image builder image scripts

You can override the `assemble`, `run`, and `save-artifacts` source-to-image (S2I) scripts provided by the builder image.

.Procedure

To override the `assemble`, `run`, and `save-artifacts` S2I scripts provided by the builder image, either:

* Provide an `assemble`, `run`, or `save-artifacts` script in the `.s2i/bin` directory of your application source repository.
* Provide a URL of a directory containing the scripts as part of the strategy definition. For example:
+
[source,yaml]
----
strategy:
  sourceStrategy:
    from:
      kind: "ImageStreamTag"
      name: "builder-image:latest"
    scripts: "http://somehost.com/scripts_directory" <1>
----
<1> This path will have `run`, `assemble`, and `save-artifacts` appended to it. If any or all scripts are found they will be used in place of the same named scripts provided in the image.

[NOTE]
====
Files located at the `scripts` URL take precedence over files located in `.s2i/bin` of the source repository.
====

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
// * builds/build-strategies.adoc

[id="builds-strategy-s2i-environment-variables_{context}"]
= Source-to-image environment variables

There are two ways to make environment variables available to the source build process and resulting image. Environment files and BuildConfig environment values. Variables provided will be present during the build process and in the output image.

:leveloffset!:

:leveloffset: +3

// Module included in the following assemblies:
// * builds/build-strategies.adoc

:_mod-docs-content-type: PROCEDURE
[id="builds-strategy-s2i-environment-files_{context}"]
= Using source-to-image environment files

Source build enables you to set environment values, one per line, inside your application, by specifying them in a `.s2i/environment` file in the source repository. The environment variables specified in this file are present during the build process and in the output image.

If you provide a `.s2i/environment` file in your source repository, source-to-image (S2I) reads this file during the build. This allows customization of the build behavior as the `assemble` script may use these variables.

.Procedure

For example, to disable assets compilation for your Rails application during the build:

* Add `DISABLE_ASSET_COMPILATION=true` in the `.s2i/environment` file.

In addition to builds, the specified environment variables are also available in the running application itself. For example, to cause the Rails application to start in `development` mode instead of `production`:

* Add `RAILS_ENV=development` to the `.s2i/environment` file.


The complete list of supported environment variables is available in the using images section for each image.

:leveloffset!:

:leveloffset: +3

// Module included in the following assemblies:
//* * builds/build-strategies.adoc

:_mod-docs-content-type: PROCEDURE
[id="builds-strategy-s2i-buildconfig-environment_{context}"]
= Using source-to-image build configuration environment

You can add environment variables to the `sourceStrategy` definition of the build configuration. The environment variables defined there are visible during the `assemble` script execution and will be defined in the output image, making them also available to the `run` script and application code.

.Procedure

* For example, to disable assets compilation for your Rails application:
+
[source,yaml]
----
sourceStrategy:
...
  env:
    - name: "DISABLE_ASSET_COMPILATION"
      value: "true"
----

[role="_additional-resources"]
.Additional resources

* The build environment section provides more advanced instructions.
* You can also manage environment variables defined in the build configuration with the `oc set env` command.

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
// * builds/build-strategies.adoc

[id="builds-strategy-s2i-ignore-source-files_{context}"]
= Ignoring source-to-image source files

Source-to-image (S2I) supports a `.s2iignore` file, which contains a list of file patterns that should be ignored. Files in the build working directory, as provided by the various input sources, that match a pattern found in the `.s2iignore` file will not be made available to the `assemble` script.

//For more details on the format of the `.s2iignore` file, see the S2I documentation.

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
//
// * builds/build-strategies.adoc
// * openshift_images/create-images.adoc

[id="images-create-s2i_{context}"]
= Creating images from source code with source-to-image

Source-to-image (S2I) is a framework that makes it easy to write images that take application source code as an input and produce a new image that runs the assembled application as output.

The main advantage of using S2I for building reproducible container images is the ease of use for developers. As a builder image author, you must understand two basic concepts in order for your images to provide the best S2I performance, the build process and S2I scripts.

:leveloffset!:

:leveloffset: +3

// Module included in the following assemblies:
//
//* builds/build-strategies.adoc
// * openshift_images/create-images.adoc

:_mod-docs-content-type: CONCEPT
[id="images-create-s2i-build_{context}"]
= Understanding the source-to-image build process

The build process consists of the following three fundamental elements, which are combined into a final container image:

* Sources
* Source-to-image (S2I) scripts
* Builder image

S2I generates a Dockerfile with the builder image as the first `FROM` instruction. The Dockerfile generated by S2I is then passed to Buildah.

:leveloffset!:

:leveloffset: +3

// Module included in the following assemblies:
//
//* builds/build-strategies.adoc
// * openshift_images/create-images.adoc

[id="images-create-s2i-scripts_{context}"]
= How to write source-to-image scripts

You can write source-to-image (S2I) scripts in any programming language, as long as the scripts are executable inside the builder image. S2I supports multiple options providing `assemble`/`run`/`save-artifacts` scripts. All of these locations are checked on each build in the following order:

. A script specified in the build configuration.
. A script found in the application source `.s2i/bin` directory.
. A script found at the default image URL with the `io.openshift.s2i.scripts-url` label.

Both the `io.openshift.s2i.scripts-url` label specified in the image and the script specified in a build configuration can take one of the following forms:

* `image:///path_to_scripts_dir`: absolute path inside the image to a directory where the S2I scripts are located.
* `$$file:///path_to_scripts_dir$$`: relative or absolute path to a directory on the host where the S2I scripts are located.
* `http(s)://path_to_scripts_dir`: URL to a directory where the S2I scripts are located.

.S2I scripts
[cols="3a,8a",options="header"]
|===

|Script |Description

|`assemble`
|The `assemble` script builds the application artifacts from a source and places them into appropriate directories inside the image. This script is required. The workflow for this script is:

. Optional: Restore build artifacts. If you want to support incremental builds, make sure to define `save-artifacts` as well.
. Place the application source in the desired location.
. Build the application artifacts.
. Install the artifacts into locations appropriate for them to run.

|`run`
|The `run` script executes your application. This script is required.

|`save-artifacts`
|The `save-artifacts` script gathers all dependencies that can speed up the build processes that follow. This script is optional. For example:

* For Ruby, `gems` installed by Bundler.
* For Java, `.m2` contents.

These dependencies are gathered into a `tar` file and streamed to the standard output.

|`usage`
|The `usage` script allows you to inform the user how to properly use your image. This script is optional.

|`test/run`
|The `test/run` script allows you to create a process to check if the image is working correctly. This script is optional. The proposed flow of that process is:

. Build the image.
. Run the image to verify the `usage` script.
. Run `s2i build` to verify the `assemble` script.
. Optional: Run `s2i build` again to verify the `save-artifacts` and `assemble` scripts save and restore artifacts functionality.
. Run the image to verify the test application is working.

[NOTE]
====
The suggested location to put the test application built by your `test/run` script is the `test/test-app` directory in your image repository.
====
|===

*Example S2I scripts*

The following example S2I scripts are written in Bash. Each example assumes its `tar` contents are unpacked into the `/tmp/s2i` directory.

.`assemble` script:
[source,bash]
----
#!/bin/bash

# restore build artifacts
if [ "$(ls /tmp/s2i/artifacts/ 2>/dev/null)" ]; then
    mv /tmp/s2i/artifacts/* $HOME/.
fi

# move the application source
mv /tmp/s2i/src $HOME/src

# build application artifacts
pushd ${HOME}
make all

# install the artifacts
make install
popd
----

.`run` script:
[source,bash]
----
#!/bin/bash

# run the application
/opt/application/run.sh
----


.`save-artifacts` script:
[source,bash]
----
#!/bin/bash

pushd ${HOME}
if [ -d deps ]; then
    # all deps contents to tar stream
    tar cf - deps
fi
popd
----

.`usage` script:
[source,bash]
----
#!/bin/bash

# inform the user how to use the image
cat <<EOF
This is a S2I sample builder image, to use it, install
https://github.com/openshift/source-to-image
EOF
----

[role="_additional-resources"]
.Additional resources
* link:https://blog.openshift.com/create-s2i-builder-image/[S2I Image Creation Tutorial]

////
* See the link:https://docs.docker.com/engine/reference/builder/#onbuild[Docker
documentation] for more information on `ONBUILD`.
////

:leveloffset!:

:context: build-strategies-s2i

:leveloffset: +2

:sourcestrategy:

:_mod-docs-content-type: PROCEDURE
[id="builds-using-build-volumes_{context}"]
= Using build volumes

You can mount build volumes to give running builds access to information that you don't want to persist in the output container image.

Build volumes provide sensitive information, such as repository credentials, that the build environment or configuration only needs at build time. Build volumes are different from xref:../../cicd/builds/creating-build-inputs.adoc#builds-define-build-inputs_creating-build-inputs[build inputs], whose data can persist in the output container image.

The mount points of build volumes, from which the running build reads data, are functionally similar to link:https://kubernetes.io/docs/concepts/storage/volumes/[pod volume mounts].

.Prerequisites
* You have xref:../../cicd/builds/creating-build-inputs.adoc#builds-input-secrets-configmaps_creating-build-inputs[added an input secret, config map, or both to a BuildConfig object].

.Procedure



* In the `sourceStrategy` definition of the `BuildConfig` object, add any build volumes to the `volumes` array. For example:
+
[source,yaml]
----
spec:
  sourceStrategy:
    volumes:
      - name: secret-mvn <1>
        mounts:
        - destinationPath: /opt/app-root/src/.ssh <2>
        source:
          type: Secret <3>
          secret:
            secretName: my-secret <4>
      - name: settings-mvn <1>
        mounts:
        - destinationPath: /opt/app-root/src/.m2 <2>
        source:
          type: ConfigMap <3>
          configMap:
            name: my-config <4>
      - name: my-csi-volume <1>
        mounts:
        - destinationPath: /opt/app-root/src/some_path  <2>
        source:
          type: CSI <3>
          csi:
            driver: csi.sharedresource.openshift.io <5>
            readOnly: true <6>
            volumeAttributes: <7>
              attribute: value
----

<1> Required. A unique name.
<2> Required. The absolute path of the mount point. It must not contain `..` or `:` and doesn't collide with the destination path generated by the builder. The `/opt/app-root/src` is the default home directory for many Red Hat S2I-enabled images.
<3> Required. The type of source, `ConfigMap`, `Secret`, or `CSI`.
<4> Required. The name of the source.
<5> Required. The driver that provides the ephemeral CSI volume.
<6> Required. This value must be set to `true`. Provides a read-only volume.
<7> Optional. The volume attributes of the ephemeral CSI volume. Consult the CSI driver's documentation for supported attribute keys and values.

[NOTE]
====
The Shared Resource CSI Driver is supported as a Technology Preview feature.
====


:!sourcestrategy:

:leveloffset!:

// Custom build strategy

:leveloffset: +1

// Module included in the following assemblies:
//
// * builds/build-strategies.adoc

[id="builds-strategy-custom-build_{context}"]
= Custom build

The custom build strategy allows developers to define a specific builder image responsible for the entire build process. Using your own builder image allows you to customize your build process.

A custom builder image is a plain container image embedded with build process logic, for example for building RPMs or base images.

Custom builds run with a high level of privilege and are not available to users by default. Only users who can be trusted with cluster administration permissions should be granted access to run custom builds.

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
//
//* builds/build-strategies.adoc

:_mod-docs-content-type: PROCEDURE
[id="builds-strategy-custom-from-image_{context}"]
= Using FROM image for custom builds

You can use the `customStrategy.from` section to indicate the image to use for the custom build

.Procedure

* Set the `customStrategy.from` section:
+
[source,yaml]
----
strategy:
  customStrategy:
    from:
      kind: "DockerImage"
      name: "openshift/sti-image-builder"
----

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
//
//* builds/build-strategies.adoc

:_mod-docs-content-type: PROCEDURE
[id="builds-strategy-custom-secrets_{context}"]
= Using secrets in custom builds

In addition to secrets for source and images that can be added to all build types, custom strategies allow adding an arbitrary list of secrets to the builder pod.

.Procedure

* To mount each secret at a specific location, edit the `secretSource` and `mountPath` fields of the `strategy` YAML file:
+
[source,yaml]
----
strategy:
  customStrategy:
    secrets:
      - secretSource: <1>
          name: "secret1"
        mountPath: "/tmp/secret1" <2>
      - secretSource:
          name: "secret2"
        mountPath: "/tmp/secret2"
----
<1> `secretSource` is a reference to a secret in the same namespace as the build.
<2> `mountPath` is the path inside the custom builder where the secret should be mounted.

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
//
//* builds/build-strategies.adoc

:_mod-docs-content-type: PROCEDURE
[id="builds-strategy-custom-environment-variables_{context}"]
= Using environment variables for custom builds

To make environment variables available to the custom build process, you can add environment variables to the `customStrategy` definition of the build configuration.

The environment variables defined there are passed to the pod that runs the
custom build.

.Procedure

. Define a custom HTTP proxy to be used during build:
+
[source,yaml]
----
customStrategy:
...
  env:
    - name: "HTTP_PROXY"
      value: "http://myproxy.net:5187/"
----
+
. To manage environment variables defined in the build configuration, enter the following command:
+
[source,terminal]
----
$ oc set env <enter_variables>
----

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
//
// * builds/build-strategies.adoc

[id="images-custom_{context}"]
= Using custom builder images

{product-title}'s custom build strategy enables you to define a specific builder image responsible for the entire build process. When you need a build to produce individual artifacts such as packages, JARs, WARs, installable ZIPs, or base images, use a custom builder image using the custom build strategy.

A custom builder image is a plain container image embedded with build process logic, which is used for building artifacts such as RPMs or base container images.

Additionally, the custom builder allows implementing any extended build process, such as a CI/CD flow that runs unit or integration tests.

[id="images-custom-builder-image-ref_{context}"]
== Custom builder image

Upon invocation, a custom builder image receives the following environment variables with the information needed to proceed with the build:

.Custom Builder Environment Variables
[cols="1,3",options="header"]
|===

|Variable Name |Description

|`BUILD`
|The entire serialized JSON of the `Build` object definition. If you must use a specific API version for serialization, you can set the `buildAPIVersion` parameter in the custom strategy specification of the build configuration.

|`SOURCE_REPOSITORY`
|The URL of a Git repository with source to be built.

|`SOURCE_URI`
|Uses the same value as `SOURCE_REPOSITORY`. Either can be used.

|`SOURCE_CONTEXT_DIR`
|Specifies the subdirectory of the Git repository to be used when building. Only present if defined.

|`SOURCE_REF`
|The Git reference to be built.

|`ORIGIN_VERSION`
|The version of the {product-title} master that created this build object.

|`OUTPUT_REGISTRY`
|The container image registry to push the image to.

|`OUTPUT_IMAGE`
|The container image tag name for the image being built.

|`PUSH_DOCKERCFG_PATH`
|The path to the container registry credentials for running a `podman push`  operation.

|===

[id="images-custom-builder-flow_{context}"]
== Custom builder workflow

Although custom builder image authors have flexibility in defining the build process, your builder image must adhere to the following required steps necessary for running a build inside of {product-title}:

. The `Build` object definition contains all the necessary information about input parameters for the build.
. Run the build process.
. If your build produces an image, push it to the output location of the build if it is defined. Other output locations can be passed with environment variables.

:leveloffset!:

// Pipeline build strategy

:leveloffset: +1

// Module included in the following assemblies:
//
//*builds/build-strategies.adoc
//*builds/understanding-image-builds

[id="builds-strategy-pipeline-build_{context}"]
= Pipeline build

[IMPORTANT]
====
The Pipeline build strategy is deprecated in {product-title} 4. Equivalent and improved functionality is present in the {product-title} Pipelines based on Tekton.

Jenkins images on {product-title} are fully supported and users should follow Jenkins user documentation for defining their `jenkinsfile` in a job or store it in a Source Control Management system.
====

The Pipeline build strategy allows developers to define a Jenkins pipeline for use by the Jenkins pipeline plugin. The build can be started, monitored, and managed by {product-title} in the same way as any other build type.

Pipeline workflows are defined in a `jenkinsfile`, either embedded directly in the build configuration, or supplied in a Git repository and referenced by the build configuration.

//The first time a project defines a build configuration using a Pipeline
//strategy, {product-title} instantiates a Jenkins server to execute the
//pipeline. Subsequent Pipeline build configurations in the project share this
//Jenkins server.

//[role="_additional-resources"]
//.Additional resources

//* Pipeline build configurations require a Jenkins server to manage the
//pipeline execution.

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
//* builds/build-strategies.adoc

:_mod-docs-content-type: CONCEPT
[id="builds-understanding-openshift-pipeline_{context}"]
= Understanding {product-title} pipelines

[IMPORTANT]
====
The Pipeline build strategy is deprecated in {product-title} 4. Equivalent and improved functionality is present in the {product-title} Pipelines based on Tekton.

Jenkins images on {product-title} are fully supported and users should follow Jenkins user documentation for defining their `jenkinsfile` in a job or store it in a Source Control Management system.
====

Pipelines give you control over building, deploying, and promoting your applications on {product-title}. Using a combination of the Jenkins Pipeline build strategy, `jenkinsfiles`, and the {product-title} Domain Specific Language (DSL) provided by the Jenkins Client Plugin, you can create advanced build, test, deploy, and promote pipelines for any scenario.

*{product-title} Jenkins Sync Plugin*

The {product-title} Jenkins Sync Plugin keeps the build configuration and build objects in sync with Jenkins jobs and builds, and provides the following:

 * Dynamic job and run creation in Jenkins.
 * Dynamic creation of agent pod templates from image streams, image stream tags, or config maps.
 * Injection of environment variables.
 * Pipeline visualization in the {product-title} web console.
 * Integration with the Jenkins Git plugin, which passes commit information from {product-title} builds to the Jenkins Git plugin.
 * Synchronization of secrets into Jenkins credential entries.

*{product-title} Jenkins Client Plugin*

The {product-title} Jenkins Client Plugin is a Jenkins plugin which aims to provide a readable, concise, comprehensive, and fluent Jenkins Pipeline syntax for rich interactions with an {product-title} API Server. The plugin uses the {product-title} command line tool, `oc`, which must be available on the nodes executing the script.

The Jenkins Client Plugin must be installed on your Jenkins master so the {product-title} DSL will be available to use within the `jenkinsfile` for your application. This plugin is installed and enabled by default when using the {product-title} Jenkins image.

For {product-title} Pipelines within your project, you will must use the Jenkins Pipeline Build Strategy. This strategy defaults to using a `jenkinsfile` at the root of your source repository, but also provides the following configuration options:

* An inline `jenkinsfile` field within your build configuration.
* A `jenkinsfilePath` field within your build configuration that references the location of the `jenkinsfile` to use relative to the source `contextDir`.

[NOTE]
====
The optional `jenkinsfilePath` field specifies the name of the file to use, relative to the source `contextDir`. If `contextDir` is omitted, it defaults to the root of the repository. If `jenkinsfilePath` is omitted, it defaults to `jenkinsfile`.
====

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
// * builds/build-strategies.adoc

:_mod-docs-content-type: PROCEDURE
[id="builds-strategy-pipeline-providing-jenkinsfile_{context}"]
= Providing the Jenkins file for pipeline builds

[IMPORTANT]
====
The Pipeline build strategy is deprecated in {product-title} 4. Equivalent and improved functionality is present in the {product-title} Pipelines based on Tekton.

Jenkins images on {product-title} are fully supported and users should follow Jenkins user documentation for defining their `jenkinsfile` in a job or store it in a Source Control Management system.
====

The `jenkinsfile` uses the standard groovy language syntax to allow fine grained control over the configuration, build, and deployment of your application.

You can supply the `jenkinsfile` in one of the following ways:

* A file located within your source code repository.
* Embedded as part of your build configuration using the `jenkinsfile` field.

When using the first option, the `jenkinsfile` must be included in your applications source code repository at one of the following locations:

* A file named `jenkinsfile` at the root of your repository.
* A file named `jenkinsfile` at the root of the source `contextDir` of your repository.
* A file name specified via the `jenkinsfilePath` field of the `JenkinsPipelineStrategy` section of your BuildConfig, which is relative to the source `contextDir` if supplied, otherwise it defaults to the root of the repository.

The `jenkinsfile` is run on the Jenkins agent pod, which must have the
{product-title} client binaries available if you intend to use the {product-title} DSL.

.Procedure

To provide the Jenkins file, you can either:

* Embed the Jenkins file in the build configuration.
* Include in the build configuration a reference to the Git repository that contains the Jenkins file.

.Embedded Definition
[source,yaml]
----
kind: "BuildConfig"
apiVersion: "v1"
metadata:
  name: "sample-pipeline"
spec:
  strategy:
    jenkinsPipelineStrategy:
      jenkinsfile: |-
        node('agent') {
          stage 'build'
          openshiftBuild(buildConfig: 'ruby-sample-build', showBuildLogs: 'true')
          stage 'deploy'
          openshiftDeploy(deploymentConfig: 'frontend')
        }
----

.Reference to Git Repository
[source,yaml]
----
kind: "BuildConfig"
apiVersion: "v1"
metadata:
  name: "sample-pipeline"
spec:
  source:
    git:
      uri: "https://github.com/openshift/ruby-hello-world"
  strategy:
    jenkinsPipelineStrategy:
      jenkinsfilePath: some/repo/dir/filename <1>
----
<1> The optional `jenkinsfilePath` field specifies the name of the file to use, relative to the source `contextDir`. If `contextDir` is omitted, it defaults to the root of the repository. If `jenkinsfilePath` is omitted, it defaults to `jenkinsfile`.

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
// * builds/build-strategies.adoc

:_mod-docs-content-type: PROCEDURE
[id="builds-strategy-pipeline-environment-variables_{context}"]
= Using environment variables for pipeline builds

[IMPORTANT]
====
The Pipeline build strategy is deprecated in {product-title} 4. Equivalent and improved functionality is present in the {product-title} Pipelines based on Tekton.

Jenkins images on {product-title} are fully supported and users should follow Jenkins user documentation for defining their `jenkinsfile` in a job or store it in a Source Control Management system.
====

To make environment variables available to the Pipeline build process, you can add environment variables to the `jenkinsPipelineStrategy` definition of the build configuration.

Once defined, the environment variables will be set as parameters for any Jenkins job associated with the build configuration.

.Procedure

* To define environment variables to be used during build, edit the YAML file:
+
[source,yaml]
----
jenkinsPipelineStrategy:
...
  env:
    - name: "FOO"
      value: "BAR"
----

You can also manage environment variables defined in the build configuration with the `oc set env` command.



//[NOTE]
//====
// This module needs specific instructions and examples.
// This is similar between Docker, S2I, and Custom.
//====

:leveloffset!:

:leveloffset: +3

// Module included in the following assemblies:
// * builds/build-strategies.adoc

[id="builds-strategy-pipeline-mapping-buildconfig-jenkins_{context}"]
= Mapping between BuildConfig environment variables and Jenkins job parameters

When a Jenkins job is created or updated based on changes to a Pipeline strategy build configuration, any environment variables in the build configuration are mapped to Jenkins job parameters definitions, where the default values for the Jenkins job parameters definitions are the current values of the associated environment variables.

After the Jenkins job's initial creation, you can still add additional parameters to the job from the Jenkins console. The parameter names differ from the names of the environment variables in the build configuration. The parameters are honored when builds are started for those Jenkins jobs.

How you start builds for the Jenkins job dictates how the parameters are set.

* If you start with `oc start-build`, the values of the environment variables in the build configuration are the parameters set for the corresponding job instance. Any changes you make to the parameters' default values from the Jenkins console are ignored. The build configuration values take precedence.

* If you start with `oc start-build -e`, the values for the environment variables specified in the `-e` option take precedence.
** If you specify an environment variable not listed in the build configuration, they will be added as a Jenkins job parameter definitions.
** Any changes you make from the Jenkins console to the parameters corresponding to the environment variables are ignored. The build configuration and what you specify with `oc start-build -e` takes precedence.

* If you start the Jenkins job with the Jenkins console, then you can control the setting of the parameters with the Jenkins console as part of starting a build for the job.

[NOTE]
====
It is recommended that you specify in the build configuration all possible environment variables to be associated with job parameters. Doing so reduces disk I/O and improves performance during Jenkins processing.
====

:leveloffset!:

:leveloffset: +2

// Module included in the following assemblies:
// * builds/build-strategies.adoc

:_mod-docs-content-type: PROCEDURE
[id="builds-tutorial-pipeline_{context}"]
= Pipeline build tutorial

[IMPORTANT]
====
The Pipeline build strategy is deprecated in {product-title} 4. Equivalent and improved functionality is present in the {product-title} Pipelines based on Tekton.

Jenkins images on {product-title} are fully supported and users should follow Jenkins user documentation for defining their `jenkinsfile` in a job or store it in a Source Control Management system.
====

This example demonstrates how to create an {product-title} Pipeline that will build, deploy, and verify a `Node.js/MongoDB` application using the `nodejs-mongodb.json` template.

.Procedure

. Create the Jenkins master:
+
[source,terminal]
----
  $ oc project <project_name>
----
+
Select the project that you want to use or create a new project with `oc new-project <project_name>`.
+
[source,terminal]
----
  $ oc new-app jenkins-ephemeral <2>
----
+
If you want to use persistent storage, use `jenkins-persistent` instead.
+
. Create a file named `nodejs-sample-pipeline.yaml` with the following content:
+
[NOTE]
====
This creates a `BuildConfig` object that employs the Jenkins pipeline strategy to build, deploy, and scale the `Node.js/MongoDB` example application.
====
+
[source,yaml]
+
----
kind: "BuildConfig"
apiVersion: "v1"
metadata:
  name: "nodejs-sample-pipeline"
spec:
  strategy:
    jenkinsPipelineStrategy:
      jenkinsfile: <pipeline content from below>
    type: JenkinsPipeline
----
+
. After you create a `BuildConfig` object with a `jenkinsPipelineStrategy`, tell the
pipeline what to do by using an inline `jenkinsfile`:
+
[NOTE]
====
This example does not set up a Git repository for the application.

The following `jenkinsfile` content is written in Groovy using the {product-title} DSL. For this example, include inline content in the `BuildConfig` object using the YAML Literal Style, though including a `jenkinsfile` in your source repository is the preferred method.
====
+
[source,groovy]
----
def templatePath = 'https://raw.githubusercontent.com/openshift/nodejs-ex/master/openshift/templates/nodejs-mongodb.json' <1>
def templateName = 'nodejs-mongodb-example' <2>
pipeline {
  agent {
    node {
      label 'nodejs' <3>
    }
  }
  options {
    timeout(time: 20, unit: 'MINUTES') <4>
  }
  stages {
    stage('preamble') {
        steps {
            script {
                openshift.withCluster() {
                    openshift.withProject() {
                        echo "Using project: ${openshift.project()}"
                    }
                }
            }
        }
    }
    stage('cleanup') {
      steps {
        script {
            openshift.withCluster() {
                openshift.withProject() {
                  openshift.selector("all", [ template : templateName ]).delete() <5>
                  if (openshift.selector("secrets", templateName).exists()) { <6>
                    openshift.selector("secrets", templateName).delete()
                  }
                }
            }
        }
      }
    }
    stage('create') {
      steps {
        script {
            openshift.withCluster() {
                openshift.withProject() {
                  openshift.newApp(templatePath) <7>
                }
            }
        }
      }
    }
    stage('build') {
      steps {
        script {
            openshift.withCluster() {
                openshift.withProject() {
                  def builds = openshift.selector("bc", templateName).related('builds')
                  timeout(5) { <8>
                    builds.untilEach(1) {
                      return (it.object().status.phase == "Complete")
                    }
                  }
                }
            }
        }
      }
    }
    stage('deploy') {
      steps {
        script {
            openshift.withCluster() {
                openshift.withProject() {
                  def rm = openshift.selector("dc", templateName).rollout()
                  timeout(5) { <9>
                    openshift.selector("dc", templateName).related('pods').untilEach(1) {
                      return (it.object().status.phase == "Running")
                    }
                  }
                }
            }
        }
      }
    }
    stage('tag') {
      steps {
        script {
            openshift.withCluster() {
                openshift.withProject() {
                  openshift.tag("${templateName}:latest", "${templateName}-staging:latest") <10>
                }
            }
        }
      }
    }
  }
}
----
<1> Path of the template to use.
<2> Name of the template that will be created.
<3> Spin up a `node.js` agent pod on which to run this build.
<4> Set a timeout of 20 minutes for this pipeline.
<5> Delete everything with this template label.
<6> Delete any secrets with this template label.
<7> Create a new application from the `templatePath`.
<8> Wait up to five minutes for the build to complete.
<9> Wait up to five minutes for the deployment to complete.
<10> If everything else succeeded, tag the `$ {templateName}:latest` image as
`$ {templateName}-staging:latest`. A pipeline build configuration for the staging
environment can watch for the `$ {templateName}-staging:latest` image to change
and then deploy it to the staging environment.
+
[NOTE]
====
The previous example was written using the declarative pipeline style, but the older scripted pipeline style is also supported.
====
+
. Create the Pipeline `BuildConfig` in your {product-title} cluster:
+
[source,terminal]
----
$ oc create -f nodejs-sample-pipeline.yaml
----
+
.. If you do not want to create your own file, you can use the sample from the Origin repository by running:
+
[source,terminal]
----
$ oc create -f https://raw.githubusercontent.com/openshift/origin/master/examples/jenkins/pipeline/nodejs-sample-pipeline.yaml
----
+
. Start the Pipeline:
+
[source,terminal]
----
$ oc start-build nodejs-sample-pipeline
----
+
[NOTE]
====
Alternatively, you can start your pipeline with the {product-title} web console by navigating to the Builds -> Pipeline section and clicking *Start Pipeline*, or by visiting the Jenkins Console, navigating to the Pipeline that you created, and clicking *Build Now*.
====
+
Once the pipeline is started, you should see the following actions performed within your project:
+
* A job instance is created on the Jenkins server.
* An agent pod is launched, if your pipeline requires one.
* The pipeline runs on the agent pod, or the master if no agent is required.
** Any previously created resources with the `template=nodejs-mongodb-example` label will be deleted.
** A new application, and all of its associated resources, will be created from the `nodejs-mongodb-example` template.
** A build will be started using the `nodejs-mongodb-example` `BuildConfig`.
*** The pipeline will wait until the build has completed to trigger the next stage.
** A deployment will be started using the `nodejs-mongodb-example` deployment configuration.
*** The pipeline will wait until the deployment has completed to trigger the next stage.
** If the build and deploy are successful, the `nodejs-mongodb-example:latest` image will be tagged as `nodejs-mongodb-example:stage`.
* The agent pod is deleted, if one was required for the pipeline.
+
[NOTE]
====
The best way to visualize the pipeline execution is by viewing it in the {product-title} web console. You can view your pipelines by logging in to the web console and navigating to Builds -> Pipelines.
====

:leveloffset!:

//include::modules/builds-strategy-force-pull-procedure.adoc[leveloffset=+1]

//include::modules/builds-strategy-docker-force-pull-example.adoc[leveloffset=+2]

//include::modules/builds-strategy-s2i-force-pull-example.adoc[leveloffset=+2]

:leveloffset: +1

// Module included in the following assemblies:
// * builds/build-strategies.adoc

:_mod-docs-content-type: PROCEDURE
[id="builds-strategy-secrets-web-console_{context}"]
= Adding secrets with web console

You can add a secret to your build configuration so that it can access a private repository.

.Procedure

To add a secret to your build configuration so that it can access a private
repository from the {product-title} web console:

. Create a new {product-title} project.

. Create a secret that contains credentials for accessing a private source code
repository.

. Create a build configuration.

. On the build configuration editor page or in the `create app from builder image` page of the web console, set the *Source Secret*.

. Click *Save*.


//[NOTE]
//====
// This module needs specific instructions and examples.
// This is applicable for Docker, S2I, and Custom.
//====

:leveloffset!:

:leveloffset: +1

// Module included in the following assemblies:
//
//* builds/running-entitled-builds.adoc

:_mod-docs-content-type: PROCEDURE
[id="builds-strategy-enable-pulling-pushing_{context}"]
= Enabling pulling and pushing

You can enable pulling to a private registry by setting the pull secret and pushing by setting the push secret in the build configuration.

.Procedure

To enable pulling to a private registry:

* Set the pull secret in the build configuration.

To enable pushing:

 * Set the push secret in the build configuration.

////
[NOTE]
====
This module needs specific instructions and examples. And needs to be used for Docker and S2I.
====
////

:leveloffset!:

//# includes=_attributes/common-attributes,modules/builds-strategy-docker-build,modules/builds-strategy-docker-from-image,modules/builds-strategy-dockerfile-path,modules/builds-strategy-docker-environment-variables,modules/builds-strategy-docker-build-arguments,modules/builds-strategy-docker-squash-layers,modules/builds-using-build-volumes,modules/builds-strategy-s2i-build,modules/builds-strategy-s2i-incremental-builds,modules/builds-strategy-s2i-override-builder-image-scripts,modules/builds-strategy-s2i-environment-variables,modules/builds-strategy-s2i-environment-files,modules/builds-strategy-s2i-buildconfig-environment,modules/builds-strategy-s2i-ignore-source-files,modules/images-create-s2i,modules/images-create-s2i-build,modules/images-create-s2i-scripts,modules/builds-strategy-custom-build,modules/builds-strategy-custom-from-image,modules/builds-strategy-custom-secrets,modules/builds-strategy-custom-environment-variables,modules/images-custom,modules/builds-strategy-pipeline-build,modules/builds-understanding-openshift-pipeline,modules/builds-strategy-pipeline-providing-jenkinsfile,modules/builds-strategy-pipeline-environment-variables,modules/builds-strategy-pipeline-mapping-buildconfig-jenkins,modules/builds-tutorial-pipeline,modules/builds-strategy-secrets-web-console,modules/builds-strategy-enable-pulling-pushing
