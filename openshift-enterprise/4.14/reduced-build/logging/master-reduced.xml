<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE book [
<!ENTITY % sgml.features "IGNORE">
<!ENTITY % xml.features "INCLUDE">
<!ENTITY % DOCBOOK_ENTS PUBLIC "-//OASIS//ENTITIES DocBook Character Entities V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/dbcentx.mod">
%DOCBOOK_ENTS;
]>
<?asciidoc-toc?>
<?asciidoc-numbered?>
<book xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0">
<info>
<title>Logging</title>
<date>2024-02-23</date>
<title>Logging</title>
<productname>OpenShift Container Platform</productname>
<productnumber>4.14</productnumber>
<subtitle>Enter a short description here.</subtitle>
<abstract>
    <para>A short overview and summary of the book's subject and purpose, traditionally no more than one paragraph long.</para>
</abstract>
<authorgroup>
    <orgname>Red Hat OpenShift Documentation Team</orgname>
</authorgroup>
<xi:include href="Common_Content/Legal_Notice.xml" xmlns:xi="http://www.w3.org/2001/XInclude" />
</info>
<chapter xml:id="_release-notes">
<title>Release notes</title>
<section xml:id="logging-5-8-release-notes">
<title>Logging 5.8</title>

<note>
<simpara>Logging is provided as an installable component, with a distinct release cycle from the core OpenShift Container Platform. The <link xlink:href="https://access.redhat.com/support/policy/updates/openshift_operators#platform-agnostic">Red Hat OpenShift Container Platform Life Cycle Policy</link> outlines release compatibility.</simpara>
</note>
<note>
<simpara>The <emphasis role="strong">stable</emphasis> channel only provides updates to the most recent release of logging. To continue receiving updates for prior releases, you must change your subscription channel to <emphasis role="strong">stable-x.y</emphasis>, where <literal>x.y</literal> represents the major and minor version of logging you have installed. For example, <emphasis role="strong">stable-5.7</emphasis>.</simpara>
</note>
<section xml:id="logging-release-notes-5-8-2">
<title>Logging 5.8.2</title>
<simpara>This release includes <link xlink:href="https://access.redhat.com/errata/RHSA-2024:0271">OpenShift Logging Bug Fix Release 5.8.2</link>.</simpara>
<section xml:id="logging-release-notes-5-8-2-bug-fixes">
<title>Bug fixes</title>
<itemizedlist>
<listitem>
<simpara>Before this update, the LokiStack ruler pods would not format the IPv6 pod IP in HTTP URLs used for cross pod communication, causing querying rules and alerts through the Prometheus-compatible API to fail. With this update, the LokiStack ruler pods encapsulate the IPv6 pod IP in square brackets, resolving the issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4890">LOG-4890</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the developer console logs did not account for the current namespace, resulting in query rejection for users without cluster-wide log access. With this update, namespace inclusion has been corrected, resolving the issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4947">LOG-4947</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the logging view plugin of the OpenShift Container Platform web console did not allow for custom node placement and tolerations. With this update, defining custom node placements and tolerations has been added to the logging view plugin of the OpenShift Container Platform web console. (<link xlink:href="https://issues.redhat.com/browse/LOG-4912">LOG-4912</link>)</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-release-notes-5-8-2-CVEs">
<title>CVEs</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-44638">CVE-2022-44638</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-1192">CVE-2023-1192</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-5345">CVE-2023-5345</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-20569">CVE-2023-20569</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-26159">CVE-2023-26159</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-39615">CVE-2023-39615</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-45871">CVE-2023-45871</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="logging-release-notes-5-8-1_logging-5-8-release-notes">
<title>Logging 5.8.1</title>
<simpara>This release includes <link xlink:href="https://access.redhat.com/errata/RHSA-2023:7720">OpenShift Logging Bug Fix Release 5.8.1</link> and <link xlink:href="https://access.redhat.com/errata/RHBA-2023:7717">OpenShift Logging Bug Fix Release 5.8.1 Kibana</link>.</simpara>
<section xml:id="logging-release-notes-5-8-1-enhancements">
<title>Enhancements</title>
<section xml:id="logging-release-notes-5-8-1-log-collection">
<title>Log Collection</title>
<itemizedlist>
<listitem>
<simpara>With this update, while configuring Vector as a collector, you can add logic to the Red Hat OpenShift Logging Operator to use a token specified in the secret in place of the token associated with the service account. (<link xlink:href="https://issues.redhat.com/browse/LOG-4780">LOG-4780</link>)</simpara>
</listitem>
<listitem>
<simpara>With this update, the <emphasis role="strong">BoltDB Shipper</emphasis> Loki dashboards are now renamed to <emphasis role="strong">Index</emphasis> dashboards. (<link xlink:href="https://issues.redhat.com/browse/LOG-4828">LOG-4828</link>)</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="logging-release-notes-5-8-1-bug-fixes">
<title>Bug fixes</title>
<itemizedlist>
<listitem>
<simpara>Before this update, the <literal>ClusterLogForwarder</literal> created empty indices after enabling the parsing of JSON logs, even when the rollover conditions were not met. With this update, the <literal>ClusterLogForwarder</literal> skips the rollover when the <literal>write-index</literal> is empty. (<link xlink:href="https://issues.redhat.com/browse/LOG-4452">LOG-4452</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the Vector set the <literal>default</literal> log level incorrectly. With this update, the correct log level is set by improving the enhancement of regular expression, or <literal>regexp</literal>, for log level detection. (<link xlink:href="https://issues.redhat.com/browse/LOG-4480">LOG-4480</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, during the process of creating index patterns, the default alias was missing from the initial index in each log output. As a result, Kibana users were unable to create index patterns by using OpenShift Elasticsearch Operator. This update adds the missing aliases to OpenShift Elasticsearch Operator, resolving the issue. Kibana users can now create index patterns that include the <literal>{app,infra,audit}-000001</literal> indexes. (<link xlink:href="https://issues.redhat.com/browse/LOG-4683">LOG-4683</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, Fluentd collector pods were in a <literal>CrashLoopBackOff</literal> state due to binding of the Prometheus server on IPv6 clusters. With this update, the collectors work properly on IPv6 clusters. (<link xlink:href="https://issues.redhat.com/browse/LOG-4706">LOG-4706</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the Red Hat OpenShift Logging Operator would undergo numerous reconciliations whenever there was a change in the <literal>ClusterLogForwarder</literal>. With this update, the Red Hat OpenShift Logging Operator disregards the status changes in the collector daemonsets that triggered the reconciliations. (<link xlink:href="https://issues.redhat.com/browse/LOG-4741">LOG-4741</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the Vector log collector pods were stuck in the <literal>CrashLoopBackOff</literal> state on IBM Power machines. With this update, the Vector log collector pods start successfully on IBM Power architecture machines. (<link xlink:href="https://issues.redhat.com/browse/LOG-4768">LOG-4768</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, forwarding with a legacy forwarder to an internal LokiStack would produce SSL certificate errors using Fluentd collector pods. With this update, the log collector service account is used by default for authentication, using the associated token and <literal>ca.crt</literal>. (<link xlink:href="https://issues.redhat.com/browse/LOG-4791">LOG-4791</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, forwarding with a legacy forwarder to an internal LokiStack would produce SSL certificate errors using Vector collector pods. With this update, the log collector service account is used by default for authentication and also using the associated token and <literal>ca.crt</literal>. (<link xlink:href="https://issues.redhat.com/browse/LOG-4852">LOG-4852</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this fix, IPv6 addresses would not be parsed correctly after evaluating a host or multiple hosts for placeholders. With this update, IPv6 addresses are correctly parsed. (<link xlink:href="https://issues.redhat.com/browse/LOG-4811">LOG-4811</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, it was necessary to create a <literal>ClusterRoleBinding</literal> to collect audit permissions for HTTP receiver inputs. With this update, it is not necessary to create the <literal>ClusterRoleBinding</literal> because the endpoint already depends upon the cluster certificate authority. (<link xlink:href="https://issues.redhat.com/browse/LOG-4815">LOG-4815</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the Loki Operator did not mount a custom CA bundle to the ruler pods. As a result, during the process to evaluate alerting or recording rules, object storage access failed. With this update, the Loki Operator mounts the custom CA bundle to all ruler pods. The ruler pods can download logs from object storage to evaluate alerting or recording rules. (<link xlink:href="https://issues.redhat.com/browse/LOG-4836">LOG-4836</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, while removing the <literal>inputs.receiver</literal> section in the <literal>ClusterLogForwarder</literal>, the HTTP input services and its associated secrets were not deleted. With this update, the HTTP input resources are deleted when not needed. (<link xlink:href="https://issues.redhat.com/browse/LOG-4612">LOG-4612</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the <literal>ClusterLogForwarder</literal> indicated validation errors in the status, but the outputs and the pipeline status did not accurately reflect the specific issues. With this update, the pipeline status displays the validation failure reasons correctly in case of misconfigured outputs, inputs, or filters. (<link xlink:href="https://issues.redhat.com/browse/LOG-4821">LOG-4821</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, changing a <literal>LogQL</literal> query that used controls such as time range or severity changed the label matcher operator defining it like a regular expression. With this update, regular expression operators remain unchanged when updating the query. (<link xlink:href="https://issues.redhat.com/browse/LOG-4841">LOG-4841</link>)</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-release-notes-5-8-1-CVEs">
<title>CVEs</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2007-4559">CVE-2007-4559</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2021-3468">CVE-2021-3468</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2021-3502">CVE-2021-3502</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2021-3826">CVE-2021-3826</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2021-43618">CVE-2021-43618</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-3523">CVE-2022-3523</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-3565">CVE-2022-3565</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-3594">CVE-2022-3594</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-4285">CVE-2022-4285</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-38457">CVE-2022-38457</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-40133">CVE-2022-40133</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-40982">CVE-2022-40982</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-41862">CVE-2022-41862</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-42895">CVE-2022-42895</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-0597">CVE-2023-0597</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-1073">CVE-2023-1073</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-1074">CVE-2023-1074</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-1075">CVE-2023-1075</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-1076">CVE-2023-1076</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-1079">CVE-2023-1079</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-1206">CVE-2023-1206</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-1249">CVE-2023-1249</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-1252">CVE-2023-1252</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-1652">CVE-2023-1652</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-1855">CVE-2023-1855</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-1981">CVE-2023-1981</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-1989">CVE-2023-1989</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-2731">CVE-2023-2731</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-3138">CVE-2023-3138</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-3141">CVE-2023-3141</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-3161">CVE-2023-3161</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-3212">CVE-2023-3212</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-3268">CVE-2023-3268</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-3316">CVE-2023-3316</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-3358">CVE-2023-3358</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-3576">CVE-2023-3576</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-3609">CVE-2023-3609</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-3772">CVE-2023-3772</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-3773">CVE-2023-3773</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-4016">CVE-2023-4016</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-4128">CVE-2023-4128</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-4155">CVE-2023-4155</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-4194">CVE-2023-4194</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-4206">CVE-2023-4206</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-4207">CVE-2023-4207</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-4208">CVE-2023-4208</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-4273">CVE-2023-4273</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-4641">CVE-2023-4641</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-22745">CVE-2023-22745</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-26545">CVE-2023-26545</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-26965">CVE-2023-26965</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-26966">CVE-2023-26966</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-27522">CVE-2023-27522</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-29491">CVE-2023-29491</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-29499">CVE-2023-29499</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-30456">CVE-2023-30456</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-31486">CVE-2023-31486</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-32324">CVE-2023-32324</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-32573">CVE-2023-32573</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-32611">CVE-2023-32611</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-32665">CVE-2023-32665</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-33203">CVE-2023-33203</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-33285">CVE-2023-33285</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-33951">CVE-2023-33951</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-33952">CVE-2023-33952</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-34241">CVE-2023-34241</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-34410">CVE-2023-34410</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-35825">CVE-2023-35825</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-36054">CVE-2023-36054</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-37369">CVE-2023-37369</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-38197">CVE-2023-38197</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-38545">CVE-2023-38545</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-38546">CVE-2023-38546</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-39191">CVE-2023-39191</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-39975">CVE-2023-39975</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-44487">CVE-2023-44487</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="logging-release-notes-5-8-0_logging-5-8-release-notes">
<title>Logging 5.8.0</title>
<simpara>This release includes <link xlink:href="https://access.redhat.com/errata/RHBA-2023:6139">OpenShift Logging Bug Fix Release 5.8.0</link> and <link xlink:href="https://access.redhat.com/errata/RHBA-2023:6134">OpenShift Logging Bug Fix Release 5.8.0 Kibana</link>.</simpara>
<section xml:id="logging-release-notes-5-8-0-deprecation-notice">
<title>Deprecation notice</title>
<simpara>In Logging 5.8, Elasticsearch, Fluentd, and Kibana are deprecated and are planned to be removed in Logging 6.0, which is expected to be shipped alongside a future release of OpenShift Container Platform. Red Hat will provide critical and above CVE bug fixes and support for these components during the current release lifecycle, but these components will no longer receive feature enhancements. The Vector-based collector provided by the Red Hat OpenShift Logging Operator and LokiStack provided by the Loki Operator are the preferred Operators for log collection and storage. We encourage all users to adopt the Vector and Loki log stack, as this will be the stack that will be enhanced going forward.</simpara>
</section>
<section xml:id="logging-release-notes-5-8-0-enhancements">
<title>Enhancements</title>
<section xml:id="logging-release-notes-5-8-0-log-collection">
<title>Log Collection</title>
<itemizedlist>
<listitem>
<simpara>With this update, the LogFileMetricExporter is no longer deployed with the collector by default. You must manually create a <literal>LogFileMetricExporter</literal> custom resource (CR) to generate metrics from the logs produced by running containers. If you do not create the <literal>LogFileMetricExporter</literal> CR, you may see a <emphasis role="strong">No datapoints found</emphasis> message in the OpenShift Container Platform web console dashboard for <emphasis role="strong">Produced Logs</emphasis>. (<link xlink:href="https://issues.redhat.com/browse/LOG-3819">LOG-3819</link>)</simpara>
</listitem>
<listitem>
<simpara>With this update, you can deploy multiple, isolated, and RBAC-protected <literal>ClusterLogForwarder</literal> custom resource (CR) instances in any namespace. This allows independent groups to forward desired logs to any destination while isolating their configuration from other collector deployments. (<link xlink:href="https://issues.redhat.com/browse/LOG-1343">LOG-1343</link>)</simpara>
<important>
<simpara>In order to support multi-cluster log forwarding in additional namespaces other than the <literal>openshift-logging</literal> namespace, you must update the Red Hat OpenShift Logging Operator to watch all namespaces. This functionality is supported by default in new Red Hat OpenShift Logging Operator version 5.8 installations.</simpara>
</important>
</listitem>
<listitem>
<simpara>With this update, you can use the flow control or rate limiting mechanism to limit the volume of log data that can be collected or forwarded by dropping excess log records. The input limits prevent poorly-performing containers from overloading the Logging and the output limits put a ceiling on the rate of logs shipped to a given data store. (<link xlink:href="https://issues.redhat.com/browse/LOG-884">LOG-884</link>)</simpara>
</listitem>
<listitem>
<simpara>With this update, you can configure the log collector to look for HTTP connections and receive logs as an HTTP server, also known as a webhook. (<link xlink:href="https://issues.redhat.com/browse/LOG-4562">LOG-4562</link>)</simpara>
</listitem>
<listitem>
<simpara>With this update, you can configure audit polices to control which Kubernetes and OpenShift API server events are forwarded by the log collector. (<link xlink:href="https://issues.redhat.com/browse/LOG-3982">LOG-3982</link>)</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-release-notes-5-8-0-log-storage">
<title>Log Storage</title>
<itemizedlist>
<listitem>
<simpara>With this update, LokiStack administrators can have more fine-grained control over who can access which logs by granting access to logs on a namespace basis. (<link xlink:href="https://issues.redhat.com/browse/LOG-3841">LOG-3841</link>)</simpara>
</listitem>
<listitem>
<simpara>With this update, the Loki Operator introduces <literal>PodDisruptionBudget</literal> configuration on LokiStack deployments to ensure normal operations during OpenShift Container Platform cluster restarts by keeping ingestion and the query path available. (<link xlink:href="https://issues.redhat.com/browse/LOG-3839">LOG-3839</link>)</simpara>
</listitem>
<listitem>
<simpara>With this update, the reliability of existing LokiStack installations are seamlessly improved by applying a set of default Affinity and Anti-Affinity policies.
(<link xlink:href="https://issues.redhat.com/browse/LOG-3840">LOG-3840</link>)</simpara>
</listitem>
<listitem>
<simpara>With this update, you can manage zone-aware data replication as an administrator in LokiStack, in order to enhance reliability in the event of a zone failure. (<link xlink:href="https://issues.redhat.com/browse/LOG-3266">LOG-3266</link>)</simpara>
</listitem>
<listitem>
<simpara>With this update, a new supported small-scale LokiStack size of 1x.extra-small is introduced for OpenShift Container Platform clusters hosting a few workloads and smaller ingestion volumes (up to 100GB/day). (<link xlink:href="https://issues.redhat.com/browse/LOG-4329">LOG-4329</link>)</simpara>
</listitem>
<listitem>
<simpara>With this update, the LokiStack administrator has access to an official Loki dashboard to inspect the storage performance and the health of each component. (<link xlink:href="https://issues.redhat.com/browse/LOG-4327">LOG-4327</link>)</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-release-notes-5-8-0-log-console">
<title>Log Console</title>
<itemizedlist>
<listitem>
<simpara>With this update, you can enable the Logging Console Plugin when Elasticsearch is the default Log Store. (<link xlink:href="https://issues.redhat.com/browse/LOG-3856">LOG-3856</link>)</simpara>
</listitem>
<listitem>
<simpara>With this update, OpenShift Container Platform application owners can receive notifications for application log-based alerts on the OpenShift Container Platform web console <emphasis role="strong">Developer</emphasis> perspective for OpenShift Container Platform version 4.14 and later. (<link xlink:href="https://issues.redhat.com/browse/LOG-3548">LOG-3548</link>)</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="logging-release-notes-5-8-0-known-issues">
<title>Known Issues</title>
<itemizedlist>
<listitem>
<simpara>Currently, there is a flaw in handling multiplexed streams in the HTTP/2 protocol, where you can repeatedly make a request for a new multiplex stream and immediately send an <literal>RST_STREAM</literal> frame to cancel it. This created extra work for the server set up and tore down the streams, resulting in a denial of service due to server resource consumption. There is currently no workaround for this issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4609">LOG-4609</link>)</simpara>
</listitem>
<listitem>
<simpara>Currently, when using  FluentD as the collector, the collector pod cannot start on the OpenShift Container Platform IPv6-enabled cluster. The pod logs produce the <literal>fluentd pod [error]: unexpected error error_class=SocketError error="getaddrinfo: Name or service not known</literal> error. There is currently no workaround for this issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4706">LOG-4706</link>)</simpara>
</listitem>
<listitem>
<simpara>Currently, the log alert is not available on an IPv6-enabled cluster. There is currently no workaround for this issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4709">LOG-4709</link>)</simpara>
</listitem>
<listitem>
<simpara>Currently, <literal>must-gather</literal> cannot gather any logs on a FIPS-enabled cluster, because the required OpenSSL library is not available in the <literal>cluster-logging-rhel9-operator</literal>. There is currently no workaround for this issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4403">LOG-4403</link>)</simpara>
</listitem>
<listitem>
<simpara>Currently, when deploying the logging version 5.8 on a FIPS-enabled cluster, the collector pods cannot start and are stuck in <literal>CrashLoopBackOff</literal> status, while using FluentD as a collector. There is currently no workaround for this issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-3933">LOG-3933</link>)</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-release-notes-5-8-0-CVEs">
<title>CVEs</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-40217">CVE-2023-40217</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="logging-5-7-release-notes">
<title>Logging 5.7</title>

<note>
<simpara>Logging is provided as an installable component, with a distinct release cycle from the core OpenShift Container Platform. The <link xlink:href="https://access.redhat.com/support/policy/updates/openshift_operators#platform-agnostic">Red Hat OpenShift Container Platform Life Cycle Policy</link> outlines release compatibility.</simpara>
</note>
<note>
<simpara>The <emphasis role="strong">stable</emphasis> channel only provides updates to the most recent release of logging. To continue receiving updates for prior releases, you must change your subscription channel to <emphasis role="strong">stable-x.y</emphasis>, where <literal>x.y</literal> represents the major and minor version of logging you have installed. For example, <emphasis role="strong">stable-5.7</emphasis>.</simpara>
</note>
<section xml:id="logging-release-notes-5-7-8_logging-5-7-release-notes">
<title>Logging 5.7.8</title>
<simpara>This release includes <link xlink:href="https://access.redhat.com/errata/RHBA-2023:6730">OpenShift Logging Bug Fix Release 5.7.8</link>.</simpara>
<section xml:id="logging-release-notes-5-7-8-bug-fixes">
<title>Bug fixes</title>
<itemizedlist>
<listitem>
<simpara>Before this update, there was a potential conflict when the same name was used for the <literal>outputRefs</literal> and <literal>inputRefs</literal> parameters in the <literal>ClusterLogForwarder</literal> custom resource (CR). As a result, the collector pods entered in a <literal>CrashLoopBackOff</literal> status. With this update, the output labels contain the <literal>OUTPUT_</literal> prefix to ensure a distinction between output labels and pipeline names. (<link xlink:href="https://issues.redhat.com/browse/LOG-4383">LOG-4383</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, while configuring the JSON log parser, if you did not set the <literal>structuredTypeKey</literal> or <literal>structuredTypeName</literal> parameters for the Cluster Logging Operator, no alert would display about an invalid configuration. With this update, the Cluster Logging Operator informs you about the configuration issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4441">LOG-4441</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, if the <literal>hecToken</literal> key was missing or incorrect in the secret specified for a Splunk output, the validation failed because the Vector forwarded logs to Splunk without a token. With this update, if the <literal>hecToken</literal> key is missing or incorrect, the validation fails with the <literal>A non-empty hecToken entry is required</literal> error message. (<link xlink:href="https://issues.redhat.com/browse/LOG-4580">LOG-4580</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, selecting a date from the <literal>Custom time range</literal> for logs caused an error in the web console. With this update, you can select a date from the time range model in the web console successfully. (<link xlink:href="https://issues.redhat.com/browse/LOG-4684">LOG-4684</link>)</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-release-notes-5-7-8-CVEs">
<title>CVEs</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-40217">CVE-2023-40217</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-44487">CVE-2023-44487</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="cluster-logging-release-notes-5-7-7_logging-5-7-release-notes">
<title>Logging 5.7.7</title>
<simpara>This release includes <link xlink:href="https://access.redhat.com/errata/RHSA-2023:5530">OpenShift Logging Bug Fix Release 5.7.7</link>.</simpara>
<section xml:id="openshift-logging-5-7-7-bug-fixes_logging-5-7-release-notes">
<title>Bug fixes</title>
<itemizedlist>
<listitem>
<simpara>Before this update, FluentD normalized the logs emitted by the EventRouter differently from Vector. With this update, the Vector produces log records in a consistent format. (<link xlink:href="https://issues.redhat.com/browse/LOG-4178">LOG-4178</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, there was an error in the query used for the <emphasis role="strong">FluentD Buffer Availability</emphasis> graph in the metrics dashboard created by the Cluster Logging Operator as it showed the minimum buffer usage. With this update, the graph shows the maximum buffer usage and is now renamed to <emphasis role="strong">FluentD Buffer Usage</emphasis>. (<link xlink:href="https://issues.redhat.com/browse/LOG-4555">LOG-4555</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, deploying a LokiStack on IPv6-only or dual-stack OpenShift Container Platform clusters caused the LokiStack memberlist registration to fail. As a result, the distributor pods went into a crash loop. With this update, an administrator can enable IPv6 by setting the <literal>lokistack.spec.hashRing.memberlist.enableIPv6:</literal> value to <literal>true</literal>, which resolves the issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4569">LOG-4569</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the log collector relied on the default configuration settings for reading the container log lines. As a result, the log collector did not read the rotated files efficiently. With this update, there is an increase in the number of bytes read, which allows the log collector to efficiently process rotated files. (<link xlink:href="https://issues.redhat.com/browse/LOG-4575">LOG-4575</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the unused metrics in the Event Router caused the container to fail due to excessive memory usage. With this update, there is reduction in the memory usage of the Event Router by removing the unused metrics. (<link xlink:href="https://issues.redhat.com/browse/LOG-4686">LOG-4686</link>)</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="openshift-logging-5-7-7-CVEs_logging-5-7-release-notes">
<title>CVEs</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-0800">CVE-2023-0800</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-0801">CVE-2023-0801</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-0802">CVE-2023-0802</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-0803">CVE-2023-0803</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-0804">CVE-2023-0804</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-2002">CVE-2023-2002</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-3090">CVE-2023-3090</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-3390">CVE-2023-3390</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-3776">CVE-2023-3776</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-4004">CVE-2023-4004</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-4527">CVE-2023-4527</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-4806">CVE-2023-4806</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-4813">CVE-2023-4813</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-4863">CVE-2023-4863</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-4911">CVE-2023-4911</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-5129">CVE-2023-5129</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-20593">CVE-2023-20593</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-29491">CVE-2023-29491</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-30630">CVE-2023-30630</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-35001">CVE-2023-35001</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-35788">CVE-2023-35788</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="cluster-logging-release-notes-5-7-6_logging-5-7-release-notes">
<title>Logging 5.7.6</title>
<simpara>This release includes <link xlink:href="https://access.redhat.com/errata/RHSA-2023:4933">OpenShift Logging Bug Fix Release 5.7.6</link>.</simpara>
<section xml:id="openshift-logging-5-7-6-bug-fixes_logging-5-7-release-notes">
<title>Bug fixes</title>
<itemizedlist>
<listitem>
<simpara>Before this update, the collector relied on the default configuration settings for reading the container log lines. As a result, the collector did not read the rotated files efficiently. With this update, there is an increase in the number of bytes read, which allows the collector to efficiently process rotated files. (<link xlink:href="https://issues.redhat.com/browse/LOG-4501">LOG-4501</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, when users pasted a URL with predefined filters, some filters did not reflect. With this update, the UI reflects all the filters in the URL. (<link xlink:href="https://issues.redhat.com/browse/LOG-4459">LOG-4459</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, forwarding to Loki using custom labels generated an error when switching from Fluentd to Vector. With this update, the Vector configuration sanitizes labels in the same way as Fluentd to ensure the collector starts and correctly processes labels. (<link xlink:href="https://issues.redhat.com/browse/LOG-4460">LOG-4460</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the Observability Logs console search field did not accept special characters that it should escape. With this update, it is escaping special characters properly in the query. (<link xlink:href="https://issues.redhat.com/browse/LOG-4456">LOG-4456</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the following warning message appeared while sending logs to Splunk: <literal>Timestamp was not found.</literal> With this update, the change overrides the name of the log field used to retrieve the Timestamp and sends it to Splunk without warning. (<link xlink:href="https://issues.redhat.com/browse/LOG-4413">LOG-4413</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the CPU and memory usage of Vector was increasing over time. With this update, the Vector configuration now contains the <literal>expire_metrics_secs=60</literal> setting to limit the lifetime of the metrics and cap the associated CPU usage and memory footprint. (<link xlink:href="https://issues.redhat.com/browse/LOG-4171">LOG-4171</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the LokiStack gateway cached authorized requests very broadly. As a result, this caused wrong authorization results. With this update, LokiStack gateway caches on a more fine-grained basis which resolves this issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4393">LOG-4393</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the Fluentd runtime image included builder tools which were unnecessary at runtime. With this update, the builder tools are removed, resolving the issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4467">LOG-4467</link>)</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="openshift-logging-5-7-6-CVEs_logging-5-7-release-notes">
<title>CVEs</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-3899">CVE-2023-3899</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-4456">CVE-2023-4456</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-32360">CVE-2023-32360</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-34969">CVE-2023-34969</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="cluster-logging-release-notes-5-7-4_logging-5-7-release-notes">
<title>Logging 5.7.4</title>
<simpara>This release includes <link xlink:href="https://access.redhat.com/errata/RHSA-2023:4341">OpenShift Logging Bug Fix Release 5.7.4</link>.</simpara>
<section xml:id="openshift-logging-5-7-4-bug-fixes_logging-5-7-release-notes">
<title>Bug fixes</title>
<itemizedlist>
<listitem>
<simpara>Before this update, when forwarding logs to CloudWatch, a <literal>namespaceUUID</literal> value was not appended to the <literal>logGroupName</literal> field. With this update, the <literal>namespaceUUID</literal> value is included, so a <literal>logGroupName</literal> in CloudWatch appears as <literal>logGroupName: vectorcw.b443fb9e-bd4c-4b6a-b9d3-c0097f9ed286</literal>. (<link xlink:href="https://issues.redhat.com/browse/LOG-2701">LOG-2701</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, when forwarding logs over HTTP to an off-cluster destination, the Vector collector was unable to authenticate to the cluster-wide HTTP proxy even though correct credentials were provided in the proxy URL. With this update, the Vector log collector can now authenticate to the cluster-wide HTTP proxy. (<link xlink:href="https://issues.redhat.com/browse/LOG-3381">LOG-3381</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the Operator would fail if the Fluentd collector was configured with Splunk as an output, due to this configuration being unsupported. With this update, configuration validation rejects unsupported outputs, resolving the issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4237">LOG-4237</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, when the Vector collector was updated an <literal>enabled = true</literal> value in the TLS configuration for AWS Cloudwatch logs and the GCP Stackdriver caused a configuration error. With this update, <literal>enabled = true</literal> value will be removed for these outputs, resolving the issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4242">LOG-4242</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the Vector collector occasionally panicked with the following error message in its log:
<literal>thread 'vector-worker' panicked at 'all branches are disabled and there is no else branch', src/kubernetes/reflector.rs:26:9</literal>. With this update, the error has been resolved. (<link xlink:href="https://issues.redhat.com/browse/LOG-4275">LOG-4275</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, an issue in the Loki Operator caused the <literal>alert-manager</literal> configuration for the application tenant to disappear if the Operator was configured with additional options for that tenant. With this update, the generated Loki configuration now contains both the custom and the auto-generated configuration. (<link xlink:href="https://issues.redhat.com/browse/LOG-4361">LOG-4361</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, when multiple roles were used to authenticate using STS with AWS Cloudwatch forwarding, a recent update caused the credentials to be non-unique. With this update, multiple combinations of STS roles and static credentials can once again be used to authenticate with AWS Cloudwatch. (<link xlink:href="https://issues.redhat.com/browse/LOG-4368">LOG-4368</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, Loki filtered label values for active streams but did not remove duplicates, making Grafana&#8217;s Label Browser unusable. With this update, Loki filters out duplicate label values for active streams, resolving the issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4389">LOG-4389</link>)</simpara>
</listitem>
<listitem>
<simpara>Pipelines with no <literal>name</literal> field specified in the <literal>ClusterLogForwarder</literal> custom resource (CR) stopped working after upgrading to OpenShift Logging 5.7. With this update, the error has been resolved. (<link xlink:href="https://issues.redhat.com/browse/LOG-4120">LOG-4120</link>)</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="openshift-logging-5-7-4-CVEs_logging-5-7-release-notes">
<title>CVEs</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-25883">CVE-2022-25883</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-22796">CVE-2023-22796</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="cluster-logging-release-notes-5-7-3_logging-5-7-release-notes">
<title>Logging 5.7.3</title>
<simpara>This release includes <link xlink:href="https://access.redhat.com/errata/RHSA-2023:3998">OpenShift Logging Bug Fix Release 5.7.3</link>.</simpara>
<section xml:id="openshift-logging-5-7-3-bug-fixes_logging-5-7-release-notes">
<title>Bug fixes</title>
<itemizedlist>
<listitem>
<simpara>Before this update, when viewing logs within the OpenShift Container Platform web console, cached files caused the data to not refresh. With this update the bootstrap files are not cached, resolving the issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4100">LOG-4100</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the Loki Operator reset errors in a way that made identifying configuration problems difficult to troubleshoot. With this update, errors persist until the configuration error is resolved. (<link xlink:href="https://issues.redhat.com/browse/LOG-4156">LOG-4156</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the LokiStack ruler did not restart after changes were made to the <literal>RulerConfig</literal> custom resource (CR). With this update, the Loki Operator restarts the ruler pods after the <literal>RulerConfig</literal> CR is updated. (<link xlink:href="https://issues.redhat.com/browse/LOG-4161">LOG-4161</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the vector collector terminated unexpectedly when input match label values contained a <literal>/</literal> character within the <literal>ClusterLogForwarder</literal>. This update resolves the issue by quoting the match label, enabling the collector to start and collect logs. (<link xlink:href="https://issues.redhat.com/browse/LOG-4176">LOG-4176</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the Loki Operator terminated unexpectedly when a <literal>LokiStack</literal> CR defined tenant limits, but not global limits. With this update, the Loki Operator can process <literal>LokiStack</literal> CRs without global limits, resolving the issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4198">LOG-4198</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, Fluentd did not send logs to an Elasticsearch cluster when the private key provided was passphrase-protected. With this update, Fluentd properly handles passphrase-protected private keys when establishing a connection with Elasticsearch. (<link xlink:href="https://issues.redhat.com/browse/LOG-4258">LOG-4258</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, clusters with more than 8,000 namespaces caused Elasticsearch to reject queries because the list of namespaces was larger than the <literal>http.max_header_size</literal> setting. With this update, the default value for header size has been increased, resolving the issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4277">LOG-4277</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, label values containing a <literal>/</literal> character within the <literal>ClusterLogForwarder</literal> CR would cause the collector to terminate unexpectedly.
With this update, slashes are replaced with underscores, resolving the issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4095">LOG-4095</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the Cluster Logging Operator terminated unexpectedly when set to an unmanaged state. With this update, a check to ensure that the <literal>ClusterLogging</literal> resource is in the correct Management state before initiating the reconciliation of the <literal>ClusterLogForwarder</literal> CR, resolving the issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4177">LOG-4177</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, when viewing logs within the OpenShift Container Platform web console, selecting a time range by dragging over the histogram didn&#8217;t work on the aggregated logs view inside the pod detail. With this update, the time range can be selected by dragging on the histogram in this view. (<link xlink:href="https://issues.redhat.com/browse/LOG-4108">LOG-4108</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, when viewing logs within the OpenShift Container Platform web console, queries longer than 30 seconds timed out. With this update, the timeout value can be configured in the configmap/logging-view-plugin. (<link xlink:href="https://issues.redhat.com/browse/LOG-3498">LOG-3498</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, when viewing logs within the OpenShift Container Platform web console, clicking the <emphasis role="strong">more data available</emphasis> option loaded more log entries only the first time it was clicked. With this update, more entries are loaded with each click. (<link xlink:href="https://issues.redhat.com/browse/OU-188">OU-188</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, when viewing logs within the OpenShift Container Platform web console, clicking the <emphasis role="strong">streaming</emphasis> option would only display the <emphasis role="strong">streaming logs</emphasis> message without showing the actual logs. With this update, both the message and the log stream are displayed correctly. (<link xlink:href="https://issues.redhat.com/browse/OU-166">OU-166</link>)</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="openshift-logging-5-7-3-CVEs_logging-5-7-release-notes">
<title>CVEs</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2020-24736">CVE-2020-24736</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-48281">CVE-2022-48281</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-1667">CVE-2023-1667</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-2283">CVE-2023-2283</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-24329">CVE-2023-24329</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-26115">CVE-2023-26115</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-26136">CVE-2023-26136</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-26604">CVE-2023-26604</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-28466">CVE-2023-28466</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="cluster-logging-release-notes-5-7-2_logging-5-7-release-notes">
<title>Logging 5.7.2</title>
<simpara>This release includes <link xlink:href="https://access.redhat.com/errata/RHSA-2023:3495">OpenShift Logging Bug Fix Release 5.7.2</link>.</simpara>
<section xml:id="openshift-logging-5-7-2-bug-fixes_logging-5-7-release-notes">
<title>Bug fixes</title>
<itemizedlist>
<listitem>
<simpara>Before this update, it was not possible to delete the <literal>openshift-logging</literal> namespace directly due to the presence of a pending finalizer. With this update, the finalizer is no longer utilized, enabling direct deletion of the namespace. (<link xlink:href="https://issues.redhat.com/browse/LOG-3316">LOG-3316</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the <literal>run.sh</literal> script would display an incorrect <literal>chunk_limit_size</literal> value if it was changed according to the OpenShift Container Platform documentation. However, when setting the <literal>chunk_limit_size</literal> via the environment variable <literal>$BUFFER_SIZE_LIMIT</literal>, the script would show the correct value. With this update, the <literal>run.sh</literal> script now consistently displays the correct <literal>chunk_limit_size</literal> value in both scenarios. (<link xlink:href="https://issues.redhat.com/browse/LOG-3330">LOG-3330</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the OpenShift Container Platform web console&#8217;s logging view plugin did not allow for custom node placement or tolerations. This update adds the ability to define node placement and tolerations for the logging view plugin. (<link xlink:href="https://issues.redhat.com/browse/LOG-3749">LOG-3749</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the Cluster Logging Operator encountered an Unsupported Media Type exception when trying to send logs to DataDog via the Fluentd HTTP Plugin. With this update, users can seamlessly assign the content type for log forwarding by configuring the HTTP header Content-Type. The value provided is automatically assigned to the <literal>content_type</literal> parameter within the plugin, ensuring successful log transmission. (<link xlink:href="https://issues.redhat.com/browse/LOG-3784">LOG-3784</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, when the <literal>detectMultilineErrors</literal> field was set to <literal>true</literal> in the <literal>ClusterLogForwarder</literal> custom resource (CR), PHP multi-line errors were recorded as separate log entries, causing the stack trace to be split across multiple messages. With this update, multi-line error detection for PHP is enabled, ensuring that the entire stack trace is included in a single log message. (<link xlink:href="https://issues.redhat.com/browse/LOG-3878">LOG-3878</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, <literal>ClusterLogForwarder</literal> pipelines containing a space in their name caused the Vector collector pods to continuously crash. With this update, all spaces, dashes (-), and dots (.) in pipeline names are replaced with underscores (_). (<link xlink:href="https://issues.redhat.com/browse/LOG-3945">LOG-3945</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the <literal>log_forwarder_output</literal> metric did not include the <literal>http</literal> parameter. This update adds the missing parameter to the metric. (<link xlink:href="https://issues.redhat.com/browse/LOG-3997">LOG-3997</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, Fluentd did not identify some multi-line JavaScript client exceptions when they ended with a colon. With this update, the Fluentd buffer name is prefixed with an underscore, resolving the issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4019">LOG-4019</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, when configuring log forwarding to write to a Kafka output topic which matched a key in the payload, logs dropped due to an error.  With this update, Fluentd&#8217;s buffer name has been prefixed with an underscore, resolving the issue.(<link xlink:href="https://issues.redhat.com/browse/LOG-4027">LOG-4027</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the LokiStack gateway returned label values for namespaces without applying the access rights of a user. With this update, the LokiStack gateway applies permissions to label value requests, resolving the issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4049">LOG-4049</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the Cluster Logging Operator API required a certificate to be provided by a secret when the <literal>tls.insecureSkipVerify</literal> option was set to <literal>true</literal>. With this update, the Cluster Logging Operator API no longer requires a certificate to be provided by a secret in such cases. The following configuration has been added to the Operator&#8217;s CR:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">tls.verify_certificate = false
tls.verify_hostname = false</programlisting>
<simpara>(<link xlink:href="https://issues.redhat.com/browse/LOG-3445">LOG-3445</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the LokiStack route configuration caused queries running longer than 30 seconds to timeout. With this update, the LokiStack global and per-tenant <literal>queryTimeout</literal> settings affect the route timeout settings, resolving the issue. (<link xlink:href="https://issues.redhat.com/browse/LOG-4052">LOG-4052</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, a prior fix to remove defaulting of the <literal>collection.type</literal> resulted in the Operator no longer honoring the deprecated specs for resource, node selections, and tolerations.  This update modifies the Operator behavior to always prefer the <literal>collection.logs</literal> spec over those of <literal>collection</literal>.  This varies from previous behavior that allowed using both the preferred fields and deprecated fields but would ignore the deprecated fields when <literal>collection.type</literal> was populated. (<link xlink:href="https://issues.redhat.com/browse/LOG-4185">LOG-4185</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the Vector log collector did not generate TLS configuration for forwarding logs to multiple Kafka brokers if the broker URLs were not specified in the output. With this update, TLS configuration is generated appropriately for multiple brokers. (<link xlink:href="https://issues.redhat.com/browse/LOG-4163">LOG-4163</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the option to enable passphrase for log forwarding to Kafka was unavailable. This limitation presented a security risk as it could potentially expose sensitive information. With this update, users now have a seamless option to enable passphrase for log forwarding to Kafka. (<link xlink:href="https://issues.redhat.com/browse/LOG-3314">LOG-3314</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, Vector log collector did not honor the <literal>tlsSecurityProfile</literal> settings for outgoing TLS connections. After this update, Vector handles TLS connection settings appropriately. (<link xlink:href="https://issues.redhat.com/browse/LOG-4011">LOG-4011</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, not all available output types were included in the <literal>log_forwarder_output_info</literal> metrics. With this update, metrics contain Splunk and Google Cloud Logging data which was missing previously. (<link xlink:href="https://issues.redhat.com/browse/LOG-4098">LOG-4098</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, when <literal>follow_inodes</literal> was set to <literal>true</literal>, the Fluentd collector could crash on file rotation. With this update, the <literal>follow_inodes</literal> setting does not crash the collector. (<link xlink:href="https://issues.redhat.com/browse/LOG-4151">LOG-4151</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the Fluentd collector could incorrectly close files that should be watched because of how those files were tracked. With this update, the tracking parameters have been corrected.  (<link xlink:href="https://issues.redhat.com/browse/LOG-4149">LOG-4149</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, forwarding logs with the Vector collector and naming a pipeline in the <literal>ClusterLogForwarder</literal> instance <literal>audit</literal>, <literal>application</literal> or <literal>infrastructure</literal> resulted in collector pods staying in the <literal>CrashLoopBackOff</literal> state with the following error in the collector log:</simpara>
<programlisting language="text" linenumbering="unnumbered">ERROR vector::cli: Configuration error. error=redefinition of table transforms.audit for key transforms.audit</programlisting>
<simpara>After this update, pipeline names no longer clash with reserved input names, and pipelines can be named <literal>audit</literal>, <literal>application</literal> or <literal>infrastructure</literal>. (<link xlink:href="https://issues.redhat.com/browse/LOG-4218">LOG-4218</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, when forwarding logs to a syslog destination with the Vector collector and setting the <literal>addLogSource</literal> flag to <literal>true</literal>, the following extra empty fields were added to the forwarded messages: <literal>namespace_name=</literal>, <literal>container_name=</literal>, and <literal>pod_name=</literal>. With this update, these fields are no longer added to journal logs. (<link xlink:href="https://issues.redhat.com/browse/">LOG-4219</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, when a <literal>structuredTypeKey</literal> was not found, and a <literal>structuredTypeName</literal> was not specified, log messages were still parsed into structured object. With this update, parsing of logs is as expected. (<link xlink:href="https://issues.redhat.com/browse/LOG-4220">LOG-4220</link>)</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="openshift-logging-5-7-2-CVEs_logging-5-7-release-notes">
<title>CVEs</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2021-26341">CVE-2021-26341</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2021-33655">CVE-2021-33655</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2021-33656">CVE-2021-33656</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-1462">CVE-2022-1462</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-1679">CVE-2022-1679</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-1789">CVE-2022-1789</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-2196">CVE-2022-2196</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-2663">CVE-2022-2663</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-3028">CVE-2022-3028</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-3239">CVE-2022-3239</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-3522">CVE-2022-3522</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-3524">CVE-2022-3524</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-3564">CVE-2022-3564</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-3566">CVE-2022-3566</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-3567">CVE-2022-3567</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-3619">CVE-2022-3619</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-3623">CVE-2022-3623</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-3625">CVE-2022-3625</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-3627">CVE-2022-3627</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-3628">CVE-2022-3628</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-3707">CVE-2022-3707</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-3970">CVE-2022-3970</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-4129">CVE-2022-4129</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-20141">CVE-2022-20141</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-25147">CVE-2022-25147</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-25265">CVE-2022-25265</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-30594">CVE-2022-30594</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-36227">CVE-2022-36227</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-39188">CVE-2022-39188</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-39189">CVE-2022-39189</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-41218">CVE-2022-41218</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-41674">CVE-2022-41674</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-42703">CVE-2022-42703</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-42720">CVE-2022-42720</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-42721">CVE-2022-42721</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-42722">CVE-2022-42722</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-43750">CVE-2022-43750</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2022-47929">CVE-2022-47929</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-0394">CVE-2023-0394</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-0461">CVE-2023-0461</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-1195">CVE-2023-1195</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-1582">CVE-2023-1582</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-2491">CVE-2023-2491</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-22490">CVE-2023-22490</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-23454">CVE-2023-23454</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-23946">CVE-2023-23946</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-25652">CVE-2023-25652</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-25815">CVE-2023-25815</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-27535">CVE-2023-27535</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-29007">CVE-2023-29007</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="logging-release-notes-5-7-1_logging-5-7-release-notes">
<title>Logging 5.7.1</title>
<simpara>This release includes: <link xlink:href="https://access.redhat.com/errata/RHBA-2023:3197">OpenShift Logging Bug Fix Release 5.7.1</link>.</simpara>
<section xml:id="logging-5-7-1-bug-fixes_logging-5-7-release-notes">
<title>Bug fixes</title>
<itemizedlist>
<listitem>
<simpara>Before this update, the presence of numerous noisy messages within the Cluster Logging Operator pod logs caused reduced log readability, and increased difficulty in identifying important system events. With this update, the issue is resolved by significantly reducing the noisy messages within Cluster Logging Operator pod logs. (<link xlink:href="https://issues.redhat.com/browse/LOG-3482">LOG-3482</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, the API server would reset the value for the <literal>CollectorSpec.Type</literal> field to <literal>vector</literal>, even when the custom resource used a different value. This update removes the default for the <literal>CollectorSpec.Type</literal> field to restore the previous behavior. (<link xlink:href="https://issues.redhat.com/browse/LOG-4086">LOG-4086</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, a time range could not be selected in the OpenShift Container Platform web console by clicking and dragging over the logs histogram. With this update, clicking and dragging can be used to successfully select a time range. (<link xlink:href="https://issues.redhat.com/browse/LOG-4501">LOG-4501</link>)</simpara>
</listitem>
<listitem>
<simpara>Before this update, clicking on the <emphasis role="strong">Show Resources</emphasis> link in the OpenShift Container Platform web console did not produce any effect. With this update, the issue is resolved by fixing the functionality of the "Show Resources" link to toggle the display of resources for each log entry. (<link xlink:href="https://issues.redhat.com/browse/LOG-3218">LOG-3218</link>)</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-5-7-1-CVEs_logging-5-7-release-notes">
<title>CVEs</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-21930">CVE-2023-21930</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-21937">CVE-2023-21937</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-21938">CVE-2023-21938</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-21939">CVE-2023-21939</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-21954">CVE-2023-21954</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-21967">CVE-2023-21967</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-21968">CVE-2023-21968</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-28617">CVE-2023-28617</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="logging-release-notes-5-7-0logging-5-7-release-notes">
<title>Logging 5.7.0</title>
<simpara>This release includes <link xlink:href="https://access.redhat.com/errata/RHBA-2023:2133">OpenShift Logging Bug Fix Release 5.7.0</link>.</simpara>
<section xml:id="logging-5-7-enhancements">
<title>Enhancements</title>
<simpara>With this update, you can enable logging to detect multi-line exceptions and reassemble them into a single log entry.</simpara>
<simpara>To enable logging to detect multi-line exceptions and reassemble them into a single log entry, ensure that the <literal>ClusterLogForwarder</literal> Custom Resource (CR) contains a <literal>detectMultilineErrors</literal> field, with a value of <literal>true</literal>.</simpara>
</section>
<section xml:id="logging-5-7-known-issues">
<title>Known Issues</title>
<simpara>None.</simpara>
</section>
<section xml:id="logging-5-7-0-bug-fixes">
<title>Bug fixes</title>
<itemizedlist>
<listitem>
<simpara>Before this update, the <literal>nodeSelector</literal> attribute for the Gateway component of the LokiStack did not impact node scheduling. With this update, the <literal>nodeSelector</literal> attribute works as expected. (<link xlink:href="https://issues.redhat.com/browse/LOG-3713">LOG-3713</link>)</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-5-7-0-CVEs">
<title>CVEs</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-1999">CVE-2023-1999</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/security/cve/CVE-2023-28617">CVE-2023-28617</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
</chapter>
<chapter xml:id="cluster-logging-support">
<title>Support</title>

<simpara>Only the configuration options described in this documentation are supported for logging.</simpara>
<simpara>Do not use any other configuration options, as they are unsupported. Configuration paradigms might change across OpenShift Container Platform releases, and such cases can only be handled gracefully if all configuration possibilities are controlled. If you use configurations other than those described in this documentation, your changes will be overwritten, because Operators are designed to reconcile any differences.</simpara>
<note>
<simpara>If you must perform configurations not described in the OpenShift Container Platform documentation, you must set your Red Hat OpenShift Logging Operator to <literal>Unmanaged</literal>. An unmanaged logging instance is not supported and does not receive updates until you return its status to <literal>Managed</literal>.</simpara>
</note>
<note>
<simpara>Logging is provided as an installable component, with a distinct release cycle from the core OpenShift Container Platform. The <link xlink:href="https://access.redhat.com/support/policy/updates/openshift_operators#platform-agnostic">Red Hat OpenShift Container Platform Life Cycle Policy</link> outlines release compatibility.</simpara>
</note>
<simpara>Logging for Red Hat OpenShift is an opinionated collector and normalizer of application, infrastructure, and audit logs. It is intended to be used for forwarding logs to various supported systems.</simpara>
<simpara>Logging is not:</simpara>
<itemizedlist>
<listitem>
<simpara>A high scale log collection system</simpara>
</listitem>
<listitem>
<simpara>Security Information and Event Monitoring (SIEM) compliant</simpara>
</listitem>
<listitem>
<simpara>Historical or long term log retention or storage</simpara>
</listitem>
<listitem>
<simpara>A guaranteed log sink</simpara>
</listitem>
<listitem>
<simpara>Secure storage - audit logs are not stored by default</simpara>
</listitem>
</itemizedlist>
<section xml:id="cluster-logging-support-CRDs">
<title>Supported API custom resource definitions</title>
<simpara>LokiStack development is ongoing. Not all APIs are currently supported.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Loki API support states</title>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">CustomResourceDefinition (CRD)</entry>
<entry align="left" valign="top">ApiVersion</entry>
<entry align="left" valign="top">Support state</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>LokiStack</simpara></entry>
<entry align="left" valign="top"><simpara>lokistack.loki.grafana.com/v1</simpara></entry>
<entry align="left" valign="top"><simpara>Supported in 5.5</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>RulerConfig</simpara></entry>
<entry align="left" valign="top"><simpara>rulerconfig.loki.grafana/v1</simpara></entry>
<entry align="left" valign="top"><simpara>Supported in 5.7</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>AlertingRule</simpara></entry>
<entry align="left" valign="top"><simpara>alertingrule.loki.grafana/v1</simpara></entry>
<entry align="left" valign="top"><simpara>Supported in 5.7</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>RecordingRule</simpara></entry>
<entry align="left" valign="top"><simpara>recordingrule.loki.grafana/v1</simpara></entry>
<entry align="left" valign="top"><simpara>Supported in 5.7</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section xml:id="cluster-logging-maintenance-support-list_cluster-logging-support">
<title>Unsupported configurations</title>
<simpara>You must set the Red&#160;Hat OpenShift Logging Operator to the <literal>Unmanaged</literal> state to modify the following components:</simpara>
<itemizedlist>
<listitem>
<simpara>The <literal>Elasticsearch</literal> custom resource (CR)</simpara>
</listitem>
<listitem>
<simpara>The Kibana deployment</simpara>
</listitem>
<listitem>
<simpara>The <literal>fluent.conf</literal> file</simpara>
</listitem>
<listitem>
<simpara>The Fluentd daemon set</simpara>
</listitem>
</itemizedlist>
<simpara>You must set the OpenShift Elasticsearch Operator to the <literal>Unmanaged</literal> state to modify the Elasticsearch deployment files.</simpara>
<simpara>Explicitly unsupported cases include:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Configuring default log rotation</emphasis>. You cannot modify the default log rotation configuration.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Configuring the collected log location</emphasis>. You cannot change the location of the log collector output file, which by default is <literal>/var/log/fluentd/fluentd.log</literal>.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Throttling log collection</emphasis>. You cannot throttle down the rate at which the logs are read in by the log collector.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Configuring the logging collector using environment variables</emphasis>. You cannot use environment variables to modify the log collector.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">Configuring how the log collector normalizes logs</emphasis>. You cannot modify default log normalization.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="unmanaged-operators_cluster-logging-support">
<title>Support policy for unmanaged Operators</title>
<simpara>The <emphasis>management state</emphasis> of an Operator determines whether an Operator is actively
managing the resources for its related component in the cluster as designed. If
an Operator is set to an <emphasis>unmanaged</emphasis> state, it does not respond to changes in
configuration nor does it receive updates.</simpara>
<simpara>While this can be helpful in non-production clusters or during debugging,
Operators in an unmanaged state are unsupported and the cluster administrator
assumes full control of the individual component configurations and upgrades.</simpara>
<simpara>An Operator can be set to an unmanaged state using the following methods:</simpara>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">Individual Operator configuration</emphasis></simpara>
<simpara>Individual Operators have a <literal>managementState</literal> parameter in their configuration.
This can be accessed in different ways, depending on the Operator. For example,
the Red Hat OpenShift Logging Operator accomplishes this by modifying a custom resource
(CR) that it manages, while the Cluster Samples Operator uses a cluster-wide
configuration resource.</simpara>
<simpara>Changing the <literal>managementState</literal> parameter to <literal>Unmanaged</literal> means that the Operator
is not actively managing its resources and will take no action related to the
related component. Some Operators might not support this management state as it
might damage the cluster and require manual recovery.</simpara>
<warning>
<simpara>Changing individual Operators to the <literal>Unmanaged</literal> state renders that particular
component and functionality unsupported. Reported issues must be reproduced in
<literal>Managed</literal> state for support to proceed.</simpara>
</warning>
</listitem>
<listitem>
<simpara><emphasis role="strong">Cluster Version Operator (CVO) overrides</emphasis></simpara>
<simpara>The <literal>spec.overrides</literal> parameter can be added to the CVO&#8217;s configuration to allow
administrators to provide a list of overrides to the CVO&#8217;s behavior for a
component. Setting the <literal>spec.overrides[].unmanaged</literal> parameter to <literal>true</literal> for a
component blocks cluster upgrades and alerts the administrator after a CVO
override has been set:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">Disabling ownership via cluster version overrides prevents upgrades. Please remove overrides before continuing.</programlisting>
<warning>
<simpara>Setting a CVO override puts the entire cluster in an unsupported state. Reported
issues must be reproduced after removing any overrides for support to proceed.</simpara>
</warning>
</listitem>
</itemizedlist>
</section>
<section xml:id="cluster-logging-support-must-gather">
<title>Collecting logging data for Red Hat Support</title>
<simpara>When opening a support case, it is helpful to provide debugging information about your cluster to Red&#160;Hat Support.</simpara>
<simpara>You can use the
<link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/support/#gathering-cluster-data"><literal>must-gather</literal> tool</link>
to collect diagnostic information for project-level resources, cluster-level resources, and each of the logging components.</simpara>
<simpara>For prompt support, supply diagnostic information for both OpenShift Container Platform and logging.</simpara>
<note>
<simpara>Do not use the <literal>hack/logging-dump.sh</literal> script. The script is no longer supported and does not collect data.</simpara>
</note>
<section xml:id="about-must-gather_cluster-logging-support">
<title>About the must-gather tool</title>
<simpara>The <literal>oc adm must-gather</literal> CLI command collects the information from your cluster that is most likely needed for debugging issues.</simpara>
<simpara>For your logging, <literal>must-gather</literal> collects the following information:</simpara>
<itemizedlist>
<listitem>
<simpara>Project-level resources, including pods, configuration maps, service accounts, roles, role bindings, and events at the project level</simpara>
</listitem>
<listitem>
<simpara>Cluster-level resources, including nodes, roles, and role bindings at the cluster level</simpara>
</listitem>
<listitem>
<simpara>OpenShift Logging resources in the <literal>openshift-logging</literal> and <literal>openshift-operators-redhat</literal> namespaces, including health status for the log collector, the log store, and the log visualizer</simpara>
</listitem>
</itemizedlist>
<simpara>When you run <literal>oc adm must-gather</literal>, a new pod is created on the cluster. The data is collected on that pod and saved in a new directory that starts with <literal>must-gather.local</literal>. This directory is created in the current working directory.</simpara>
</section>
<section xml:id="cluster-logging-must-gather-collecting_cluster-logging-support">
<title>Collecting OpenShift Logging data</title>
<simpara>You can use the <literal>oc adm must-gather</literal> CLI command to collect information about your logging.</simpara>
<formalpara>
<title>Procedure</title>
<para>To collect logging information with <literal>must-gather</literal>:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Navigate to the directory where you want to store the <literal>must-gather</literal> information.</simpara>
</listitem>
<listitem>
<simpara>Run the <literal>oc adm must-gather</literal> command against the OpenShift Logging image:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm must-gather --image=$(oc -n openshift-logging get deployment.apps/cluster-logging-operator -o jsonpath='{.spec.template.spec.containers[?(@.name == "cluster-logging-operator")].image}')</programlisting>
<simpara>The <literal>must-gather</literal> tool creates a new directory that starts with <literal>must-gather.local</literal> within the current directory. For example:
<literal>must-gather.local.4157245944708210408</literal>.</simpara>
</listitem>
<listitem>
<simpara>Create a compressed file from the <literal>must-gather</literal> directory that was just created. For example, on a computer that uses a Linux operating system, run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ tar -cvaf must-gather.tar.gz must-gather.local.4157245944708210408</programlisting>
</listitem>
<listitem>
<simpara>Attach the compressed file to your support case on the <link xlink:href="https://access.redhat.com/">Red Hat Customer Portal</link>.</simpara>
</listitem>
</orderedlist>
</section>
</section>
</chapter>
<chapter xml:id="_troubleshooting-logging">
<title>Troubleshooting logging</title>
<section xml:id="cluster-logging-cluster-status">
<title>Viewing Logging status</title>

<simpara>You can view the status of the Red Hat OpenShift Logging Operator and other logging components.</simpara>
<section xml:id="cluster-logging-clo-status_cluster-logging-cluster-status">
<title>Viewing the status of the Red Hat OpenShift Logging Operator</title>
<simpara>You can view the status of the Red Hat OpenShift Logging Operator.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>The Red Hat OpenShift Logging Operator and OpenShift Elasticsearch Operator are installed.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Change to the <literal>openshift-logging</literal> project by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc project openshift-logging</programlisting>
</listitem>
<listitem>
<simpara>Get the <literal>ClusterLogging</literal> instance status by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get clusterlogging instance -o yaml</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
# ...
status:  <co xml:id="CO1-1"/>
  collection:
    logs:
      fluentdStatus:
        daemonSet: fluentd  <co xml:id="CO1-2"/>
        nodes:
          collector-2rhqp: ip-10-0-169-13.ec2.internal
          collector-6fgjh: ip-10-0-165-244.ec2.internal
          collector-6l2ff: ip-10-0-128-218.ec2.internal
          collector-54nx5: ip-10-0-139-30.ec2.internal
          collector-flpnn: ip-10-0-147-228.ec2.internal
          collector-n2frh: ip-10-0-157-45.ec2.internal
        pods:
          failed: []
          notReady: []
          ready:
          - collector-2rhqp
          - collector-54nx5
          - collector-6fgjh
          - collector-6l2ff
          - collector-flpnn
          - collector-n2frh
  logstore: <co xml:id="CO1-3"/>
    elasticsearchStatus:
    - ShardAllocationEnabled:  all
      cluster:
        activePrimaryShards:    5
        activeShards:           5
        initializingShards:     0
        numDataNodes:           1
        numNodes:               1
        pendingTasks:           0
        relocatingShards:       0
        status:                 green
        unassignedShards:       0
      clusterName:             elasticsearch
      nodeConditions:
        elasticsearch-cdm-mkkdys93-1:
      nodeCount:  1
      pods:
        client:
          failed:
          notReady:
          ready:
          - elasticsearch-cdm-mkkdys93-1-7f7c6-mjm7c
        data:
          failed:
          notReady:
          ready:
          - elasticsearch-cdm-mkkdys93-1-7f7c6-mjm7c
        master:
          failed:
          notReady:
          ready:
          - elasticsearch-cdm-mkkdys93-1-7f7c6-mjm7c
visualization:  <co xml:id="CO1-4"/>
    kibanaStatus:
    - deployment: kibana
      pods:
        failed: []
        notReady: []
        ready:
        - kibana-7fb4fd4cc9-f2nls
      replicaSets:
      - kibana-7fb4fd4cc9
      replicas: 1</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO1-1">
<para>In the output, the cluster status fields appear in the <literal>status</literal> stanza.</para>
</callout>
<callout arearefs="CO1-2">
<para>Information on the Fluentd pods.</para>
</callout>
<callout arearefs="CO1-3">
<para>Information on the Elasticsearch pods, including Elasticsearch cluster health, <literal>green</literal>, <literal>yellow</literal>, or <literal>red</literal>.</para>
</callout>
<callout arearefs="CO1-4">
<para>Information on the Kibana pods.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
<section xml:id="cluster-logging-clo-status-message_cluster-logging-cluster-status">
<title>Example condition messages</title>
<simpara>The following are examples of some condition messages from the <literal>Status.Nodes</literal> section of the <literal>ClusterLogging</literal> instance.</simpara>
<simpara>A status message similar to the following indicates a node has exceeded the configured low watermark and no shard will be allocated to this node:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">  nodes:
  - conditions:
    - lastTransitionTime: 2019-03-15T15:57:22Z
      message: Disk storage usage for node is 27.5gb (36.74%). Shards will be not
        be allocated on this node.
      reason: Disk Watermark Low
      status: "True"
      type: NodeStorage
    deploymentName: example-elasticsearch-clientdatamaster-0-1
    upgradeStatus: {}</programlisting>
</para>
</formalpara>
<simpara>A status message similar to the following indicates a node has exceeded the configured high watermark and shards will be relocated to other nodes:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">  nodes:
  - conditions:
    - lastTransitionTime: 2019-03-15T16:04:45Z
      message: Disk storage usage for node is 27.5gb (36.74%). Shards will be relocated
        from this node.
      reason: Disk Watermark High
      status: "True"
      type: NodeStorage
    deploymentName: cluster-logging-operator
    upgradeStatus: {}</programlisting>
</para>
</formalpara>
<simpara>A status message similar to the following indicates the Elasticsearch node selector in the CR does not match any nodes in the cluster:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">    Elasticsearch Status:
      Shard Allocation Enabled:  shard allocation unknown
      Cluster:
        Active Primary Shards:  0
        Active Shards:          0
        Initializing Shards:    0
        Num Data Nodes:         0
        Num Nodes:              0
        Pending Tasks:          0
        Relocating Shards:      0
        Status:                 cluster health unknown
        Unassigned Shards:      0
      Cluster Name:             elasticsearch
      Node Conditions:
        elasticsearch-cdm-mkkdys93-1:
          Last Transition Time:  2019-06-26T03:37:32Z
          Message:               0/5 nodes are available: 5 node(s) didn't match node selector.
          Reason:                Unschedulable
          Status:                True
          Type:                  Unschedulable
        elasticsearch-cdm-mkkdys93-2:
      Node Count:  2
      Pods:
        Client:
          Failed:
          Not Ready:
            elasticsearch-cdm-mkkdys93-1-75dd69dccd-f7f49
            elasticsearch-cdm-mkkdys93-2-67c64f5f4c-n58vl
          Ready:
        Data:
          Failed:
          Not Ready:
            elasticsearch-cdm-mkkdys93-1-75dd69dccd-f7f49
            elasticsearch-cdm-mkkdys93-2-67c64f5f4c-n58vl
          Ready:
        Master:
          Failed:
          Not Ready:
            elasticsearch-cdm-mkkdys93-1-75dd69dccd-f7f49
            elasticsearch-cdm-mkkdys93-2-67c64f5f4c-n58vl
          Ready:</programlisting>
</para>
</formalpara>
<simpara>A status message similar to the following indicates that the requested PVC could not bind to PV:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">      Node Conditions:
        elasticsearch-cdm-mkkdys93-1:
          Last Transition Time:  2019-06-26T03:37:32Z
          Message:               pod has unbound immediate PersistentVolumeClaims (repeated 5 times)
          Reason:                Unschedulable
          Status:                True
          Type:                  Unschedulable</programlisting>
</para>
</formalpara>
<simpara>A status message similar to the following indicates that the Fluentd pods cannot be scheduled because the node selector did not match any nodes:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">Status:
  Collection:
    Logs:
      Fluentd Status:
        Daemon Set:  fluentd
        Nodes:
        Pods:
          Failed:
          Not Ready:
          Ready:</programlisting>
</para>
</formalpara>
</section>
</section>
<section xml:id="cluster-logging-clo-status-comp_cluster-logging-cluster-status">
<title>Viewing the status of logging components</title>
<simpara>You can view the status for a number of logging components.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>The Red Hat OpenShift Logging Operator and OpenShift Elasticsearch Operator are installed.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Change to the <literal>openshift-logging</literal> project.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc project openshift-logging</programlisting>
</listitem>
<listitem>
<simpara>View the status of logging environment:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc describe deployment cluster-logging-operator</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">Name:                   cluster-logging-operator

....

Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable

....

Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  62m   deployment-controller  Scaled up replica set cluster-logging-operator-574b8987df to 1----</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>View the status of the logging replica set:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Get the name of a replica set:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get replicaset</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                                      DESIRED   CURRENT   READY   AGE
cluster-logging-operator-574b8987df       1         1         1       159m
elasticsearch-cdm-uhr537yu-1-6869694fb    1         1         1       157m
elasticsearch-cdm-uhr537yu-2-857b6d676f   1         1         1       156m
elasticsearch-cdm-uhr537yu-3-5b6fdd8cfd   1         1         1       155m
kibana-5bd5544f87                         1         1         1       157m</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Get the status of the replica set:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc describe replicaset cluster-logging-operator-574b8987df</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">Name:           cluster-logging-operator-574b8987df

....

Replicas:       1 current / 1 desired
Pods Status:    1 Running / 0 Waiting / 0 Succeeded / 0 Failed

....

Events:
  Type    Reason            Age   From                   Message
  ----    ------            ----  ----                   -------
  Normal  SuccessfulCreate  66m   replicaset-controller  Created pod: cluster-logging-operator-574b8987df-qjhqv----</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
</section>
</section>
<section xml:id="log-forwarding-troubleshooting">
<title>Troubleshooting log forwarding</title>

<section xml:id="redeploying-fluentd-pods_log-forwarding-troubleshooting">
<title>Redeploying Fluentd pods</title>
<simpara>When you create a <literal>ClusterLogForwarder</literal> custom resource (CR), if the Red Hat OpenShift Logging Operator does not redeploy the Fluentd pods automatically, you can delete the Fluentd pods to force them to redeploy.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have created a <literal>ClusterLogForwarder</literal> custom resource (CR) object.</simpara>
</listitem>
</itemizedlist>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>Delete the Fluentd pods to force them to redeploy by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc delete pod --selector logging-infra=collector</programlisting>
</listitem>
</itemizedlist>
</section>
<section xml:id="loki-rate-limit-errors_log-forwarding-troubleshooting">
<title>Troubleshooting Loki rate limit errors</title>
<simpara>If the Log Forwarder API forwards a large block of messages that exceeds the rate limit to Loki, Loki generates rate limit (<literal>429</literal>) errors.</simpara>
<simpara>These errors can occur during normal operation. For example, when adding the logging to a cluster that already has some logs, rate limit errors might occur while the logging tries to ingest all of the existing log entries. In this case, if the rate of addition of new logs is less than the total rate limit, the historical data is eventually ingested, and the rate limit errors are resolved without requiring user intervention.</simpara>
<simpara>In cases where the rate limit errors continue to occur, you can fix the issue by modifying the <literal>LokiStack</literal> custom resource (CR).</simpara>
<important>
<simpara>The <literal>LokiStack</literal> CR is not available on Grafana-hosted Loki. This topic does not apply to Grafana-hosted Loki servers.</simpara>
</important>
<itemizedlist>
<title>Conditions</title>
<listitem>
<simpara>The Log Forwarder API is configured to forward logs to Loki.</simpara>
</listitem>
<listitem>
<simpara>Your system sends a block of messages that is larger than 2 MB to Loki. For example:</simpara>
<programlisting language="text" linenumbering="unnumbered">"values":[["1630410392689800468","{\"kind\":\"Event\",\"apiVersion\":\
.......
......
......
......
\"received_at\":\"2021-08-31T11:46:32.800278+00:00\",\"version\":\"1.7.4 1.6.0\"}},\"@timestamp\":\"2021-08-31T11:46:32.799692+00:00\",\"viaq_index_name\":\"audit-write\",\"viaq_msg_id\":\"MzFjYjJkZjItNjY0MC00YWU4LWIwMTEtNGNmM2E5ZmViMGU4\",\"log_type\":\"audit\"}"]]}]}</programlisting>
</listitem>
<listitem>
<simpara>After you enter <literal>oc logs -n openshift-logging -l component=collector</literal>, the collector logs in your cluster show a line containing one of the following error messages:</simpara>
<programlisting language="text" linenumbering="unnumbered">429 Too Many Requests Ingestion rate limit exceeded</programlisting>
<formalpara>
<title>Example Vector error message</title>
<para>
<programlisting language="text" linenumbering="unnumbered">2023-08-25T16:08:49.301780Z  WARN sink{component_kind="sink" component_id=default_loki_infra component_type=loki component_name=default_loki_infra}: vector::sinks::util::retries: Retrying after error. error=Server responded with an error: 429 Too Many Requests internal_log_rate_limit=true</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example Fluentd error message</title>
<para>
<programlisting language="text" linenumbering="unnumbered">2023-08-30 14:52:15 +0000 [warn]: [default_loki_infra] failed to flush the buffer. retry_times=2 next_retry_time=2023-08-30 14:52:19 +0000 chunk="604251225bf5378ed1567231a1c03b8b" error_class=Fluent::Plugin::LokiOutput::LogPostError error="429 Too Many Requests Ingestion rate limit exceeded for user infrastructure (limit: 4194304 bytes/sec) while attempting to ingest '4082' lines totaling '7820025' bytes, reduce log volume or contact your Loki administrator to see if the limit can be increased\n"</programlisting>
</para>
</formalpara>
<simpara>The error is also visible on the receiving end. For example, in the LokiStack ingester pod:</simpara>
<formalpara>
<title>Example Loki ingester error message</title>
<para>
<programlisting language="text" linenumbering="unnumbered">level=warn ts=2023-08-30T14:57:34.155592243Z caller=grpc_logging.go:43 duration=1.434942ms method=/logproto.Pusher/Push err="rpc error: code = Code(429) desc = entry with timestamp 2023-08-30 14:57:32.012778399 +0000 UTC ignored, reason: 'Per stream rate limit exceeded (limit: 3MB/sec) while attempting to ingest for stream</programlisting>
</para>
</formalpara>
</listitem>
</itemizedlist>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>Update the <literal>ingestionBurstSize</literal> and <literal>ingestionRate</literal> fields in the <literal>LokiStack</literal> CR:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: logging-loki
  namespace: openshift-logging
spec:
  limits:
    global:
      ingestion:
        ingestionBurstSize: 16 <co xml:id="CO2-1"/>
        ingestionRate: 8 <co xml:id="CO2-2"/>
# ...</programlisting>
<calloutlist>
<callout arearefs="CO2-1">
<para>The <literal>ingestionBurstSize</literal> field defines the maximum local rate-limited sample size per distributor replica in MB. This value is a hard limit. Set this value to at least the maximum logs size expected in a single push request. Single requests that are larger than the <literal>ingestionBurstSize</literal> value are not permitted.</para>
</callout>
<callout arearefs="CO2-2">
<para>The <literal>ingestionRate</literal> field is a soft limit on the maximum amount of ingested samples per second in MB. Rate limit errors occur if the rate of logs exceeds the limit, but the collector retries sending the logs. As long as the total average is lower than the limit, the system recovers and errors are resolved without user intervention.</para>
</callout>
</calloutlist>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="troubleshooting-logging-alerts">
<title>Troubleshooting logging alerts</title>

<simpara>You can use the following procedures to troubleshoot logging alerts on your cluster.</simpara>
<section xml:id="es-cluster-health-is-red_troubleshooting-logging-alerts">
<title>Elasticsearch cluster health status is red</title>
<simpara>At least one primary shard and its replicas are not allocated to a node. Use the following procedure to troubleshoot this alert.</simpara>
<tip>
<simpara>Some commands in this documentation reference an Elasticsearch pod by using a <literal>$ES_POD_NAME</literal> shell variable. If you want to copy and paste the commands directly from this documentation, you must set this variable to a value that is valid for your Elasticsearch cluster.</simpara>
<simpara>You can list the available Elasticsearch pods by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging get pods -l component=elasticsearch</programlisting>
<simpara>Choose one of the pods listed and set the <literal>$ES_POD_NAME</literal> variable, by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ export ES_POD_NAME=&lt;elasticsearch_pod_name&gt;</programlisting>
<simpara>You can now use the <literal>$ES_POD_NAME</literal> variable in commands.</simpara>
</tip>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Check the Elasticsearch cluster health and verify that the cluster <literal>status</literal> is red by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME -- health</programlisting>
</listitem>
<listitem>
<simpara>List the nodes that have joined the cluster by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=_cat/nodes?v</programlisting>
</listitem>
<listitem>
<simpara>List the Elasticsearch pods and compare them with the nodes in the command output from the previous step, by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging get pods -l component=elasticsearch</programlisting>
</listitem>
<listitem>
<simpara>If some of the Elasticsearch nodes have not joined the cluster, perform the following steps.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Confirm that Elasticsearch has an elected master node by running the following command and observing the output:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=_cat/master?v</programlisting>
</listitem>
<listitem>
<simpara>Review the pod logs of the elected master node for issues by running the following command and observing the output:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc logs &lt;elasticsearch_master_pod_name&gt; -c elasticsearch -n openshift-logging</programlisting>
</listitem>
<listitem>
<simpara>Review the logs of nodes that have not joined the cluster for issues by running the following command and observing the output:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc logs &lt;elasticsearch_node_name&gt; -c elasticsearch -n openshift-logging</programlisting>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>If all the nodes have joined the cluster, check if the cluster is in the process of recovering by running the following command and observing the output:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=_cat/recovery?active_only=true</programlisting>
<simpara>If there is no command output, the recovery process might be delayed or stalled by pending tasks.</simpara>
</listitem>
<listitem>
<simpara>Check if there are pending tasks by running the following command and observing the output:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- health | grep number_of_pending_tasks</programlisting>
</listitem>
<listitem>
<simpara>If there are pending tasks, monitor their status. If their status changes and indicates that the cluster is recovering, continue waiting. The recovery time varies according to the size of the cluster and other factors. Otherwise, if the status of the pending tasks does not change, this indicates that the recovery has stalled.</simpara>
</listitem>
<listitem>
<simpara>If it seems like the recovery has stalled, check if the <literal>cluster.routing.allocation.enable</literal> value is set to <literal>none</literal>, by running the following command and observing the output:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=_cluster/settings?pretty</programlisting>
</listitem>
<listitem>
<simpara>If the <literal>cluster.routing.allocation.enable</literal> value is set to <literal>none</literal>, set it to <literal>all</literal>, by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=_cluster/settings?pretty \
  -X PUT -d '{"persistent": {"cluster.routing.allocation.enable":"all"}}'</programlisting>
</listitem>
<listitem>
<simpara>Check if any indices are still red by running the following command and observing the output:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=_cat/indices?v</programlisting>
</listitem>
<listitem>
<simpara>If any indices are still red, try to clear them by performing the following steps.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Clear the cache by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=&lt;elasticsearch_index_name&gt;/_cache/clear?pretty</programlisting>
</listitem>
<listitem>
<simpara>Increase the max allocation retries by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=&lt;elasticsearch_index_name&gt;/_settings?pretty \
  -X PUT -d '{"index.allocation.max_retries":10}'</programlisting>
</listitem>
<listitem>
<simpara>Delete all the scroll items by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=_search/scroll/_all -X DELETE</programlisting>
</listitem>
<listitem>
<simpara>Increase the timeout by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=&lt;elasticsearch_index_name&gt;/_settings?pretty \
  -X PUT -d '{"index.unassigned.node_left.delayed_timeout":"10m"}'</programlisting>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>If the preceding steps do not clear the red indices, delete the indices individually.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Identify the red index name by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=_cat/indices?v</programlisting>
</listitem>
<listitem>
<simpara>Delete the red index by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=&lt;elasticsearch_red_index_name&gt; -X DELETE</programlisting>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>If there are no red indices and the cluster status is red, check for a continuous heavy processing load on a data node.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Check if the Elasticsearch JVM Heap usage is high by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=_nodes/stats?pretty</programlisting>
<simpara>In the command output, review the <literal>node_name.jvm.mem.heap_used_percent</literal> field to determine the JVM Heap usage.</simpara>
</listitem>
<listitem>
<simpara>Check for high CPU utilization. For more information about CPU utilitzation, see the OpenShift Container Platform "Reviewing monitoring dashboards" documentation.</simpara>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/monitoring/#reviewing-monitoring-dashboards">Reviewing monitoring dashboards</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://www.elastic.co/guide/en/elasticsearch/reference/7.13/fix-common-cluster-issues.html#fix-red-yellow-cluster-status">Fix a red or yellow cluster status</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="elasticsearch-cluster-health-is-yellow">
<title>Elasticsearch cluster health status is yellow</title>
<simpara>Replica shards for at least one primary shard are not allocated to nodes. Increase the node count by adjusting the <literal>nodeCount</literal> value in the <literal>ClusterLogging</literal> custom resource (CR).</simpara>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://www.elastic.co/guide/en/elasticsearch/reference/7.13/fix-common-cluster-issues.html#fix-red-yellow-cluster-status">Fix a red or yellow cluster status</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="es-node-disk-low-watermark-reached_troubleshooting-logging-alerts">
<title>Elasticsearch node disk low watermark reached</title>
<simpara>Elasticsearch does not allocate shards to nodes that reach the low watermark.</simpara>
<tip>
<simpara>Some commands in this documentation reference an Elasticsearch pod by using a <literal>$ES_POD_NAME</literal> shell variable. If you want to copy and paste the commands directly from this documentation, you must set this variable to a value that is valid for your Elasticsearch cluster.</simpara>
<simpara>You can list the available Elasticsearch pods by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging get pods -l component=elasticsearch</programlisting>
<simpara>Choose one of the pods listed and set the <literal>$ES_POD_NAME</literal> variable, by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ export ES_POD_NAME=&lt;elasticsearch_pod_name&gt;</programlisting>
<simpara>You can now use the <literal>$ES_POD_NAME</literal> variable in commands.</simpara>
</tip>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Identify the node on which Elasticsearch is deployed by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging get po -o wide</programlisting>
</listitem>
<listitem>
<simpara>Check if there are unassigned shards by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=_cluster/health?pretty | grep unassigned_shards</programlisting>
</listitem>
<listitem>
<simpara>If there are unassigned shards, check the disk space on each node, by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ for pod in `oc -n openshift-logging get po -l component=elasticsearch -o jsonpath='{.items[*].metadata.name}'`; \
  do echo $pod; oc -n openshift-logging exec -c elasticsearch $pod \
  -- df -h /elasticsearch/persistent; done</programlisting>
</listitem>
<listitem>
<simpara>In the command output, check the <literal>Use</literal> column to determine the used disk percentage on that node.</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">elasticsearch-cdm-kcrsda6l-1-586cc95d4f-h8zq8
Filesystem      Size  Used Avail Use% Mounted on
/dev/nvme1n1     19G  522M   19G   3% /elasticsearch/persistent
elasticsearch-cdm-kcrsda6l-2-5b548fc7b-cwwk7
Filesystem      Size  Used Avail Use% Mounted on
/dev/nvme2n1     19G  522M   19G   3% /elasticsearch/persistent
elasticsearch-cdm-kcrsda6l-3-5dfc884d99-59tjw
Filesystem      Size  Used Avail Use% Mounted on
/dev/nvme3n1     19G  528M   19G   3% /elasticsearch/persistent</programlisting>
</para>
</formalpara>
<simpara>If the used disk percentage is above 85%, the node has exceeded the low watermark, and shards can no longer be allocated to this node.</simpara>
</listitem>
<listitem>
<simpara>To check the current <literal>redundancyPolicy</literal>, run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging get es elasticsearch \
  -o jsonpath='{.spec.redundancyPolicy}'</programlisting>
<simpara>If you are using a <literal>ClusterLogging</literal> resource on your cluster, run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging get cl \
  -o jsonpath='{.items[*].spec.logStore.elasticsearch.redundancyPolicy}'</programlisting>
<simpara>If the cluster <literal>redundancyPolicy</literal> value is higher than the <literal>SingleRedundancy</literal> value, set it to the <literal>SingleRedundancy</literal> value and save this change.</simpara>
</listitem>
<listitem>
<simpara>If the preceding steps do not fix the issue, delete the old indices.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Check the status of all indices on Elasticsearch by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME -- indices</programlisting>
</listitem>
<listitem>
<simpara>Identify an old index that can be deleted.</simpara>
</listitem>
<listitem>
<simpara>Delete the index by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=&lt;elasticsearch_index_name&gt; -X DELETE</programlisting>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
</section>
<section xml:id="es-node-disk-high-watermark-reached_troubleshooting-logging-alerts">
<title>Elasticsearch node disk high watermark reached</title>
<simpara>Elasticsearch attempts to relocate shards away from a node that has reached the high watermark to a node with low disk usage that has not crossed any watermark threshold limits.</simpara>
<simpara>To allocate shards to a particular node, you must free up some space on that node. If increasing the disk space is not possible, try adding a new data node to the cluster, or decrease the total cluster redundancy policy.</simpara>
<tip>
<simpara>Some commands in this documentation reference an Elasticsearch pod by using a <literal>$ES_POD_NAME</literal> shell variable. If you want to copy and paste the commands directly from this documentation, you must set this variable to a value that is valid for your Elasticsearch cluster.</simpara>
<simpara>You can list the available Elasticsearch pods by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging get pods -l component=elasticsearch</programlisting>
<simpara>Choose one of the pods listed and set the <literal>$ES_POD_NAME</literal> variable, by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ export ES_POD_NAME=&lt;elasticsearch_pod_name&gt;</programlisting>
<simpara>You can now use the <literal>$ES_POD_NAME</literal> variable in commands.</simpara>
</tip>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Identify the node on which Elasticsearch is deployed by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging get po -o wide</programlisting>
</listitem>
<listitem>
<simpara>Check the disk space on each node:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ for pod in `oc -n openshift-logging get po -l component=elasticsearch -o jsonpath='{.items[*].metadata.name}'`; \
  do echo $pod; oc -n openshift-logging exec -c elasticsearch $pod \
  -- df -h /elasticsearch/persistent; done</programlisting>
</listitem>
<listitem>
<simpara>Check if the cluster is rebalancing:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=_cluster/health?pretty | grep relocating_shards</programlisting>
<simpara>If the command output shows relocating shards, the high watermark has been exceeded. The default value of the high watermark is 90%.</simpara>
</listitem>
<listitem>
<simpara>Increase the disk space on all nodes. If increasing the disk space is not possible, try adding a new data node to the cluster, or decrease the total cluster redundancy policy.</simpara>
</listitem>
<listitem>
<simpara>To check the current <literal>redundancyPolicy</literal>, run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging get es elasticsearch \
  -o jsonpath='{.spec.redundancyPolicy}'</programlisting>
<simpara>If you are using a <literal>ClusterLogging</literal> resource on your cluster, run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging get cl \
  -o jsonpath='{.items[*].spec.logStore.elasticsearch.redundancyPolicy}'</programlisting>
<simpara>If the cluster <literal>redundancyPolicy</literal> value is higher than the <literal>SingleRedundancy</literal> value, set it to the <literal>SingleRedundancy</literal> value and save this change.</simpara>
</listitem>
<listitem>
<simpara>If the preceding steps do not fix the issue, delete the old indices.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Check the status of all indices on Elasticsearch by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME -- indices</programlisting>
</listitem>
<listitem>
<simpara>Identify an old index that can be deleted.</simpara>
</listitem>
<listitem>
<simpara>Delete the index by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=&lt;elasticsearch_index_name&gt; -X DELETE</programlisting>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
</section>
<section xml:id="es-node-disk-flood-watermark-reached_troubleshooting-logging-alerts">
<title>Elasticsearch node disk flood watermark reached</title>
<simpara>Elasticsearch enforces a read-only index block on every index that has both of these conditions:</simpara>
<itemizedlist>
<listitem>
<simpara>One or more shards are allocated to the node.</simpara>
</listitem>
<listitem>
<simpara>One or more disks exceed the <link xlink:href="https://www.elastic.co/guide/en/elasticsearch/reference/6.8/disk-allocator.html">flood stage</link>.</simpara>
</listitem>
</itemizedlist>
<simpara>Use the following procedure to troubleshoot this alert.</simpara>
<tip>
<simpara>Some commands in this documentation reference an Elasticsearch pod by using a <literal>$ES_POD_NAME</literal> shell variable. If you want to copy and paste the commands directly from this documentation, you must set this variable to a value that is valid for your Elasticsearch cluster.</simpara>
<simpara>You can list the available Elasticsearch pods by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging get pods -l component=elasticsearch</programlisting>
<simpara>Choose one of the pods listed and set the <literal>$ES_POD_NAME</literal> variable, by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ export ES_POD_NAME=&lt;elasticsearch_pod_name&gt;</programlisting>
<simpara>You can now use the <literal>$ES_POD_NAME</literal> variable in commands.</simpara>
</tip>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Get the disk space of the Elasticsearch node:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ for pod in `oc -n openshift-logging get po -l component=elasticsearch -o jsonpath='{.items[*].metadata.name}'`; \
  do echo $pod; oc -n openshift-logging exec -c elasticsearch $pod \
  -- df -h /elasticsearch/persistent; done</programlisting>
</listitem>
<listitem>
<simpara>In the command output, check the <literal>Avail</literal> column to determine the free disk space on that node.</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">elasticsearch-cdm-kcrsda6l-1-586cc95d4f-h8zq8
Filesystem      Size  Used Avail Use% Mounted on
/dev/nvme1n1     19G  522M   19G   3% /elasticsearch/persistent
elasticsearch-cdm-kcrsda6l-2-5b548fc7b-cwwk7
Filesystem      Size  Used Avail Use% Mounted on
/dev/nvme2n1     19G  522M   19G   3% /elasticsearch/persistent
elasticsearch-cdm-kcrsda6l-3-5dfc884d99-59tjw
Filesystem      Size  Used Avail Use% Mounted on
/dev/nvme3n1     19G  528M   19G   3% /elasticsearch/persistent</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Increase the disk space on all nodes. If increasing the disk space is not possible, try adding a new data node to the cluster, or decrease the total cluster redundancy policy.</simpara>
</listitem>
<listitem>
<simpara>To check the current <literal>redundancyPolicy</literal>, run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging get es elasticsearch \
  -o jsonpath='{.spec.redundancyPolicy}'</programlisting>
<simpara>If you are using a <literal>ClusterLogging</literal> resource on your cluster, run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging get cl \
  -o jsonpath='{.items[*].spec.logStore.elasticsearch.redundancyPolicy}'</programlisting>
<simpara>If the cluster <literal>redundancyPolicy</literal> value is higher than the <literal>SingleRedundancy</literal> value, set it to the <literal>SingleRedundancy</literal> value and save this change.</simpara>
</listitem>
<listitem>
<simpara>If the preceding steps do not fix the issue, delete the old indices.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Check the status of all indices on Elasticsearch by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME -- indices</programlisting>
</listitem>
<listitem>
<simpara>Identify an old index that can be deleted.</simpara>
</listitem>
<listitem>
<simpara>Delete the index by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=&lt;elasticsearch_index_name&gt; -X DELETE</programlisting>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Continue freeing up and monitoring the disk space. After the used disk space drops below 90%, unblock writing to this node by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=_all/_settings?pretty \
  -X PUT -d '{"index.blocks.read_only_allow_delete": null}'</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="troubleshooting-logging-alerts-es-jvm-heap-use-is-high">
<title>Elasticsearch JVM heap usage is high</title>
<simpara>The Elasticsearch node Java virtual machine (JVM) heap memory used is above 75%. Consider <link xlink:href="https://www.elastic.co/guide/en/elasticsearch/reference/current/advanced-configuration.html#set-jvm-heap-size">increasing the heap size</link>.</simpara>
</section>
<section xml:id="troubleshooting-logging-alerts-aggregated-logging-system-cpu-is-high">
<title>Aggregated logging system CPU is high</title>
<simpara>System CPU usage on the node is high. Check the CPU of the cluster node. Consider allocating more CPU resources to the node.</simpara>
</section>
<section xml:id="troubleshooting-logging-alerts-es-process-cpu-is-high">
<title>Elasticsearch process CPU is high</title>
<simpara>Elasticsearch process CPU usage on the node is high. Check the CPU of the cluster node. Consider allocating more CPU resources to the node.</simpara>
</section>
<section xml:id="es-disk-space-low_troubleshooting-logging-alerts">
<title>Elasticsearch disk space is running low</title>
<simpara>Elasticsearch is predicted to run out of disk space within the next 6 hours based on current disk usage. Use the following procedure to troubleshoot this alert.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Get the disk space of the Elasticsearch node:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ for pod in `oc -n openshift-logging get po -l component=elasticsearch -o jsonpath='{.items[*].metadata.name}'`; \
  do echo $pod; oc -n openshift-logging exec -c elasticsearch $pod \
  -- df -h /elasticsearch/persistent; done</programlisting>
</listitem>
<listitem>
<simpara>In the command output, check the <literal>Avail</literal> column to determine the free disk space on that node.</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">elasticsearch-cdm-kcrsda6l-1-586cc95d4f-h8zq8
Filesystem      Size  Used Avail Use% Mounted on
/dev/nvme1n1     19G  522M   19G   3% /elasticsearch/persistent
elasticsearch-cdm-kcrsda6l-2-5b548fc7b-cwwk7
Filesystem      Size  Used Avail Use% Mounted on
/dev/nvme2n1     19G  522M   19G   3% /elasticsearch/persistent
elasticsearch-cdm-kcrsda6l-3-5dfc884d99-59tjw
Filesystem      Size  Used Avail Use% Mounted on
/dev/nvme3n1     19G  528M   19G   3% /elasticsearch/persistent</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Increase the disk space on all nodes. If increasing the disk space is not possible, try adding a new data node to the cluster, or decrease the total cluster redundancy policy.</simpara>
</listitem>
<listitem>
<simpara>To check the current <literal>redundancyPolicy</literal>, run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging get es elasticsearch -o jsonpath='{.spec.redundancyPolicy}'</programlisting>
<simpara>If you are using a <literal>ClusterLogging</literal> resource on your cluster, run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging get cl \
  -o jsonpath='{.items[*].spec.logStore.elasticsearch.redundancyPolicy}'</programlisting>
<simpara>If the cluster <literal>redundancyPolicy</literal> value is higher than the <literal>SingleRedundancy</literal> value, set it to the <literal>SingleRedundancy</literal> value and save this change.</simpara>
</listitem>
<listitem>
<simpara>If the preceding steps do not fix the issue, delete the old indices.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Check the status of all indices on Elasticsearch by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME -- indices</programlisting>
</listitem>
<listitem>
<simpara>Identify an old index that can be deleted.</simpara>
</listitem>
<listitem>
<simpara>Delete the index by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch $ES_POD_NAME \
  -- es_util --query=&lt;elasticsearch_index_name&gt; -X DELETE</programlisting>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://www.elastic.co/guide/en/elasticsearch/reference/7.13/fix-common-cluster-issues.html#fix-red-yellow-cluster-status">Fix a red or yellow cluster status</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="troubleshooting-logging-alerts-es-filedescriptor-usage-is-high">
<title>Elasticsearch FileDescriptor usage is high</title>
<simpara>Based on current usage trends, the predicted number of file descriptors on the node is insufficient. Check the value of <literal>max_file_descriptors</literal> for each node as described in the Elasticsearch <link xlink:href="https://www.elastic.co/guide/en/elasticsearch/reference/6.8/file-descriptors.html">File Descriptors</link> documentation.</simpara>
</section>
</section>
<section xml:id="cluster-logging-log-store-status">
<title>Viewing the status of the Elasticsearch log store</title>

<simpara>You can view the status of the OpenShift Elasticsearch Operator and for a number of Elasticsearch components.</simpara>
<section xml:id="cluster-logging-log-store-comp-viewing_cluster-logging-elasticsearch">
<title>Viewing the status of the Elasticsearch log store</title>
<simpara>You can view the status of the Elasticsearch log store.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>The Red Hat OpenShift Logging Operator and OpenShift Elasticsearch Operator are installed.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Change to the <literal>openshift-logging</literal> project by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc project openshift-logging</programlisting>
</listitem>
<listitem>
<simpara>To view the status:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Get the name of the Elasticsearch log store instance by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get Elasticsearch</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME            AGE
elasticsearch   5h9m</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Get the Elasticsearch log store status by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get Elasticsearch &lt;Elasticsearch-instance&gt; -o yaml</programlisting>
<simpara>For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get Elasticsearch elasticsearch -n openshift-logging -o yaml</programlisting>
<simpara>The output includes information similar to the following:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">status: <co xml:id="CO3-1"/>
  cluster: <co xml:id="CO3-2"/>
    activePrimaryShards: 30
    activeShards: 60
    initializingShards: 0
    numDataNodes: 3
    numNodes: 3
    pendingTasks: 0
    relocatingShards: 0
    status: green
    unassignedShards: 0
  clusterHealth: ""
  conditions: [] <co xml:id="CO3-3"/>
  nodes: <co xml:id="CO3-4"/>
  - deploymentName: elasticsearch-cdm-zjf34ved-1
    upgradeStatus: {}
  - deploymentName: elasticsearch-cdm-zjf34ved-2
    upgradeStatus: {}
  - deploymentName: elasticsearch-cdm-zjf34ved-3
    upgradeStatus: {}
  pods: <co xml:id="CO3-5"/>
    client:
      failed: []
      notReady: []
      ready:
      - elasticsearch-cdm-zjf34ved-1-6d7fbf844f-sn422
      - elasticsearch-cdm-zjf34ved-2-dfbd988bc-qkzjz
      - elasticsearch-cdm-zjf34ved-3-c8f566f7c-t7zkt
    data:
      failed: []
      notReady: []
      ready:
      - elasticsearch-cdm-zjf34ved-1-6d7fbf844f-sn422
      - elasticsearch-cdm-zjf34ved-2-dfbd988bc-qkzjz
      - elasticsearch-cdm-zjf34ved-3-c8f566f7c-t7zkt
    master:
      failed: []
      notReady: []
      ready:
      - elasticsearch-cdm-zjf34ved-1-6d7fbf844f-sn422
      - elasticsearch-cdm-zjf34ved-2-dfbd988bc-qkzjz
      - elasticsearch-cdm-zjf34ved-3-c8f566f7c-t7zkt
  shardAllocationEnabled: all</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO3-1">
<para>In the output, the cluster status fields appear in the <literal>status</literal> stanza.</para>
</callout>
<callout arearefs="CO3-2">
<para>The status of the Elasticsearch log store:</para>
<itemizedlist>
<listitem>
<simpara>The number of active primary shards.</simpara>
</listitem>
<listitem>
<simpara>The number of active shards.</simpara>
</listitem>
<listitem>
<simpara>The number of shards that are initializing.</simpara>
</listitem>
<listitem>
<simpara>The number of Elasticsearch log store data nodes.</simpara>
</listitem>
<listitem>
<simpara>The total number of Elasticsearch log store nodes.</simpara>
</listitem>
<listitem>
<simpara>The number of pending tasks.</simpara>
</listitem>
<listitem>
<simpara>The Elasticsearch log store status: <literal>green</literal>, <literal>red</literal>, <literal>yellow</literal>.</simpara>
</listitem>
<listitem>
<simpara>The number of unassigned shards.</simpara>
</listitem>
</itemizedlist>
</callout>
<callout arearefs="CO3-3">
<para>Any status conditions, if present. The Elasticsearch log store status indicates the reasons from the scheduler if a pod could not be placed. Any events related to the following conditions are shown:</para>
<itemizedlist>
<listitem>
<simpara>Container Waiting for both the Elasticsearch log store and proxy containers.</simpara>
</listitem>
<listitem>
<simpara>Container Terminated for both the Elasticsearch log store and proxy containers.</simpara>
</listitem>
<listitem>
<simpara>Pod unschedulable.
Also, a condition is shown for a number of issues; see <emphasis role="strong">Example condition messages</emphasis>.</simpara>
</listitem>
</itemizedlist>
</callout>
<callout arearefs="CO3-4">
<para>The Elasticsearch log store nodes in the cluster, with <literal>upgradeStatus</literal>.</para>
</callout>
<callout arearefs="CO3-5">
<para>The Elasticsearch log store client, data, and master pods in the cluster, listed under <literal>failed</literal>, <literal>notReady</literal>, or <literal>ready</literal> state.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
<section xml:id="cluster-logging-elasticsearch-status-message_cluster-logging-elasticsearch">
<title>Example condition messages</title>
<simpara>The following are examples of some condition messages from the <literal>Status</literal> section of the Elasticsearch instance.</simpara>
<simpara>The following status message indicates that a node has exceeded the configured low watermark, and no shard will be allocated to this node.</simpara>
<programlisting language="yaml" linenumbering="unnumbered">status:
  nodes:
  - conditions:
    - lastTransitionTime: 2019-03-15T15:57:22Z
      message: Disk storage usage for node is 27.5gb (36.74%). Shards will be not
        be allocated on this node.
      reason: Disk Watermark Low
      status: "True"
      type: NodeStorage
    deploymentName: example-elasticsearch-cdm-0-1
    upgradeStatus: {}</programlisting>
<simpara>The following status message indicates that a node has exceeded the configured high watermark, and shards will be relocated to other nodes.</simpara>
<programlisting language="yaml" linenumbering="unnumbered">status:
  nodes:
  - conditions:
    - lastTransitionTime: 2019-03-15T16:04:45Z
      message: Disk storage usage for node is 27.5gb (36.74%). Shards will be relocated
        from this node.
      reason: Disk Watermark High
      status: "True"
      type: NodeStorage
    deploymentName: example-elasticsearch-cdm-0-1
    upgradeStatus: {}</programlisting>
<simpara>The following status message indicates that the Elasticsearch log store node selector in the custom resource (CR) does not match any nodes in the cluster:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">status:
    nodes:
    - conditions:
      - lastTransitionTime: 2019-04-10T02:26:24Z
        message: '0/8 nodes are available: 8 node(s) didn''t match node selector.'
        reason: Unschedulable
        status: "True"
        type: Unschedulable</programlisting>
<simpara>The following status message indicates that the Elasticsearch log store CR uses a non-existent persistent volume claim (PVC).</simpara>
<programlisting language="yaml" linenumbering="unnumbered">status:
   nodes:
   - conditions:
     - last Transition Time:  2019-04-10T05:55:51Z
       message:               pod has unbound immediate PersistentVolumeClaims (repeated 5 times)
       reason:                Unschedulable
       status:                True
       type:                  Unschedulable</programlisting>
<simpara>The following status message indicates that your Elasticsearch log store cluster does not have enough nodes to support the redundancy policy.</simpara>
<programlisting language="yaml" linenumbering="unnumbered">status:
  clusterHealth: ""
  conditions:
  - lastTransitionTime: 2019-04-17T20:01:31Z
    message: Wrong RedundancyPolicy selected. Choose different RedundancyPolicy or
      add more nodes with data roles
    reason: Invalid Settings
    status: "True"
    type: InvalidRedundancy</programlisting>
<simpara>This status message indicates your cluster has too many control plane nodes:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">status:
  clusterHealth: green
  conditions:
    - lastTransitionTime: '2019-04-17T20:12:34Z'
      message: &gt;-
        Invalid master nodes count. Please ensure there are no more than 3 total
        nodes with master roles
      reason: Invalid Settings
      status: 'True'
      type: InvalidMasters</programlisting>
<simpara>The following status message indicates that Elasticsearch storage does not support the change you tried to make.</simpara>
<simpara>For example:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">status:
  clusterHealth: green
  conditions:
    - lastTransitionTime: "2021-05-07T01:05:13Z"
      message: Changing the storage structure for a custom resource is not supported
      reason: StorageStructureChangeIgnored
      status: 'True'
      type: StorageStructureChangeIgnored</programlisting>
<simpara>The <literal>reason</literal> and <literal>type</literal> fields specify the type of unsupported change:</simpara>
<variablelist>
<varlistentry>
<term><literal>StorageClassNameChangeIgnored</literal></term>
<listitem>
<simpara>Unsupported change to the storage class name.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term><literal>StorageSizeChangeIgnored</literal></term>
<listitem>
<simpara>Unsupported change the storage size.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term><literal>StorageStructureChangeIgnored</literal></term>
<listitem>
<simpara>Unsupported change between ephemeral and persistent storage structures.</simpara>
<important>
<simpara>If you try to configure the <literal>ClusterLogging</literal> CR to switch from ephemeral to persistent storage, the OpenShift Elasticsearch Operator creates a persistent volume claim (PVC) but does not create a persistent volume (PV). To clear the <literal>StorageStructureChangeIgnored</literal> status, you must revert the change to the <literal>ClusterLogging</literal> CR and delete the PVC.</simpara>
</important>
</listitem>
</varlistentry>
</variablelist>
</section>
</section>
<section xml:id="cluster-logging-elasticsearch-status-comp_cluster-logging-elasticsearch">
<title>Viewing the status of the log store components</title>
<simpara>You can view the status for a number of the log store components.</simpara>
<variablelist>
<varlistentry>
<term>Elasticsearch indices</term>
<listitem>
<simpara>You can view the status of the Elasticsearch indices.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Get the name of an Elasticsearch pod:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods --selector component=elasticsearch -o name</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">pod/elasticsearch-cdm-1godmszn-1-6f8495-vp4lw
pod/elasticsearch-cdm-1godmszn-2-5769cf-9ms2n
pod/elasticsearch-cdm-1godmszn-3-f66f7d-zqkz7</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Get the status of the indices:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec elasticsearch-cdm-4vjor49p-2-6d4d7db474-q2w7z -- indices</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">Defaulting container name to elasticsearch.
Use 'oc describe pod/elasticsearch-cdm-4vjor49p-2-6d4d7db474-q2w7z -n openshift-logging' to see all of the containers in this pod.

green  open   infra-000002                                                     S4QANnf1QP6NgCegfnrnbQ   3   1     119926            0        157             78
green  open   audit-000001                                                     8_EQx77iQCSTzFOXtxRqFw   3   1          0            0          0              0
green  open   .security                                                        iDjscH7aSUGhIdq0LheLBQ   1   1          5            0          0              0
green  open   .kibana_-377444158_kubeadmin                                     yBywZ9GfSrKebz5gWBZbjw   3   1          1            0          0              0
green  open   infra-000001                                                     z6Dpe__ORgiopEpW6Yl44A   3   1     871000            0        874            436
green  open   app-000001                                                       hIrazQCeSISewG3c2VIvsQ   3   1       2453            0          3              1
green  open   .kibana_1                                                        JCitcBMSQxKOvIq6iQW6wg   1   1          0            0          0              0
green  open   .kibana_-1595131456_user1                                        gIYFIEGRRe-ka0W3okS-mQ   3   1          1            0          0              0</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>Log store pods</term>
<listitem>
<simpara>You can view the status of the pods that host the log store.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Get the name of a pod:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods --selector component=elasticsearch -o name</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">pod/elasticsearch-cdm-1godmszn-1-6f8495-vp4lw
pod/elasticsearch-cdm-1godmszn-2-5769cf-9ms2n
pod/elasticsearch-cdm-1godmszn-3-f66f7d-zqkz7</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Get the status of a pod:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc describe pod elasticsearch-cdm-1godmszn-1-6f8495-vp4lw</programlisting>
<simpara>The output includes the following status information:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">....
Status:             Running

....

Containers:
  elasticsearch:
    Container ID:   cri-o://b7d44e0a9ea486e27f47763f5bb4c39dfd2
    State:          Running
      Started:      Mon, 08 Jun 2020 10:17:56 -0400
    Ready:          True
    Restart Count:  0
    Readiness:  exec [/usr/share/elasticsearch/probe/readiness.sh] delay=10s timeout=30s period=5s #success=1 #failure=3

....

  proxy:
    Container ID:  cri-o://3f77032abaddbb1652c116278652908dc01860320b8a4e741d06894b2f8f9aa1
    State:          Running
      Started:      Mon, 08 Jun 2020 10:18:38 -0400
    Ready:          True
    Restart Count:  0

....

Conditions:
  Type              Status
  Initialized       True
  Ready             True
  ContainersReady   True
  PodScheduled      True

....

Events:          &lt;none&gt;</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>Log storage pod deployment configuration</term>
<listitem>
<simpara>You can view the status of the log store deployment configuration.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Get the name of a deployment configuration:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get deployment --selector component=elasticsearch -o name</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">deployment.extensions/elasticsearch-cdm-1gon-1
deployment.extensions/elasticsearch-cdm-1gon-2
deployment.extensions/elasticsearch-cdm-1gon-3</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Get the deployment configuration status:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc describe deployment elasticsearch-cdm-1gon-1</programlisting>
<simpara>The output includes the following status information:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">....
  Containers:
   elasticsearch:
    Image:      registry.redhat.io/openshift-logging/elasticsearch6-rhel8
    Readiness:  exec [/usr/share/elasticsearch/probe/readiness.sh] delay=10s timeout=30s period=5s #success=1 #failure=3

....

Conditions:
  Type           Status   Reason
  ----           ------   ------
  Progressing    Unknown  DeploymentPaused
  Available      True     MinimumReplicasAvailable

....

Events:          &lt;none&gt;</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>Log store replica set</term>
<listitem>
<simpara>You can view the status of the log store replica set.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Get the name of a replica set:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get replicaSet --selector component=elasticsearch -o name

replicaset.extensions/elasticsearch-cdm-1gon-1-6f8495
replicaset.extensions/elasticsearch-cdm-1gon-2-5769cf
replicaset.extensions/elasticsearch-cdm-1gon-3-f66f7d</programlisting>
</listitem>
<listitem>
<simpara>Get the status of the replica set:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc describe replicaSet elasticsearch-cdm-1gon-1-6f8495</programlisting>
<simpara>The output includes the following status information:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">....
  Containers:
   elasticsearch:
    Image:      registry.redhat.io/openshift-logging/elasticsearch6-rhel8@sha256:4265742c7cdd85359140e2d7d703e4311b6497eec7676957f455d6908e7b1c25
    Readiness:  exec [/usr/share/elasticsearch/probe/readiness.sh] delay=10s timeout=30s period=5s #success=1 #failure=3

....

Events:          &lt;none&gt;</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</listitem>
</varlistentry>
</variablelist>
</section>
<section xml:id="ref_cluster-logging-elasticsearch-cluster-status_cluster-logging-elasticsearch">
<title>Elasticsearch cluster status</title>
<simpara role="_abstract">A dashboard in the <emphasis role="strong">Observe</emphasis> section of the
OpenShift Container Platform web console
displays the status of the Elasticsearch cluster.</simpara>
<simpara>To get the status of the OpenShift Elasticsearch cluster, visit the dashboard in the <emphasis role="strong">Observe</emphasis> section of the
OpenShift Container Platform web console
at
<literal>&lt;cluster_url&gt;/monitoring/dashboards/grafana-dashboard-cluster-logging</literal>.</simpara>
<variablelist>
<title>Elasticsearch status fields</title>
<varlistentry>
<term><literal>eo_elasticsearch_cr_cluster_management_state</literal></term>
<listitem>
<simpara>Shows whether the Elasticsearch cluster is in a managed or unmanaged state. For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">eo_elasticsearch_cr_cluster_management_state{state="managed"} 1
eo_elasticsearch_cr_cluster_management_state{state="unmanaged"} 0</programlisting>
</listitem>
</varlistentry>
<varlistentry>
<term><literal>eo_elasticsearch_cr_restart_total</literal></term>
<listitem>
<simpara>Shows the number of times the Elasticsearch nodes have restarted for certificate restarts, rolling restarts, or scheduled restarts. For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">eo_elasticsearch_cr_restart_total{reason="cert_restart"} 1
eo_elasticsearch_cr_restart_total{reason="rolling_restart"} 1
eo_elasticsearch_cr_restart_total{reason="scheduled_restart"} 3</programlisting>
</listitem>
</varlistentry>
<varlistentry>
<term><literal>es_index_namespaces_total</literal></term>
<listitem>
<simpara>Shows the total number of Elasticsearch index namespaces. For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">Total number of Namespaces.
es_index_namespaces_total 5</programlisting>
</listitem>
</varlistentry>
<varlistentry>
<term><literal>es_index_document_count</literal></term>
<listitem>
<simpara>Shows the number of records for each namespace. For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">es_index_document_count{namespace="namespace_1"} 25
es_index_document_count{namespace="namespace_2"} 10
es_index_document_count{namespace="namespace_3"} 5</programlisting>
</listitem>
</varlistentry>
</variablelist>
<formalpara>
<title>The "Secret Elasticsearch fields are either missing or empty" message</title>
<para>If Elasticsearch is missing the <literal>admin-cert</literal>, <literal>admin-key</literal>, <literal>logging-es.crt</literal>, or <literal>logging-es.key</literal> files, the dashboard shows a status message similar to the following example:</para>
</formalpara>
<programlisting language="terminal" linenumbering="unnumbered">message": "Secret \"elasticsearch\" fields are either missing or empty: [admin-cert, admin-key, logging-es.crt, logging-es.key]",
"reason": "Missing Required Secrets",</programlisting>
</section>
</section>
</chapter>
<chapter xml:id="cluster-logging">
<title>About Logging</title>

<simpara>As a cluster administrator, you can deploy logging on an OpenShift Container Platform cluster, and use it to collect and aggregate node system audit logs, application container logs, and infrastructure logs. You can forward logs to your chosen log outputs, including on-cluster, Red&#160;Hat managed log storage. You can also visualize your log data in the OpenShift Container Platform web console, or the Kibana web console, depending on your deployed log storage solution.</simpara>
<note>
<simpara>The Kibana web console is now deprecated is planned to be removed in a future logging release.</simpara>
</note>
<simpara>OpenShift Container Platform cluster administrators can deploy logging by using Operators. For information, see <link linkend="cluster-logging-deploying">Installing logging</link>.</simpara>
<simpara>The Operators are responsible for deploying, upgrading, and maintaining logging. After the Operators are installed, you can create a <literal>ClusterLogging</literal> custom resource (CR) to schedule logging pods and other resources necessary to support logging. You can also create a <literal>ClusterLogForwarder</literal> CR to specify which logs are collected, how they are transformed, and where they are forwarded to.</simpara>
<note>
<simpara>Because the internal OpenShift Container Platform Elasticsearch log store does not provide secure storage for audit logs, audit logs are not stored in the internal Elasticsearch instance by default. If you want to send the audit logs to the default internal Elasticsearch log store, for example to view the audit logs in Kibana, you must use the Log Forwarding API as described in <link linkend="cluster-logging-elasticsearch-audit_logging-config-es-store">Forward audit logs to the log store</link>.</simpara>
</note>
<section xml:id="logging-architecture-overview_cluster-logging">
<title>Logging architecture</title>
<simpara>The major components of the logging are:</simpara>
<variablelist>
<varlistentry>
<term>Collector</term>
<listitem>
<simpara>The collector is a daemonset that deploys pods to each OpenShift Container Platform node. It collects log data from each node, transforms the data, and forwards it to configured outputs. You can use the Vector collector or the legacy Fluentd collector.</simpara>
<note>
<simpara>Fluentd is deprecated and is planned to be removed in a future release. Red Hat provides bug fixes and support for this feature during the current release lifecycle, but this feature no longer receives enhancements. As an alternative to Fluentd, you can use Vector instead.</simpara>
</note>
</listitem>
</varlistentry>
<varlistentry>
<term>Log store</term>
<listitem>
<simpara>The log store stores log data for analysis and is the default output for the log forwarder. You can use the default LokiStack log store, the legacy Elasticsearch log store, or forward logs to additional external log stores.</simpara>
<note>
<simpara>The OpenShift Elasticsearch Operator is deprecated and is planned to be removed in a future release. Red&#160;Hat provides bug fixes and support for this feature during the current release lifecycle, but this feature no longer receives enhancements. As an alternative to using the OpenShift Elasticsearch Operator to manage the default log storage, you can use the Loki Operator.</simpara>
</note>
</listitem>
</varlistentry>
<varlistentry>
<term>Visualization</term>
<listitem>
<simpara>You can use a UI component to view a visual representation of your log data. The UI provides a graphical interface to search, query, and view stored logs. The OpenShift Container Platform web console UI is provided by enabling the OpenShift Container Platform console plugin.</simpara>
<note>
<simpara>The Kibana web console is now deprecated is planned to be removed in a future logging release.</simpara>
</note>
</listitem>
</varlistentry>
</variablelist>
<simpara>Logging collects container logs and node logs. These are categorized into types:</simpara>
<variablelist>
<varlistentry>
<term>Application logs</term>
<listitem>
<simpara>Container logs generated by user applications running in the cluster, except infrastructure container applications.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Infrastructure logs</term>
<listitem>
<simpara>Container logs generated by infrastructure namespaces: <literal>openshift*</literal>, <literal>kube*</literal>, or <literal>default</literal>, as well as journald messages from nodes.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Audit logs</term>
<listitem>
<simpara>Logs generated by auditd, the node audit system, which are stored in the <emphasis role="strong">/var/log/audit/audit.log</emphasis> file, and logs from the <literal>auditd</literal>, <literal>kube-apiserver</literal>, <literal>openshift-apiserver</literal> services, as well as the <literal>ovn</literal> project if enabled.</simpara>
</listitem>
</varlistentry>
</variablelist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link linkend="log-visualization-ocp-console">Log visualization with the web console</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="cluster-logging-about_cluster-logging">
<title>About deploying logging</title>
<simpara>Administrators can deploy the logging by using the OpenShift Container Platform web console or the OpenShift CLI (<literal>oc</literal>) to install the logging Operators. The Operators are responsible for deploying, upgrading, and maintaining the logging.</simpara>
<simpara>Administrators and application developers can view the logs of the projects for which they have view access.</simpara>
<section xml:id="cluster-logging-about-custom-resources_cluster-logging">
<title>Logging custom resources</title>
<simpara>You can configure your logging deployment with custom resource (CR) YAML files implemented by each Operator.</simpara>
<simpara><emphasis role="strong">Red Hat OpenShift Logging Operator</emphasis>:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>ClusterLogging</literal> (CL) - After the Operators are installed, you create a <literal>ClusterLogging</literal> custom resource (CR) to schedule logging pods and other resources necessary to support the logging. The <literal>ClusterLogging</literal> CR deploys the collector and forwarder, which currently are both implemented by a daemonset running on each node. The Red Hat OpenShift Logging Operator watches the <literal>ClusterLogging</literal> CR and adjusts the logging deployment accordingly.</simpara>
</listitem>
<listitem>
<simpara><literal>ClusterLogForwarder</literal> (CLF) - Generates collector configuration to forward logs per user configuration.</simpara>
</listitem>
</itemizedlist>
<simpara><emphasis role="strong">Loki Operator</emphasis>:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>LokiStack</literal> - Controls the Loki cluster as log store and the web proxy with OpenShift Container Platform authentication integration to enforce multi-tenancy.</simpara>
</listitem>
</itemizedlist>
<simpara><emphasis role="strong">OpenShift Elasticsearch Operator</emphasis>:</simpara>
<note>
<simpara>These CRs are generated and managed by the OpenShift Elasticsearch Operator. Manual changes cannot be made without being overwritten by the Operator.</simpara>
</note>
<itemizedlist>
<listitem>
<simpara><literal>ElasticSearch</literal> - Configure and deploy an Elasticsearch instance as the default log store.</simpara>
</listitem>
<listitem>
<simpara><literal>Kibana</literal> - Configure and deploy Kibana instance to search, query and view logs.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="cluster-logging-json-logging-about_cluster-logging">
<title>About JSON OpenShift Container Platform Logging</title>
<simpara>You can use JSON logging to configure the Log Forwarding API to parse JSON strings into a structured object. You can perform the following tasks:</simpara>
<itemizedlist>
<listitem>
<simpara>Parse JSON logs</simpara>
</listitem>
<listitem>
<simpara>Configure JSON log data for Elasticsearch</simpara>
</listitem>
<listitem>
<simpara>Forward JSON logs to the Elasticsearch log store</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="cluster-logging-collecting-storing-kubernetes-events-about_cluster-logging">
<title>About collecting and storing Kubernetes events</title>
<simpara>The OpenShift Container Platform Event Router is a pod that watches Kubernetes events and logs them for collection by OpenShift Container Platform Logging. You must manually deploy the Event Router.</simpara>
<simpara>For information, see <link linkend="cluster-logging-eventrouter">About collecting and storing Kubernetes events</link>.</simpara>
</section>
<section xml:id="cluster-logging-troubleshoot-logging-about_cluster-logging">
<title>About troubleshooting OpenShift Container Platform Logging</title>
<simpara>You can troubleshoot the logging issues by performing the following tasks:</simpara>
<itemizedlist>
<listitem>
<simpara>Viewing logging status</simpara>
</listitem>
<listitem>
<simpara>Viewing the status of the log store</simpara>
</listitem>
<listitem>
<simpara>Understanding logging alerts</simpara>
</listitem>
<listitem>
<simpara>Collecting logging data for Red Hat Support</simpara>
</listitem>
<listitem>
<simpara>Troubleshooting for critical alerts</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="cluster-logging-export-fields-about_cluster-logging">
<title>About exporting fields</title>
<simpara>The logging system exports fields. Exported fields are present in the log records and are available for searching from Elasticsearch and Kibana.</simpara>
<simpara>For information, see <link linkend="cluster-logging-exported-fields">About exporting fields</link>.</simpara>
</section>
<section xml:id="cluster-logging-eventrouter-about_cluster-logging">
<title>About event routing</title>
<simpara>The Event Router is a pod that watches OpenShift Container Platform events so they can be collected by logging.
The Event Router collects events from all projects and writes them to <literal>STDOUT</literal>. Fluentd collects those events and forwards them into the OpenShift Container Platform Elasticsearch instance. Elasticsearch indexes the events to the <literal>infra</literal> index.</simpara>
<simpara>You must manually deploy the Event Router.</simpara>
<simpara>For information, see <link linkend="cluster-logging-eventrouter">Collecting and storing Kubernetes events</link>.</simpara>
</section>
</section>
</chapter>
<chapter xml:id="cluster-logging-deploying">
<title>Installing Logging</title>

<simpara>You can deploy logging by installing the Red Hat OpenShift Logging Operator. The Red Hat OpenShift Logging Operator creates and manages the components of the logging stack.</simpara>
<note>
<simpara>Logging is provided as an installable component, with a distinct release cycle from the core OpenShift Container Platform. The <link xlink:href="https://access.redhat.com/support/policy/updates/openshift_operators#platform-agnostic">Red Hat OpenShift Container Platform Life Cycle Policy</link> outlines release compatibility.</simpara>
</note>
<important>
<simpara>For new installations, use Vector and LokiStack. Elasticsearch and Fluentd are deprecated and are planned to be removed in a future release.</simpara>
</important>
<section xml:id="cluster-logging-deploy-console_cluster-logging-deploying">
<title>Installing the Red Hat OpenShift Logging Operator by using the web console</title>
<simpara>You can install the Red Hat OpenShift Logging Operator by using the OpenShift Container Platform web console.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have access to the OpenShift Container Platform web console.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the OpenShift Container Platform web console, click <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">OperatorHub</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Type <literal>OpenShift Logging</literal> in the <emphasis role="strong">Filter by keyword</emphasis> box.</simpara>
</listitem>
<listitem>
<simpara>Choose  <emphasis role="strong">Red Hat OpenShift Logging</emphasis> from the list of available Operators, and click <emphasis role="strong">Install</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">stable-5.y</emphasis> as the <emphasis role="strong">Update channel</emphasis>.</simpara>
<note>
<simpara>The <emphasis role="strong">stable</emphasis> channel only provides updates to the most recent release of logging. To continue receiving updates for prior releases, you must change your subscription channel to <emphasis role="strong">stable-x.y</emphasis>, where <literal>x.y</literal> represents the major and minor version of logging you have installed. For example, <emphasis role="strong">stable-5.7</emphasis>.</simpara>
</note>
</listitem>
<listitem>
<simpara>Select a <emphasis role="strong">Version</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Ensure that <emphasis role="strong">A specific namespace on the cluster</emphasis> is selected under <emphasis role="strong">Installation mode</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Ensure that <emphasis role="strong">Operator recommended namespace</emphasis> is <emphasis role="strong">openshift-logging</emphasis> under <emphasis role="strong">Installed Namespace</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select an <emphasis role="strong">Update approval</emphasis>.</simpara>
<itemizedlist>
<listitem>
<simpara>The <emphasis role="strong">Automatic</emphasis> strategy allows Operator Lifecycle Manager (OLM) to automatically update the Operator when a new version is available.</simpara>
</listitem>
<listitem>
<simpara>The <emphasis role="strong">Manual</emphasis> strategy requires a user with appropriate credentials to approve the Operator update.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">Enable</emphasis> or <emphasis role="strong">Disable</emphasis> for the <emphasis role="strong">Console plugin</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Install</emphasis>.</simpara>
</listitem>
</orderedlist>
<orderedlist numeration="arabic">
<title>Verification</title>
<listitem>
<simpara>Verify that the <emphasis role="strong">Red Hat OpenShift Logging Operator</emphasis> is installed by switching to the <emphasis role="strong">Operators</emphasis> → <emphasis role="strong">Installed Operators</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Status</emphasis> column, verify that you see green checkmarks with <emphasis role="strong">InstallSucceeded</emphasis> and the text <emphasis role="strong">Up to date</emphasis>.</simpara>
</listitem>
</orderedlist>
<important>
<simpara>An Operator might display a <literal>Failed</literal> status before the installation finishes. If the Operator install completes with an <literal>InstallSucceeded</literal> message, refresh the page.</simpara>
</important>
<simpara>If the Operator does not show as installed, choose one of the following troubleshooting options:</simpara>
<itemizedlist>
<listitem>
<simpara>Go to the <emphasis role="strong">Operators</emphasis> → <emphasis role="strong">Installed Operators</emphasis> page, and inspect the <emphasis role="strong">Status</emphasis> column for any errors or failures.</simpara>
</listitem>
<listitem>
<simpara>Go to the <emphasis role="strong">Workloads</emphasis> → <emphasis role="strong">Pods</emphasis> page, and check the logs in any pods in the <literal>openshift-logging</literal> project that are reporting issues.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="create-cluster-logging-cr-console_cluster-logging-deploying">
<title>Creating a ClusterLogging object by using the web console</title>
<simpara>After you have installed the logging Operators, you must create a <literal>ClusterLogging</literal> custom resource to configure log storage, visualization, and the log collector for your cluster.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator.</simpara>
</listitem>
<listitem>
<simpara>You have access to the OpenShift Container Platform web console <emphasis role="strong">Administrator</emphasis> perspective.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to the <emphasis role="strong">Custom Resource Definitions</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>On the <emphasis role="strong">Custom Resource Definitions</emphasis> page, click <emphasis role="strong">ClusterLogging</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>On the <emphasis role="strong">Custom Resource Definition details</emphasis> page, select <emphasis role="strong">View Instances</emphasis> from the <emphasis role="strong">Actions</emphasis> menu.</simpara>
</listitem>
<listitem>
<simpara>On the <emphasis role="strong">ClusterLoggings</emphasis> page, click <emphasis role="strong">Create ClusterLogging</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">collection</emphasis> section, select a <emphasis role="strong">Collector Implementation</emphasis>.</simpara>
<note>
<simpara>Fluentd is deprecated and is planned to be removed in a future release. Red Hat provides bug fixes and support for this feature during the current release lifecycle, but this feature no longer receives enhancements. As an alternative to Fluentd, you can use Vector instead.</simpara>
</note>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">logStore</emphasis> section, select a type.</simpara>
<note>
<simpara>The OpenShift Elasticsearch Operator is deprecated and is planned to be removed in a future release. Red&#160;Hat provides bug fixes and support for this feature during the current release lifecycle, but this feature no longer receives enhancements. As an alternative to using the OpenShift Elasticsearch Operator to manage the default log storage, you can use the Loki Operator.</simpara>
</note>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Create</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="cluster-logging-deploy-cli_cluster-logging-deploying">
<title>Installing the Red Hat OpenShift Logging Operator by using the CLI</title>
<simpara>You can use the OpenShift CLI (<literal>oc</literal>) to install the Red Hat OpenShift Logging Operator.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a <literal>Namespace</literal> object as a YAML file:</simpara>
<formalpara>
<title>Example <literal>Namespace</literal> object</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Namespace
metadata:
  name: &lt;name&gt; <co xml:id="CO4-1"/>
  annotations:
    openshift.io/node-selector: ""
  labels:
    openshift.io/cluster-monitoring: "true"</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO4-1">
<para>You must specify <literal>openshift-logging</literal> as the name of the namespace for logging versions 5.7 and earlier versions. For logging 5.8 and later versions, you can use any name.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>Namespace</literal> object by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
<listitem>
<simpara>Create an <literal>OperatorGroup</literal> object as a YAML file:</simpara>
<formalpara>
<title>Example <literal>OperatorGroup</literal> object</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: cluster-logging
  namespace: openshift-logging <co xml:id="CO5-1"/>
spec:
  targetNamespaces:
  - openshift-logging <co xml:id="CO5-2"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO5-1 CO5-2">
<para>You must specify the <literal>openshift-logging</literal> namespace for logging versions 5.7 and older. For logging 5.8 and later versions, you can use any namespace.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>OperatorGroup</literal> object by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
<listitem>
<simpara>Create a <literal>Subscription</literal> object to subscribe the namespace to the Red Hat OpenShift Logging Operator:</simpara>
<formalpara>
<title>Example <literal>Subscription</literal> object</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: cluster-logging
  namespace: openshift-logging <co xml:id="CO6-1"/>
spec:
  channel: stable <co xml:id="CO6-2"/>
  name: cluster-logging
  source: redhat-operators <co xml:id="CO6-3"/>
  sourceNamespace: openshift-marketplace</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO6-1">
<para>You must specify the <literal>openshift-logging</literal> namespace for logging versions 5.7 and older. For logging 5.8 and later versions, you can use any namespace.</para>
</callout>
<callout arearefs="CO6-2">
<para>Specify <literal>stable</literal> or <literal>stable-x.y</literal> as the channel.</para>
</callout>
<callout arearefs="CO6-3">
<para>Specify <literal>redhat-operators</literal>. If your OpenShift Container Platform cluster is installed on a restricted network, also known as a disconnected cluster, specify the name of the <literal>CatalogSource</literal> object you created when you configured the Operator Lifecycle Manager (OLM).</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the subscription by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
<simpara>The Red Hat OpenShift Logging Operator is installed to the <literal>openshift-logging</literal> namespace.</simpara>
</listitem>
</orderedlist>
<orderedlist numeration="arabic">
<title>Verification</title>
<listitem>
<simpara>Run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get csv -n &lt;namespace&gt;</programlisting>
</listitem>
<listitem>
<simpara>Observe the output and confirm that the Red Hat OpenShift Logging Operator exists in the namespace:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAMESPACE                                               NAME                                         DISPLAY                  VERSION               REPLACES   PHASE
...
openshift-logging                                       clusterlogging.5.8.0-202007012112.p0         OpenShift Logging          5.8.0-202007012112.p0              Succeeded
...</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</section>
<section xml:id="create-cluster-logging-cli_cluster-logging-deploying">
<title>Creating a ClusterLogging object by using the CLI</title>
<simpara>This default logging configuration supports a wide array of environments. Review the topics on tuning and configuring components for information about modifications you can make.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator.</simpara>
</listitem>
<listitem>
<simpara>You have installed the OpenShift Elasticsearch Operator for your log store.</simpara>
</listitem>
<listitem>
<simpara>You have installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a <literal>ClusterLogging</literal> object as a YAML file:</simpara>
<formalpara>
<title>Example <literal>ClusterLogging</literal> object</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
  name: instance <co xml:id="CO7-1"/>
  namespace: openshift-logging
spec:
  managementState: Managed <co xml:id="CO7-2"/>
  logStore:
    type: elasticsearch <co xml:id="CO7-3"/>
    retentionPolicy: <co xml:id="CO7-4"/>
      application:
        maxAge: 1d
      infra:
        maxAge: 7d
      audit:
        maxAge: 7d
    elasticsearch:
      nodeCount: 3 <co xml:id="CO7-5"/>
      storage:
        storageClassName: &lt;storage_class_name&gt; <co xml:id="CO7-6"/>
        size: 200G
      resources: <co xml:id="CO7-7"/>
          limits:
            memory: 16Gi
          requests:
            memory: 16Gi
      proxy: <co xml:id="CO7-8"/>
        resources:
          limits:
            memory: 256Mi
          requests:
            memory: 256Mi
      redundancyPolicy: SingleRedundancy
  visualization:
    type: kibana <co xml:id="CO7-9"/>
    kibana:
      replicas: 1
  collection:
    type: fluentd <co xml:id="CO7-10"/>
    fluentd: {}</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO7-1">
<para>The name must be <literal>instance</literal>.</para>
</callout>
<callout arearefs="CO7-2">
<para>The OpenShift Logging management state. In some cases, if you change the OpenShift Logging defaults, you must set this to <literal>Unmanaged</literal>.
However, an unmanaged deployment does not receive updates until OpenShift Logging is placed back into a managed state.</para>
</callout>
<callout arearefs="CO7-3">
<para>Settings for configuring Elasticsearch. Using the CR, you can configure shard replication policy and persistent storage.</para>
</callout>
<callout arearefs="CO7-4">
<para>Specify the length of time that Elasticsearch should retain each log source. Enter an integer and a time designation: weeks(w), hours(h/H), minutes(m) and seconds(s). For example, <literal>7d</literal> for seven days. Logs older than the <literal>maxAge</literal> are deleted. You must specify a retention policy for each log source or the Elasticsearch indices will not be created for that source.</para>
</callout>
<callout arearefs="CO7-5">
<para>Specify the number of Elasticsearch nodes. See the note that follows this list.</para>
</callout>
<callout arearefs="CO7-6">
<para>Enter the name of an existing storage class for Elasticsearch storage. For best performance, specify a storage class that allocates block storage. If you do not specify a storage class, OpenShift Logging uses ephemeral storage.</para>
</callout>
<callout arearefs="CO7-7">
<para>Specify the CPU and memory requests for Elasticsearch as needed. If you leave these values blank, the OpenShift Elasticsearch Operator sets default values that should be sufficient for most deployments. The default values are <literal>16Gi</literal> for the memory request and <literal>1</literal> for the CPU request.</para>
</callout>
<callout arearefs="CO7-8">
<para>Specify the CPU and memory requests for the Elasticsearch proxy as needed. If you leave these values blank, the OpenShift Elasticsearch Operator sets default values that should be sufficient for most deployments. The default values are <literal>256Mi</literal> for the memory request and <literal>100m</literal> for the CPU request.</para>
</callout>
<callout arearefs="CO7-9">
<para>Settings for configuring Kibana. Using the CR, you can scale Kibana for redundancy and configure the CPU and memory for your Kibana nodes. For more information, see <emphasis role="strong">Configuring the log visualizer</emphasis>.</para>
</callout>
<callout arearefs="CO7-10">
<para>Settings for configuring Fluentd. Using the CR, you can configure Fluentd CPU and memory limits. For more information, see "Configuring Fluentd".</para>
</callout>
</calloutlist>
<note>
<simpara>The maximum number of Elasticsearch control plane nodes is three. If you specify a <literal>nodeCount</literal> greater than <literal>3</literal>, OpenShift Container Platform creates three Elasticsearch nodes that are Master-eligible nodes, with the master, client, and data roles. The additional Elasticsearch nodes are created as data-only nodes, using client and data roles. Control plane nodes perform cluster-wide actions such as creating or deleting an index, shard allocation, and tracking nodes. Data nodes hold the shards and perform data-related operations such as CRUD, search, and aggregations. Data-related operations are I/O-, memory-, and CPU-intensive. It is important to monitor these resources and to add more Data nodes if the current nodes are overloaded.</simpara>
<simpara>For example, if <literal>nodeCount=4</literal>, the following nodes are created:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get deployment</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
cluster-logging-operator       1/1     1            1           18h
elasticsearch-cd-x6kdekli-1    1/1     1            1          6m54s
elasticsearch-cdm-x6kdekli-1   1/1     1            1           18h
elasticsearch-cdm-x6kdekli-2   1/1     1            1           6m49s
elasticsearch-cdm-x6kdekli-3   1/1     1            1           6m44s</programlisting>
</para>
</formalpara>
<simpara>The number of primary shards for the index templates is equal to the number of Elasticsearch data nodes.</simpara>
</note>
</listitem>
</orderedlist>
<formalpara>
<title>Verification</title>
<para>You can verify the installation by listing the pods in the <literal>openshift-logging</literal> project.</para>
</formalpara>
<itemizedlist>
<listitem>
<simpara>List the pods by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods -n openshift-logging</programlisting>
<simpara>Observe the pods for components of the logging, similar to the following list:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                                            READY   STATUS    RESTARTS   AGE
cluster-logging-operator-66f77ffccb-ppzbg       1/1     Running   0          7m
elasticsearch-cdm-ftuhduuw-1-ffc4b9566-q6bhp    2/2     Running   0          2m40s
elasticsearch-cdm-ftuhduuw-2-7b4994dbfc-rd2gc   2/2     Running   0          2m36s
elasticsearch-cdm-ftuhduuw-3-84b5ff7ff8-gqnm2   2/2     Running   0          2m4s
collector-587vb                                   1/1     Running   0          2m26s
collector-7mpb9                                   1/1     Running   0          2m30s
collector-flm6j                                   1/1     Running   0          2m33s
collector-gn4rn                                   1/1     Running   0          2m26s
collector-nlgb6                                   1/1     Running   0          2m30s
collector-snpkt                                   1/1     Running   0          2m28s
kibana-d6d5668c5-rppqm                          2/2     Running   0          2m39s</programlisting>
</para>
</formalpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="cluster-logging-deploying-postinstallation">
<title>Postinstallation tasks</title>
<simpara>After you have installed the Red Hat OpenShift Logging Operator, you can configure your deployment by creating and modifying a <literal>ClusterLogging</literal> custom resource (CR).</simpara>
<tip>
<simpara>If you are not using the Elasticsearch log store, you can remove the internal Elasticsearch <literal>logStore</literal> and Kibana <literal>visualization</literal> components from the <literal>ClusterLogging</literal> custom resource (CR). Removing these components is optional but saves resources. See <link linkend="cluster-logging-removing-unused-components-if-no-elasticsearch_logging-config-es-store">Removing unused components if you do not use the Elasticsearch log store</link>.</simpara>
</tip>
<section xml:id="cluster-logging-about-crd_cluster-logging-deploying">
<title>About the ClusterLogging custom resource</title>
<simpara>To make changes to your logging environment, create and modify the <literal>ClusterLogging</literal> custom resource (CR).</simpara>
<formalpara>
<title>Sample <literal>ClusterLogging</literal> custom resource (CR)</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
  name: instance <co xml:id="CO8-1"/>
  namespace: openshift-logging <co xml:id="CO8-2"/>
spec:
  managementState: Managed <co xml:id="CO8-3"/>
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO8-1">
<para>The CR name must be <literal>instance</literal>.</para>
</callout>
<callout arearefs="CO8-2">
<para>The CR must be installed to the <literal>openshift-logging</literal> namespace.</para>
</callout>
<callout arearefs="CO8-3">
<para>The Red Hat OpenShift Logging Operator management state. When the state is set to <literal>unmanaged</literal>, the Operator is in an unsupported state and does not receive updates.</para>
</callout>
</calloutlist>
</section>
<section xml:id="configuring-log-storage-cr_cluster-logging-deploying">
<title>Configuring log storage</title>
<simpara>You can configure which log storage type your logging uses by modifying the <literal>ClusterLogging</literal> custom resource (CR).</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator and an internal log store that is either the LokiStack or Elasticsearch.</simpara>
</listitem>
<listitem>
<simpara>You have created a <literal>ClusterLogging</literal> CR.</simpara>
</listitem>
</itemizedlist>
<note>
<simpara>The OpenShift Elasticsearch Operator is deprecated and is planned to be removed in a future release. Red&#160;Hat provides bug fixes and support for this feature during the current release lifecycle, but this feature no longer receives enhancements. As an alternative to using the OpenShift Elasticsearch Operator to manage the default log storage, you can use the Loki Operator.</simpara>
</note>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Modify the <literal>ClusterLogging</literal> CR <literal>logStore</literal> spec:</simpara>
<formalpara>
<title><literal>ClusterLogging</literal> CR example</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
# ...
spec:
# ...
  logStore:
    type: &lt;log_store_type&gt; <co xml:id="CO9-1"/>
    elasticsearch: <co xml:id="CO9-2"/>
      nodeCount: &lt;integer&gt;
      resources: {}
      storage: {}
      redundancyPolicy: &lt;redundancy_type&gt; <co xml:id="CO9-3"/>
    lokistack: <co xml:id="CO9-4"/>
      name: {}
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO9-1">
<para>Specify the log store type. This can be either <literal>lokistack</literal> or <literal>elasticsearch</literal>.</para>
</callout>
<callout arearefs="CO9-2">
<para>Optional configuration options for the Elasticsearch log store.</para>
</callout>
<callout arearefs="CO9-3">
<para>Specify the redundancy type. This value can be <literal>ZeroRedundancy</literal>, <literal>SingleRedundancy</literal>, <literal>MultipleRedundancy</literal>, or <literal>FullRedundancy</literal>.</para>
</callout>
<callout arearefs="CO9-4">
<para>Optional configuration options for LokiStack.</para>
</callout>
</calloutlist>
<formalpara>
<title>Example <literal>ClusterLogging</literal> CR to specify LokiStack as the log store</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
  name: instance
  namespace: openshift-logging
spec:
  managementState: Managed
  logStore:
    type: lokistack
    lokistack:
      name: logging-loki
# ...</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Apply the <literal>ClusterLogging</literal> CR by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="configuring-logging-collector_cluster-logging-deploying">
<title>Configuring the log collector</title>
<simpara>You can configure which log collector type your logging uses by modifying the <literal>ClusterLogging</literal> custom resource (CR).</simpara>
<note>
<simpara>Fluentd is deprecated and is planned to be removed in a future release. Red Hat provides bug fixes and support for this feature during the current release lifecycle, but this feature no longer receives enhancements. As an alternative to Fluentd, you can use Vector instead.</simpara>
</note>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator.</simpara>
</listitem>
<listitem>
<simpara>You have created a <literal>ClusterLogging</literal> CR.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Modify the <literal>ClusterLogging</literal> CR <literal>collection</literal> spec:</simpara>
<formalpara>
<title><literal>ClusterLogging</literal> CR example</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
# ...
spec:
# ...
  collection:
    type: &lt;log_collector_type&gt; <co xml:id="CO10-1"/>
    resources: {}
    tolerations: {}
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO10-1">
<para>The log collector type you want to use for the logging. This can be <literal>vector</literal> or <literal>fluentd</literal>.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>ClusterLogging</literal> CR by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="configuring-log-visualizer_cluster-logging-deploying">
<title>Configuring the log visualizer</title>
<simpara>You can configure which log visualizer type your logging uses by modifying the <literal>ClusterLogging</literal> custom resource (CR).</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator.</simpara>
</listitem>
<listitem>
<simpara>You have created a <literal>ClusterLogging</literal> CR.</simpara>
</listitem>
</itemizedlist>
<important>
<simpara>If you want to use the OpenShift Container Platform web console for visualization, you must enable the logging Console Plugin. See the documentation about "Log visualization with the web console".</simpara>
</important>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Modify the <literal>ClusterLogging</literal> CR <literal>visualization</literal> spec:</simpara>
<formalpara>
<title><literal>ClusterLogging</literal> CR example</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
# ...
spec:
# ...
  visualization:
    type: &lt;visualizer_type&gt; <co xml:id="CO11-1"/>
    kibana: <co xml:id="CO11-2"/>
      resources: {}
      nodeSelector: {}
      proxy: {}
      replicas: {}
      tolerations: {}
    ocpConsole: <co xml:id="CO11-3"/>
      logsLimit: {}
      timeout: {}
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO11-1">
<para>The type of visualizer you want to use for your logging. This can be either <literal>kibana</literal> or <literal>ocp-console</literal>. The Kibana console is only compatible with deployments that use Elasticsearch log storage, while the OpenShift Container Platform console is only compatible with LokiStack deployments.</para>
</callout>
<callout arearefs="CO11-2">
<para>Optional configurations for the Kibana console.</para>
</callout>
<callout arearefs="CO11-3">
<para>Optional configurations for the OpenShift Container Platform web console.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>ClusterLogging</literal> CR by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="cluster-logging-deploy-multitenant_cluster-logging-deploying">
<title>Allowing traffic between projects when network isolation is enabled</title>
<simpara>Your cluster network plugin might enforce network isolation. If so, you must allow network traffic between the projects that contain the operators deployed by OpenShift Logging.</simpara>
<simpara>Network isolation blocks network traffic between pods or services that are in different projects. The logging installs the <emphasis>OpenShift Elasticsearch Operator</emphasis> in the <literal>openshift-operators-redhat</literal> project and the <emphasis>Red Hat OpenShift Logging Operator</emphasis> in the <literal>openshift-logging</literal> project. Therefore, you must allow traffic between these two projects.</simpara>
<simpara>OpenShift Container Platform offers two supported choices for the network plugin, OpenShift SDN and OVN-Kubernetes. These two providers implement various network isolation policies.</simpara>
<simpara>OpenShift SDN has three modes:</simpara>
<variablelist>
<varlistentry>
<term>network policy</term>
<listitem>
<simpara>This is the default mode. If no policy is defined, it allows all traffic. However, if a user defines a policy, they typically start by denying all traffic and then adding exceptions. This process might break applications that are running in different projects. Therefore, explicitly configure the policy to allow traffic to egress from one logging-related project to the other.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>multitenant</term>
<listitem>
<simpara>This mode enforces network isolation. You must join the two logging-related projects to allow traffic between them.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>subnet</term>
<listitem>
<simpara>This mode allows all traffic. It does not enforce network isolation. No action is needed.</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>OVN-Kubernetes always uses a <emphasis role="strong">network policy</emphasis>. Therefore, as with OpenShift SDN, you must configure the policy to allow traffic to egress from one logging-related project to the other.</simpara>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>If you are using OpenShift SDN in <emphasis role="strong">multitenant</emphasis> mode, join the two projects. For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm pod-network join-projects --to=openshift-operators-redhat openshift-logging</programlisting>
</listitem>
<listitem>
<simpara>Otherwise, for OpenShift SDN in <emphasis role="strong">network policy</emphasis> mode and OVN-Kubernetes, perform the following actions:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Set a label on the <literal>openshift-operators-redhat</literal> namespace. For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc label namespace openshift-operators-redhat project=openshift-operators-redhat</programlisting>
</listitem>
<listitem>
<simpara>Create a network policy object in the <literal>openshift-logging</literal> namespace that allows ingress from the <literal>openshift-operators-redhat</literal>, <literal>openshift-monitoring</literal> and <literal>openshift-ingress</literal> projects to the openshift-logging project. For example:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-from-openshift-monitoring-ingress-operators-redhat
spec:
  ingress:
  - from:
    - podSelector: {}
  - from:
    - namespaceSelector:
        matchLabels:
          project: "openshift-operators-redhat"
  - from:
    - namespaceSelector:
        matchLabels:
          name: "openshift-monitoring"
  - from:
    - namespaceSelector:
        matchLabels:
          network.openshift.io/policy-group: ingress
  podSelector: {}
  policyTypes:
  - Ingress</programlisting>
</listitem>
</orderedlist>
</listitem>
</itemizedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/networking/#">About network policy</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/networking/#">About the OpenShift SDN default CNI network provider</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/networking/#">About the OVN-Kubernetes default Container Network Interface (CNI) network provider</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
</chapter>
<chapter xml:id="cluster-logging-upgrading">
<title>Updating Logging</title>

<simpara>There are two types of logging updates: minor release updates (5.y.z) and major release updates (5.y).</simpara>
<section xml:id="cluster-logging-upgrading-minor">
<title>Minor release updates</title>
<simpara>If you installed the logging Operators using the <emphasis role="strong">Automatic</emphasis> update approval option, your Operators receive minor version updates automatically. You do not need to complete any manual update steps.</simpara>
<simpara>If you installed the logging Operators using the <emphasis role="strong">Manual</emphasis> update approval option, you must manually approve minor version updates. For more information, see <link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/operators/#olm-approving-pending-upgrade_olm-upgrading-operators">Manually approving a pending Operator update</link>.</simpara>
</section>
<section xml:id="cluster-logging-upgrading-major">
<title>Major release updates</title>
<simpara>For major version updates you must complete some manual steps.</simpara>
<simpara>For major release version compatibility and support information, see <link xlink:href="https://access.redhat.com/support/policy/updates/openshift_operators#platform-agnostic">OpenShift Operator Life Cycles</link>.</simpara>
</section>
<section xml:id="logging-operator-upgrading-all-ns_cluster-logging-upgrading">
<title>Upgrading the Red Hat OpenShift Logging Operator to watch all namespaces</title>
<simpara>In logging 5.7 and older versions, the Red Hat OpenShift Logging Operator only watches the <literal>openshift-logging</literal> namespace.
If you want the Red Hat OpenShift Logging Operator to watch all namespaces on your cluster, you must redeploy the Operator. You can complete the following procedure to redeploy the Operator without deleting your logging components.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Delete the subscription by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging delete subscription &lt;subscription&gt;</programlisting>
</listitem>
<listitem>
<simpara>Delete the Operator group by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging delete operatorgroup &lt;operator_group_name&gt;</programlisting>
</listitem>
<listitem>
<simpara>Delete the cluster service version (CSV) by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc delete clusterserviceversion cluster-logging.&lt;version&gt;</programlisting>
</listitem>
<listitem>
<simpara>Redeploy the Red Hat OpenShift Logging Operator by following the "Installing Logging" documentation.</simpara>
</listitem>
</orderedlist>
<itemizedlist>
<title>Verification</title>
<listitem>
<simpara>Check that the <literal>targetNamespaces</literal> field in the <literal>OperatorGroup</literal> resource is not present or is set to an empty string.</simpara>
<simpara>To do this, run the following command and inspect the output:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get operatorgroup &lt;operator_group_name&gt; -o yaml</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: openshift-logging-f52cn
  namespace: openshift-logging
spec:
  upgradeStrategy: Default
status:
  namespaces:
  - ""
# ...</programlisting>
</para>
</formalpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-upgrading-clo_cluster-logging-upgrading">
<title>Updating the Red Hat OpenShift Logging Operator</title>
<simpara>To update the Red Hat OpenShift Logging Operator to a new major release version, you must modify the update channel for the Operator subscription.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator.</simpara>
</listitem>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have access to the OpenShift Container Platform web console and are viewing the <emphasis role="strong">Administrator</emphasis> perspective.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select the <emphasis role="strong">openshift-logging</emphasis> project.</simpara>
</listitem>
<listitem>
<simpara>Click the <emphasis role="strong">Red Hat OpenShift Logging</emphasis> Operator.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Subscription</emphasis>. In the <emphasis role="strong">Subscription details</emphasis> section, click the <emphasis role="strong">Update channel</emphasis> link. This link text might be <emphasis role="strong">stable</emphasis> or <emphasis role="strong">stable-5.y</emphasis>, depending on your current update channel.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Change Subscription Update Channel</emphasis> window, select the latest major version update channel, <emphasis role="strong">stable-5.y</emphasis>, and click <emphasis role="strong">Save</emphasis>. Note the <literal>cluster-logging.v5.y.z</literal> version.</simpara>
</listitem>
</orderedlist>
<orderedlist numeration="arabic">
<title>Verification</title>
<listitem>
<simpara>Wait for a few seconds, then click <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>. Verify that the Red Hat OpenShift Logging Operator version matches the latest <literal>cluster-logging.v5.y.z</literal> version.</simpara>
</listitem>
<listitem>
<simpara>On the <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis> page, wait for the <emphasis role="strong">Status</emphasis> field to report <emphasis role="strong">Succeeded</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="logging-upgrading-loki_cluster-logging-upgrading">
<title>Updating the Loki Operator</title>
<simpara>To update the Loki Operator to a new major release version, you must modify the update channel for the Operator subscription.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have installed the Loki Operator.</simpara>
</listitem>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have access to the OpenShift Container Platform web console and are viewing the <emphasis role="strong">Administrator</emphasis> perspective.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Navigate to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select the <emphasis role="strong">openshift-operators-redhat</emphasis> project.</simpara>
</listitem>
<listitem>
<simpara>Click the <emphasis role="strong">Loki Operator</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Subscription</emphasis>. In the <emphasis role="strong">Subscription details</emphasis> section, click the <emphasis role="strong">Update channel</emphasis> link. This link text might be <emphasis role="strong">stable</emphasis> or <emphasis role="strong">stable-5.y</emphasis>, depending on your current update channel.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Change Subscription Update Channel</emphasis> window, select the latest major version update channel, <emphasis role="strong">stable-5.y</emphasis>, and click <emphasis role="strong">Save</emphasis>. Note the <literal>loki-operator.v5.y.z</literal> version.</simpara>
</listitem>
</orderedlist>
<orderedlist numeration="arabic">
<title>Verification</title>
<listitem>
<simpara>Wait for a few seconds, then click <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>. Verify that the Loki Operator version matches the latest <literal>loki-operator.v5.y.z</literal> version.</simpara>
</listitem>
<listitem>
<simpara>On the <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis> page, wait for the <emphasis role="strong">Status</emphasis> field to report <emphasis role="strong">Succeeded</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="cluster-logging-upgrading-elasticsearch_cluster-logging-upgrading">
<title>Updating the OpenShift Elasticsearch Operator</title>
<simpara>To update the OpenShift Elasticsearch Operator to the current version, you must modify the subscription.</simpara>
<note>
<simpara>The OpenShift Elasticsearch Operator is deprecated and is planned to be removed in a future release. Red&#160;Hat provides bug fixes and support for this feature during the current release lifecycle, but this feature no longer receives enhancements. As an alternative to using the OpenShift Elasticsearch Operator to manage the default log storage, you can use the Loki Operator.</simpara>
</note>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>If you are using Elasticsearch as the default log store, and Kibana as the UI, update the OpenShift Elasticsearch Operator before you update the Red Hat OpenShift Logging Operator.</simpara>
<important>
<simpara>If you update the Operators in the wrong order, Kibana does not update and the Kibana custom resource (CR) is not created. To fix this issue, delete the Red Hat OpenShift Logging Operator pod. When the Red Hat OpenShift Logging Operator pod redeploys, it creates the Kibana CR and Kibana becomes available again.</simpara>
</important>
</listitem>
<listitem>
<simpara>The Logging status is healthy:</simpara>
<itemizedlist>
<listitem>
<simpara>All pods have a <literal>ready</literal> status.</simpara>
</listitem>
<listitem>
<simpara>The Elasticsearch cluster is healthy.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Your <link xlink:href="https://www.elastic.co/guide/en/elasticsearch/reference/current/snapshot-restore.html">Elasticsearch and Kibana data is backed up</link>.</simpara>
</listitem>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have installed the OpenShift CLI (<literal>oc</literal>) for the verification steps.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the OpenShift Container Platform web console, click <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select the <emphasis role="strong">openshift-operators-redhat</emphasis> project.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">OpenShift Elasticsearch Operator</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Subscription</emphasis> &#8594; <emphasis role="strong">Channel</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Change Subscription Update Channel</emphasis> window, select <emphasis role="strong">stable-5.y</emphasis> and click <emphasis role="strong">Save</emphasis>. Note the <literal>elasticsearch-operator.v5.y.z</literal> version.</simpara>
</listitem>
<listitem>
<simpara>Wait for a few seconds, then click <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>. Verify that the OpenShift Elasticsearch Operator version matches the latest <literal>elasticsearch-operator.v5.y.z</literal> version.</simpara>
</listitem>
<listitem>
<simpara>On the <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis> page, wait for the <emphasis role="strong">Status</emphasis> field to report <emphasis role="strong">Succeeded</emphasis>.</simpara>
</listitem>
</orderedlist>
<orderedlist numeration="arabic">
<title>Verification</title>
<listitem>
<simpara>Verify that all Elasticsearch pods have a <emphasis role="strong">Ready</emphasis> status by entering the following command and observing the output:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pod -n openshift-logging --selector component=elasticsearch</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                                            READY   STATUS    RESTARTS   AGE
elasticsearch-cdm-1pbrl44l-1-55b7546f4c-mshhk   2/2     Running   0          31m
elasticsearch-cdm-1pbrl44l-2-5c6d87589f-gx5hk   2/2     Running   0          30m
elasticsearch-cdm-1pbrl44l-3-88df5d47-m45jc     2/2     Running   0          29m</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Verify that the Elasticsearch cluster status is <literal>green</literal> by entering the following command and observing the output:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -n openshift-logging -c elasticsearch elasticsearch-cdm-1pbrl44l-1-55b7546f4c-mshhk -- health</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="json" linenumbering="unnumbered">{
  "cluster_name" : "elasticsearch",
  "status" : "green",
}</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Verify that the Elasticsearch cron jobs are created by entering the following commands and observing the output:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc project openshift-logging</programlisting>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get cronjob</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                     SCHEDULE       SUSPEND   ACTIVE   LAST SCHEDULE   AGE
elasticsearch-im-app     */15 * * * *   False     0        &lt;none&gt;          56s
elasticsearch-im-audit   */15 * * * *   False     0        &lt;none&gt;          56s
elasticsearch-im-infra   */15 * * * *   False     0        &lt;none&gt;          56s</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Verify that the log store is updated to the correct version and the indices are <literal>green</literal> by entering the following command and observing the output:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -c elasticsearch &lt;any_es_pod_in_the_cluster&gt; -- indices</programlisting>
<simpara>Verify that the output includes the <literal>app-00000x</literal>, <literal>infra-00000x</literal>, <literal>audit-00000x</literal>, <literal>.security</literal> indices:</simpara>
<example>
<title>Sample output with indices in a green status</title>
<programlisting language="terminal" linenumbering="unnumbered">Tue Jun 30 14:30:54 UTC 2020
health status index                                                                 uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   infra-000008                                                          bnBvUFEXTWi92z3zWAzieQ   3 1       222195            0        289            144
green  open   infra-000004                                                          rtDSzoqsSl6saisSK7Au1Q   3 1       226717            0        297            148
green  open   infra-000012                                                          RSf_kUwDSR2xEuKRZMPqZQ   3 1       227623            0        295            147
green  open   .kibana_7                                                             1SJdCqlZTPWlIAaOUd78yg   1 1            4            0          0              0
green  open   infra-000010                                                          iXwL3bnqTuGEABbUDa6OVw   3 1       248368            0        317            158
green  open   infra-000009                                                          YN9EsULWSNaxWeeNvOs0RA   3 1       258799            0        337            168
green  open   infra-000014                                                          YP0U6R7FQ_GVQVQZ6Yh9Ig   3 1       223788            0        292            146
green  open   infra-000015                                                          JRBbAbEmSMqK5X40df9HbQ   3 1       224371            0        291            145
green  open   .orphaned.2020.06.30                                                  n_xQC2dWQzConkvQqei3YA   3 1            9            0          0              0
green  open   infra-000007                                                          llkkAVSzSOmosWTSAJM_hg   3 1       228584            0        296            148
green  open   infra-000005                                                          d9BoGQdiQASsS3BBFm2iRA   3 1       227987            0        297            148
green  open   infra-000003                                                          1-goREK1QUKlQPAIVkWVaQ   3 1       226719            0        295            147
green  open   .security                                                             zeT65uOuRTKZMjg_bbUc1g   1 1            5            0          0              0
green  open   .kibana-377444158_kubeadmin                                           wvMhDwJkR-mRZQO84K0gUQ   3 1            1            0          0              0
green  open   infra-000006                                                          5H-KBSXGQKiO7hdapDE23g   3 1       226676            0        295            147
green  open   infra-000001                                                          eH53BQ-bSxSWR5xYZB6lVg   3 1       341800            0        443            220
green  open   .kibana-6                                                             RVp7TemSSemGJcsSUmuf3A   1 1            4            0          0              0
green  open   infra-000011                                                          J7XWBauWSTe0jnzX02fU6A   3 1       226100            0        293            146
green  open   app-000001                                                            axSAFfONQDmKwatkjPXdtw   3 1       103186            0        126             57
green  open   infra-000016                                                          m9c1iRLtStWSF1GopaRyCg   3 1        13685            0         19              9
green  open   infra-000002                                                          Hz6WvINtTvKcQzw-ewmbYg   3 1       228994            0        296            148
green  open   infra-000013                                                          KR9mMFUpQl-jraYtanyIGw   3 1       228166            0        298            148
green  open   audit-000001                                                          eERqLdLmQOiQDFES1LBATQ   3 1            0            0          0              0</programlisting>
</example>
</listitem>
<listitem>
<simpara>Verify that the log visualizer is updated to the correct version by entering the following command and observing the output:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get kibana kibana -o json</programlisting>
<simpara>Verify that the output includes a Kibana pod with the <literal>ready</literal> status:</simpara>
<example>
<title>Sample output with a ready Kibana pod</title>
<programlisting language="json" linenumbering="unnumbered">[
{
"clusterCondition": {
"kibana-5fdd766ffd-nb2jj": [
{
"lastTransitionTime": "2020-06-30T14:11:07Z",
"reason": "ContainerCreating",
"status": "True",
"type": ""
},
{
"lastTransitionTime": "2020-06-30T14:11:07Z",
"reason": "ContainerCreating",
"status": "True",
"type": ""
}
]
},
"deployment": "kibana",
"pods": {
"failed": [],
"notReady": []
"ready": []
},
"replicaSets": [
"kibana-5fdd766ffd"
],
"replicas": 1
}
]</programlisting>
</example>
</listitem>
</orderedlist>
</section>
</chapter>
<chapter xml:id="_visualizing-logs">
<title>Visualizing logs</title>
<section xml:id="log-visualization">
<title>About log visualization</title>

<simpara>You can visualize your log data in the OpenShift Container Platform web console, or the Kibana web console, depending on your deployed log storage solution. The Kibana console can be used with ElasticSearch log stores, and the OpenShift Container Platform web console can be used with the ElasticSearch log store or the LokiStack.</simpara>
<note>
<simpara>The Kibana web console is now deprecated is planned to be removed in a future logging release.</simpara>
</note>
<section xml:id="configuring-log-visualizer_log-visualization">
<title>Configuring the log visualizer</title>
<simpara>You can configure which log visualizer type your logging uses by modifying the <literal>ClusterLogging</literal> custom resource (CR).</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator.</simpara>
</listitem>
<listitem>
<simpara>You have created a <literal>ClusterLogging</literal> CR.</simpara>
</listitem>
</itemizedlist>
<important>
<simpara>If you want to use the OpenShift Container Platform web console for visualization, you must enable the logging Console Plugin. See the documentation about "Log visualization with the web console".</simpara>
</important>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Modify the <literal>ClusterLogging</literal> CR <literal>visualization</literal> spec:</simpara>
<formalpara>
<title><literal>ClusterLogging</literal> CR example</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
# ...
spec:
# ...
  visualization:
    type: &lt;visualizer_type&gt; <co xml:id="CO12-1"/>
    kibana: <co xml:id="CO12-2"/>
      resources: {}
      nodeSelector: {}
      proxy: {}
      replicas: {}
      tolerations: {}
    ocpConsole: <co xml:id="CO12-3"/>
      logsLimit: {}
      timeout: {}
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO12-1">
<para>The type of visualizer you want to use for your logging. This can be either <literal>kibana</literal> or <literal>ocp-console</literal>. The Kibana console is only compatible with deployments that use Elasticsearch log storage, while the OpenShift Container Platform console is only compatible with LokiStack deployments.</para>
</callout>
<callout arearefs="CO12-2">
<para>Optional configurations for the Kibana console.</para>
</callout>
<callout arearefs="CO12-3">
<para>Optional configurations for the OpenShift Container Platform web console.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>ClusterLogging</literal> CR by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="log-visualization-resource-logs">
<title>Viewing logs for a resource</title>
<simpara>Resource logs are a default feature that provides limited log viewing capability. You can view the logs for various resources, such as builds, deployments, and pods by using the OpenShift CLI (<literal>oc</literal>) and the web console.</simpara>
<tip>
<simpara>To enhance your log retrieving and viewing experience, install the logging. The logging aggregates all the logs from your OpenShift Container Platform cluster, such as node system audit logs, application container logs, and infrastructure logs, into a dedicated log store. You can then query, discover, and visualize your log data through the Kibana console or the OpenShift Container Platform web console. Resource logs do not access the logging log store.</simpara>
</tip>
<section xml:id="viewing-resource-logs-cli-console_log-visualization">
<title>Viewing resource logs</title>
<simpara>You can view the log for various resources in the OpenShift CLI (<literal>oc</literal>) and web console. Logs read from the tail, or end, of the log.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Access to the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure (UI)</title>
<listitem>
<simpara>In the OpenShift Container Platform console, navigate to <emphasis role="strong">Workloads</emphasis> &#8594; <emphasis role="strong">Pods</emphasis> or navigate to the pod through the resource you want to investigate.</simpara>
<note>
<simpara>Some resources, such as builds, do not have pods to query directly. In such instances, you can locate the <emphasis role="strong">Logs</emphasis> link on the <emphasis role="strong">Details</emphasis> page for the resource.</simpara>
</note>
</listitem>
<listitem>
<simpara>Select a project from the drop-down menu.</simpara>
</listitem>
<listitem>
<simpara>Click the name of the pod you want to investigate.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Logs</emphasis>.</simpara>
</listitem>
</orderedlist>
<itemizedlist>
<title>Procedure (CLI)</title>
<listitem>
<simpara>View the log for a specific pod:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc logs -f &lt;pod_name&gt; -c &lt;container_name&gt;</programlisting>
<simpara>where:</simpara>
<variablelist>
<varlistentry>
<term><literal>-f</literal></term>
<listitem>
<simpara>Optional: Specifies that the output follows what is being written into the logs.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term><literal>&lt;pod_name&gt;</literal></term>
<listitem>
<simpara>Specifies the name of the pod.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term><literal>&lt;container_name&gt;</literal></term>
<listitem>
<simpara>Optional: Specifies the name of a container. When a pod has more than one container, you must specify the container name.</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc logs ruby-58cd97df55-mww7r</programlisting>
<programlisting language="terminal" linenumbering="unnumbered">$ oc logs -f ruby-57f7f4855b-znl92 -c ruby</programlisting>
<simpara>The contents of log files are printed out.</simpara>
</listitem>
<listitem>
<simpara>View the log for a specific resource:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc logs &lt;object_type&gt;/&lt;resource_name&gt; <co xml:id="CO13-1"/></programlisting>
<calloutlist>
<callout arearefs="CO13-1">
<para>Specifies the resource type and name.</para>
</callout>
</calloutlist>
<simpara>For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc logs deployment/ruby</programlisting>
<simpara>The contents of log files are printed out.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="log-visualization-ocp-console">
<title>Log visualization with the web console</title>

<simpara>You can use the OpenShift Container Platform web console to visualize log data by configuring the logging Console Plugin.</simpara>
<simpara>For information about configuring the plugin during the logging installation, see <link linkend="cluster-logging-deploy-console_cluster-logging-deploying">Installing the logging using the web console</link>.</simpara>
<simpara>If you have already installed the logging and want to configure the plugin, use one of the following procedures.</simpara>
<section xml:id="enabling-log-console-plugin_log-visualization-ocp-console">
<title>Enabling the logging Console Plugin after you have installed the Red Hat OpenShift Logging Operator</title>
<simpara>You can enable the logging Console Plugin as part of the Red Hat OpenShift Logging Operator installation, but you can also enable the plugin if you have already installed the Red Hat OpenShift Logging Operator with the plugin disabled.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator and selected <emphasis role="strong">Disabled</emphasis> for the <emphasis role="strong">Console plugin</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>You have access to the OpenShift Container Platform web console.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the OpenShift Container Platform web console <emphasis role="strong">Administrator</emphasis> perspective, navigate to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Red Hat OpenShift Logging</emphasis>. This takes you to the Operator <emphasis role="strong">Details</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Details</emphasis> page, click <emphasis role="strong">Disabled</emphasis> for the <emphasis role="strong">Console plugin</emphasis> option.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Console plugin enablement</emphasis> dialog, select <emphasis role="strong">Enable</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Save</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Verify that the <emphasis role="strong">Console plugin</emphasis> option now shows <emphasis role="strong">Enabled</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>The web console displays a pop-up window when changes have been applied. The window prompts you to reload the web console. Refresh the browser when you see the pop-up window to apply the changes.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="logging-plugin-es-loki_log-visualization-ocp-console">
<title>Configuring the logging Console Plugin when you have the Elasticsearch log store and LokiStack installed</title>
<simpara>In logging version 5.8 and later, if the Elasticsearch log store is your default log store but you have also installed the LokiStack, you can enable the logging Console Plugin by using the following procedure.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator, the OpenShift Elasticsearch Operator, and the Loki Operator.</simpara>
</listitem>
<listitem>
<simpara>You have installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
<listitem>
<simpara>You have created a <literal>ClusterLogging</literal> custom resource (CR).</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Ensure that the logging Console Plugin is enabled by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get consoles.operator.openshift.io cluster -o yaml |grep logging-view-plugin  \
|| oc patch consoles.operator.openshift.io cluster  --type=merge \
--patch '{ "spec": { "plugins": ["logging-view-plugin"]}}'</programlisting>
</listitem>
<listitem>
<simpara>Add the <literal>.metadata.annotations.logging.openshift.io/ocp-console-migration-target: lokistack-dev</literal> annotation to the <literal>ClusterLogging</literal> CR, by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc patch clusterlogging instance --type=merge --patch \
'{ "metadata": { "annotations": { "logging.openshift.io/ocp-console-migration-target": "lokistack-dev" }}}' \
-n openshift-logging</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">clusterlogging.logging.openshift.io/instance patched</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
<itemizedlist>
<title>Verification</title>
<listitem>
<simpara>Verify that the annotation was added successfully, by running the following command and observing the output:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get clusterlogging instance \
-o=jsonpath='{.metadata.annotations.logging\.openshift\.io/ocp-console-migration-target}' \
-n openshift-logging</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">"lokistack-dev"</programlisting>
</para>
</formalpara>
</listitem>
</itemizedlist>
<simpara>The logging Console Plugin pod is now deployed. You can view logging data by navigating to the OpenShift Container Platform web console and viewing the <emphasis role="strong">Observe</emphasis> &#8594; <emphasis role="strong">Logs</emphasis> page.</simpara>
</section>
</section>
<section xml:id="cluster-logging-dashboards">
<title>Viewing cluster dashboards</title>

<simpara>The <emphasis role="strong">Logging/Elasticsearch Nodes</emphasis> and <emphasis role="strong">Openshift Logging</emphasis> dashboards in the
OpenShift Container Platform web console
contain in-depth details about your Elasticsearch instance and the individual Elasticsearch nodes that you can use to prevent and diagnose problems.</simpara>
<simpara>The <emphasis role="strong">OpenShift Logging</emphasis> dashboard contains charts that show details about your Elasticsearch instance at a cluster level, including cluster resources, garbage collection, shards in the cluster, and Fluentd statistics.</simpara>
<simpara>The <emphasis role="strong">Logging/Elasticsearch Nodes</emphasis> dashboard contains charts that show details about your Elasticsearch instance, many at node level, including details on indexing, shards, resources, and so forth.</simpara>
<section xml:id="cluster-logging-dashboards-access_cluster-logging-dashboards">
<title>Accessing the Elasticsearch and OpenShift Logging dashboards</title>
<simpara>You can view the <emphasis role="strong">Logging/Elasticsearch Nodes</emphasis> and <emphasis role="strong">OpenShift Logging</emphasis> dashboards in the
OpenShift Container Platform web console.</simpara>
<formalpara>
<title>Procedure</title>
<para>To launch the dashboards:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>In the OpenShift Container Platform web console, click <emphasis role="strong">Observe</emphasis> &#8594; <emphasis role="strong">Dashboards</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>On the <emphasis role="strong">Dashboards</emphasis> page, select <emphasis role="strong">Logging/Elasticsearch Nodes</emphasis> or <emphasis role="strong">OpenShift Logging</emphasis> from the <emphasis role="strong">Dashboard</emphasis> menu.</simpara>
<simpara>For the <emphasis role="strong">Logging/Elasticsearch Nodes</emphasis> dashboard, you can select the Elasticsearch node you want to view and set the data resolution.</simpara>
<simpara>The appropriate dashboard is displayed, showing multiple charts of data.</simpara>
</listitem>
<listitem>
<simpara>Optional: Select a different time range to display or refresh rate for the data from the <emphasis role="strong">Time Range</emphasis> and <emphasis role="strong">Refresh Interval</emphasis> menus.</simpara>
</listitem>
</orderedlist>
<simpara>For information on the dashboard charts, see <link linkend="cluster-logging-dashboards-logging_cluster-logging-dashboards">About the OpenShift Logging dashboard</link> and <link linkend="cluster-logging-dashboards-es_cluster-logging-dashboards">About the Logging/Elastisearch Nodes dashboard</link>.</simpara>
</section>
<section xml:id="cluster-logging-dashboards-logging_cluster-logging-dashboards">
<title>About the OpenShift Logging dashboard</title>
<simpara>The <emphasis role="strong">OpenShift Logging</emphasis> dashboard contains charts that show details about your Elasticsearch instance at a cluster-level that you can use to diagnose and anticipate problems.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>OpenShift Logging charts</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Metric</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Elastic Cluster Status</simpara></entry>
<entry align="left" valign="top"><simpara>The current Elasticsearch status:</simpara>
<itemizedlist>
<listitem>
<simpara>ONLINE - Indicates that the Elasticsearch instance is online.</simpara>
</listitem>
<listitem>
<simpara>OFFLINE - Indicates that the Elasticsearch instance is offline.</simpara>
</listitem>
</itemizedlist></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Elastic Nodes</simpara></entry>
<entry align="left" valign="top"><simpara>The total number of Elasticsearch nodes in the Elasticsearch instance.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Elastic Shards</simpara></entry>
<entry align="left" valign="top"><simpara>The total number of Elasticsearch shards in the Elasticsearch instance.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Elastic Documents</simpara></entry>
<entry align="left" valign="top"><simpara>The total number of Elasticsearch documents in the Elasticsearch instance.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Total Index Size on Disk</simpara></entry>
<entry align="left" valign="top"><simpara>The total disk space that is being used for the Elasticsearch indices.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Elastic Pending Tasks</simpara></entry>
<entry align="left" valign="top"><simpara>The total number of Elasticsearch changes that have not been completed, such as index creation, index mapping, shard allocation, or shard failure.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Elastic JVM GC time</simpara></entry>
<entry align="left" valign="top"><simpara>The amount of time that the JVM spent executing Elasticsearch garbage collection operations in the cluster.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Elastic JVM GC Rate</simpara></entry>
<entry align="left" valign="top"><simpara>The total number of times that JVM executed garbage activities per second.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Elastic Query/Fetch Latency Sum</simpara></entry>
<entry align="left" valign="top"><itemizedlist>
<listitem>
<simpara>Query latency: The average time each Elasticsearch search query takes to execute.</simpara>
</listitem>
<listitem>
<simpara>Fetch latency: The average time each Elasticsearch search query spends fetching data.</simpara>
</listitem>
</itemizedlist>
<simpara>Fetch latency typically takes less time than query latency. If fetch latency is consistently increasing, it might indicate slow disks, data enrichment, or large requests with too many results.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Elastic Query Rate</simpara></entry>
<entry align="left" valign="top"><simpara>The total queries executed against the Elasticsearch instance per second for each Elasticsearch node.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>CPU</simpara></entry>
<entry align="left" valign="top"><simpara>The amount of CPU used by Elasticsearch, Fluentd, and Kibana, shown for each component.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Elastic JVM Heap Used</simpara></entry>
<entry align="left" valign="top"><simpara>The amount of JVM memory used. In a healthy cluster, the graph shows regular drops as memory is freed by JVM garbage collection.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Elasticsearch Disk Usage</simpara></entry>
<entry align="left" valign="top"><simpara>The total disk space used by the Elasticsearch instance for each Elasticsearch node.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>File Descriptors In Use</simpara></entry>
<entry align="left" valign="top"><simpara>The total number of file descriptors used by Elasticsearch, Fluentd, and Kibana.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>FluentD emit count</simpara></entry>
<entry align="left" valign="top"><simpara>The total number of Fluentd messages per second for the Fluentd default output, and the retry count for the default output.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>FluentD Buffer Usage</simpara></entry>
<entry align="left" valign="top"><simpara>The percent of the Fluentd buffer that is being used for chunks. A full buffer might indicate that Fluentd is not able to process the number of logs received.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Elastic rx bytes</simpara></entry>
<entry align="left" valign="top"><simpara>The total number of bytes that Elasticsearch has received from FluentD, the Elasticsearch nodes, and other sources.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Elastic Index Failure Rate</simpara></entry>
<entry align="left" valign="top"><simpara>The total number of times per second that an Elasticsearch index fails. A high rate might indicate an issue with indexing.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>FluentD Output Error Rate</simpara></entry>
<entry align="left" valign="top"><simpara>The total number of times per second that FluentD is not able to output logs.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section xml:id="cluster-logging-dashboards-es_cluster-logging-dashboards">
<title>Charts on the Logging/Elasticsearch nodes dashboard</title>
<simpara>The <emphasis role="strong">Logging/Elasticsearch Nodes</emphasis> dashboard contains charts that show details about your Elasticsearch instance, many at node-level, for further diagnostics.</simpara>
<variablelist>
<varlistentry>
<term>Elasticsearch status</term>
<listitem>
<simpara>The <emphasis role="strong">Logging/Elasticsearch Nodes</emphasis> dashboard contains the following charts about the status of your Elasticsearch instance.</simpara>
</listitem>
</varlistentry>
</variablelist>
<table frame="all" rowsep="1" colsep="1">
<title>Elasticsearch status fields</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Metric</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Cluster status</simpara></entry>
<entry align="left" valign="top"><simpara>The cluster health status during the selected time period, using the Elasticsearch green, yellow, and red statuses:</simpara>
<itemizedlist>
<listitem>
<simpara>0 - Indicates that the Elasticsearch instance is in green status, which means that all shards are allocated.</simpara>
</listitem>
<listitem>
<simpara>1 - Indicates that the Elasticsearch instance is in yellow status, which means that replica shards for at least one shard are not allocated.</simpara>
</listitem>
<listitem>
<simpara>2 - Indicates that the Elasticsearch instance is in red status, which means that at least one primary shard and its replicas are not allocated.</simpara>
</listitem>
</itemizedlist></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Cluster nodes</simpara></entry>
<entry align="left" valign="top"><simpara>The total number of Elasticsearch nodes in the cluster.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Cluster data nodes</simpara></entry>
<entry align="left" valign="top"><simpara>The number of Elasticsearch data nodes in the cluster.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Cluster pending tasks</simpara></entry>
<entry align="left" valign="top"><simpara>The number of cluster state changes that are not finished and are waiting in a cluster queue, for example, index creation, index deletion, or shard allocation. A growing trend indicates that the cluster is not able to keep up with changes.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<variablelist>
<varlistentry>
<term>Elasticsearch cluster index shard status</term>
<listitem>
<simpara>Each Elasticsearch index is a logical group of one or more shards, which are basic units of persisted data. There are two types of index shards: primary shards, and replica shards. When a document is indexed into an index, it is stored in one of its primary shards and copied into every replica of that shard. The number of primary shards is specified when the index is created, and the number cannot change during index lifetime. You can change the number of replica shards at any time.</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>The index shard can be in several states depending on its lifecycle phase or events occurring in the cluster. When the shard is able to perform search and indexing requests, the shard is active. If the shard cannot perform these requests, the shard is non–active. A shard might be non-active if the shard is initializing, reallocating, unassigned, and so forth.</simpara>
<simpara>Index shards consist of a number of smaller internal blocks, called index segments, which are physical representations of the data. An index segment is a relatively small, immutable Lucene index that is created when Lucene commits newly-indexed data. Lucene, a search library used by Elasticsearch, merges index segments into larger segments in the background to keep the total number of segments low. If the process of merging segments is slower than the speed at which new segments are created, it could indicate a problem.</simpara>
<simpara>When Lucene performs data operations, such as a search operation, Lucene performs the operation against the index segments in the relevant index. For that purpose, each segment contains specific data structures that are loaded in the memory and mapped. Index mapping can have a significant impact on the memory used by segment data structures.</simpara>
<simpara>The <emphasis role="strong">Logging/Elasticsearch Nodes</emphasis> dashboard contains the following charts about the Elasticsearch index shards.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Elasticsearch cluster shard status charts</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Metric</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Cluster active shards</simpara></entry>
<entry align="left" valign="top"><simpara>The number of active primary shards and the total number of shards, including replicas, in the cluster. If the number of shards grows higher, the cluster performance can start degrading.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Cluster initializing shards</simpara></entry>
<entry align="left" valign="top"><simpara>The number of non-active shards in the cluster. A non-active shard is one that is initializing, being reallocated to a different node, or is unassigned. A cluster typically has non–active shards for short periods. A growing number of non–active shards over longer periods could indicate a problem.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Cluster relocating shards</simpara></entry>
<entry align="left" valign="top"><simpara>The number of shards that Elasticsearch is relocating to a new node. Elasticsearch relocates nodes for multiple reasons, such as high memory use on a node or after a new node is added to the cluster.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Cluster unassigned shards</simpara></entry>
<entry align="left" valign="top"><simpara>The number of unassigned shards. Elasticsearch shards might be unassigned for reasons such as a new index being added or the failure of a node.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<variablelist>
<varlistentry>
<term>Elasticsearch node metrics</term>
<listitem>
<simpara>Each Elasticsearch node has a finite amount of resources that can be used to process tasks. When all the resources are being used and Elasticsearch attempts to perform a new task, Elasticsearch puts the tasks into a queue until some resources become available.</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>The <emphasis role="strong">Logging/Elasticsearch Nodes</emphasis> dashboard contains the following charts about resource usage for a selected node and the number of tasks waiting in the Elasticsearch queue.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Elasticsearch node metric charts</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Metric</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>ThreadPool tasks</simpara></entry>
<entry align="left" valign="top"><simpara>The number of waiting tasks in individual queues, shown by task type. A long–term accumulation of tasks in any queue could indicate node resource shortages or some other problem.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>CPU usage</simpara></entry>
<entry align="left" valign="top"><simpara>The amount of CPU being used by the selected Elasticsearch node as a percentage of the total CPU allocated to the host container.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Memory usage</simpara></entry>
<entry align="left" valign="top"><simpara>The amount of memory being used by the selected Elasticsearch node.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Disk usage</simpara></entry>
<entry align="left" valign="top"><simpara>The total disk space being used for index data and metadata on the selected Elasticsearch node.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Documents indexing rate</simpara></entry>
<entry align="left" valign="top"><simpara>The rate that documents are indexed on the selected Elasticsearch node.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Indexing latency</simpara></entry>
<entry align="left" valign="top"><simpara>The time taken to index the documents on the selected Elasticsearch node. Indexing latency can be affected by many factors, such as JVM Heap memory and overall load. A growing latency indicates a resource capacity shortage in the instance.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Search rate</simpara></entry>
<entry align="left" valign="top"><simpara>The number of search requests run on the selected Elasticsearch node.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Search latency</simpara></entry>
<entry align="left" valign="top"><simpara>The time taken to complete search requests on the selected Elasticsearch node. Search latency can be affected by many factors. A growing latency indicates a resource capacity shortage in the instance.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Documents count (with replicas)</simpara></entry>
<entry align="left" valign="top"><simpara>The number of Elasticsearch documents stored on the selected Elasticsearch node, including documents stored in both the primary shards and replica shards that are allocated on the node.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Documents deleting rate</simpara></entry>
<entry align="left" valign="top"><simpara>The number of Elasticsearch documents being deleted from any of the index shards that are allocated to the selected Elasticsearch node.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Documents merging rate</simpara></entry>
<entry align="left" valign="top"><simpara>The number of Elasticsearch documents being merged in any of index shards that are allocated to the selected Elasticsearch node.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<variablelist>
<varlistentry>
<term>Elasticsearch node fielddata</term>
<listitem>
<simpara><link xlink:href="https://www.elastic.co/guide/en/elasticsearch/reference/6.8/fielddata.html"><emphasis>Fielddata</emphasis></link> is an Elasticsearch data structure that holds lists of terms in an index and is kept in the JVM Heap. Because fielddata building is an expensive operation, Elasticsearch caches the fielddata structures. Elasticsearch can evict a fielddata cache when the underlying index segment is deleted or merged, or if there is not enough JVM HEAP memory for all the fielddata caches.</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>The <emphasis role="strong">Logging/Elasticsearch Nodes</emphasis> dashboard contains the following charts about Elasticsearch fielddata.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Elasticsearch node fielddata charts</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Metric</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Fielddata memory size</simpara></entry>
<entry align="left" valign="top"><simpara>The amount of JVM Heap used for the fielddata cache on the selected Elasticsearch node.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Fielddata evictions</simpara></entry>
<entry align="left" valign="top"><simpara>The number of fielddata structures that were deleted from the selected Elasticsearch node.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<variablelist>
<varlistentry>
<term>Elasticsearch node query cache</term>
<listitem>
<simpara>If the data stored in the index does not change, search query results are cached in a node-level query cache for reuse by Elasticsearch.</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>The <emphasis role="strong">Logging/Elasticsearch Nodes</emphasis> dashboard contains the following charts about the Elasticsearch node query cache.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Elasticsearch node query charts</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Metric</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Query cache size</simpara></entry>
<entry align="left" valign="top"><simpara>The total amount of memory used for the query cache for all the shards allocated to the selected Elasticsearch node.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Query cache evictions</simpara></entry>
<entry align="left" valign="top"><simpara>The number of query cache evictions on the selected Elasticsearch node.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Query cache hits</simpara></entry>
<entry align="left" valign="top"><simpara>The number of query cache hits on the selected Elasticsearch node.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Query cache misses</simpara></entry>
<entry align="left" valign="top"><simpara>The number of query cache misses on the selected Elasticsearch node.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<variablelist>
<varlistentry>
<term>Elasticsearch index throttling</term>
<listitem>
<simpara>When indexing documents, Elasticsearch stores the documents in index segments, which are physical representations of the data. At the same time, Elasticsearch periodically merges smaller segments into a larger segment as a way to optimize resource use. If the indexing is faster then the ability to merge segments, the merge process does not complete quickly enough, which can lead to issues with searches and performance. To prevent this situation, Elasticsearch throttles indexing, typically by reducing the number of threads allocated to indexing down to a single thread.</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>The <emphasis role="strong">Logging/Elasticsearch Nodes</emphasis> dashboard contains the following charts about Elasticsearch index throttling.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Index throttling charts</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Metric</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Indexing throttling</simpara></entry>
<entry align="left" valign="top"><simpara>The amount of time that Elasticsearch has been throttling the indexing operations on the selected Elasticsearch node.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Merging throttling</simpara></entry>
<entry align="left" valign="top"><simpara>The amount of time that Elasticsearch has been throttling the segment merge operations on the selected Elasticsearch node.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<variablelist>
<varlistentry>
<term>Node JVM Heap statistics</term>
<listitem>
<simpara>The <emphasis role="strong">Logging/Elasticsearch Nodes</emphasis> dashboard contains the following charts about JVM Heap operations.</simpara>
</listitem>
</varlistentry>
</variablelist>
<table frame="all" rowsep="1" colsep="1">
<title>JVM Heap statistic charts</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Metric</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Heap used</simpara></entry>
<entry align="left" valign="top"><simpara>The amount of the total allocated JVM Heap space that is used on the selected Elasticsearch node.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>GC count</simpara></entry>
<entry align="left" valign="top"><simpara>The number of garbage collection operations that have been run on the selected Elasticsearch node, by old and young garbage collection.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>GC time</simpara></entry>
<entry align="left" valign="top"><simpara>The amount of time that the JVM spent running garbage collection operations on the selected Elasticsearch node, by old and young garbage collection.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
</section>
<section xml:id="logging-kibana">
<title>Log visualization with Kibana</title>

<simpara>If you are using the ElasticSearch log store, you can use the Kibana console to visualize collected log data.</simpara>
<simpara>Using Kibana, you can do the following with your data:</simpara>
<itemizedlist>
<listitem>
<simpara>Search and browse the data using the <emphasis role="strong">Discover</emphasis> tab.</simpara>
</listitem>
<listitem>
<simpara>Chart and map the data using the <emphasis role="strong">Visualize</emphasis> tab.</simpara>
</listitem>
<listitem>
<simpara>Create and view custom dashboards using the <emphasis role="strong">Dashboard</emphasis> tab.</simpara>
</listitem>
</itemizedlist>
<simpara>Use and configuration of the Kibana interface is beyond the scope of this documentation. For more information about using the interface, see the <link xlink:href="https://www.elastic.co/guide/en/kibana/6.8/connect-to-elasticsearch.html">Kibana documentation</link>.</simpara>
<note>
<simpara>The audit logs are not stored in the internal OpenShift Container Platform Elasticsearch instance by default. To view the audit logs in Kibana, you must use the <link linkend="cluster-logging-elasticsearch-audit_logging-config-es-store">Log Forwarding API</link> to configure a pipeline that uses the <literal>default</literal> output for audit logs.</simpara>
</note>
<section xml:id="cluster-logging-visualizer-indices_logging-kibana">
<title>Defining Kibana index patterns</title>
<simpara>An index pattern defines the Elasticsearch indices that you want to visualize. To explore and visualize data in Kibana, you must create an index pattern.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>A user must have the <literal>cluster-admin</literal> role, the <literal>cluster-reader</literal> role, or both roles to view the <emphasis role="strong">infra</emphasis> and <emphasis role="strong">audit</emphasis> indices in Kibana. The default <literal>kubeadmin</literal> user has proper permissions to view these indices.</simpara>
<simpara>If you can view the pods and logs in the <literal>default</literal>, <literal>kube-</literal> and <literal>openshift-</literal> projects, you should be able to access these indices. You can use the following command to check if the current user has appropriate permissions:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc auth can-i get pods --subresource log -n &lt;project&gt;</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">yes</programlisting>
</para>
</formalpara>
<note>
<simpara>The audit logs are not stored in the internal OpenShift Container Platform Elasticsearch instance by default. To view the audit logs in Kibana, you must use the Log Forwarding API to configure a pipeline that uses the <literal>default</literal> output for audit logs.</simpara>
</note>
</listitem>
<listitem>
<simpara>Elasticsearch documents must be indexed before you can create index patterns. This is done automatically, but it might take a few minutes in a new or updated cluster.</simpara>
</listitem>
</itemizedlist>
<formalpara>
<title>Procedure</title>
<para>To define index patterns and create visualizations in Kibana:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>In the OpenShift Container Platform console, click the Application Launcher <inlinemediaobject>
<imageobject>
<imagedata fileref="images/app-launcher.png"/>
</imageobject>
<textobject><phrase>app launcher</phrase></textobject>
</inlinemediaobject> and select <emphasis role="strong">Logging</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Create your Kibana index patterns by clicking <emphasis role="strong">Management</emphasis> &#8594; <emphasis role="strong">Index Patterns</emphasis> &#8594; <emphasis role="strong">Create index pattern</emphasis>:</simpara>
<itemizedlist>
<listitem>
<simpara>Each user must manually create index patterns when logging into Kibana the first time to see logs for their projects. Users must create an index pattern named <literal>app</literal> and use the <literal>@timestamp</literal> time field to view their container logs.</simpara>
</listitem>
<listitem>
<simpara>Each admin user must create index patterns when logged into Kibana the first time for the <literal>app</literal>, <literal>infra</literal>, and <literal>audit</literal> indices using the <literal>@timestamp</literal> time field.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Create Kibana Visualizations from the new index patterns.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="cluster-logging-visualizer-kibana_logging-kibana">
<title>Viewing cluster logs in Kibana</title>
<simpara>You view cluster logs in the Kibana web console. The methods for viewing and visualizing your data in Kibana that are beyond the scope of this documentation. For more information, refer to the <link xlink:href="https://www.elastic.co/guide/en/kibana/6.8/tutorial-sample-discover.html">Kibana documentation</link>.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>The Red Hat OpenShift Logging and Elasticsearch Operators must be installed.</simpara>
</listitem>
<listitem>
<simpara>Kibana index patterns must exist.</simpara>
</listitem>
<listitem>
<simpara>A user must have the <literal>cluster-admin</literal> role, the <literal>cluster-reader</literal> role, or both roles to view the <emphasis role="strong">infra</emphasis> and <emphasis role="strong">audit</emphasis> indices in Kibana. The default <literal>kubeadmin</literal> user has proper permissions to view these indices.</simpara>
<simpara>If you can view the pods and logs in the <literal>default</literal>, <literal>kube-</literal> and <literal>openshift-</literal> projects, you should be able to access these indices. You can use the following command to check if the current user has appropriate permissions:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc auth can-i get pods --subresource log -n &lt;project&gt;</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">yes</programlisting>
</para>
</formalpara>
<note>
<simpara>The audit logs are not stored in the internal OpenShift Container Platform Elasticsearch instance by default. To view the audit logs in Kibana, you must use the Log Forwarding API to configure a pipeline that uses the <literal>default</literal> output for audit logs.</simpara>
</note>
</listitem>
</itemizedlist>
<formalpara>
<title>Procedure</title>
<para>To view logs in Kibana:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>In the OpenShift Container Platform console, click the Application Launcher <inlinemediaobject>
<imageobject>
<imagedata fileref="images/app-launcher.png"/>
</imageobject>
<textobject><phrase>app launcher</phrase></textobject>
</inlinemediaobject> and select <emphasis role="strong">Logging</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Log in using the same credentials you use to log in to the OpenShift Container Platform console.</simpara>
<simpara>The Kibana interface launches.</simpara>
</listitem>
<listitem>
<simpara>In Kibana, click <emphasis role="strong">Discover</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select the index pattern you created from the drop-down menu in the top-left corner: <emphasis role="strong">app</emphasis>, <emphasis role="strong">audit</emphasis>, or <emphasis role="strong">infra</emphasis>.</simpara>
<simpara>The log data displays as  time-stamped documents.</simpara>
</listitem>
<listitem>
<simpara>Expand one of the time-stamped documents.</simpara>
</listitem>
<listitem>
<simpara>Click the <emphasis role="strong">JSON</emphasis> tab to display the log entry for that document.</simpara>
<example>
<title>Sample infrastructure log entry in Kibana</title>
<programlisting language="terminal" linenumbering="unnumbered">{
  "_index": "infra-000001",
  "_type": "_doc",
  "_id": "YmJmYTBlNDkZTRmLTliMGQtMjE3NmFiOGUyOWM3",
  "_version": 1,
  "_score": null,
  "_source": {
    "docker": {
      "container_id": "f85fa55bbef7bb783f041066be1e7c267a6b88c4603dfce213e32c1"
    },
    "kubernetes": {
      "container_name": "registry-server",
      "namespace_name": "openshift-marketplace",
      "pod_name": "redhat-marketplace-n64gc",
      "container_image": "registry.redhat.io/redhat/redhat-marketplace-index:v4.7",
      "container_image_id": "registry.redhat.io/redhat/redhat-marketplace-index@sha256:65fc0c45aabb95809e376feb065771ecda9e5e59cc8b3024c4545c168f",
      "pod_id": "8f594ea2-c866-4b5c-a1c8-a50756704b2a",
      "host": "ip-10-0-182-28.us-east-2.compute.internal",
      "master_url": "https://kubernetes.default.svc",
      "namespace_id": "3abab127-7669-4eb3-b9ef-44c04ad68d38",
      "namespace_labels": {
        "openshift_io/cluster-monitoring": "true"
      },
      "flat_labels": [
        "catalogsource_operators_coreos_com/update=redhat-marketplace"
      ]
    },
    "message": "time=\"2020-09-23T20:47:03Z\" level=info msg=\"serving registry\" database=/database/index.db port=50051",
    "level": "unknown",
    "hostname": "ip-10-0-182-28.internal",
    "pipeline_metadata": {
      "collector": {
        "ipaddr4": "10.0.182.28",
        "inputname": "fluent-plugin-systemd",
        "name": "fluentd",
        "received_at": "2020-09-23T20:47:15.007583+00:00",
        "version": "1.7.4 1.6.0"
      }
    },
    "@timestamp": "2020-09-23T20:47:03.422465+00:00",
    "viaq_msg_id": "YmJmYTBlNDktMDMGQtMjE3NmFiOGUyOWM3",
    "openshift": {
      "labels": {
        "logging": "infra"
      }
    }
  },
  "fields": {
    "@timestamp": [
      "2020-09-23T20:47:03.422Z"
    ],
    "pipeline_metadata.collector.received_at": [
      "2020-09-23T20:47:15.007Z"
    ]
  },
  "sort": [
    1600894023422
  ]
}</programlisting>
</example>
</listitem>
</orderedlist>
</section>
<section xml:id="logging-kibana-configuring">
<title>Configuring Kibana</title>
<simpara>You can configure using the Kibana console by modifying the <literal>ClusterLogging</literal> custom resource (CR).</simpara>
<section xml:id="cluster-logging-memory-limits_logging-kibana">
<title>Configuring CPU and memory limits</title>
<simpara>The logging components allow for adjustments to both the CPU and memory limits.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Edit the <literal>ClusterLogging</literal> custom resource (CR) in the <literal>openshift-logging</literal> project:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging edit ClusterLogging instance</programlisting>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"
  namespace: openshift-logging

...

spec:
  managementState: "Managed"
  logStore:
    type: "elasticsearch"
    elasticsearch:
      nodeCount: 3
      resources: <co xml:id="CO14-1"/>
        limits:
          memory: 16Gi
        requests:
          cpu: 200m
          memory: 16Gi
      storage:
        storageClassName: "gp2"
        size: "200G"
      redundancyPolicy: "SingleRedundancy"
  visualization:
    type: "kibana"
    kibana:
      resources: <co xml:id="CO14-2"/>
        limits:
          memory: 1Gi
        requests:
          cpu: 500m
          memory: 1Gi
      proxy:
        resources: <co xml:id="CO14-3"/>
          limits:
            memory: 100Mi
          requests:
            cpu: 100m
            memory: 100Mi
      replicas: 2
  collection:
    logs:
      type: "fluentd"
      fluentd:
        resources: <co xml:id="CO14-4"/>
          limits:
            memory: 736Mi
          requests:
            cpu: 200m
            memory: 736Mi</programlisting>
<calloutlist>
<callout arearefs="CO14-1">
<para>Specify the CPU and memory limits and requests for the log store as needed. For Elasticsearch, you must adjust both the request value and the limit value.</para>
</callout>
<callout arearefs="CO14-2 CO14-3">
<para>Specify the CPU and memory limits and requests for the log visualizer as needed.</para>
</callout>
<callout arearefs="CO14-4">
<para>Specify the CPU and memory limits and requests for the log collector as needed.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
</section>
<section xml:id="cluster-logging-kibana-scaling_logging-kibana">
<title>Scaling redundancy for the log visualizer nodes</title>
<simpara>You can scale the pod that hosts the log visualizer for redundancy.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Edit the <literal>ClusterLogging</literal> custom resource (CR) in the <literal>openshift-logging</literal> project:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit ClusterLogging instance</programlisting>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"

....

spec:
    visualization:
      type: "kibana"
      kibana:
        replicas: 1 <co xml:id="CO15-1"/></programlisting>
<calloutlist>
<callout arearefs="CO15-1">
<para>Specify the number of Kibana nodes.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
</section>
</section>
</section>
</chapter>
<chapter xml:id="_configuring-your-logging-deployment">
<title>Configuring your Logging deployment</title>
<section xml:id="cluster-logging-memory">
<title>Configuring CPU and memory limits for logging components</title>

<simpara>You can configure both the CPU and memory limits for each of the logging components as needed.</simpara>
<section xml:id="cluster-logging-memory-limits_cluster-logging-memory">
<title>Configuring CPU and memory limits</title>
<simpara>The logging components allow for adjustments to both the CPU and memory limits.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Edit the <literal>ClusterLogging</literal> custom resource (CR) in the <literal>openshift-logging</literal> project:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging edit ClusterLogging instance</programlisting>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"
  namespace: openshift-logging

...

spec:
  managementState: "Managed"
  logStore:
    type: "elasticsearch"
    elasticsearch:
      nodeCount: 3
      resources: <co xml:id="CO16-1"/>
        limits:
          memory: 16Gi
        requests:
          cpu: 200m
          memory: 16Gi
      storage:
        storageClassName: "gp2"
        size: "200G"
      redundancyPolicy: "SingleRedundancy"
  visualization:
    type: "kibana"
    kibana:
      resources: <co xml:id="CO16-2"/>
        limits:
          memory: 1Gi
        requests:
          cpu: 500m
          memory: 1Gi
      proxy:
        resources: <co xml:id="CO16-3"/>
          limits:
            memory: 100Mi
          requests:
            cpu: 100m
            memory: 100Mi
      replicas: 2
  collection:
    logs:
      type: "fluentd"
      fluentd:
        resources: <co xml:id="CO16-4"/>
          limits:
            memory: 736Mi
          requests:
            cpu: 200m
            memory: 736Mi</programlisting>
<calloutlist>
<callout arearefs="CO16-1">
<para>Specify the CPU and memory limits and requests for the log store as needed. For Elasticsearch, you must adjust both the request value and the limit value.</para>
</callout>
<callout arearefs="CO16-2 CO16-3">
<para>Specify the CPU and memory limits and requests for the log visualizer as needed.</para>
</callout>
<callout arearefs="CO16-4">
<para>Specify the CPU and memory limits and requests for the log collector as needed.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
</section>
</section>
<section xml:id="cluster-logging-systemd">
<title>Configuring systemd-journald and Fluentd</title>

<simpara>Because Fluentd reads from the journal, and the journal default settings are very low, journal entries can be lost because the journal cannot keep up with the logging rate from system services.</simpara>
<simpara>We recommend setting <literal>RateLimitIntervalSec=30s</literal> and <literal>RateLimitBurst=10000</literal> (or even higher if necessary) to prevent the journal from losing entries.</simpara>
<section xml:id="cluster-logging-systemd-scaling_cluster-logging-systemd">
<title>Configuring systemd-journald for OpenShift Logging</title>
<simpara>As you scale up your project, the default logging environment might need some
adjustments.</simpara>
<simpara>For example, if you are missing logs, you might have to increase the rate limits for journald.
You can adjust the number of messages to retain for a specified period of time to ensure that
OpenShift Logging does not use excessive resources without dropping logs.</simpara>
<simpara>You can also determine if you want the logs compressed, how long to retain logs, how or if the logs are stored,
and other settings.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a Butane config file, <literal>40-worker-custom-journald.bu</literal>, that includes an <literal>/etc/systemd/journald.conf</literal> file with the required settings.</simpara>
<note>
<simpara>See "Creating machine configs with Butane" for information about Butane.</simpara>
</note>
<programlisting language="yaml" linenumbering="unnumbered">variant: openshift
version: 4.14.0
metadata:
  name: 40-worker-custom-journald
  labels:
    machineconfiguration.openshift.io/role: "worker"
storage:
  files:
  - path: /etc/systemd/journald.conf
    mode: 0644 <co xml:id="CO17-1"/>
    overwrite: true
    contents:
      inline: |
        Compress=yes <co xml:id="CO17-2"/>
        ForwardToConsole=no <co xml:id="CO17-3"/>
        ForwardToSyslog=no
        MaxRetentionSec=1month <co xml:id="CO17-4"/>
        RateLimitBurst=10000 <co xml:id="CO17-5"/>
        RateLimitIntervalSec=30s
        Storage=persistent <co xml:id="CO17-6"/>
        SyncIntervalSec=1s <co xml:id="CO17-7"/>
        SystemMaxUse=8G <co xml:id="CO17-8"/>
        SystemKeepFree=20% <co xml:id="CO17-9"/>
        SystemMaxFileSize=10M <co xml:id="CO17-10"/></programlisting>
<calloutlist>
<callout arearefs="CO17-1">
<para>Set the permissions for the <literal>journald.conf</literal> file. It is recommended to set <literal>0644</literal> permissions.</para>
</callout>
<callout arearefs="CO17-2">
<para>Specify whether you want logs compressed before they are written to the file system.
Specify <literal>yes</literal> to compress the message or <literal>no</literal> to not compress. The default is <literal>yes</literal>.</para>
</callout>
<callout arearefs="CO17-3">
<para>Configure whether to forward log messages. Defaults to <literal>no</literal> for each. Specify:</para>
<itemizedlist>
<listitem>
<simpara><literal>ForwardToConsole</literal> to forward logs to the system console.</simpara>
</listitem>
<listitem>
<simpara><literal>ForwardToKMsg</literal> to forward logs to the kernel log buffer.</simpara>
</listitem>
<listitem>
<simpara><literal>ForwardToSyslog</literal> to forward to a syslog daemon.</simpara>
</listitem>
<listitem>
<simpara><literal>ForwardToWall</literal> to forward messages as wall messages to all logged-in users.</simpara>
</listitem>
</itemizedlist>
</callout>
<callout arearefs="CO17-4">
<para>Specify the maximum time to store journal entries. Enter a number to specify seconds. Or
include a unit: "year", "month", "week", "day", "h" or "m". Enter <literal>0</literal> to disable. The default is <literal>1month</literal>.</para>
</callout>
<callout arearefs="CO17-5">
<para>Configure rate limiting. If more logs are received than what is specified in <literal>RateLimitBurst</literal> during the time interval defined by <literal>RateLimitIntervalSec</literal>, all further messages within the interval are dropped until the interval is over. It is recommended to set <literal>RateLimitIntervalSec=30s</literal> and <literal>RateLimitBurst=10000</literal>, which are the defaults.</para>
</callout>
<callout arearefs="CO17-6">
<para>Specify how logs are stored. The default is <literal>persistent</literal>:</para>
<itemizedlist>
<listitem>
<simpara><literal>volatile</literal> to store logs in memory in <literal>/run/log/journal/</literal>. These logs are lost after rebooting.</simpara>
</listitem>
<listitem>
<simpara><literal>persistent</literal> to store logs to disk in <literal>/var/log/journal/</literal>. systemd creates the directory if it does not exist.</simpara>
</listitem>
<listitem>
<simpara><literal>auto</literal> to store logs in <literal>/var/log/journal/</literal> if the directory exists. If it does not exist, systemd temporarily stores logs in <literal>/run/systemd/journal</literal>.</simpara>
</listitem>
<listitem>
<simpara><literal>none</literal> to not store logs. systemd drops all logs.</simpara>
</listitem>
</itemizedlist>
</callout>
<callout arearefs="CO17-7">
<para>Specify the timeout before synchronizing journal files to disk for <emphasis role="strong">ERR</emphasis>, <emphasis role="strong">WARNING</emphasis>, <emphasis role="strong">NOTICE</emphasis>, <emphasis role="strong">INFO</emphasis>, and <emphasis role="strong">DEBUG</emphasis> logs.
systemd immediately syncs after receiving a <emphasis role="strong">CRIT</emphasis>, <emphasis role="strong">ALERT</emphasis>, or <emphasis role="strong">EMERG</emphasis> log. The default is <literal>1s</literal>.</para>
</callout>
<callout arearefs="CO17-8">
<para>Specify the maximum size the journal can use. The default is <literal>8G</literal>.</para>
</callout>
<callout arearefs="CO17-9">
<para>Specify how much disk space systemd must leave free. The default is <literal>20%</literal>.</para>
</callout>
<callout arearefs="CO17-10">
<para>Specify the maximum size for individual journal files stored persistently in <literal>/var/log/journal</literal>. The default is <literal>10M</literal>.</para>
<note>
<simpara>If you are removing the rate limit, you might see increased CPU utilization on the
system logging daemons as it processes any messages that would have previously
been throttled.</simpara>
</note>
<simpara>For more information on systemd settings, see <link xlink:href="https://www.freedesktop.org/software/systemd/man/journald.conf.html">https://www.freedesktop.org/software/systemd/man/journald.conf.html</link>. The default settings listed on that page might not apply to OpenShift Container Platform.</simpara>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Use Butane to generate a <literal>MachineConfig</literal> object file, <literal>40-worker-custom-journald.yaml</literal>, containing the configuration to be delivered to the nodes:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ butane 40-worker-custom-journald.bu -o 40-worker-custom-journald.yaml</programlisting>
</listitem>
<listitem>
<simpara>Apply the machine config. For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f 40-worker-custom-journald.yaml</programlisting>
<simpara>The controller detects the new <literal>MachineConfig</literal> object and generates a new <literal>rendered-worker-&lt;hash&gt;</literal> version.</simpara>
</listitem>
<listitem>
<simpara>Monitor the status of the rollout of the new rendered configuration to each node:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc describe machineconfigpool/worker</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">Name:         worker
Namespace:
Labels:       machineconfiguration.openshift.io/mco-built-in=
Annotations:  &lt;none&gt;
API Version:  machineconfiguration.openshift.io/v1
Kind:         MachineConfigPool

...

Conditions:
  Message:
  Reason:                All nodes are updating to rendered-worker-913514517bcea7c93bd446f4830bc64e</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</section>
</section>
</chapter>
<chapter xml:id="_log-collection-and-forwarding">
<title>Log collection and forwarding</title>
<section xml:id="log-forwarding">
<title>About log collection and forwarding</title>

<simpara>The Red Hat OpenShift Logging Operator deploys a collector based on the <literal>ClusterLogForwarder</literal> resource specification. There are two collector options supported by this Operator: the legacy Fluentd collector, and the Vector collector.</simpara>
<note>
<simpara>Fluentd is deprecated and is planned to be removed in a future release. Red Hat provides bug fixes and support for this feature during the current release lifecycle, but this feature no longer receives enhancements. As an alternative to Fluentd, you can use Vector instead.</simpara>
</note>
<section xml:id="about-log-collection_log-forwarding">
<title>Log collection</title>
<simpara>The log collector is a daemon set that deploys pods to each OpenShift Container Platform node to collect container and node logs.</simpara>
<simpara>By default, the log collector uses the following sources:</simpara>
<itemizedlist>
<listitem>
<simpara>System and infrastructure logs generated by journald log messages from the operating system, the container runtime, and OpenShift Container Platform.</simpara>
</listitem>
<listitem>
<simpara><literal>/var/log/containers/*.log</literal> for all container logs.</simpara>
</listitem>
</itemizedlist>
<simpara>If you configure the log collector to collect audit logs, it collects them from <literal>/var/log/audit/audit.log</literal>.</simpara>
<simpara>The log collector collects the logs from these sources and forwards them internally or externally depending on your logging configuration.</simpara>
<section xml:id="about-log-collectors-types_log-forwarding">
<title>Log collector types</title>
<simpara><link xlink:href="https://vector.dev/docs/about/what-is-vector/">Vector</link> is a log collector offered as an alternative to Fluentd for the logging.</simpara>
<simpara>You can configure which logging collector type your cluster uses by modifying the <literal>ClusterLogging</literal> custom resource (CR) <literal>collection</literal> spec:</simpara>
<formalpara>
<title>Example ClusterLogging CR that configures Vector as the collector</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
  name: instance
  namespace: openshift-logging
spec:
  collection:
    logs:
      type: vector
      vector: {}
# ...</programlisting>
</para>
</formalpara>
</section>
<section xml:id="about-log-collectors-limitations_log-forwarding">
<title>Log collection limitations</title>
<simpara>The container runtimes provide minimal information to identify the source of log messages: project, pod name, and container ID. This information is not sufficient to uniquely identify the source of the logs. If a pod with a given name and project is deleted before the log collector begins processing its logs, information from the API server, such as labels and annotations, might not be available. There might not be a way to distinguish the log messages from a similarly named pod and project or trace the logs to their source. This limitation means that log collection and normalization are considered <emphasis>best effort</emphasis>.</simpara>
<important>
<simpara>The available container runtimes provide minimal information to identify the source of log messages and do not guarantee unique individual log messages or that these messages can be traced to their source.</simpara>
</important>
</section>
<section xml:id="logging-vector-fluentd-feature-comparison_log-forwarding">
<title>Log collector features by type</title>
<table frame="all" rowsep="1" colsep="1">
<title>Log Sources</title>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Feature</entry>
<entry align="left" valign="top">Fluentd</entry>
<entry align="left" valign="top">Vector</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>App container logs</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>App-specific routing</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>App-specific routing by namespace</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Infra container logs</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Infra journal logs</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Kube API audit logs</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>OpenShift API audit logs</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Open Virtual Network (OVN) audit logs</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<table frame="all" rowsep="1" colsep="1">
<title>Authorization and Authentication</title>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Feature</entry>
<entry align="left" valign="top">Fluentd</entry>
<entry align="left" valign="top">Vector</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Elasticsearch certificates</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Elasticsearch username / password</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Amazon Cloudwatch keys</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Amazon Cloudwatch STS</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Kafka certificates</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Kafka username / password</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Kafka SASL</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Loki bearer token</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<table frame="all" rowsep="1" colsep="1">
<title>Normalizations and Transformations</title>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Feature</entry>
<entry align="left" valign="top">Fluentd</entry>
<entry align="left" valign="top">Vector</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Viaq data model - app</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Viaq data model - infra</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Viaq data model - infra(journal)</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Viaq data model - Linux audit</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Viaq data model - kube-apiserver audit</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Viaq data model - OpenShift API audit</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Viaq data model - OVN</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Loglevel Normalization</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>JSON parsing</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Structured Index</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Multiline error detection</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Multicontainer / split indices</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Flatten labels</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>CLF static labels</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<table frame="all" rowsep="1" colsep="1">
<title>Tuning</title>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Feature</entry>
<entry align="left" valign="top">Fluentd</entry>
<entry align="left" valign="top">Vector</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Fluentd readlinelimit</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Fluentd buffer</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>- chunklimitsize</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>- totallimitsize</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>- overflowaction</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>- flushthreadcount</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>- flushmode</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>- flushinterval</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>- retrywait</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>- retrytype</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>- retrymaxinterval</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>- retrytimeout</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
</tbody>
</tgroup>
</table>
<table frame="all" rowsep="1" colsep="1">
<title>Visibility</title>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Feature</entry>
<entry align="left" valign="top">Fluentd</entry>
<entry align="left" valign="top">Vector</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Metrics</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Dashboard</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Alerts</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<table frame="all" rowsep="1" colsep="1">
<title>Miscellaneous</title>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Feature</entry>
<entry align="left" valign="top">Fluentd</entry>
<entry align="left" valign="top">Vector</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Global proxy support</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>x86 support</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>ARM support</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>IBM Power&#174; support</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>IBM Z&#174; support</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>IPv6 support</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Log event buffering</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Disconnected Cluster</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section xml:id="log-forwarding-collector-outputs_log-forwarding">
<title>Collector outputs</title>
<simpara>The following collector outputs are supported:</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Supported outputs</title>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Feature</entry>
<entry align="left" valign="top">Fluentd</entry>
<entry align="left" valign="top">Vector</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Elasticsearch v6-v8</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Fluent forward</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Syslog RFC3164</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003; (Logging 5.7+)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Syslog RFC5424</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003; (Logging 5.7+)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Kafka</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Amazon Cloudwatch</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Amazon Cloudwatch STS</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Loki</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>HTTP</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003; (Logging 5.7+)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Google Cloud Logging</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
<entry align="left" valign="top"><simpara>&#10003;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Splunk</simpara></entry>
<entry align="left" valign="top"></entry>
<entry align="left" valign="top"><simpara>&#10003; (Logging 5.6+)</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
</section>
<section xml:id="log-forwarding-about-clf">
<title>Log forwarding</title>
<simpara>Administrators can create <literal>ClusterLogForwarder</literal> resources that specify which logs are collected, how they are transformed, and where they are forwarded to.</simpara>
<simpara><literal>ClusterLogForwarder</literal> resources can be used up to forward container, infrastructure, and audit logs to specific endpoints within or outside of a cluster. Transport Layer Security (TLS) is supported so that log forwarders can be configured to send logs securely.</simpara>
<simpara>Administrators can also authorize RBAC permissions that define which service accounts and users can access and forward which types of logs.</simpara>
<section xml:id="log-forwarding-implementations_log-forwarding">
<title>Log forwarding implementations</title>
<simpara>There are two log forwarding implementations available: the legacy implementation, and the multi log forwarder feature.</simpara>
<important>
<simpara>Only the Vector collector is supported for use with the multi log forwarder feature. The Fluentd collector can only be used with legacy implementations.</simpara>
</important>
<section xml:id="log-forwarding-implementations-legacy_log-forwarding">
<title>Legacy implementation</title>
<simpara>In legacy implementations, you can only use one log forwarder in your cluster. The <literal>ClusterLogForwarder</literal> resource in this mode must be named <literal>instance</literal>, and must be created in the <literal>openshift-logging</literal> namespace. The <literal>ClusterLogForwarder</literal> resource also requires a corresponding <literal>ClusterLogging</literal> resource named <literal>instance</literal> in the <literal>openshift-logging</literal> namespace.</simpara>
</section>
<section xml:id="log-forwarding-implementations-multi-clf_log-forwarding">
<title>Multi log forwarder feature</title>
<simpara>The multi log forwarder feature is available in logging 5.8 and later, and provides the following functionality:</simpara>
<itemizedlist>
<listitem>
<simpara>Administrators can control which users are allowed to define log collection and which logs they are allowed to collect.</simpara>
</listitem>
<listitem>
<simpara>Users who have the required permissions are able to specify additional log collection configurations.</simpara>
</listitem>
<listitem>
<simpara>Administrators who are migrating from the deprecated Fluentd collector to the Vector collector can deploy a new log forwarder separately from their existing deployment. The existing and new log forwarders can operate simultaneously while workloads are being migrated.</simpara>
</listitem>
</itemizedlist>
<simpara>In multi log forwarder implementations, you are not required to create a corresponding <literal>ClusterLogging</literal> resource for your <literal>ClusterLogForwarder</literal> resource. You can create multiple <literal>ClusterLogForwarder</literal> resources using any name, in any namespace, with the following exceptions:</simpara>
<itemizedlist>
<listitem>
<simpara>You cannot create a <literal>ClusterLogForwarder</literal> resource named <literal>instance</literal> in the <literal>openshift-logging</literal> namespace, because this is reserved for a log forwarder that supports the legacy workflow using the Fluentd collector.</simpara>
</listitem>
<listitem>
<simpara>You cannot create a <literal>ClusterLogForwarder</literal> resource named <literal>collector</literal> in the <literal>openshift-logging</literal> namespace, because this is reserved for the collector.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="log-forwarding-enabling-multi-clf-feature">
<title>Enabling the multi log forwarder feature for a cluster</title>
<simpara>To use the multi log forwarder feature, you must create a service account and cluster role bindings for that service account. You can then reference the service account in the <literal>ClusterLogForwarder</literal> resource to control access permissions.</simpara>
<important>
<simpara>In order to support multi log forwarding in additional namespaces other than the <literal>openshift-logging</literal> namespace, you must <link linkend="logging-operator-upgrading-all-ns_cluster-logging-upgrading">update the Red Hat OpenShift Logging Operator to watch all namespaces</link>. This functionality is supported by default in new Red Hat OpenShift Logging Operator version 5.8 installations.</simpara>
</important>
<section xml:id="log-collection-rbac-permissions_log-forwarding">
<title>Authorizing log collection RBAC permissions</title>
<simpara>In logging 5.8 and later, the Red Hat OpenShift Logging Operator provides <literal>collect-audit-logs</literal>, <literal>collect-application-logs</literal>, and <literal>collect-infrastructure-logs</literal> cluster roles, which enable the collector to collect audit logs, application logs, and infrastructure logs respectively.</simpara>
<simpara>You can authorize RBAC permissions for log collection by binding the required cluster roles to a service account.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>The Red Hat OpenShift Logging Operator is installed in the <literal>openshift-logging</literal> namespace.</simpara>
</listitem>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a service account for the collector. If you want to write logs to storage that requires a token for authentication, you must include a token in the service account.</simpara>
</listitem>
<listitem>
<simpara>Bind the appropriate cluster roles to the service account:</simpara>
<formalpara>
<title>Example binding command</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm policy add-cluster-role-to-user &lt;cluster_role_name&gt; system:serviceaccount:&lt;namespace_name&gt;:&lt;service_account_name&gt;</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/authentication_and_authorization/#using-rbac">Using RBAC to define and apply permissions</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/authentication_and_authorization/#using-service-accounts-in-applications">Using service accounts in applications</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/">Using RBAC Authorization Kubernetes documentation</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
</section>
<section xml:id="logging-output-types">
<title>Log output types</title>

<simpara>Outputs define the destination where logs are sent to from a log forwarder. You can configure multiple types of outputs in the <literal>ClusterLogForwarder</literal> custom resource (CR) to send logs to servers that support different protocols.</simpara>
<section xml:id="supported-log-outputs_logging-output-types">
<title>Supported log forwarding outputs</title>
<simpara>Outputs can be any of the following types:</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Supported log output types</title>
<tgroup cols="5">
<colspec colname="col_1" colwidth="20*"/>
<colspec colname="col_2" colwidth="20*"/>
<colspec colname="col_3" colwidth="20*"/>
<colspec colname="col_4" colwidth="20*"/>
<colspec colname="col_5" colwidth="20*"/>
<thead>
<row>
<entry align="left" valign="top">Output type</entry>
<entry align="left" valign="top">Protocol</entry>
<entry align="left" valign="top">Tested with</entry>
<entry align="left" valign="top">Logging versions</entry>
<entry align="left" valign="top">Supported collector type</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Elasticsearch v6</simpara></entry>
<entry align="left" valign="top"><simpara>HTTP 1.1</simpara></entry>
<entry align="left" valign="top"><simpara>6.8.1, 6.8.23</simpara></entry>
<entry align="left" valign="top"><simpara>5.6+</simpara></entry>
<entry align="left" valign="top"><simpara>Fluentd, Vector</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Elasticsearch v7</simpara></entry>
<entry align="left" valign="top"><simpara>HTTP 1.1</simpara></entry>
<entry align="left" valign="top"><simpara>7.12.2, 7.17.7, 7.10.1</simpara></entry>
<entry align="left" valign="top"><simpara>5.6+</simpara></entry>
<entry align="left" valign="top"><simpara>Fluentd, Vector</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Elasticsearch v8</simpara></entry>
<entry align="left" valign="top"><simpara>HTTP 1.1</simpara></entry>
<entry align="left" valign="top"><simpara>8.4.3, 8.6.1</simpara></entry>
<entry align="left" valign="top"><simpara>5.6+</simpara></entry>
<entry align="left" valign="top"><simpara>Fluentd <superscript>[1]</superscript>, Vector</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Fluent Forward</simpara></entry>
<entry align="left" valign="top"><simpara>Fluentd forward v1</simpara></entry>
<entry align="left" valign="top"><simpara>Fluentd 1.14.6, Logstash 7.10.1, Fluentd 1.14.5</simpara></entry>
<entry align="left" valign="top"><simpara>5.4+</simpara></entry>
<entry align="left" valign="top"><simpara>Fluentd</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Google Cloud Logging</simpara></entry>
<entry align="left" valign="top"><simpara>REST over HTTPS</simpara></entry>
<entry align="left" valign="top"><simpara>Latest</simpara></entry>
<entry align="left" valign="top"><simpara>5.7+</simpara></entry>
<entry align="left" valign="top"><simpara>Vector</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>HTTP</simpara></entry>
<entry align="left" valign="top"><simpara>HTTP 1.1</simpara></entry>
<entry align="left" valign="top"><simpara>Fluentd 1.14.6, Vector 0.21</simpara></entry>
<entry align="left" valign="top"><simpara>5.7+</simpara></entry>
<entry align="left" valign="top"><simpara>Fluentd, Vector</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Kafka</simpara></entry>
<entry align="left" valign="top"><simpara>Kafka 0.11</simpara></entry>
<entry align="left" valign="top"><simpara>Kafka 2.4.1, 2.7.0, 3.3.1</simpara></entry>
<entry align="left" valign="top"><simpara>5.4+</simpara></entry>
<entry align="left" valign="top"><simpara>Fluentd, Vector</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Loki</simpara></entry>
<entry align="left" valign="top"><simpara>REST over HTTP and HTTPS</simpara></entry>
<entry align="left" valign="top"><simpara>2.3.0, 2.5.0, 2.7, 2.2.1</simpara></entry>
<entry align="left" valign="top"><simpara>5.4+</simpara></entry>
<entry align="left" valign="top"><simpara>Fluentd, Vector</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Splunk</simpara></entry>
<entry align="left" valign="top"><simpara>HEC</simpara></entry>
<entry align="left" valign="top"><simpara>8.2.9, 9.0.0</simpara></entry>
<entry align="left" valign="top"><simpara>5.7+</simpara></entry>
<entry align="left" valign="top"><simpara>Vector</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Syslog</simpara></entry>
<entry align="left" valign="top"><simpara>RFC3164, RFC5424</simpara></entry>
<entry align="left" valign="top"><simpara>Rsyslog 8.37.0-9.el7, rsyslog-8.39.0</simpara></entry>
<entry align="left" valign="top"><simpara>5.4+</simpara></entry>
<entry align="left" valign="top"><simpara>Fluentd, Vector <superscript>[2]</superscript></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Amazon CloudWatch</simpara></entry>
<entry align="left" valign="top"><simpara>REST over HTTPS</simpara></entry>
<entry align="left" valign="top"><simpara>Latest</simpara></entry>
<entry align="left" valign="top"><simpara>5.4+</simpara></entry>
<entry align="left" valign="top"><simpara>Fluentd, Vector</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<para role="small">
<orderedlist numeration="arabic">
<listitem>
<simpara>Fluentd does not support Elasticsearch 8 in the logging version 5.6.2.</simpara>
</listitem>
<listitem>
<simpara>Vector supports Syslog in the logging version 5.7 and higher.</simpara>
</listitem>
</orderedlist>
</para>
</section>
<section xml:id="logging-output-types-descriptions">
<title>Output type descriptions</title>
<variablelist>
<varlistentry>
<term><literal>default</literal></term>
<listitem>
<simpara>The on-cluster, Red&#160;Hat managed log store. You are not required to configure the default output.</simpara>
<note>
<simpara>If you configure a <literal>default</literal> output, you receive an error message, because the <literal>default</literal> output name is reserved for referencing the on-cluster, Red&#160;Hat managed log store.</simpara>
</note>
</listitem>
</varlistentry>
<varlistentry>
<term><literal>loki</literal></term>
<listitem>
<simpara>Loki, a horizontally scalable, highly available, multi-tenant log aggregation system.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term><literal>kafka</literal></term>
<listitem>
<simpara>A Kafka broker. The <literal>kafka</literal> output can use a TCP or TLS connection.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term><literal>elasticsearch</literal></term>
<listitem>
<simpara>An external Elasticsearch instance. The <literal>elasticsearch</literal> output can use a TLS connection.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term><literal>fluentdForward</literal></term>
<listitem>
<simpara>An external log aggregation solution that supports Fluentd. This option uses the Fluentd <literal>forward</literal> protocols. The <literal>fluentForward</literal> output can use a TCP or TLS connection and supports shared-key authentication by providing a <literal>shared_key</literal> field in a secret. Shared-key authentication can be used with or without TLS.</simpara>
<important>
<simpara>The <literal>fluentdForward</literal> output is only supported if you are using the Fluentd collector. It is not supported if you are using the Vector collector. If you are using the Vector collector, you can forward logs to Fluentd by using the <literal>http</literal> output.</simpara>
</important>
</listitem>
</varlistentry>
<varlistentry>
<term><literal>syslog</literal></term>
<listitem>
<simpara>An external log aggregation solution that supports the syslog <link xlink:href="https://tools.ietf.org/html/rfc3164">RFC3164</link> or <link xlink:href="https://tools.ietf.org/html/rfc5424">RFC5424</link> protocols. The <literal>syslog</literal> output can use a UDP, TCP, or TLS connection.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term><literal>cloudwatch</literal></term>
<listitem>
<simpara>Amazon CloudWatch, a monitoring and log storage service hosted by Amazon Web Services (AWS).</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
</section>
<section xml:id="cluster-logging-enabling-json-logging">
<title>Enabling JSON log forwarding</title>

<simpara>You can configure the Log Forwarding API to parse JSON strings into a structured object.</simpara>
<section xml:id="cluster-logging-json-log-forwarding_cluster-logging-enabling-json-logging">
<title>Parsing JSON logs</title>
<simpara>You can use a <literal>ClusterLogForwarder</literal> object to parse JSON logs into a structured object and forward them to a supported output.</simpara>
<simpara>To illustrate how this works, suppose that you have the following structured JSON log entry:</simpara>
<formalpara>
<title>Example structured JSON log entry</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">{"level":"info","name":"fred","home":"bedrock"}</programlisting>
</para>
</formalpara>
<simpara>To enable parsing JSON log, you add <literal>parse: json</literal> to a pipeline in the <literal>ClusterLogForwarder</literal> CR, as shown in the following example:</simpara>
<formalpara>
<title>Example snippet showing <literal>parse: json</literal></title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">pipelines:
- inputRefs: [ application ]
  outputRefs: myFluentd
  parse: json</programlisting>
</para>
</formalpara>
<simpara>When you enable parsing JSON logs by using <literal>parse: json</literal>, the CR copies the JSON-structured log entry in a <literal>structured</literal> field, as shown in the following example:</simpara>
<formalpara>
<title>Example <literal>structured</literal> output containing the structured JSON log entry</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">{"structured": { "level": "info", "name": "fred", "home": "bedrock" },
 "more fields..."}</programlisting>
</para>
</formalpara>
<important>
<simpara>If the log entry does not contain valid structured JSON, the <literal>structured</literal> field is absent.</simpara>
</important>
</section>
<section xml:id="cluster-logging-configuration-of-json-log-data-for-default-elasticsearch_cluster-logging-enabling-json-logging">
<title>Configuring JSON log data for Elasticsearch</title>
<simpara>If your JSON logs follow more than one schema, storing them in a single index might cause type conflicts and cardinality problems. To avoid that, you must configure the <literal>ClusterLogForwarder</literal> custom resource (CR) to group each schema into a single output definition. This way, each schema is forwarded to a separate index.</simpara>
<important>
<simpara>If you forward JSON logs to the default Elasticsearch instance managed by OpenShift Logging, it generates new indices based on your configuration. To avoid performance issues associated with having too many indices, consider keeping the number of possible schemas low by standardizing to common schemas.</simpara>
</important>
<formalpara>
<title>Structure types</title>
<para>You can use the following structure types in the <literal>ClusterLogForwarder</literal> CR to construct index names for the Elasticsearch log store:</para>
</formalpara>
<itemizedlist>
<listitem>
<simpara><literal>structuredTypeKey</literal> is the name of a message field. The value of that field is used to construct the index name.</simpara>
<itemizedlist>
<listitem>
<simpara><literal>kubernetes.labels.&lt;key&gt;</literal> is the Kubernetes pod label whose value is used to construct the index name.</simpara>
</listitem>
<listitem>
<simpara><literal>openshift.labels.&lt;key&gt;</literal> is the <literal>pipeline.label.&lt;key&gt;</literal> element in the <literal>ClusterLogForwarder</literal> CR whose value is used to construct the index name.</simpara>
</listitem>
<listitem>
<simpara><literal>kubernetes.container_name</literal> uses the container name to construct the index name.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara><literal>structuredTypeName</literal>: If the <literal>structuredTypeKey</literal> field is not set or its key is not present, the <literal>structuredTypeName</literal> value is used as the structured type. When you use both the <literal>structuredTypeKey</literal> field and the <literal>structuredTypeName</literal> field together, the <literal>structuredTypeName</literal> value provides a fallback index name if the key in the <literal>structuredTypeKey</literal> field is missing from the JSON log data.</simpara>
</listitem>
</itemizedlist>
<note>
<simpara>Although you can set the value of <literal>structuredTypeKey</literal> to any field shown in the "Log Record Fields" topic, the most useful fields are shown in the preceding list of structure types.</simpara>
</note>
<formalpara>
<title>A structuredTypeKey: kubernetes.labels.&lt;key&gt; example</title>
<para>Suppose the following:</para>
</formalpara>
<itemizedlist>
<listitem>
<simpara>Your cluster is running application pods that produce JSON logs in two different formats, "apache" and "google".</simpara>
</listitem>
<listitem>
<simpara>The user labels these application pods with <literal>logFormat=apache</literal> and <literal>logFormat=google</literal>.</simpara>
</listitem>
<listitem>
<simpara>You use the following snippet in your <literal>ClusterLogForwarder</literal> CR YAML file.</simpara>
</listitem>
</itemizedlist>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
# ...
spec:
# ...
  outputDefaults:
    elasticsearch:
      structuredTypeKey: kubernetes.labels.logFormat <co xml:id="CO18-1"/>
      structuredTypeName: nologformat
  pipelines:
  - inputRefs:
    - application
    outputRefs:
    - default
    parse: json <co xml:id="CO18-2"/></programlisting>
<calloutlist>
<callout arearefs="CO18-1">
<para>Uses the value of the key-value pair that is formed by the Kubernetes <literal>logFormat</literal> label.</para>
</callout>
<callout arearefs="CO18-2">
<para>Enables parsing JSON logs.</para>
</callout>
</calloutlist>
<simpara>In that case, the following structured log record goes to the <literal>app-apache-write</literal> index:</simpara>
<screen linenumbering="unnumbered">{
  "structured":{"name":"fred","home":"bedrock"},
  "kubernetes":{"labels":{"logFormat": "apache", ...}}
}</screen>
<simpara>And the following structured log record goes to the <literal>app-google-write</literal> index:</simpara>
<screen linenumbering="unnumbered">{
  "structured":{"name":"wilma","home":"bedrock"},
  "kubernetes":{"labels":{"logFormat": "google", ...}}
}</screen>
<formalpara>
<title>A structuredTypeKey: openshift.labels.&lt;key&gt; example</title>
<para>Suppose that you use the following snippet in your <literal>ClusterLogForwarder</literal> CR YAML file.</para>
</formalpara>
<programlisting language="yaml" linenumbering="unnumbered">outputDefaults:
 elasticsearch:
    structuredTypeKey: openshift.labels.myLabel <co xml:id="CO19-1"/>
    structuredTypeName: nologformat
pipelines:
 - name: application-logs
   inputRefs:
   - application
   - audit
   outputRefs:
   - elasticsearch-secure
   - default
   parse: json
   labels:
     myLabel: myValue <co xml:id="CO19-2"/></programlisting>
<calloutlist>
<callout arearefs="CO19-1">
<para>Uses the value of the key-value pair that is formed by the OpenShift <literal>myLabel</literal> label.</para>
</callout>
<callout arearefs="CO19-2">
<para>The <literal>myLabel</literal> element gives its string value, <literal>myValue</literal>, to the structured log record.</para>
</callout>
</calloutlist>
<simpara>In that case, the following structured log record goes to the <literal>app-myValue-write</literal> index:</simpara>
<screen linenumbering="unnumbered">{
  "structured":{"name":"fred","home":"bedrock"},
  "openshift":{"labels":{"myLabel": "myValue", ...}}
}</screen>
<itemizedlist>
<title>Additional considerations</title>
<listitem>
<simpara>The Elasticsearch <emphasis>index</emphasis> for structured records is formed by prepending "app-" to the structured type and appending "-write".</simpara>
</listitem>
<listitem>
<simpara>Unstructured records are not sent to the structured index. They are indexed as usual in the application, infrastructure, or audit indices.</simpara>
</listitem>
<listitem>
<simpara>If there is no non-empty structured type, forward an <emphasis>unstructured</emphasis> record with no <literal>structured</literal> field.</simpara>
</listitem>
</itemizedlist>
<simpara>It is important not to overload Elasticsearch with too many indices. Only use distinct structured types for distinct log <emphasis>formats</emphasis>, <emphasis role="strong">not</emphasis> for each application or namespace. For example, most Apache applications use the same JSON log format and structured type, such as <literal>LogApache</literal>.</simpara>
</section>
<section xml:id="cluster-logging-forwarding-json-logs-to-the-default-elasticsearch_cluster-logging-enabling-json-logging">
<title>Forwarding JSON logs to the Elasticsearch log store</title>
<simpara>For an Elasticsearch log store, if your JSON log entries <emphasis>follow different schemas</emphasis>, configure the <literal>ClusterLogForwarder</literal> custom resource (CR) to group each JSON schema into a single output definition. This way, Elasticsearch uses a separate index for each schema.</simpara>
<important>
<simpara>Because forwarding different schemas to the same index can cause type conflicts and cardinality problems, you must perform this configuration before you forward data to the Elasticsearch store.</simpara>
<simpara>To avoid performance issues associated with having too many indices, consider keeping the number of possible schemas low by standardizing to common schemas.</simpara>
</important>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Add the following snippet to your <literal>ClusterLogForwarder</literal> CR YAML file.</simpara>
<programlisting language="yaml" linenumbering="unnumbered">outputDefaults:
 elasticsearch:
    structuredTypeKey: &lt;log record field&gt;
    structuredTypeName: &lt;name&gt;
pipelines:
- inputRefs:
  - application
  outputRefs: default
  parse: json</programlisting>
</listitem>
<listitem>
<simpara>Use <literal>structuredTypeKey</literal> field to specify one of the log record fields.</simpara>
</listitem>
<listitem>
<simpara>Use <literal>structuredTypeName</literal> field to specify a name.</simpara>
<important>
<simpara>To parse JSON logs, you must set both the <literal>structuredTypeKey</literal> and <literal>structuredTypeName</literal> fields.</simpara>
</important>
</listitem>
<listitem>
<simpara>For <literal>inputRefs</literal>, specify which log types to forward by using that pipeline, such as <literal>application,</literal> <literal>infrastructure</literal>, or <literal>audit</literal>.</simpara>
</listitem>
<listitem>
<simpara>Add the <literal>parse: json</literal> element to pipelines.</simpara>
</listitem>
<listitem>
<simpara>Create the CR object:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create -f &lt;filename&gt;.yaml</programlisting>
<simpara>The Red Hat OpenShift Logging Operator redeploys the collector pods. However, if they do not redeploy, delete the collector pods to force them to redeploy.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc delete pod --selector logging-infra=collector</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="cluster-logging-forwarding-separate-indices_cluster-logging-enabling-json-logging">
<title>Forwarding JSON logs from containers in the same pod to separate indices</title>
<simpara>You can forward structured logs from different containers within the same pod to different indices. To use this feature, you must configure the pipeline with multi-container support and annotate the pods. Logs are written to indices with a prefix of <literal>app-</literal>. It is recommended that Elasticsearch be configured with aliases to accommodate this.</simpara>
<important>
<simpara>JSON formatting of logs varies by application. Because creating too many indices impacts performance, limit your use of this feature to creating indices for logs that have incompatible JSON formats. Use queries to separate logs from different namespaces, or applications with compatible JSON formats.</simpara>
</important>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Logging for Red Hat OpenShift: 5.5</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create or edit a YAML file that defines the <literal>ClusterLogForwarder</literal> CR object:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging
spec:
  outputDefaults:
    elasticsearch:
      structuredTypeKey: kubernetes.labels.logFormat <co xml:id="CO20-1"/>
      structuredTypeName: nologformat
      enableStructuredContainerLogs: true <co xml:id="CO20-2"/>
  pipelines:
  - inputRefs:
    - application
    name: application-logs
    outputRefs:
    - default
    parse: json</programlisting>
<calloutlist>
<callout arearefs="CO20-1">
<para>Uses the value of the key-value pair that is formed by the Kubernetes <literal>logFormat</literal> label.</para>
</callout>
<callout arearefs="CO20-2">
<para>Enables multi-container outputs.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Create or edit a YAML file that defines the <literal>Pod</literal> CR object:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  annotations:
    containerType.logging.openshift.io/heavy: heavy <co xml:id="CO21-1"/>
    containerType.logging.openshift.io/low: low
spec:
  containers:
  - name: heavy <co xml:id="CO21-2"/>
    image: heavyimage
  - name: low
    image: lowimage</programlisting>
<calloutlist>
<callout arearefs="CO21-1">
<para>Format: <literal>containerType.logging.openshift.io/&lt;container-name&gt;: &lt;index&gt;</literal></para>
</callout>
<callout arearefs="CO21-2">
<para>Annotation names must match container names</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
<warning>
<simpara>This configuration might significantly increase the number of shards on the cluster.</simpara>
</warning>
<itemizedlist>
<title>Additional Resources</title>
<listitem>
<simpara><link xlink:href="https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/">Kubernetes Annotations</link></simpara>
</listitem>
</itemizedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link linkend="log-forwarding">About log forwarding</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="configuring-log-forwarding">
<title>Configuring log forwarding</title>

<simpara>By default, the logging sends container and infrastructure logs to the default internal log store defined in the <literal>ClusterLogging</literal> custom resource. However, it does not send audit logs to the internal store because it does not provide secure storage. If this default configuration meets your needs, you do not need to configure the Cluster Log Forwarder.</simpara>
<note>
<simpara>To send audit logs to the internal Elasticsearch log store, use the Cluster Log Forwarder as described in <link linkend="cluster-logging-elasticsearch-audit_logging-config-es-store">Forwarding audit logs to the log store</link>.</simpara>
</note>
<section xml:id="cluster-logging-collector-log-forwarding-about_configuring-log-forwarding">
<title>About forwarding logs to third-party systems</title>
<simpara>To send logs to specific endpoints inside and outside your OpenShift Container Platform cluster, you specify a combination of <emphasis>outputs</emphasis> and <emphasis>pipelines</emphasis> in a <literal>ClusterLogForwarder</literal> custom resource (CR). You can also use <emphasis>inputs</emphasis> to forward the application logs associated with a specific project to an endpoint. Authentication is provided by a Kubernetes <emphasis>Secret</emphasis> object.</simpara>
<variablelist>
<varlistentry>
<term><emphasis>pipeline</emphasis></term>
<listitem>
<simpara>Defines simple routing from one log type to one or more outputs, or which logs you want to send. The log types are one of the following:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>application</literal>. Container logs generated by user applications running in the cluster, except infrastructure container applications.</simpara>
</listitem>
<listitem>
<simpara><literal>infrastructure</literal>. Container logs from pods that run in the <literal>openshift*</literal>, <literal>kube*</literal>, or <literal>default</literal> projects and journal logs sourced from node file system.</simpara>
</listitem>
<listitem>
<simpara><literal>audit</literal>. Audit logs generated by the node audit system, <literal>auditd</literal>, Kubernetes API server, OpenShift API server, and OVN network.</simpara>
</listitem>
</itemizedlist>
<simpara>You can add labels to outbound log messages by using <literal>key:value</literal> pairs in the pipeline. For example, you might add a label to messages that are forwarded to other data centers or label the logs by type. Labels that are added to objects are also forwarded with the log message.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term><emphasis>input</emphasis></term>
<listitem>
<simpara>Forwards the application logs associated with a specific project to a pipeline.</simpara>
<simpara>In the pipeline, you define which log types to forward using an <literal>inputRef</literal> parameter and where to forward the logs to using an <literal>outputRef</literal> parameter.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term><emphasis>Secret</emphasis></term>
<listitem>
<simpara>A <literal>key:value map</literal> that contains confidential data such as user credentials.</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Note the following:</simpara>
<itemizedlist>
<listitem>
<simpara>If a <literal>ClusterLogForwarder</literal> CR object exists, logs are not forwarded to the default Elasticsearch instance, unless there is a pipeline with the <literal>default</literal> output.</simpara>
</listitem>
<listitem>
<simpara>By default, the logging sends container and infrastructure logs to the default internal Elasticsearch log store defined in the <literal>ClusterLogging</literal> custom resource. However, it does not send audit logs to the internal store because it does not provide secure storage. If this default configuration meets your needs, do not configure the Log Forwarding API.</simpara>
</listitem>
<listitem>
<simpara>If you do not define a pipeline for a log type, the logs of the undefined types are dropped. For example, if you specify a pipeline for the <literal>application</literal> and <literal>audit</literal> types, but do not specify a pipeline for the <literal>infrastructure</literal> type, <literal>infrastructure</literal> logs are dropped.</simpara>
</listitem>
<listitem>
<simpara>You can use multiple types of outputs in the <literal>ClusterLogForwarder</literal> custom resource (CR) to send logs to servers that support different protocols.</simpara>
</listitem>
<listitem>
<simpara>The internal OpenShift Container Platform Elasticsearch instance does not provide secure storage for audit logs. We recommend you ensure that the system to which you forward audit logs is compliant with your organizational and governmental regulations and is properly secured. The logging does not comply with those regulations.</simpara>
</listitem>
</itemizedlist>
<simpara>The following example forwards the audit logs to a secure external Elasticsearch instance, the infrastructure logs to an insecure external Elasticsearch instance, the application logs to a Kafka broker, and the application logs from the <literal>my-apps-logs</literal> project to the internal Elasticsearch instance.</simpara>
<formalpara>
<title>Sample log forwarding outputs and pipelines</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: "logging.openshift.io/v1"
kind: ClusterLogForwarder
metadata:
  name: &lt;log_forwarder_name&gt; <co xml:id="CO22-1"/>
  namespace: &lt;log_forwarder_namespace&gt; <co xml:id="CO22-2"/>
spec:
  serviceAccountName: &lt;service_account_name&gt; <co xml:id="CO22-3"/>
  outputs:
   - name: elasticsearch-secure <co xml:id="CO22-4"/>
     type: "elasticsearch"
     url: https://elasticsearch.secure.com:9200
     secret:
        name: elasticsearch
   - name: elasticsearch-insecure <co xml:id="CO22-5"/>
     type: "elasticsearch"
     url: http://elasticsearch.insecure.com:9200
   - name: kafka-app <co xml:id="CO22-6"/>
     type: "kafka"
     url: tls://kafka.secure.com:9093/app-topic
  inputs: <co xml:id="CO22-7"/>
   - name: my-app-logs
     application:
        namespaces:
        - my-project
  pipelines:
   - name: audit-logs <co xml:id="CO22-8"/>
     inputRefs:
      - audit
     outputRefs:
      - elasticsearch-secure
      - default
     labels:
       secure: "true" <co xml:id="CO22-9"/>
       datacenter: "east"
   - name: infrastructure-logs <co xml:id="CO22-10"/>
     inputRefs:
      - infrastructure
     outputRefs:
      - elasticsearch-insecure
     labels:
       datacenter: "west"
   - name: my-app <co xml:id="CO22-11"/>
     inputRefs:
      - my-app-logs
     outputRefs:
      - default
   - inputRefs: <co xml:id="CO22-12"/>
      - application
     outputRefs:
      - kafka-app
     labels:
       datacenter: "south"</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO22-1">
<para>In legacy implementations, the CR name must be <literal>instance</literal>. In multi log forwarder implementations, you can use any name.</para>
</callout>
<callout arearefs="CO22-2">
<para>In legacy implementations, the CR namespace must be <literal>openshift-logging</literal>. In multi log forwarder implementations, you can use any namespace.</para>
</callout>
<callout arearefs="CO22-3">
<para>The name of your service account. The service account is only required in multi log forwarder implementations if the log forwarder is not deployed in the <literal>openshift-logging</literal> namespace.</para>
</callout>
<callout arearefs="CO22-4">
<para>Configuration for an secure Elasticsearch output using a secret with a secure URL.</para>
<itemizedlist>
<listitem>
<simpara>A name to describe the output.</simpara>
</listitem>
<listitem>
<simpara>The type of output: <literal>elasticsearch</literal>.</simpara>
</listitem>
<listitem>
<simpara>The secure URL and port of the Elasticsearch instance as a valid absolute URL, including the prefix.</simpara>
</listitem>
<listitem>
<simpara>The secret required by the endpoint for TLS communication. The secret must exist in the <literal>openshift-logging</literal> project.</simpara>
</listitem>
</itemizedlist>
</callout>
<callout arearefs="CO22-5">
<para>Configuration for an insecure Elasticsearch output:</para>
<itemizedlist>
<listitem>
<simpara>A name to describe the output.</simpara>
</listitem>
<listitem>
<simpara>The type of output: <literal>elasticsearch</literal>.</simpara>
</listitem>
<listitem>
<simpara>The insecure URL and port of the Elasticsearch instance as a valid absolute URL, including the prefix.</simpara>
</listitem>
</itemizedlist>
</callout>
<callout arearefs="CO22-6">
<para>Configuration for a Kafka output using a client-authenticated TLS communication over a secure URL:</para>
<itemizedlist>
<listitem>
<simpara>A name to describe the output.</simpara>
</listitem>
<listitem>
<simpara>The type of output: <literal>kafka</literal>.</simpara>
</listitem>
<listitem>
<simpara>Specify the URL and port of the Kafka broker as a valid absolute URL, including the prefix.</simpara>
</listitem>
</itemizedlist>
</callout>
<callout arearefs="CO22-7">
<para>Configuration for an input to filter application logs from the <literal>my-project</literal> namespace.</para>
</callout>
<callout arearefs="CO22-8">
<para>Configuration for a pipeline to send audit logs to the secure external Elasticsearch instance:</para>
<itemizedlist>
<listitem>
<simpara>A name to describe the pipeline.</simpara>
</listitem>
<listitem>
<simpara>The <literal>inputRefs</literal> is the log type, in this example <literal>audit</literal>.</simpara>
</listitem>
<listitem>
<simpara>The <literal>outputRefs</literal> is the name of the output to use, in this example <literal>elasticsearch-secure</literal> to forward to the secure Elasticsearch instance and <literal>default</literal> to forward to the internal Elasticsearch instance.</simpara>
</listitem>
<listitem>
<simpara>Optional: Labels to add to the logs.</simpara>
</listitem>
</itemizedlist>
</callout>
<callout arearefs="CO22-9">
<para>Optional: String. One or more labels to add to the logs. Quote values like "true" so they are recognized as string values, not as a boolean.</para>
</callout>
<callout arearefs="CO22-10">
<para>Configuration for a pipeline to send infrastructure logs to the insecure external Elasticsearch instance.</para>
</callout>
<callout arearefs="CO22-11">
<para>Configuration for a pipeline to send logs from the <literal>my-project</literal> project to the internal Elasticsearch instance.</para>
<itemizedlist>
<listitem>
<simpara>A name to describe the pipeline.</simpara>
</listitem>
<listitem>
<simpara>The <literal>inputRefs</literal> is a specific input: <literal>my-app-logs</literal>.</simpara>
</listitem>
<listitem>
<simpara>The <literal>outputRefs</literal> is <literal>default</literal>.</simpara>
</listitem>
<listitem>
<simpara>Optional: String. One or more labels to add to the logs.</simpara>
</listitem>
</itemizedlist>
</callout>
<callout arearefs="CO22-12">
<para>Configuration for a pipeline to send logs to the Kafka broker, with no pipeline name:</para>
<itemizedlist>
<listitem>
<simpara>The <literal>inputRefs</literal> is the log type, in this example <literal>application</literal>.</simpara>
</listitem>
<listitem>
<simpara>The <literal>outputRefs</literal> is the name of the output to use.</simpara>
</listitem>
<listitem>
<simpara>Optional: String. One or more labels to add to the logs.</simpara>
</listitem>
</itemizedlist>
</callout>
</calloutlist>
<bridgehead xml:id="cluster-logging-external-fluentd_configuring-log-forwarding" renderas="sect4">Fluentd log handling when the external log aggregator is unavailable</bridgehead>
<simpara>If your external logging aggregator becomes unavailable and cannot receive logs, Fluentd continues to collect logs and stores them in a buffer. When the log aggregator becomes available, log forwarding resumes, including the buffered logs. If the buffer fills completely, Fluentd stops collecting logs. OpenShift Container Platform rotates the logs and deletes them. You cannot adjust the buffer size or add a persistent volume claim (PVC) to the Fluentd daemon set or pods.</simpara>
<bridgehead xml:id="_supported-authorization-keys" renderas="sect4">Supported Authorization Keys</bridgehead>
<simpara>Common key types are provided here. Some output types support additional specialized keys, documented with the output-specific configuration field. All secret keys are optional. Enable the security features you want by setting the relevant keys. You are responsible for creating and maintaining any additional configurations that external destinations might require, such as keys and secrets, service accounts, port openings, or global proxy configuration. Open Shift Logging will not attempt to verify a mismatch between authorization combinations.</simpara>
<variablelist>
<varlistentry>
<term>Transport Layer Security (TLS)</term>
<listitem>
<simpara>Using a TLS URL (<literal>http://...</literal> or <literal>ssl://...</literal>) without a secret enables basic TLS server-side authentication. Additional TLS features are enabled by including a secret and setting the following optional fields:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>passphrase</literal>: (string) Passphrase to decode an encoded TLS private key. Requires <literal>tls.key</literal>.</simpara>
</listitem>
<listitem>
<simpara><literal>ca-bundle.crt</literal>: (string) File name of a customer CA for server authentication.</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>Username and Password</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>username</literal>: (string) Authentication user name. Requires <literal>password</literal>.</simpara>
</listitem>
<listitem>
<simpara><literal>password</literal>: (string) Authentication password. Requires <literal>username</literal>.</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>Simple Authentication Security Layer (SASL)</term>
<listitem>
<itemizedlist>
<listitem>
<simpara><literal>sasl.enable</literal> (boolean) Explicitly enable or disable SASL.
If missing, SASL is automatically enabled when any of the other <literal>sasl.</literal> keys are set.</simpara>
</listitem>
<listitem>
<simpara><literal>sasl.mechanisms</literal>: (array) List of allowed SASL mechanism names.
If missing or empty, the system defaults are used.</simpara>
</listitem>
<listitem>
<simpara><literal>sasl.allow-insecure</literal>: (boolean) Allow mechanisms that send clear-text passwords. Defaults to false.</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<section xml:id="_creating-a-secret">
<title>Creating a Secret</title>
<simpara>You can create a secret in the directory that contains your certificate and key files by using the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create secret generic -n &lt;namespace&gt; &lt;secret_name&gt; \
  --from-file=ca-bundle.crt=&lt;your_bundle_file&gt; \
  --from-literal=username=&lt;your_username&gt; \
  --from-literal=password=&lt;your_password&gt;</programlisting>
<note>
<simpara>Generic or opaque secrets are recommended for best results.</simpara>
</note>
</section>
</section>
<section xml:id="logging-create-clf_configuring-log-forwarding">
<title>Creating a log forwarder</title>
<simpara>To create a log forwarder, you must create a <literal>ClusterLogForwarder</literal> CR that specifies the log input types that the service account can collect. You can also specify which outputs the logs can be forwarded to. If you are using the multi log forwarder feature, you must also reference the service account in the <literal>ClusterLogForwarder</literal> CR.</simpara>
<simpara>If you are using the multi log forwarder feature on your cluster, you can create <literal>ClusterLogForwarder</literal> custom resources (CRs) in any namespace, using any name.
If you are using a legacy implementation, the <literal>ClusterLogForwarder</literal> CR must be named <literal>instance</literal>, and must be created in the <literal>openshift-logging</literal> namespace.</simpara>
<important>
<simpara>You need administrator permissions for the namespace where you create the <literal>ClusterLogForwarder</literal> CR.</simpara>
</important>
<formalpara>
<title>ClusterLogForwarder resource example</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: &lt;log_forwarder_name&gt; <co xml:id="CO23-1"/>
  namespace: &lt;log_forwarder_namespace&gt; <co xml:id="CO23-2"/>
spec:
  serviceAccountName: &lt;service_account_name&gt; <co xml:id="CO23-3"/>
  pipelines:
   - inputRefs:
     - &lt;log_type&gt; <co xml:id="CO23-4"/>
     outputRefs:
     - &lt;output_name&gt; <co xml:id="CO23-5"/>
  outputs:
  - name: &lt;output_name&gt; <co xml:id="CO23-6"/>
    type: &lt;output_type&gt; <co xml:id="CO23-7"/>
    url: &lt;log_output_url&gt; <co xml:id="CO23-8"/>
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO23-1">
<para>In legacy implementations, the CR name must be <literal>instance</literal>. In multi log forwarder implementations, you can use any name.</para>
</callout>
<callout arearefs="CO23-2">
<para>In legacy implementations, the CR namespace must be <literal>openshift-logging</literal>. In multi log forwarder implementations, you can use any namespace.</para>
</callout>
<callout arearefs="CO23-3">
<para>The name of your service account. The service account is only required in multi log forwarder implementations if the log forwarder is not deployed in the <literal>openshift-logging</literal> namespace.</para>
</callout>
<callout arearefs="CO23-4">
<para>The log types that are collected. The value for this field can be <literal>audit</literal> for audit logs, <literal>application</literal> for application logs, <literal>infrastructure</literal> for infrastructure logs, or a named input that has been defined for your application.</para>
</callout>
<callout arearefs="CO23-5 CO23-7">
<para>The type of output that you want to forward logs to. The value of this field can be <literal>default</literal>, <literal>loki</literal>, <literal>kafka</literal>, <literal>elasticsearch</literal>, <literal>fluentdForward</literal>, <literal>syslog</literal>, or <literal>cloudwatch</literal>.</para>
<note>
<simpara>The <literal>default</literal> output type is not supported in mutli log forwarder implementations.</simpara>
</note>
</callout>
<callout arearefs="CO23-6">
<para>A name for the output that you want to forward logs to.</para>
</callout>
<callout arearefs="CO23-8">
<para>The URL of the output that you want to forward logs to.</para>
</callout>
</calloutlist>
</section>
<section xml:id="logging-multiline-except_configuring-log-forwarding">
<title>Enabling multi-line exception detection</title>
<simpara>Enables multi-line error detection of container logs.</simpara>
<warning>
<simpara>Enabling this feature could have performance implications and may require additional computing resources or alternate logging solutions.</simpara>
</warning>
<simpara>Log parsers often incorrectly identify separate lines of the same exception as separate exceptions. This leads to extra log entries and an incomplete or inaccurate view of the traced information.</simpara>
<formalpara>
<title>Example java exception</title>
<para>
<programlisting language="text" linenumbering="unnumbered">java.lang.NullPointerException: Cannot invoke "String.toString()" because "&lt;param1&gt;" is null
    at testjava.Main.handle(Main.java:47)
    at testjava.Main.printMe(Main.java:19)
    at testjava.Main.main(Main.java:10)</programlisting>
</para>
</formalpara>
<itemizedlist>
<listitem>
<simpara>To enable logging to detect multi-line exceptions and reassemble them into a single log entry, ensure that the <literal>ClusterLogForwarder</literal> Custom Resource (CR) contains a <literal>detectMultilineErrors</literal> field, with a value of <literal>true</literal>.</simpara>
</listitem>
</itemizedlist>
<formalpara>
<title>Example ClusterLogForwarder CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging
spec:
  pipelines:
    - name: my-app-logs
      inputRefs:
        - application
      outputRefs:
        - default
      detectMultilineErrors: true</programlisting>
</para>
</formalpara>
<section xml:id="_details">
<title>Details</title>
<simpara>When log messages appear as a consecutive sequence forming an exception stack trace, they are combined into a single, unified log record. The first log message&#8217;s content is replaced with the concatenated content of all the message fields in the sequence.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Supported languages per collector:</title>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Language</entry>
<entry align="left" valign="top">Fluentd</entry>
<entry align="left" valign="top">Vector</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Java</simpara></entry>
<entry align="left" valign="top"><simpara>✓</simpara></entry>
<entry align="left" valign="top"><simpara>✓</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>JS</simpara></entry>
<entry align="left" valign="top"><simpara>✓</simpara></entry>
<entry align="left" valign="top"><simpara>✓</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Ruby</simpara></entry>
<entry align="left" valign="top"><simpara>✓</simpara></entry>
<entry align="left" valign="top"><simpara>✓</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Python</simpara></entry>
<entry align="left" valign="top"><simpara>✓</simpara></entry>
<entry align="left" valign="top"><simpara>✓</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Golang</simpara></entry>
<entry align="left" valign="top"><simpara>✓</simpara></entry>
<entry align="left" valign="top"><simpara>✓</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>PHP</simpara></entry>
<entry align="left" valign="top"><simpara>✓</simpara></entry>
<entry align="left" valign="top"><simpara>✓</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Dart</simpara></entry>
<entry align="left" valign="top"><simpara>✓</simpara></entry>
<entry align="left" valign="top"><simpara>✓</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section xml:id="_troubleshooting">
<title>Troubleshooting</title>
<simpara>When enabled, the collector configuration will include a new section with type: <literal>detect_exceptions</literal></simpara>
<formalpara>
<title>Example vector configuration section</title>
<para>
<screen>[transforms.detect_exceptions_app-logs]
 type = "detect_exceptions"
 inputs = ["application"]
 languages = ["All"]
 group_by = ["kubernetes.namespace_name","kubernetes.pod_name","kubernetes.container_name"]
 expire_after_ms = 2000
 multiline_flush_interval_ms = 1000</screen>
</para>
</formalpara>
<formalpara>
<title>Example fluentd config section</title>
<para>
<screen>&lt;label @MULTILINE_APP_LOGS&gt;
  &lt;match kubernetes.**&gt;
    @type detect_exceptions
    remove_tag_prefix 'kubernetes'
    message message
    force_line_breaks true
    multiline_flush_interval .2
  &lt;/match&gt;
&lt;/label&gt;</screen>
</para>
</formalpara>
</section>
</section>
<section xml:id="cluster-logging-collector-log-forward-gcp_configuring-log-forwarding">
<title>Forwarding logs to Google Cloud Platform (GCP)</title>
<simpara>You can forward logs to <link xlink:href="https://cloud.google.com/logging/docs/basic-concepts">Google Cloud Logging</link> in addition to, or instead of, the internal default OpenShift Container Platform log store.</simpara>
<note>
<simpara>Using this feature with Fluentd is not supported.</simpara>
</note>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Red Hat OpenShift Logging Operator 5.5.1 and later</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a secret using your <link xlink:href="https://cloud.google.com/iam/docs/creating-managing-service-account-keys">Google service account key</link>.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging create secret generic gcp-secret --from-file google-application-credentials.json=<emphasis>&lt;your_service_account_key_file.json&gt;</emphasis></programlisting>
</listitem>
<listitem>
<simpara>Create a <literal>ClusterLogForwarder</literal> Custom Resource YAML using the template below:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: &lt;log_forwarder_name&gt; <co xml:id="CO24-1"/>
  namespace: &lt;log_forwarder_namespace&gt; <co xml:id="CO24-2"/>
spec:
  serviceAccountName: &lt;service_account_name&gt; <co xml:id="CO24-3"/>
  outputs:
    - name: gcp-1
      type: googleCloudLogging
      secret:
        name: gcp-secret
      googleCloudLogging:
        projectId : "openshift-gce-devel" <co xml:id="CO24-4"/>
        logId : "app-gcp" <co xml:id="CO24-5"/>
  pipelines:
    - name: test-app
      inputRefs: <co xml:id="CO24-6"/>
        - application
      outputRefs:
        - gcp-1</programlisting>
<calloutlist>
<callout arearefs="CO24-1">
<para>In legacy implementations, the CR name must be <literal>instance</literal>. In multi log forwarder implementations, you can use any name.</para>
</callout>
<callout arearefs="CO24-2">
<para>In legacy implementations, the CR namespace must be <literal>openshift-logging</literal>. In multi log forwarder implementations, you can use any namespace.</para>
</callout>
<callout arearefs="CO24-3">
<para>The name of your service account. The service account is only required in multi log forwarder implementations if the log forwarder is not deployed in the <literal>openshift-logging</literal> namespace.</para>
</callout>
<callout arearefs="CO24-4">
<para>Set a <literal>projectId</literal>, <literal>folderId</literal>, <literal>organizationId</literal>, or <literal>billingAccountId</literal> field and its corresponding value, depending on where you want to store your logs in the <link xlink:href="https://cloud.google.com/resource-manager/docs/cloud-platform-resource-hierarchy">GCP resource hierarchy</link>.</para>
</callout>
<callout arearefs="CO24-5">
<para>Set the value to add to the <literal>logName</literal> field of the <link xlink:href="https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry">Log Entry</link>.</para>
</callout>
<callout arearefs="CO24-6">
<para>Specify which log types to forward by using the pipeline: <literal>application</literal>, <literal>infrastructure</literal>, or <literal>audit</literal>.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://cloud.google.com/billing/docs/concepts">Google Cloud Billing Documentation</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://cloud.google.com/logging/docs/view/logging-query-language">Google Cloud Logging Query Language Documentation</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-forward-splunk_configuring-log-forwarding">
<title>Forwarding logs to Splunk</title>
<simpara>You can forward logs to the <link xlink:href="https://docs.splunk.com/Documentation/Splunk/9.0.0/Data/UsetheHTTPEventCollector">Splunk HTTP Event Collector (HEC)</link> in addition to, or instead of, the internal default OpenShift Container Platform log store.</simpara>
<note>
<simpara>Using this feature with Fluentd is not supported.</simpara>
</note>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Red Hat OpenShift Logging Operator 5.6 or later</simpara>
</listitem>
<listitem>
<simpara>A <literal>ClusterLogging</literal> instance with <literal>vector</literal> specified as the collector</simpara>
</listitem>
<listitem>
<simpara>Base64 encoded Splunk HEC token</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a secret using your Base64 encoded Splunk HEC token.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging create secret generic vector-splunk-secret --from-literal hecToken=&lt;HEC_Token&gt;</programlisting>
</listitem>
<listitem>
<simpara>Create or edit the <literal>ClusterLogForwarder</literal> Custom Resource (CR) using the template below:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: &lt;log_forwarder_name&gt; <co xml:id="CO25-1"/>
  namespace: &lt;log_forwarder_namespace&gt; <co xml:id="CO25-2"/>
spec:
  serviceAccountName: &lt;service_account_name&gt; <co xml:id="CO25-3"/>
  outputs:
    - name: splunk-receiver <co xml:id="CO25-4"/>
      secret:
        name: vector-splunk-secret <co xml:id="CO25-5"/>
      type: splunk <co xml:id="CO25-6"/>
      url: &lt;http://your.splunk.hec.url:8088&gt; <co xml:id="CO25-7"/>
  pipelines: <co xml:id="CO25-8"/>
    - inputRefs:
        - application
        - infrastructure
      name: <co xml:id="CO25-9"/>
      outputRefs:
        - splunk-receiver <co xml:id="CO25-10"/></programlisting>
<calloutlist>
<callout arearefs="CO25-1">
<para>In legacy implementations, the CR name must be <literal>instance</literal>. In multi log forwarder implementations, you can use any name.</para>
</callout>
<callout arearefs="CO25-2">
<para>In legacy implementations, the CR namespace must be <literal>openshift-logging</literal>. In multi log forwarder implementations, you can use any namespace.</para>
</callout>
<callout arearefs="CO25-3">
<para>The name of your service account. The service account is only required in multi log forwarder implementations if the log forwarder is not deployed in the <literal>openshift-logging</literal> namespace.</para>
</callout>
<callout arearefs="CO25-4">
<para>Specify a name for the output.</para>
</callout>
<callout arearefs="CO25-5">
<para>Specify the name of the secret that contains your HEC token.</para>
</callout>
<callout arearefs="CO25-6">
<para>Specify the output type as <literal>splunk</literal>.</para>
</callout>
<callout arearefs="CO25-7">
<para>Specify the URL (including port) of your Splunk HEC.</para>
</callout>
<callout arearefs="CO25-8">
<para>Specify which log types to forward by using the pipeline: <literal>application</literal>, <literal>infrastructure</literal>, or <literal>audit</literal>.</para>
</callout>
<callout arearefs="CO25-9">
<para>Optional: Specify a name for the pipeline.</para>
</callout>
<callout arearefs="CO25-10">
<para>Specify the name of the output to use when forwarding logs with this pipeline.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
</section>
<section xml:id="logging-http-forward_configuring-log-forwarding">
<title>Forwarding logs over HTTP</title>
<simpara>Forwarding logs over HTTP is supported for both the Fluentd and Vector log collectors. To enable, specify <literal>http</literal> as the output type in the <literal>ClusterLogForwarder</literal> custom resource (CR).</simpara>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>Create or edit the <literal>ClusterLogForwarder</literal> CR using the template below:</simpara>
<formalpara>
<title>Example ClusterLogForwarder CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: &lt;log_forwarder_name&gt; <co xml:id="CO26-1"/>
  namespace: &lt;log_forwarder_namespace&gt; <co xml:id="CO26-2"/>
spec:
  serviceAccountName: &lt;service_account_name&gt; <co xml:id="CO26-3"/>
  outputs:
    - name: httpout-app
      type: http
      url: <co xml:id="CO26-4"/>
      http:
        headers: <co xml:id="CO26-5"/>
          h1: v1
          h2: v2
        method: POST
      secret:
        name: <co xml:id="CO26-6"/>
      tls:
        insecureSkipVerify: <co xml:id="CO26-7"/>
  pipelines:
    - name:
      inputRefs:
        - application
      outputRefs:
        - <co xml:id="CO26-8"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO26-1">
<para>In legacy implementations, the CR name must be <literal>instance</literal>. In multi log forwarder implementations, you can use any name.</para>
</callout>
<callout arearefs="CO26-2">
<para>In legacy implementations, the CR namespace must be <literal>openshift-logging</literal>. In multi log forwarder implementations, you can use any namespace.</para>
</callout>
<callout arearefs="CO26-3">
<para>The name of your service account. The service account is only required in multi log forwarder implementations if the log forwarder is not deployed in the <literal>openshift-logging</literal> namespace.</para>
</callout>
<callout arearefs="CO26-4">
<para>Destination address for logs.</para>
</callout>
<callout arearefs="CO26-5">
<para>Additional headers to send with the log record.</para>
</callout>
<callout arearefs="CO26-6">
<para>Secret name for destination credentials.</para>
</callout>
<callout arearefs="CO26-7">
<para>Values are either <literal>true</literal> or <literal>false</literal>.</para>
</callout>
<callout arearefs="CO26-8">
<para>This value should be the same as the output name.</para>
</callout>
</calloutlist>
</listitem>
</itemizedlist>
</section>
<section xml:id="cluster-logging-collector-log-forward-project_configuring-log-forwarding">
<title>Forwarding application logs from specific projects</title>
<simpara>You can forward a copy of the application logs from specific projects to an external log aggregator, in addition to, or instead of, using the internal log store. You must also configure the external log aggregator to receive log data from OpenShift Container Platform.</simpara>
<simpara>To configure forwarding application logs from a project, you must create a <literal>ClusterLogForwarder</literal> custom resource (CR) with at least one input from a project, optional outputs for other log aggregators, and pipelines that use those inputs and outputs.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You must have a logging server that is configured to receive the logging data using the specified protocol or format.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create or edit a YAML file that defines the <literal>ClusterLogForwarder</literal> CR:</simpara>
<formalpara>
<title>Example <literal>ClusterLogForwarder</literal> CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance <co xml:id="CO27-1"/>
  namespace: openshift-logging <co xml:id="CO27-2"/>
spec:
  outputs:
   - name: fluentd-server-secure <co xml:id="CO27-3"/>
     type: fluentdForward <co xml:id="CO27-4"/>
     url: 'tls://fluentdserver.security.example.com:24224' <co xml:id="CO27-5"/>
     secret: <co xml:id="CO27-6"/>
        name: fluentd-secret
   - name: fluentd-server-insecure
     type: fluentdForward
     url: 'tcp://fluentdserver.home.example.com:24224'
  inputs: <co xml:id="CO27-7"/>
   - name: my-app-logs
     application:
        namespaces:
        - my-project <co xml:id="CO27-8"/>
  pipelines:
   - name: forward-to-fluentd-insecure <co xml:id="CO27-9"/>
     inputRefs: <co xml:id="CO27-10"/>
     - my-app-logs
     outputRefs: <co xml:id="CO27-11"/>
     - fluentd-server-insecure
     labels:
       project: "my-project" <co xml:id="CO27-12"/>
   - name: forward-to-fluentd-secure <co xml:id="CO27-13"/>
     inputRefs:
     - application <co xml:id="CO27-14"/>
     - audit
     - infrastructure
     outputRefs:
     - fluentd-server-secure
     - default
     labels:
       clusterId: "C1234"</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO27-1">
<para>The name of the <literal>ClusterLogForwarder</literal> CR must be <literal>instance</literal>.</para>
</callout>
<callout arearefs="CO27-2">
<para>The namespace for the <literal>ClusterLogForwarder</literal> CR must be <literal>openshift-logging</literal>.</para>
</callout>
<callout arearefs="CO27-3">
<para>The name of the output.</para>
</callout>
<callout arearefs="CO27-4">
<para>The output type: <literal>elasticsearch</literal>, <literal>fluentdForward</literal>, <literal>syslog</literal>, or <literal>kafka</literal>.</para>
</callout>
<callout arearefs="CO27-5">
<para>The URL and port of the external log aggregator as a valid absolute URL. If the cluster-wide proxy using the CIDR annotation is enabled, the output must be a server name or FQDN, not an IP address.</para>
</callout>
<callout arearefs="CO27-6">
<para>If using a <literal>tls</literal> prefix, you must specify the name of the secret required by the endpoint for TLS communication. The secret must exist in the <literal>openshift-logging</literal> project and have <emphasis role="strong">tls.crt</emphasis>, <emphasis role="strong">tls.key</emphasis>, and <emphasis role="strong">ca-bundle.crt</emphasis> keys that each point to the certificates they represent.</para>
</callout>
<callout arearefs="CO27-7">
<para>The configuration for an input to filter application logs from the specified projects.</para>
</callout>
<callout arearefs="CO27-8">
<para>If no namespace is specified, logs are collected from all namespaces.</para>
</callout>
<callout arearefs="CO27-9">
<para>The pipeline configuration directs logs from a named input to a named output. In this example, a pipeline named <literal>forward-to-fluentd-insecure</literal> forwards logs from an input named <literal>my-app-logs</literal> to an output named <literal>fluentd-server-insecure</literal>.</para>
</callout>
<callout arearefs="CO27-10">
<para>A list of inputs.</para>
</callout>
<callout arearefs="CO27-11">
<para>The name of the output to use.</para>
</callout>
<callout arearefs="CO27-12">
<para>Optional: String. One or more labels to add to the logs.</para>
</callout>
<callout arearefs="CO27-13">
<para>Configuration for a pipeline to send logs to other log aggregators.</para>
<itemizedlist>
<listitem>
<simpara>Optional: Specify a name for the pipeline.</simpara>
</listitem>
<listitem>
<simpara>Specify which log types to forward by using the pipeline: <literal>application,</literal> <literal>infrastructure</literal>, or <literal>audit</literal>.</simpara>
</listitem>
<listitem>
<simpara>Specify the name of the output to use when forwarding logs with this pipeline.</simpara>
</listitem>
<listitem>
<simpara>Optional: Specify the <literal>default</literal> output to forward logs to the default log store.</simpara>
</listitem>
<listitem>
<simpara>Optional: String. One or more labels to add to the logs.</simpara>
</listitem>
</itemizedlist>
</callout>
<callout arearefs="CO27-14">
<para>Note that application logs from all namespaces are collected when using this configuration.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>ClusterLogForwarder</literal> CR by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="cluster-logging-collector-log-forward-logs-from-application-pods_configuring-log-forwarding">
<title>Forwarding application logs from specific pods</title>
<simpara>As a cluster administrator, you can use Kubernetes pod labels to gather log data from specific pods and forward it to a log collector.</simpara>
<simpara>Suppose that you have an application composed of pods running alongside other pods in various namespaces. If those pods have labels that identify the application, you can gather and output their log data to a specific log collector.</simpara>
<simpara>To specify the pod labels, you use one or more <literal>matchLabels</literal> key-value pairs. If you specify multiple key-value pairs, the pods must match all of them to be selected.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create or edit a YAML file that defines the <literal>ClusterLogForwarder</literal> CR object. In the file, specify the pod labels using simple equality-based selectors under <literal>inputs[].name.application.selector.matchLabels</literal>, as shown in the following example.</simpara>
<formalpara>
<title>Example <literal>ClusterLogForwarder</literal> CR YAML file</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: &lt;log_forwarder_name&gt; <co xml:id="CO28-1"/>
  namespace: &lt;log_forwarder_namespace&gt; <co xml:id="CO28-2"/>
spec:
  pipelines:
    - inputRefs: [ myAppLogData ] <co xml:id="CO28-3"/>
      outputRefs: [ default ] <co xml:id="CO28-4"/>
  inputs: <co xml:id="CO28-5"/>
    - name: myAppLogData
      application:
        selector:
          matchLabels: <co xml:id="CO28-6"/>
            environment: production
            app: nginx
        namespaces: <co xml:id="CO28-7"/>
        - app1
        - app2
  outputs: <co xml:id="CO28-8"/>
    - &lt;output_name&gt;
    ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO28-1">
<para>In legacy implementations, the CR name must be <literal>instance</literal>. In multi log forwarder implementations, you can use any name.</para>
</callout>
<callout arearefs="CO28-2">
<para>In legacy implementations, the CR namespace must be <literal>openshift-logging</literal>. In multi log forwarder implementations, you can use any namespace.</para>
</callout>
<callout arearefs="CO28-3">
<para>Specify one or more comma-separated values from <literal>inputs[].name</literal>.</para>
</callout>
<callout arearefs="CO28-4">
<para>Specify one or more comma-separated values from <literal>outputs[]</literal>.</para>
</callout>
<callout arearefs="CO28-5">
<para>Define a unique <literal>inputs[].name</literal> for each application that has a unique set of pod labels.</para>
</callout>
<callout arearefs="CO28-6">
<para>Specify the key-value pairs of pod labels whose log data you want to gather. You must specify both a key and value, not just a key. To be selected, the pods must match all the key-value pairs.</para>
</callout>
<callout arearefs="CO28-7">
<para>Optional: Specify one or more namespaces.</para>
</callout>
<callout arearefs="CO28-8">
<para>Specify one or more outputs to forward your log data to.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Optional: To restrict the gathering of log data to specific namespaces, use <literal>inputs[].name.application.namespaces</literal>, as shown in the preceding example.</simpara>
</listitem>
<listitem>
<simpara>Optional: You can send log data from additional applications that have different pod labels to the same pipeline.</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>For each unique combination of pod labels, create an additional <literal>inputs[].name</literal> section similar to the one shown.</simpara>
</listitem>
<listitem>
<simpara>Update the <literal>selectors</literal> to match the pod labels of this application.</simpara>
</listitem>
<listitem>
<simpara>Add the new <literal>inputs[].name</literal> value to <literal>inputRefs</literal>. For example:</simpara>
<screen>- inputRefs: [ myAppLogData, myOtherAppLogData ]</screen>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Create the CR object:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create -f &lt;file-name&gt;.yaml</programlisting>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara>For more information on <literal>matchLabels</literal> in Kubernetes, see <link xlink:href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#resources-that-support-set-based-requirements">Resources that support set-based requirements</link>.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging_audit_filtering_configuring-log-forwarding">
<title>Overview of API audit filter</title>
<simpara>OpenShift API servers generate audit events for each API call, detailing the request, response, and the identity of the requester, leading to large volumes of data. The API Audit filter uses rules to enable the exclusion of non-essential events and the reduction of event size, facilitating a more manageable audit trail. Rules are checked in order, checking stops at the first match. How much data is included in an event is determined by the value of the <literal>level</literal> field:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>None</literal>: The event is dropped.</simpara>
</listitem>
<listitem>
<simpara><literal>Metadata</literal>: Audit metadata is included, request and response bodies are removed.</simpara>
</listitem>
<listitem>
<simpara><literal>Request</literal>: Audit metadata and the request body are included, the response body is removed.</simpara>
</listitem>
<listitem>
<simpara><literal>RequestResponse</literal>: All data is included: metadata, request body and response body. The response body can be very large. For example, <literal>oc get pods -A</literal> generates a response body containing the YAML description of every pod in the cluster.</simpara>
</listitem>
</itemizedlist>
<simpara>In logging 5.8 and later, the <literal>ClusterLogForwarder</literal> custom resource (CR) uses the same format as the standard <link xlink:href="https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/#audit-policy">Kubernetes audit policy</link>, while providing the following additional functions:</simpara>
<variablelist>
<varlistentry>
<term>Wildcards</term>
<listitem>
<simpara>Names of users, groups, namespaces, and resources can have a leading or trailing <literal>*</literal> asterisk character. For example, namespace <literal>openshift-\*</literal> matches <literal>openshift-apiserver</literal> or <literal>openshift-authentication</literal>. Resource <literal>\*/status</literal> matches <literal>Pod/status</literal> or <literal>Deployment/status</literal>.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Default Rules</term>
<listitem>
<simpara>Events that do not match any rule in the policy are filtered as follows:</simpara>
<itemizedlist>
<listitem>
<simpara>Read-only system events such as <literal>get</literal>, <literal>list</literal>, <literal>watch</literal> are dropped.</simpara>
</listitem>
<listitem>
<simpara>Service account write events that occur within the same namespace as the service account are dropped.</simpara>
</listitem>
<listitem>
<simpara>All other events are forwarded, subject to any configured rate limits.</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>To disable these defaults, either end your rules list with a rule that has only a <literal>level</literal> field or add an empty rule.</simpara>
<variablelist>
<varlistentry>
<term>Omit Response Codes</term>
<listitem>
<simpara>A list of integer status codes to omit. You can drop events based on the HTTP status code in the response by using the <literal>OmitResponseCodes</literal> field, a list of HTTP status code for which no events are created. The default value is <literal>[404, 409, 422, 429]</literal>. If the value is an empty list, <literal>[]</literal>, then no status codes are omitted.</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>The <literal>ClusterLogForwarder</literal> CR audit policy acts in addition to the OpenShift Container Platform audit policy. The <literal>ClusterLogForwarder</literal> CR audit filter changes what the log collector forwards, and provides the ability to filter by verb, user, group, namespace, or resource. You can create multiple filters to send different summaries of the same audit stream to different places. For example, you can send a detailed stream to the local cluster log store, and a less detailed stream to a remote site.</simpara>
<note>
<simpara>The example provided is intended to illustrate the range of rules possible in an audit policy and is not a recommended configuration.</simpara>
</note>
<formalpara>
<title>Example audit policy</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging
spec:
  pipelines:
    - name: my-pipeline
      inputRefs: audit <co xml:id="CO29-1"/>
      filterRefs: my-policy <co xml:id="CO29-2"/>
      outputRefs: default
  filters:
    - name: my-policy
      type: kubeAPIAudit
      kubeAPIAudit:
        # Don't generate audit events for all requests in RequestReceived stage.
        omitStages:
          - "RequestReceived"

        rules:
          # Log pod changes at RequestResponse level
          - level: RequestResponse
            resources:
            - group: ""
              resources: ["pods"]

          # Log "pods/log", "pods/status" at Metadata level
          - level: Metadata
            resources:
            - group: ""
              resources: ["pods/log", "pods/status"]

          # Don't log requests to a configmap called "controller-leader"
          - level: None
            resources:
            - group: ""
              resources: ["configmaps"]
              resourceNames: ["controller-leader"]

          # Don't log watch requests by the "system:kube-proxy" on endpoints or services
          - level: None
            users: ["system:kube-proxy"]
            verbs: ["watch"]
            resources:
            - group: "" # core API group
              resources: ["endpoints", "services"]

          # Don't log authenticated requests to certain non-resource URL paths.
          - level: None
            userGroups: ["system:authenticated"]
            nonResourceURLs:
            - "/api*" # Wildcard matching.
            - "/version"

          # Log the request body of configmap changes in kube-system.
          - level: Request
            resources:
            - group: "" # core API group
              resources: ["configmaps"]
            # This rule only applies to resources in the "kube-system" namespace.
            # The empty string "" can be used to select non-namespaced resources.
            namespaces: ["kube-system"]

          # Log configmap and secret changes in all other namespaces at the Metadata level.
          - level: Metadata
            resources:
            - group: "" # core API group
              resources: ["secrets", "configmaps"]

          # Log all other resources in core and extensions at the Request level.
          - level: Request
            resources:
            - group: "" # core API group
            - group: "extensions" # Version of group should NOT be included.

          # A catch-all rule to log all other requests at the Metadata level.
          - level: Metadata</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO29-1">
<para>The log types that are collected. The value for this field can be <literal>audit</literal> for audit logs, <literal>application</literal> for application logs, <literal>infrastructure</literal> for infrastructure logs, or a named input that has been defined for your application.</para>
</callout>
<callout arearefs="CO29-2">
<para>The name of your audit policy.</para>
</callout>
</calloutlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/networking/#logging-network-policy">Logging for egress firewall and network policy rules</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="cluster-logging-collector-log-forward-loki_configuring-log-forwarding">
<title>Forwarding logs to an external Loki logging system</title>
<simpara>You can forward logs to an external Loki logging system in addition to, or instead of, the default log store.</simpara>
<simpara>To configure log forwarding to Loki, you must create a <literal>ClusterLogForwarder</literal> custom resource (CR) with an output to Loki, and a pipeline that uses the output. The output to Loki can use the HTTP (insecure) or HTTPS (secure HTTP) connection.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You must have a Loki logging system running at the URL you specify with the <literal>url</literal> field in the CR.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create or edit a YAML file that defines the <literal>ClusterLogForwarder</literal> CR object:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: &lt;log_forwarder_name&gt; <co xml:id="CO30-1"/>
  namespace: &lt;log_forwarder_namespace&gt; <co xml:id="CO30-2"/>
spec:
  serviceAccountName: &lt;service_account_name&gt; <co xml:id="CO30-3"/>
  outputs:
  - name: loki-insecure <co xml:id="CO30-4"/>
    type: "loki" <co xml:id="CO30-5"/>
    url: http://loki.insecure.com:3100 <co xml:id="CO30-6"/>
    loki:
      tenantKey: kubernetes.namespace_name
      labelKeys:
      - kubernetes.labels.foo
  - name: loki-secure <co xml:id="CO30-7"/>
    type: "loki"
    url: https://loki.secure.com:3100
    secret:
      name: loki-secret <co xml:id="CO30-8"/>
    loki:
      tenantKey: kubernetes.namespace_name <co xml:id="CO30-9"/>
      labelKeys:
      - kubernetes.labels.foo <co xml:id="CO30-10"/>
  pipelines:
  - name: application-logs <co xml:id="CO30-11"/>
    inputRefs:  <co xml:id="CO30-12"/>
    - application
    - audit
    outputRefs: <co xml:id="CO30-13"/>
    - loki-secure</programlisting>
<calloutlist>
<callout arearefs="CO30-1">
<para>In legacy implementations, the CR name must be <literal>instance</literal>. In multi log forwarder implementations, you can use any name.</para>
</callout>
<callout arearefs="CO30-2">
<para>In legacy implementations, the CR namespace must be <literal>openshift-logging</literal>. In multi log forwarder implementations, you can use any namespace.</para>
</callout>
<callout arearefs="CO30-3">
<para>The name of your service account. The service account is only required in multi log forwarder implementations if the log forwarder is not deployed in the <literal>openshift-logging</literal> namespace.</para>
</callout>
<callout arearefs="CO30-4">
<para>Specify a name for the output.</para>
</callout>
<callout arearefs="CO30-5">
<para>Specify the type as <literal>"loki"</literal>.</para>
</callout>
<callout arearefs="CO30-6">
<para>Specify the URL and port of the Loki system as a valid absolute URL. You can use the <literal>http</literal> (insecure) or <literal>https</literal> (secure HTTP) protocol. If the cluster-wide proxy using the CIDR annotation is enabled, the output must be a server name or FQDN, not an IP Address. Loki&#8217;s default port for HTTP(S) communication is 3100.</para>
</callout>
<callout arearefs="CO30-7">
<para>For a secure connection, you can specify an <literal>https</literal> or <literal>http</literal> URL that you authenticate by specifying a <literal>secret</literal>.</para>
</callout>
<callout arearefs="CO30-8">
<para>For an <literal>https</literal> prefix, specify the name of the secret required by the endpoint for TLS communication. The secret must contain a <literal>ca-bundle.crt</literal> key that points to the certificates it represents. Otherwise, for <literal>http</literal> and <literal>https</literal> prefixes, you can specify a secret that contains a username and password. In legacy implementations, the secret must exist in the <literal>openshift-logging</literal> project. For more information, see the following "Example: Setting a secret that contains a username and password."</para>
</callout>
<callout arearefs="CO30-9">
<para>Optional: Specify a metadata key field to generate values for the <literal>TenantID</literal> field in Loki. For example, setting <literal>tenantKey: kubernetes.namespace_name</literal> uses the names of the Kubernetes namespaces as values for tenant IDs in Loki. To see which other log record fields you can specify, see the "Log Record Fields" link in the following "Additional resources" section.</para>
</callout>
<callout arearefs="CO30-10">
<para>Optional: Specify a list of metadata field keys to replace the default Loki labels. Loki label names must match the regular expression <literal>[a-zA-Z_:][a-zA-Z0-9_:]*</literal>. Illegal characters in metadata keys are replaced with <literal>_</literal> to form the label name. For example, the <literal>kubernetes.labels.foo</literal> metadata key becomes Loki label <literal>kubernetes_labels_foo</literal>. If you do not set <literal>labelKeys</literal>, the default value is: <literal>[log_type, kubernetes.namespace_name, kubernetes.pod_name, kubernetes_host]</literal>. Keep the set of labels small because Loki limits the size and number of labels allowed. See <link xlink:href="https://grafana.com/docs/loki/latest/configuration/#limits_config">Configuring Loki, limits_config</link>. You can still query based on any log record field using query filters.</para>
</callout>
<callout arearefs="CO30-11">
<para>Optional: Specify a name for the pipeline.</para>
</callout>
<callout arearefs="CO30-12">
<para>Specify which log types to forward by using the pipeline: <literal>application,</literal> <literal>infrastructure</literal>, or <literal>audit</literal>.</para>
</callout>
<callout arearefs="CO30-13">
<para>Specify the name of the output to use when forwarding logs with this pipeline.</para>
</callout>
</calloutlist>
<note>
<simpara>Because Loki requires log streams to be correctly ordered by timestamp, <literal>labelKeys</literal> always includes the <literal>kubernetes_host</literal> label set, even if you do not specify it. This inclusion ensures that each stream originates from a single host, which prevents timestamps from becoming disordered due to clock differences on different hosts.</simpara>
</note>
</listitem>
<listitem>
<simpara>Apply the <literal>ClusterLogForwarder</literal> CR object by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://grafana.com/docs/loki/latest/configuration/">Configuring Loki server</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="cluster-logging-collector-log-forward-es_configuring-log-forwarding">
<title>Forwarding logs to an external Elasticsearch instance</title>
<simpara>You can forward logs to an external Elasticsearch instance in addition to, or instead of, the internal log store. You are responsible for configuring the external log aggregator to receive log data from OpenShift Container Platform.</simpara>
<simpara>To configure log forwarding to an external Elasticsearch instance, you must create a <literal>ClusterLogForwarder</literal> custom resource (CR) with an output to that instance, and a pipeline that uses the output. The external Elasticsearch output can use the HTTP (insecure) or HTTPS (secure HTTP) connection.</simpara>
<simpara>To forward logs to both an external and the internal Elasticsearch instance, create outputs and pipelines to the external instance and a pipeline that uses the <literal>default</literal> output to forward logs to the internal instance.</simpara>
<note>
<simpara>If you only want to forward logs to an internal Elasticsearch instance, you do not need to create a <literal>ClusterLogForwarder</literal> CR.</simpara>
</note>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You must have a logging server that is configured to receive the logging data using the specified protocol or format.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create or edit a YAML file that defines the <literal>ClusterLogForwarder</literal> CR:</simpara>
<formalpara>
<title>Example <literal>ClusterLogForwarder</literal> CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: &lt;log_forwarder_name&gt; <co xml:id="CO31-1"/>
  namespace: &lt;log_forwarder_namespace&gt; <co xml:id="CO31-2"/>
spec:
  serviceAccountName: &lt;service_account_name&gt; <co xml:id="CO31-3"/>
  outputs:
   - name: elasticsearch-example <co xml:id="CO31-4"/>
     type: elasticsearch <co xml:id="CO31-5"/>
     elasticsearch:
       version: 8 <co xml:id="CO31-6"/>
     url: http://elasticsearch.example.com:9200 <co xml:id="CO31-7"/>
     secret:
       name: es-secret <co xml:id="CO31-8"/>
  pipelines:
   - name: application-logs <co xml:id="CO31-9"/>
     inputRefs: <co xml:id="CO31-10"/>
     - application
     - audit
     outputRefs:
     - elasticsearch-example <co xml:id="CO31-11"/>
     - default <co xml:id="CO31-12"/>
     labels:
       myLabel: "myValue" <co xml:id="CO31-13"/>
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO31-1">
<para>In legacy implementations, the CR name must be <literal>instance</literal>. In multi log forwarder implementations, you can use any name.</para>
</callout>
<callout arearefs="CO31-2">
<para>In legacy implementations, the CR namespace must be <literal>openshift-logging</literal>. In multi log forwarder implementations, you can use any namespace.</para>
</callout>
<callout arearefs="CO31-3">
<para>The name of your service account. The service account is only required in multi log forwarder implementations if the log forwarder is not deployed in the <literal>openshift-logging</literal> namespace.</para>
</callout>
<callout arearefs="CO31-4">
<para>Specify a name for the output.</para>
</callout>
<callout arearefs="CO31-5">
<para>Specify the <literal>elasticsearch</literal> type.</para>
</callout>
<callout arearefs="CO31-6">
<para>Specify the Elasticsearch version. This can be <literal>6</literal>, <literal>7</literal>, or <literal>8</literal>.</para>
</callout>
<callout arearefs="CO31-7">
<para>Specify the URL and port of the external Elasticsearch instance as a valid absolute URL. You can use the <literal>http</literal> (insecure) or <literal>https</literal> (secure HTTP) protocol. If the cluster-wide proxy using the CIDR annotation is enabled, the output must be a server name or FQDN, not an IP Address.</para>
</callout>
<callout arearefs="CO31-8">
<para>For an <literal>https</literal> prefix, specify the name of the secret required by the endpoint for TLS communication. The secret must contain a <literal>ca-bundle.crt</literal> key that points to the certificate it represents. Otherwise, for <literal>http</literal> and <literal>https</literal> prefixes, you can specify a secret that contains a username and password. In legacy implementations, the secret must exist in the <literal>openshift-logging</literal> project. For more information, see the following "Example: Setting a secret that contains a username and password."</para>
</callout>
<callout arearefs="CO31-9">
<para>Optional: Specify a name for the pipeline.</para>
</callout>
<callout arearefs="CO31-10">
<para>Specify which log types to forward by using the pipeline: <literal>application,</literal> <literal>infrastructure</literal>, or <literal>audit</literal>.</para>
</callout>
<callout arearefs="CO31-11">
<para>Specify the name of the output to use when forwarding logs with this pipeline.</para>
</callout>
<callout arearefs="CO31-12">
<para>Optional: Specify the <literal>default</literal> output to send the logs to the internal Elasticsearch instance.</para>
</callout>
<callout arearefs="CO31-13">
<para>Optional: String. One or more labels to add to the logs.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>ClusterLogForwarder</literal> CR:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
<formalpara>
<title>Example: Setting a secret that contains a username and password</title>
<para>You can use a secret that contains a username and password to authenticate a secure connection to an external Elasticsearch instance.</para>
</formalpara>
<simpara>For example, if you cannot use mutual TLS (mTLS) keys because a third party operates the Elasticsearch instance, you can use HTTP or HTTPS and set a secret that contains the username and password.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Create a <literal>Secret</literal> YAML file similar to the following example. Use base64-encoded values for the <literal>username</literal> and <literal>password</literal> fields. The secret type is opaque by default.</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Secret
metadata:
  name: openshift-test-secret
data:
  username: &lt;username&gt;
  password: &lt;password&gt;
# ...</programlisting>
</listitem>
<listitem>
<simpara>Create the secret:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create secret -n openshift-logging openshift-test-secret.yaml</programlisting>
</listitem>
<listitem>
<simpara>Specify the name of the secret in the <literal>ClusterLogForwarder</literal> CR:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging
spec:
  outputs:
   - name: elasticsearch
     type: "elasticsearch"
     url: https://elasticsearch.secure.com:9200
     secret:
        name: openshift-test-secret
# ...</programlisting>
<note>
<simpara>In the value of the <literal>url</literal> field, the prefix can be <literal>http</literal> or <literal>https</literal>.</simpara>
</note>
</listitem>
<listitem>
<simpara>Apply the CR object:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="cluster-logging-collector-log-forward-fluentd_configuring-log-forwarding">
<title>Forwarding logs using the Fluentd forward protocol</title>
<simpara>You can use the Fluentd <emphasis role="strong">forward</emphasis> protocol to send a copy of your logs to an external log aggregator that is configured to accept the protocol instead of, or in addition to, the default Elasticsearch log store. You are responsible for configuring the external log aggregator to receive the logs from OpenShift Container Platform.</simpara>
<simpara>To configure log forwarding using the <emphasis role="strong">forward</emphasis> protocol, you must create a <literal>ClusterLogForwarder</literal> custom resource (CR) with one or more outputs to the Fluentd servers, and pipelines that use those outputs. The Fluentd output can use a TCP (insecure) or TLS (secure TCP) connection.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You must have a logging server that is configured to receive the logging data using the specified protocol or format.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create or edit a YAML file that defines the <literal>ClusterLogForwarder</literal> CR object:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance <co xml:id="CO32-1"/>
  namespace: openshift-logging <co xml:id="CO32-2"/>
spec:
  outputs:
   - name: fluentd-server-secure <co xml:id="CO32-3"/>
     type: fluentdForward <co xml:id="CO32-4"/>
     url: 'tls://fluentdserver.security.example.com:24224' <co xml:id="CO32-5"/>
     secret: <co xml:id="CO32-6"/>
        name: fluentd-secret
   - name: fluentd-server-insecure
     type: fluentdForward
     url: 'tcp://fluentdserver.home.example.com:24224'
  pipelines:
   - name: forward-to-fluentd-secure <co xml:id="CO32-7"/>
     inputRefs:  <co xml:id="CO32-8"/>
     - application
     - audit
     outputRefs:
     - fluentd-server-secure <co xml:id="CO32-9"/>
     - default <co xml:id="CO32-10"/>
     labels:
       clusterId: "C1234" <co xml:id="CO32-11"/>
   - name: forward-to-fluentd-insecure <co xml:id="CO32-12"/>
     inputRefs:
     - infrastructure
     outputRefs:
     - fluentd-server-insecure
     labels:
       clusterId: "C1234"</programlisting>
<calloutlist>
<callout arearefs="CO32-1">
<para>The name of the <literal>ClusterLogForwarder</literal> CR must be <literal>instance</literal>.</para>
</callout>
<callout arearefs="CO32-2">
<para>The namespace for the <literal>ClusterLogForwarder</literal> CR must be <literal>openshift-logging</literal>.</para>
</callout>
<callout arearefs="CO32-3">
<para>Specify a name for the output.</para>
</callout>
<callout arearefs="CO32-4">
<para>Specify the <literal>fluentdForward</literal> type.</para>
</callout>
<callout arearefs="CO32-5">
<para>Specify the URL and port of the external Fluentd instance as a valid absolute URL. You can use the <literal>tcp</literal> (insecure) or <literal>tls</literal> (secure TCP) protocol. If the cluster-wide proxy using the CIDR annotation is enabled, the output must be a server name or FQDN, not an IP address.</para>
</callout>
<callout arearefs="CO32-6">
<para>If you are using a <literal>tls</literal> prefix, you must specify the name of the secret required by the endpoint for TLS communication. The secret must exist in the <literal>openshift-logging</literal> project and must contain a <literal>ca-bundle.crt</literal> key that points to the certificate it represents.</para>
</callout>
<callout arearefs="CO32-7">
<para>Optional: Specify a name for the pipeline.</para>
</callout>
<callout arearefs="CO32-8">
<para>Specify which log types to forward by using the pipeline: <literal>application,</literal> <literal>infrastructure</literal>, or <literal>audit</literal>.</para>
</callout>
<callout arearefs="CO32-9">
<para>Specify the name of the output to use when forwarding logs with this pipeline.</para>
</callout>
<callout arearefs="CO32-10">
<para>Optional: Specify the <literal>default</literal> output to forward logs to the internal Elasticsearch instance.</para>
</callout>
<callout arearefs="CO32-11">
<para>Optional: String. One or more labels to add to the logs.</para>
</callout>
<callout arearefs="CO32-12">
<para>Optional: Configure multiple outputs to forward logs to other external log aggregators of any supported type:</para>
<itemizedlist>
<listitem>
<simpara>A name to describe the pipeline.</simpara>
</listitem>
<listitem>
<simpara>The <literal>inputRefs</literal> is the log type to forward by using the pipeline: <literal>application,</literal> <literal>infrastructure</literal>, or <literal>audit</literal>.</simpara>
</listitem>
<listitem>
<simpara>The <literal>outputRefs</literal> is the name of the output to use.</simpara>
</listitem>
<listitem>
<simpara>Optional: String. One or more labels to add to the logs.</simpara>
</listitem>
</itemizedlist>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Create the CR object:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create -f &lt;file-name&gt;.yaml</programlisting>
</listitem>
</orderedlist>
<section xml:id="cluster-logging-collector-log-forward-nano-precision">
<title>Enabling nanosecond precision for Logstash to ingest data from fluentd</title>
<simpara>For Logstash to ingest log data from fluentd, you must enable nanosecond precision in the Logstash configuration file.</simpara>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>In the Logstash configuration file,  set <literal>nanosecond_precision</literal> to <literal>true</literal>.</simpara>
</listitem>
</itemizedlist>
<formalpara>
<title>Example Logstash configuration file</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">input { tcp { codec =&gt; fluent { nanosecond_precision =&gt; true } port =&gt; 24114 } }
filter { }
output { stdout { codec =&gt; rubydebug } }</programlisting>
</para>
</formalpara>
</section>
</section>
<section xml:id="cluster-logging-collector-log-forward-syslog_configuring-log-forwarding">
<title>Forwarding logs using the syslog protocol</title>
<simpara>You can use the <emphasis role="strong">syslog</emphasis> <link xlink:href="https://tools.ietf.org/html/rfc3164">RFC3164</link> or <link xlink:href="https://tools.ietf.org/html/rfc5424">RFC5424</link> protocol to send a copy of your logs to an external log aggregator that is configured to accept the protocol instead of, or in addition to, the default Elasticsearch log store. You are responsible for configuring the external log aggregator, such as a syslog server, to receive the logs from OpenShift Container Platform.</simpara>
<simpara>To configure log forwarding using the <emphasis role="strong">syslog</emphasis> protocol, you must create a <literal>ClusterLogForwarder</literal> custom resource (CR) with one or more outputs to the syslog servers, and pipelines that use those outputs. The syslog output can use a UDP, TCP, or TLS connection.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You must have a logging server that is configured to receive the logging data using the specified protocol or format.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create or edit a YAML file that defines the <literal>ClusterLogForwarder</literal> CR object:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: &lt;log_forwarder_name&gt; <co xml:id="CO33-1"/>
  namespace: &lt;log_forwarder_namespace&gt; <co xml:id="CO33-2"/>
spec:
  serviceAccountName: &lt;service_account_name&gt; <co xml:id="CO33-3"/>
  outputs:
   - name: rsyslog-east <co xml:id="CO33-4"/>
     type: syslog <co xml:id="CO33-5"/>
     syslog: <co xml:id="CO33-6"/>
       facility: local0
       rfc: RFC3164
       payloadKey: message
       severity: informational
     url: 'tls://rsyslogserver.east.example.com:514' <co xml:id="CO33-7"/>
     secret: <co xml:id="CO33-8"/>
        name: syslog-secret
   - name: rsyslog-west
     type: syslog
     syslog:
      appName: myapp
      facility: user
      msgID: mymsg
      procID: myproc
      rfc: RFC5424
      severity: debug
     url: 'tcp://rsyslogserver.west.example.com:514'
  pipelines:
   - name: syslog-east <co xml:id="CO33-9"/>
     inputRefs: <co xml:id="CO33-10"/>
     - audit
     - application
     outputRefs: <co xml:id="CO33-11"/>
     - rsyslog-east
     - default <co xml:id="CO33-12"/>
     labels:
       secure: "true" <co xml:id="CO33-13"/>
       syslog: "east"
   - name: syslog-west <co xml:id="CO33-14"/>
     inputRefs:
     - infrastructure
     outputRefs:
     - rsyslog-west
     - default
     labels:
       syslog: "west"</programlisting>
<calloutlist>
<callout arearefs="CO33-1">
<para>In legacy implementations, the CR name must be <literal>instance</literal>. In multi log forwarder implementations, you can use any name.</para>
</callout>
<callout arearefs="CO33-2">
<para>In legacy implementations, the CR namespace must be <literal>openshift-logging</literal>. In multi log forwarder implementations, you can use any namespace.</para>
</callout>
<callout arearefs="CO33-3">
<para>The name of your service account. The service account is only required in multi log forwarder implementations if the log forwarder is not deployed in the <literal>openshift-logging</literal> namespace.</para>
</callout>
<callout arearefs="CO33-4">
<para>Specify a name for the output.</para>
</callout>
<callout arearefs="CO33-5">
<para>Specify the <literal>syslog</literal> type.</para>
</callout>
<callout arearefs="CO33-6">
<para>Optional: Specify the syslog parameters, listed below.</para>
</callout>
<callout arearefs="CO33-7">
<para>Specify the URL and port of the external syslog instance. You can use the <literal>udp</literal> (insecure), <literal>tcp</literal> (insecure) or <literal>tls</literal> (secure TCP) protocol. If the cluster-wide proxy using the CIDR annotation is enabled, the output must be a server name or FQDN, not an IP address.</para>
</callout>
<callout arearefs="CO33-8">
<para>If using a <literal>tls</literal> prefix, you must specify the name of the secret required by the endpoint for TLS communication. The secret must contain a <literal>ca-bundle.crt</literal> key that points to the certificate it represents. In legacy implementations, the secret must exist in the <literal>openshift-logging</literal> project.</para>
</callout>
<callout arearefs="CO33-9">
<para>Optional: Specify a name for the pipeline.</para>
</callout>
<callout arearefs="CO33-10">
<para>Specify which log types to forward by using the pipeline: <literal>application,</literal> <literal>infrastructure</literal>, or <literal>audit</literal>.</para>
</callout>
<callout arearefs="CO33-11">
<para>Specify the name of the output to use when forwarding logs with this pipeline.</para>
</callout>
<callout arearefs="CO33-12">
<para>Optional: Specify the <literal>default</literal> output to forward logs to the internal Elasticsearch instance.</para>
</callout>
<callout arearefs="CO33-13">
<para>Optional: String. One or more labels to add to the logs. Quote values like "true" so they are recognized as string values, not as a boolean.</para>
</callout>
<callout arearefs="CO33-14">
<para>Optional: Configure multiple outputs to forward logs to other external log aggregators of any supported type:</para>
<itemizedlist>
<listitem>
<simpara>A name to describe the pipeline.</simpara>
</listitem>
<listitem>
<simpara>The <literal>inputRefs</literal> is the log type to forward by using the pipeline: <literal>application,</literal> <literal>infrastructure</literal>, or <literal>audit</literal>.</simpara>
</listitem>
<listitem>
<simpara>The <literal>outputRefs</literal> is the name of the output to use.</simpara>
</listitem>
<listitem>
<simpara>Optional: String. One or more labels to add to the logs.</simpara>
</listitem>
</itemizedlist>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Create the CR object:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
<section xml:id="cluster-logging-collector-log-forward-examples-syslog-log-source">
<title>Adding log source information to message output</title>
<simpara>You can add <literal>namespace_name</literal>, <literal>pod_name</literal>, and <literal>container_name</literal> elements to the <literal>message</literal> field of the record by adding the <literal>AddLogSource</literal> field to your <literal>ClusterLogForwarder</literal> custom resource (CR).</simpara>
<programlisting language="yaml" linenumbering="unnumbered">  spec:
    outputs:
    - name: syslogout
      syslog:
        addLogSource: true
        facility: user
        payloadKey: message
        rfc: RFC3164
        severity: debug
        tag: mytag
      type: syslog
      url: tls://syslog-receiver.openshift-logging.svc:24224
    pipelines:
    - inputRefs:
      - application
      name: test-app
      outputRefs:
      - syslogout</programlisting>
<note>
<simpara>This configuration is compatible with both RFC3164 and RFC5424.</simpara>
</note>
<formalpara>
<title>Example syslog message output without <literal>AddLogSource</literal></title>
<para>
<programlisting language="text" linenumbering="unnumbered">&lt;15&gt;1 2020-11-15T17:06:14+00:00 fluentd-9hkb4 mytag - - -  {"msgcontent"=&gt;"Message Contents", "timestamp"=&gt;"2020-11-15 17:06:09", "tag_key"=&gt;"rec_tag", "index"=&gt;56}</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example syslog message output with <literal>AddLogSource</literal></title>
<para>
<programlisting language="text" linenumbering="unnumbered">&lt;15&gt;1 2020-11-16T10:49:37+00:00 crc-j55b9-master-0 mytag - - -  namespace_name=clo-test-6327,pod_name=log-generator-ff9746c49-qxm7l,container_name=log-generator,message={"msgcontent":"My life is my message", "timestamp":"2020-11-16 10:49:36", "tag_key":"rec_tag", "index":76}</programlisting>
</para>
</formalpara>
</section>
<section xml:id="cluster-logging-collector-log-forward-examples-syslog-parms">
<title>Syslog parameters</title>
<simpara>You can configure the following for the <literal>syslog</literal> outputs. For more information, see the syslog <link xlink:href="https://tools.ietf.org/html/rfc3164">RFC3164</link> or <link xlink:href="https://tools.ietf.org/html/rfc5424">RFC5424</link> RFC.</simpara>
<itemizedlist>
<listitem>
<simpara>facility: The <link xlink:href="https://tools.ietf.org/html/rfc5424#section-6.2.1">syslog facility</link>. The value can be a decimal integer or a case-insensitive keyword:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>0</literal> or <literal>kern</literal> for kernel messages</simpara>
</listitem>
<listitem>
<simpara><literal>1</literal> or <literal>user</literal> for user-level messages, the default.</simpara>
</listitem>
<listitem>
<simpara><literal>2</literal> or <literal>mail</literal> for the mail system</simpara>
</listitem>
<listitem>
<simpara><literal>3</literal> or <literal>daemon</literal> for system daemons</simpara>
</listitem>
<listitem>
<simpara><literal>4</literal> or <literal>auth</literal> for security/authentication messages</simpara>
</listitem>
<listitem>
<simpara><literal>5</literal> or <literal>syslog</literal> for messages generated internally by syslogd</simpara>
</listitem>
<listitem>
<simpara><literal>6</literal> or <literal>lpr</literal> for the line printer subsystem</simpara>
</listitem>
<listitem>
<simpara><literal>7</literal> or <literal>news</literal> for the network news subsystem</simpara>
</listitem>
<listitem>
<simpara><literal>8</literal> or <literal>uucp</literal> for the UUCP subsystem</simpara>
</listitem>
<listitem>
<simpara><literal>9</literal> or <literal>cron</literal> for the clock daemon</simpara>
</listitem>
<listitem>
<simpara><literal>10</literal> or <literal>authpriv</literal> for security authentication messages</simpara>
</listitem>
<listitem>
<simpara><literal>11</literal> or <literal>ftp</literal> for the FTP daemon</simpara>
</listitem>
<listitem>
<simpara><literal>12</literal> or <literal>ntp</literal> for the NTP subsystem</simpara>
</listitem>
<listitem>
<simpara><literal>13</literal> or <literal>security</literal> for the syslog audit log</simpara>
</listitem>
<listitem>
<simpara><literal>14</literal> or <literal>console</literal> for the syslog alert log</simpara>
</listitem>
<listitem>
<simpara><literal>15</literal> or <literal>solaris-cron</literal> for the scheduling daemon</simpara>
</listitem>
<listitem>
<simpara><literal>16</literal>–<literal>23</literal> or <literal>local0</literal> – <literal>local7</literal> for locally used facilities</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Optional: <literal>payloadKey</literal>: The record field to use as payload for the syslog message.</simpara>
<note>
<simpara>Configuring the <literal>payloadKey</literal> parameter prevents other parameters from being forwarded to the syslog.</simpara>
</note>
</listitem>
<listitem>
<simpara>rfc: The RFC to be used for sending logs using syslog. The default is RFC5424.</simpara>
</listitem>
<listitem>
<simpara>severity: The <link xlink:href="https://tools.ietf.org/html/rfc5424#section-6.2.1">syslog severity</link> to set on outgoing syslog records. The value can be a decimal integer or a case-insensitive keyword:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>0</literal> or <literal>Emergency</literal> for messages indicating the system is unusable</simpara>
</listitem>
<listitem>
<simpara><literal>1</literal> or <literal>Alert</literal> for messages indicating action must be taken immediately</simpara>
</listitem>
<listitem>
<simpara><literal>2</literal> or <literal>Critical</literal> for messages indicating critical conditions</simpara>
</listitem>
<listitem>
<simpara><literal>3</literal> or <literal>Error</literal> for messages indicating error conditions</simpara>
</listitem>
<listitem>
<simpara><literal>4</literal> or <literal>Warning</literal> for messages indicating warning conditions</simpara>
</listitem>
<listitem>
<simpara><literal>5</literal> or <literal>Notice</literal> for messages indicating normal but significant conditions</simpara>
</listitem>
<listitem>
<simpara><literal>6</literal> or <literal>Informational</literal> for messages indicating informational messages</simpara>
</listitem>
<listitem>
<simpara><literal>7</literal> or <literal>Debug</literal> for messages indicating debug-level messages, the default</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>tag: Tag specifies a record field to use as a tag on the syslog message.</simpara>
</listitem>
<listitem>
<simpara>trimPrefix: Remove the specified prefix from the tag.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="cluster-logging-collector-log-forward-examples-syslog-5424">
<title>Additional RFC5424 syslog parameters</title>
<simpara>The following parameters apply to RFC5424:</simpara>
<itemizedlist>
<listitem>
<simpara>appName: The APP-NAME is a free-text string that identifies the application that sent the log. Must be specified for <literal>RFC5424</literal>.</simpara>
</listitem>
<listitem>
<simpara>msgID: The MSGID is a free-text string that identifies the type of message. Must be specified for <literal>RFC5424</literal>.</simpara>
</listitem>
<listitem>
<simpara>procID: The PROCID is a free-text string. A change in the value indicates a discontinuity in syslog reporting. Must be specified for <literal>RFC5424</literal>.</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="cluster-logging-collector-log-forward-kafka_configuring-log-forwarding">
<title>Forwarding logs to a Kafka broker</title>
<simpara>You can forward logs to an external Kafka broker in addition to, or instead of, the default log store.</simpara>
<simpara>To configure log forwarding to an external Kafka instance, you must create a <literal>ClusterLogForwarder</literal> custom resource (CR) with an output to that instance, and a pipeline that uses the output. You can include a specific Kafka topic in the output or use the default. The Kafka output can use a TCP (insecure) or TLS (secure TCP) connection.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create or edit a YAML file that defines the <literal>ClusterLogForwarder</literal> CR object:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: &lt;log_forwarder_name&gt; <co xml:id="CO34-1"/>
  namespace: &lt;log_forwarder_namespace&gt; <co xml:id="CO34-2"/>
spec:
  serviceAccountName: &lt;service_account_name&gt; <co xml:id="CO34-3"/>
  outputs:
   - name: app-logs <co xml:id="CO34-4"/>
     type: kafka <co xml:id="CO34-5"/>
     url: tls://kafka.example.devlab.com:9093/app-topic <co xml:id="CO34-6"/>
     secret:
       name: kafka-secret <co xml:id="CO34-7"/>
   - name: infra-logs
     type: kafka
     url: tcp://kafka.devlab2.example.com:9093/infra-topic <co xml:id="CO34-8"/>
   - name: audit-logs
     type: kafka
     url: tls://kafka.qelab.example.com:9093/audit-topic
     secret:
        name: kafka-secret-qe
  pipelines:
   - name: app-topic <co xml:id="CO34-9"/>
     inputRefs: <co xml:id="CO34-10"/>
     - application
     outputRefs: <co xml:id="CO34-11"/>
     - app-logs
     labels:
       logType: "application" <co xml:id="CO34-12"/>
   - name: infra-topic <co xml:id="CO34-13"/>
     inputRefs:
     - infrastructure
     outputRefs:
     - infra-logs
     labels:
       logType: "infra"
   - name: audit-topic
     inputRefs:
     - audit
     outputRefs:
     - audit-logs
     labels:
       logType: "audit"</programlisting>
<calloutlist>
<callout arearefs="CO34-1">
<para>In legacy implementations, the CR name must be <literal>instance</literal>. In multi log forwarder implementations, you can use any name.</para>
</callout>
<callout arearefs="CO34-2">
<para>In legacy implementations, the CR namespace must be <literal>openshift-logging</literal>. In multi log forwarder implementations, you can use any namespace.</para>
</callout>
<callout arearefs="CO34-3">
<para>The name of your service account. The service account is only required in multi log forwarder implementations if the log forwarder is not deployed in the <literal>openshift-logging</literal> namespace.</para>
</callout>
<callout arearefs="CO34-4">
<para>Specify a name for the output.</para>
</callout>
<callout arearefs="CO34-5">
<para>Specify the <literal>kafka</literal> type.</para>
</callout>
<callout arearefs="CO34-6">
<para>Specify the URL and port of the Kafka broker as a valid absolute URL, optionally with a specific topic. You can use the <literal>tcp</literal> (insecure) or <literal>tls</literal> (secure TCP) protocol. If the cluster-wide proxy using the CIDR annotation is enabled, the output must be a server name or FQDN, not an IP address.</para>
</callout>
<callout arearefs="CO34-7">
<para>If you are using a <literal>tls</literal> prefix, you must specify the name of the secret required by the endpoint for TLS communication. The secret must contain a <literal>ca-bundle.crt</literal> key that points to the certificate it represents. In legacy implementations, the secret must exist in the <literal>openshift-logging</literal> project.</para>
</callout>
<callout arearefs="CO34-8">
<para>Optional: To send an insecure output, use a <literal>tcp</literal> prefix in front of the URL. Also omit the <literal>secret</literal> key and its <literal>name</literal> from this output.</para>
</callout>
<callout arearefs="CO34-9">
<para>Optional: Specify a name for the pipeline.</para>
</callout>
<callout arearefs="CO34-10">
<para>Specify which log types to forward by using the pipeline: <literal>application,</literal> <literal>infrastructure</literal>, or <literal>audit</literal>.</para>
</callout>
<callout arearefs="CO34-11">
<para>Specify the name of the output to use when forwarding logs with this pipeline.</para>
</callout>
<callout arearefs="CO34-12">
<para>Optional: String. One or more labels to add to the logs.</para>
</callout>
<callout arearefs="CO34-13">
<para>Optional: Configure multiple outputs to forward logs to other external log aggregators of any supported type:</para>
<itemizedlist>
<listitem>
<simpara>A name to describe the pipeline.</simpara>
</listitem>
<listitem>
<simpara>The <literal>inputRefs</literal> is the log type to forward by using the pipeline: <literal>application,</literal> <literal>infrastructure</literal>, or <literal>audit</literal>.</simpara>
</listitem>
<listitem>
<simpara>The <literal>outputRefs</literal> is the name of the output to use.</simpara>
</listitem>
<listitem>
<simpara>Optional: String. One or more labels to add to the logs.</simpara>
</listitem>
</itemizedlist>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Optional: To forward a single output to multiple Kafka brokers, specify an array of Kafka brokers as shown in the following example:</simpara>
<programlisting language="yaml" linenumbering="unnumbered"># ...
spec:
  outputs:
  - name: app-logs
    type: kafka
    secret:
      name: kafka-secret-dev
    kafka:  <co xml:id="CO35-1"/>
      brokers: <co xml:id="CO35-2"/>
        - tls://kafka-broker1.example.com:9093/
        - tls://kafka-broker2.example.com:9093/
      topic: app-topic <co xml:id="CO35-3"/>
# ...</programlisting>
<calloutlist>
<callout arearefs="CO35-1">
<para>Specify a <literal>kafka</literal> key that has a <literal>brokers</literal> and <literal>topic</literal> key.</para>
</callout>
<callout arearefs="CO35-2">
<para>Use the <literal>brokers</literal> key to specify an array of one or more brokers.</para>
</callout>
<callout arearefs="CO35-3">
<para>Use the <literal>topic</literal> key to specify the target topic that receives the logs.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>ClusterLogForwarder</literal> CR by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="cluster-logging-collector-log-forward-cloudwatch_configuring-log-forwarding">
<title>Forwarding logs to Amazon CloudWatch</title>
<simpara>You can forward logs to Amazon CloudWatch, a monitoring and log storage service hosted by Amazon Web Services (AWS). You can forward logs to CloudWatch in addition to, or instead of, the default log store.</simpara>
<simpara>To configure log forwarding to CloudWatch, you must create a <literal>ClusterLogForwarder</literal> custom resource (CR) with an output for CloudWatch, and a pipeline that uses the output.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a <literal>Secret</literal> YAML file that uses the <literal>aws_access_key_id</literal> and <literal>aws_secret_access_key</literal> fields to specify your base64-encoded AWS credentials. For example:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Secret
metadata:
  name: cw-secret
  namespace: openshift-logging
data:
  aws_access_key_id: QUtJQUlPU0ZPRE5ON0VYQU1QTEUK
  aws_secret_access_key: d0phbHJYVXRuRkVNSS9LN01ERU5HL2JQeFJmaUNZRVhBTVBMRUtFWQo=</programlisting>
</listitem>
<listitem>
<simpara>Create the secret. For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f cw-secret.yaml</programlisting>
</listitem>
<listitem>
<simpara>Create or edit a YAML file that defines the <literal>ClusterLogForwarder</literal> CR object. In the file, specify the name of the secret. For example:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: &lt;log_forwarder_name&gt; <co xml:id="CO36-1"/>
  namespace: &lt;log_forwarder_namespace&gt; <co xml:id="CO36-2"/>
spec:
  serviceAccountName: &lt;service_account_name&gt; <co xml:id="CO36-3"/>
  outputs:
   - name: cw <co xml:id="CO36-4"/>
     type: cloudwatch <co xml:id="CO36-5"/>
     cloudwatch:
       groupBy: logType <co xml:id="CO36-6"/>
       groupPrefix: &lt;group prefix&gt; <co xml:id="CO36-7"/>
       region: us-east-2 <co xml:id="CO36-8"/>
     secret:
        name: cw-secret <co xml:id="CO36-9"/>
  pipelines:
    - name: infra-logs <co xml:id="CO36-10"/>
      inputRefs: <co xml:id="CO36-11"/>
        - infrastructure
        - audit
        - application
      outputRefs:
        - cw <co xml:id="CO36-12"/></programlisting>
<calloutlist>
<callout arearefs="CO36-1">
<para>In legacy implementations, the CR name must be <literal>instance</literal>. In multi log forwarder implementations, you can use any name.</para>
</callout>
<callout arearefs="CO36-2">
<para>In legacy implementations, the CR namespace must be <literal>openshift-logging</literal>. In multi log forwarder implementations, you can use any namespace.</para>
</callout>
<callout arearefs="CO36-3">
<para>The name of your service account. The service account is only required in multi log forwarder implementations if the log forwarder is not deployed in the <literal>openshift-logging</literal> namespace.</para>
</callout>
<callout arearefs="CO36-4">
<para>Specify a name for the output.</para>
</callout>
<callout arearefs="CO36-5">
<para>Specify the <literal>cloudwatch</literal> type.</para>
</callout>
<callout arearefs="CO36-6">
<para>Optional: Specify how to group the logs:</para>
<itemizedlist>
<listitem>
<simpara><literal>logType</literal> creates log groups for each log type.</simpara>
</listitem>
<listitem>
<simpara><literal>namespaceName</literal> creates a log group for each application name space. It also creates separate log groups for infrastructure and audit logs.</simpara>
</listitem>
<listitem>
<simpara><literal>namespaceUUID</literal> creates a new log groups for each application namespace UUID. It also creates separate log groups for infrastructure and audit logs.</simpara>
</listitem>
</itemizedlist>
</callout>
<callout arearefs="CO36-7">
<para>Optional: Specify a string to replace the default <literal>infrastructureName</literal> prefix in the names of the log groups.</para>
</callout>
<callout arearefs="CO36-8">
<para>Specify the AWS region.</para>
</callout>
<callout arearefs="CO36-9">
<para>Specify the name of the secret that contains your AWS credentials.</para>
</callout>
<callout arearefs="CO36-10">
<para>Optional: Specify a name for the pipeline.</para>
</callout>
<callout arearefs="CO36-11">
<para>Specify which log types to forward by using the pipeline: <literal>application,</literal> <literal>infrastructure</literal>, or <literal>audit</literal>.</para>
</callout>
<callout arearefs="CO36-12">
<para>Specify the name of the output to use when forwarding logs with this pipeline.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Create the CR object:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create -f &lt;file-name&gt;.yaml</programlisting>
</listitem>
</orderedlist>
<formalpara>
<title>Example: Using ClusterLogForwarder with Amazon CloudWatch</title>
<para>Here, you see an example <literal>ClusterLogForwarder</literal> custom resource (CR) and the log data that it outputs to Amazon CloudWatch.</para>
</formalpara>
<simpara>Suppose that you are running
an OpenShift Container Platform cluster
named <literal>mycluster</literal>. The following command returns the cluster&#8217;s <literal>infrastructureName</literal>, which you will use to compose <literal>aws</literal> commands later on:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get Infrastructure/cluster -ojson | jq .status.infrastructureName
"mycluster-7977k"</programlisting>
<simpara>To generate log data for this example, you run a <literal>busybox</literal> pod in a namespace called <literal>app</literal>. The <literal>busybox</literal> pod writes a message to stdout every three seconds:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc run busybox --image=busybox -- sh -c 'while true; do echo "My life is my message"; sleep 3; done'
$ oc logs -f busybox
My life is my message
My life is my message
My life is my message
...</programlisting>
<simpara>You can look up the UUID of the <literal>app</literal> namespace where the <literal>busybox</literal> pod runs:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get ns/app -ojson | jq .metadata.uid
"794e1e1a-b9f5-4958-a190-e76a9b53d7bf"</programlisting>
<simpara>In your <literal>ClusterLogForwarder</literal> custom resource (CR), you configure the <literal>infrastructure</literal>, <literal>audit</literal>, and <literal>application</literal> log types as inputs to the <literal>all-logs</literal> pipeline. You also connect this pipeline to <literal>cw</literal> output, which forwards the logs to a CloudWatch instance in the <literal>us-east-2</literal> region:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: "logging.openshift.io/v1"
kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging
spec:
  outputs:
   - name: cw
     type: cloudwatch
     cloudwatch:
       groupBy: logType
       region: us-east-2
     secret:
        name: cw-secret
  pipelines:
    - name: all-logs
      inputRefs:
        - infrastructure
        - audit
        - application
      outputRefs:
        - cw</programlisting>
<simpara>Each region in CloudWatch contains three levels of objects:</simpara>
<itemizedlist>
<listitem>
<simpara>log group</simpara>
<itemizedlist>
<listitem>
<simpara>log stream</simpara>
<itemizedlist>
<listitem>
<simpara>log event</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
<simpara>With <literal>groupBy: logType</literal> in the <literal>ClusterLogForwarding</literal> CR, the three log types in the <literal>inputRefs</literal> produce three log groups in Amazon Cloudwatch:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ aws --output json logs describe-log-groups | jq .logGroups[].logGroupName
"mycluster-7977k.application"
"mycluster-7977k.audit"
"mycluster-7977k.infrastructure"</programlisting>
<simpara>Each of the log groups contains log streams:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ aws --output json logs describe-log-streams --log-group-name mycluster-7977k.application | jq .logStreams[].logStreamName
"kubernetes.var.log.containers.busybox_app_busybox-da085893053e20beddd6747acdbaf98e77c37718f85a7f6a4facf09ca195ad76.log"</programlisting>
<programlisting language="terminal" linenumbering="unnumbered">$ aws --output json logs describe-log-streams --log-group-name mycluster-7977k.audit | jq .logStreams[].logStreamName
"ip-10-0-131-228.us-east-2.compute.internal.k8s-audit.log"
"ip-10-0-131-228.us-east-2.compute.internal.linux-audit.log"
"ip-10-0-131-228.us-east-2.compute.internal.openshift-audit.log"
...</programlisting>
<programlisting language="terminal" linenumbering="unnumbered">$ aws --output json logs describe-log-streams --log-group-name mycluster-7977k.infrastructure | jq .logStreams[].logStreamName
"ip-10-0-131-228.us-east-2.compute.internal.kubernetes.var.log.containers.apiserver-69f9fd9b58-zqzw5_openshift-oauth-apiserver_oauth-apiserver-453c5c4ee026fe20a6139ba6b1cdd1bed25989c905bf5ac5ca211b7cbb5c3d7b.log"
"ip-10-0-131-228.us-east-2.compute.internal.kubernetes.var.log.containers.apiserver-797774f7c5-lftrx_openshift-apiserver_openshift-apiserver-ce51532df7d4e4d5f21c4f4be05f6575b93196336be0027067fd7d93d70f66a4.log"
"ip-10-0-131-228.us-east-2.compute.internal.kubernetes.var.log.containers.apiserver-797774f7c5-lftrx_openshift-apiserver_openshift-apiserver-check-endpoints-82a9096b5931b5c3b1d6dc4b66113252da4a6472c9fff48623baee761911a9ef.log"
...</programlisting>
<simpara>Each log stream contains log events. To see a log event from the <literal>busybox</literal> Pod, you specify its log stream from the <literal>application</literal> log group:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ aws logs get-log-events --log-group-name mycluster-7977k.application --log-stream-name kubernetes.var.log.containers.busybox_app_busybox-da085893053e20beddd6747acdbaf98e77c37718f85a7f6a4facf09ca195ad76.log
{
    "events": [
        {
            "timestamp": 1629422704178,
            "message": "{\"docker\":{\"container_id\":\"da085893053e20beddd6747acdbaf98e77c37718f85a7f6a4facf09ca195ad76\"},\"kubernetes\":{\"container_name\":\"busybox\",\"namespace_name\":\"app\",\"pod_name\":\"busybox\",\"container_image\":\"docker.io/library/busybox:latest\",\"container_image_id\":\"docker.io/library/busybox@sha256:0f354ec1728d9ff32edcd7d1b8bbdfc798277ad36120dc3dc683be44524c8b60\",\"pod_id\":\"870be234-90a3-4258-b73f-4f4d6e2777c7\",\"host\":\"ip-10-0-216-3.us-east-2.compute.internal\",\"labels\":{\"run\":\"busybox\"},\"master_url\":\"https://kubernetes.default.svc\",\"namespace_id\":\"794e1e1a-b9f5-4958-a190-e76a9b53d7bf\",\"namespace_labels\":{\"kubernetes_io/metadata_name\":\"app\"}},\"message\":\"My life is my message\",\"level\":\"unknown\",\"hostname\":\"ip-10-0-216-3.us-east-2.compute.internal\",\"pipeline_metadata\":{\"collector\":{\"ipaddr4\":\"10.0.216.3\",\"inputname\":\"fluent-plugin-systemd\",\"name\":\"fluentd\",\"received_at\":\"2021-08-20T01:25:08.085760+00:00\",\"version\":\"1.7.4 1.6.0\"}},\"@timestamp\":\"2021-08-20T01:25:04.178986+00:00\",\"viaq_index_name\":\"app-write\",\"viaq_msg_id\":\"NWRjZmUyMWQtZjgzNC00MjI4LTk3MjMtNTk3NmY3ZjU4NDk1\",\"log_type\":\"application\",\"time\":\"2021-08-20T01:25:04+00:00\"}",
            "ingestionTime": 1629422744016
        },
...</programlisting>
<formalpara>
<title>Example: Customizing the prefix in log group names</title>
<para>In the log group names, you can replace the default <literal>infrastructureName</literal> prefix, <literal>mycluster-7977k</literal>, with an arbitrary string like <literal>demo-group-prefix</literal>. To make this change, you update the <literal>groupPrefix</literal> field in the <literal>ClusterLogForwarding</literal> CR:</para>
</formalpara>
<programlisting language="yaml" linenumbering="unnumbered">cloudwatch:
    groupBy: logType
    groupPrefix: demo-group-prefix
    region: us-east-2</programlisting>
<simpara>The value of <literal>groupPrefix</literal> replaces the default <literal>infrastructureName</literal> prefix:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ aws --output json logs describe-log-groups | jq .logGroups[].logGroupName
"demo-group-prefix.application"
"demo-group-prefix.audit"
"demo-group-prefix.infrastructure"</programlisting>
<formalpara>
<title>Example: Naming log groups after application namespace names</title>
<para>For each application namespace in your cluster, you can create a log group in CloudWatch whose name is based on the name of the application namespace.</para>
</formalpara>
<simpara>If you delete an application namespace object and create a new one that has the same name, CloudWatch continues using the same log group as before.</simpara>
<simpara>If you consider successive application namespace objects that have the same name as equivalent to each other, use the approach described in this example. Otherwise, if you need to distinguish the resulting log groups from each other, see the following "Naming log groups for application namespace UUIDs" section instead.</simpara>
<simpara>To create application log groups whose names are based on the names of the application namespaces, you set the value of the <literal>groupBy</literal> field to <literal>namespaceName</literal> in the <literal>ClusterLogForwarder</literal> CR:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">cloudwatch:
    groupBy: namespaceName
    region: us-east-2</programlisting>
<simpara>Setting <literal>groupBy</literal> to <literal>namespaceName</literal> affects the application log group only. It does not affect the <literal>audit</literal> and <literal>infrastructure</literal> log groups.</simpara>
<simpara>In Amazon Cloudwatch, the namespace name appears at the end of each log group name. Because there is a single application namespace, "app", the following output shows a new <literal>mycluster-7977k.app</literal> log group instead of <literal>mycluster-7977k.application</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ aws --output json logs describe-log-groups | jq .logGroups[].logGroupName
"mycluster-7977k.app"
"mycluster-7977k.audit"
"mycluster-7977k.infrastructure"</programlisting>
<simpara>If the cluster in this example had contained multiple application namespaces, the output would show multiple log groups, one for each namespace.</simpara>
<simpara>The <literal>groupBy</literal> field affects the application log group only. It does not affect the <literal>audit</literal> and <literal>infrastructure</literal> log groups.</simpara>
<formalpara>
<title>Example: Naming log groups after application namespace UUIDs</title>
<para>For each application namespace in your cluster, you can create a log group in CloudWatch whose name is based on the UUID of the application namespace.</para>
</formalpara>
<simpara>If you delete an application namespace object and create a new one, CloudWatch creates a new log group.</simpara>
<simpara>If you consider successive application namespace objects with the same name as different from each other, use the approach described in this example. Otherwise, see the preceding "Example: Naming log groups for application namespace names" section instead.</simpara>
<simpara>To name log groups after application namespace UUIDs, you set the value of the <literal>groupBy</literal> field to <literal>namespaceUUID</literal> in the <literal>ClusterLogForwarder</literal> CR:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">cloudwatch:
    groupBy: namespaceUUID
    region: us-east-2</programlisting>
<simpara>In Amazon Cloudwatch, the namespace UUID appears at the end of each log group name. Because there is a single application namespace, "app", the following output shows a new <literal>mycluster-7977k.794e1e1a-b9f5-4958-a190-e76a9b53d7bf</literal> log group instead of <literal>mycluster-7977k.application</literal>:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ aws --output json logs describe-log-groups | jq .logGroups[].logGroupName
"mycluster-7977k.794e1e1a-b9f5-4958-a190-e76a9b53d7bf" // uid of the "app" namespace
"mycluster-7977k.audit"
"mycluster-7977k.infrastructure"</programlisting>
<simpara>The <literal>groupBy</literal> field affects the application log group only. It does not affect the <literal>audit</literal> and <literal>infrastructure</literal> log groups.</simpara>
</section>
<section xml:id="cluster-logging-collector-log-forward-secret-cloudwatch_configuring-log-forwarding">
<title>Creating a secret for AWS CloudWatch with an existing AWS role</title>
<simpara>If you have an existing role for AWS, you can create a secret for AWS with STS using the <literal>oc create secret --from-literal</literal> command.</simpara>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>In the CLI, enter the following to generate a secret for AWS:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create secret generic cw-sts-secret -n openshift-logging --from-literal=role_arn=arn:aws:iam::123456789012:role/my-role_with-permissions</programlisting>
<formalpara>
<title>Example Secret</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Secret
metadata:
  namespace: openshift-logging
  name: my-secret-name
stringData:
  role_arn: arn:aws:iam::123456789012:role/my-role_with-permissions</programlisting>
</para>
</formalpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="cluster-logging-collector-log-forward-sts-cloudwatch_configuring-log-forwarding">
<title>Forwarding logs to Amazon CloudWatch from STS enabled clusters</title>
<simpara>For clusters with AWS Security Token Service (STS) enabled, you can create an AWS service account manually or create a credentials request by using the
<link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/authentication_and_authorization/#">Cloud Credential Operator(CCO)</link>
 utility <literal>ccoctl</literal>.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Logging for Red Hat OpenShift: 5.5 and later</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a <literal>CredentialsRequest</literal> custom resource YAML by using the template below:</simpara>
<formalpara>
<title>CloudWatch credentials request template</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: cloudcredential.openshift.io/v1
kind: CredentialsRequest
metadata:
  name: &lt;your_role_name&gt;-credrequest
  namespace: openshift-cloud-credential-operator
spec:
  providerSpec:
    apiVersion: cloudcredential.openshift.io/v1
    kind: AWSProviderSpec
    statementEntries:
      - action:
          - logs:PutLogEvents
          - logs:CreateLogGroup
          - logs:PutRetentionPolicy
          - logs:CreateLogStream
          - logs:DescribeLogGroups
          - logs:DescribeLogStreams
        effect: Allow
        resource: arn:aws:logs:*:*:*
  secretRef:
    name: &lt;your_role_name&gt;
    namespace: openshift-logging
  serviceAccountNames:
    - logcollector</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Use the <literal>ccoctl</literal> command to create a role for AWS using your <literal>CredentialsRequest</literal> CR. With the <literal>CredentialsRequest</literal> object, this <literal>ccoctl</literal> command creates an IAM role with a trust policy that is tied to the specified OIDC identity provider, and a permissions policy that grants permissions to perform operations on CloudWatch resources. This command also creates a YAML configuration file in <literal>/&lt;path_to_ccoctl_output_dir&gt;/manifests/openshift-logging-&lt;your_role_name&gt;-credentials.yaml</literal>. This secret file contains the <literal>role_arn</literal> key/value used during authentication with the AWS IAM identity provider.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ ccoctl aws create-iam-roles \
--name=&lt;name&gt; \
--region=&lt;aws_region&gt; \
--credentials-requests-dir=&lt;path_to_directory_with_list_of_credentials_requests&gt;/credrequests \
--identity-provider-arn=arn:aws:iam::&lt;aws_account_id&gt;:oidc-provider/&lt;name&gt;-oidc.s3.&lt;aws_region&gt;.amazonaws.com <co xml:id="CO37-1"/></programlisting>
<calloutlist>
<callout arearefs="CO37-1">
<para>&lt;name&gt; is the name used to tag your cloud resources and should match the name used during your STS cluster install</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the secret created:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f output/manifests/openshift-logging-&lt;your_role_name&gt;-credentials.yaml</programlisting>
</listitem>
<listitem>
<simpara>Create or edit a <literal>ClusterLogForwarder</literal> custom resource:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: &lt;log_forwarder_name&gt; <co xml:id="CO38-1"/>
  namespace: &lt;log_forwarder_namespace&gt; <co xml:id="CO38-2"/>
spec:
  serviceAccountName: clf-collector <co xml:id="CO38-3"/>
  outputs:
   - name: cw <co xml:id="CO38-4"/>
     type: cloudwatch <co xml:id="CO38-5"/>
     cloudwatch:
       groupBy: logType <co xml:id="CO38-6"/>
       groupPrefix: &lt;group prefix&gt; <co xml:id="CO38-7"/>
       region: us-east-2 <co xml:id="CO38-8"/>
     secret:
        name: &lt;your_secret_name&gt; <co xml:id="CO38-9"/>
  pipelines:
    - name: to-cloudwatch <co xml:id="CO38-10"/>
      inputRefs: <co xml:id="CO38-11"/>
        - infrastructure
        - audit
        - application
      outputRefs:
        - cw <co xml:id="CO38-12"/></programlisting>
<calloutlist>
<callout arearefs="CO38-1">
<para>In legacy implementations, the CR name must be <literal>instance</literal>. In multi log forwarder implementations, you can use any name.</para>
</callout>
<callout arearefs="CO38-2">
<para>In legacy implementations, the CR namespace must be <literal>openshift-logging</literal>. In multi log forwarder implementations, you can use any namespace.</para>
</callout>
<callout arearefs="CO38-3">
<para>Specify the <literal>clf-collector</literal> service account. The service account is only required in multi log forwarder implementations if the log forwarder is not deployed in the <literal>openshift-logging</literal> namespace.</para>
</callout>
<callout arearefs="CO38-4">
<para>Specify a name for the output.</para>
</callout>
<callout arearefs="CO38-5">
<para>Specify the <literal>cloudwatch</literal> type.</para>
</callout>
<callout arearefs="CO38-6">
<para>Optional: Specify how to group the logs:</para>
<itemizedlist>
<listitem>
<simpara><literal>logType</literal> creates log groups for each log type.</simpara>
</listitem>
<listitem>
<simpara><literal>namespaceName</literal> creates a log group for each application name space. Infrastructure and audit logs are unaffected, remaining grouped by <literal>logType</literal>.</simpara>
</listitem>
<listitem>
<simpara><literal>namespaceUUID</literal> creates a new log groups for each application namespace UUID. It also creates separate log groups for infrastructure and audit logs.</simpara>
</listitem>
</itemizedlist>
</callout>
<callout arearefs="CO38-7">
<para>Optional: Specify a string to replace the default <literal>infrastructureName</literal> prefix in the names of the log groups.</para>
</callout>
<callout arearefs="CO38-8">
<para>Specify the AWS region.</para>
</callout>
<callout arearefs="CO38-9">
<para>Specify the name of the secret that contains your AWS credentials.</para>
</callout>
<callout arearefs="CO38-10">
<para>Optional: Specify a name for the pipeline.</para>
</callout>
<callout arearefs="CO38-11">
<para>Specify which log types to forward by using the pipeline: <literal>application,</literal> <literal>infrastructure</literal>, or <literal>audit</literal>.</para>
</callout>
<callout arearefs="CO38-12">
<para>Specify the name of the output to use when forwarding logs with this pipeline.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://docs.aws.amazon.com/STS/latest/APIReference/welcome.html">AWS STS API Reference</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="cluster-logging-collector">
<title>Configuring the logging collector</title>

<simpara>Logging for Red Hat OpenShift collects operations and application logs from your cluster and enriches the data with Kubernetes pod and project metadata.
All supported modifications to the log collector can be performed though the <literal>spec.collection</literal> stanza in the <literal>ClusterLogging</literal> custom resource (CR).</simpara>
<section xml:id="configuring-logging-collector_cluster-logging-collector">
<title>Configuring the log collector</title>
<simpara>You can configure which log collector type your logging uses by modifying the <literal>ClusterLogging</literal> custom resource (CR).</simpara>
<note>
<simpara>Fluentd is deprecated and is planned to be removed in a future release. Red Hat provides bug fixes and support for this feature during the current release lifecycle, but this feature no longer receives enhancements. As an alternative to Fluentd, you can use Vector instead.</simpara>
</note>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator.</simpara>
</listitem>
<listitem>
<simpara>You have created a <literal>ClusterLogging</literal> CR.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Modify the <literal>ClusterLogging</literal> CR <literal>collection</literal> spec:</simpara>
<formalpara>
<title><literal>ClusterLogging</literal> CR example</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
# ...
spec:
# ...
  collection:
    type: &lt;log_collector_type&gt; <co xml:id="CO39-1"/>
    resources: {}
    tolerations: {}
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO39-1">
<para>The log collector type you want to use for the logging. This can be <literal>vector</literal> or <literal>fluentd</literal>.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>ClusterLogging</literal> CR by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="creating-logfilesmetricexporter_cluster-logging-collector">
<title>Creating a LogFileMetricExporter resource</title>
<simpara>In logging version 5.8 and newer versions, the LogFileMetricExporter is no longer deployed with the collector by default. You must manually create a <literal>LogFileMetricExporter</literal> custom resource (CR) to generate metrics from the logs produced by running containers.</simpara>
<simpara>If you do not create the <literal>LogFileMetricExporter</literal> CR, you may see a <emphasis role="strong">No datapoints found</emphasis> message in the OpenShift Container Platform web console dashboard for <emphasis role="strong">Produced Logs</emphasis>.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator.</simpara>
</listitem>
<listitem>
<simpara>You have installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a <literal>LogFileMetricExporter</literal> CR as a YAML file:</simpara>
<formalpara>
<title>Example <literal>LogFileMetricExporter</literal> CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1alpha1
kind: LogFileMetricExporter
metadata:
  name: instance
  namespace: openshift-logging
spec:
  nodeSelector: {} <co xml:id="CO40-1"/>
  resources: <co xml:id="CO40-2"/>
    limits:
      cpu: 500m
      memory: 256Mi
    requests:
      cpu: 200m
      memory: 128Mi
  tolerations: [] <co xml:id="CO40-3"/>
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO40-1">
<para>Optional: The <literal>nodeSelector</literal> stanza defines which nodes the pods are scheduled on.</para>
</callout>
<callout arearefs="CO40-2">
<para>The <literal>resources</literal> stanza defines resource requirements for the <literal>LogFileMetricExporter</literal> CR.</para>
</callout>
<callout arearefs="CO40-3">
<para>Optional: The <literal>tolerations</literal> stanza defines the tolerations that the pods accept.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>LogFileMetricExporter</literal> CR by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
<formalpara>
<title>Verification</title>
<para>A <literal>logfilesmetricexporter</literal> pod runs concurrently with a <literal>collector</literal> pod on each node.</para>
</formalpara>
<itemizedlist>
<listitem>
<simpara>Verify that the <literal>logfilesmetricexporter</literal> pods are running in the namespace where you have created the <literal>LogFileMetricExporter</literal> CR, by running the following command and observing the output:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods -l app.kubernetes.io/component=logfilesmetricexporter -n openshift-logging</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                           READY   STATUS    RESTARTS   AGE
logfilesmetricexporter-9qbjj   1/1     Running   0          2m46s
logfilesmetricexporter-cbc4v   1/1     Running   0          2m46s</programlisting>
</para>
</formalpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="log-collector-resources-scheduling_cluster-logging-collector">
<title>Configuring resources and scheduling for logging collectors</title>
<simpara>Administrators can modify the resources or scheduling of the collector by creating a <literal>ClusterLogging</literal> custom resource (CR) that is in the same namespace and has the same name as the <literal>ClusterLogForwarder</literal> CR that it supports.</simpara>
<simpara>The applicable stanzas for the <literal>ClusterLogging</literal> CR when using multiple log forwarders in a deployment are <literal>managmentState</literal> and <literal>collection</literal>. All other stanzas are ignored.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator version 5.8 or newer.</simpara>
</listitem>
<listitem>
<simpara>You have created a <literal>ClusterLogForwarder</literal> CR.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a <literal>ClusterLogging</literal> CR that supports your existing <literal>ClusterLogForwarder</literal> CR:</simpara>
<formalpara>
<title>Example <literal>ClusterLogging</literal> CR YAML</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
  name:  &lt;name&gt; <co xml:id="CO41-1"/>
  namespace: &lt;namespace&gt; <co xml:id="CO41-2"/>
spec:
  managementState: "Managed"
  collection:
    type: "vector"
    tolerations:
    - key: "logging"
      operator: "Exists"
      effect: "NoExecute"
      tolerationSeconds: 6000
    resources:
      limits:
        memory: 1Gi
      requests:
        cpu: 100m
        memory: 1Gi
    nodeSelector:
      collector: needed
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO41-1">
<para>The name must be the same name as the <literal>ClusterLogForwarder</literal> CR.</para>
</callout>
<callout arearefs="CO41-2">
<para>The namespace must be the same namespace as the <literal>ClusterLogForwarder</literal> CR.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>ClusterLogging</literal> CR by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="cluster-logging-collector-pod-location_cluster-logging-collector">
<title>Viewing logging collector pods</title>
<simpara>You can view the logging collector pods and the corresponding nodes that they are running on.</simpara>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>Run the following command in a project to view the logging collector pods and their details:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods --selector component=collector -o wide -n &lt;project_name&gt;</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME           READY  STATUS    RESTARTS   AGE     IP            NODE                  NOMINATED NODE   READINESS GATES
collector-8d69v  1/1    Running   0          134m    10.130.2.30   master1.example.com   &lt;none&gt;           &lt;none&gt;
collector-bd225  1/1    Running   0          134m    10.131.1.11   master2.example.com   &lt;none&gt;           &lt;none&gt;
collector-cvrzs  1/1    Running   0          134m    10.130.0.21   master3.example.com   &lt;none&gt;           &lt;none&gt;
collector-gpqg2  1/1    Running   0          134m    10.128.2.27   worker1.example.com   &lt;none&gt;           &lt;none&gt;
collector-l9j7j  1/1    Running   0          134m    10.129.2.31   worker2.example.com   &lt;none&gt;           &lt;none&gt;</programlisting>
</para>
</formalpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="cluster-logging-collector-limits_cluster-logging-collector">
<title>Configure log collector CPU and memory limits</title>
<simpara>The log collector allows for adjustments to both the CPU and memory limits.</simpara>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>Edit the <literal>ClusterLogging</literal> custom resource (CR) in the <literal>openshift-logging</literal> project:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging edit ClusterLogging instance</programlisting>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
  name: instance
  namespace: openshift-logging
spec:
  collection:
    type: fluentd
    resources:
      limits: <co xml:id="CO42-1"/>
        memory: 736Mi
        requests:
          cpu: 100m
          memory: 736Mi
# ...</programlisting>
<calloutlist>
<callout arearefs="CO42-1">
<para>Specify the CPU and memory limits and requests as needed. The values shown are the default values.</para>
</callout>
</calloutlist>
</listitem>
</itemizedlist>
</section>
<section xml:id="cluster-logging-collector-tuning_cluster-logging-collector">
<title>Advanced configuration for the Fluentd log forwarder</title>
<note>
<simpara>Fluentd is deprecated and is planned to be removed in a future release. Red Hat provides bug fixes and support for this feature during the current release lifecycle, but this feature no longer receives enhancements. As an alternative to Fluentd, you can use Vector instead.</simpara>
</note>
<simpara>Logging includes multiple Fluentd parameters that you can use for tuning the performance of the Fluentd log forwarder. With these parameters, you can change the following Fluentd behaviors:</simpara>
<itemizedlist>
<listitem>
<simpara>Chunk and chunk buffer sizes</simpara>
</listitem>
<listitem>
<simpara>Chunk flushing behavior</simpara>
</listitem>
<listitem>
<simpara>Chunk forwarding retry behavior</simpara>
</listitem>
</itemizedlist>
<simpara>Fluentd collects log data in a single blob called a <emphasis>chunk</emphasis>. When Fluentd creates a chunk, the chunk is considered to be in the <emphasis>stage</emphasis>, where the chunk gets filled with data. When the chunk is full, Fluentd moves the chunk to the <emphasis>queue</emphasis>, where chunks are held before being flushed, or written out to their destination. Fluentd can fail to flush a chunk for a number of reasons, such as network issues or capacity issues at the destination. If a chunk cannot be flushed, Fluentd retries flushing as configured.</simpara>
<simpara>By default in OpenShift Container Platform, Fluentd uses the <emphasis>exponential backoff</emphasis> method to retry flushing, where Fluentd doubles the time it waits between attempts to retry flushing again, which helps reduce connection requests to the destination. You can disable exponential backoff and use the <emphasis>periodic</emphasis> retry method instead, which retries flushing the chunks at a specified interval.</simpara>
<simpara>These parameters can help you determine the trade-offs between latency and throughput.</simpara>
<itemizedlist>
<listitem>
<simpara>To optimize Fluentd for throughput, you could use these parameters to reduce network packet count by configuring larger buffers and queues, delaying flushes, and setting longer times between retries. Be aware that larger buffers require more space on the node file system.</simpara>
</listitem>
<listitem>
<simpara>To optimize for low latency, you could use the parameters to send data as soon as possible, avoid the build-up of batches, have shorter queues and buffers, and use more frequent flush and retries.</simpara>
</listitem>
</itemizedlist>
<simpara>You can configure the chunking and flushing behavior using the following parameters in the <literal>ClusterLogging</literal> custom resource (CR). The parameters are then automatically added to the Fluentd config map for use by Fluentd.</simpara>
<note>
<simpara>These parameters are:</simpara>
<itemizedlist>
<listitem>
<simpara>Not relevant to most users. The default settings should give good general performance.</simpara>
</listitem>
<listitem>
<simpara>Only for advanced users with detailed knowledge of Fluentd configuration and performance.</simpara>
</listitem>
<listitem>
<simpara>Only for performance tuning. They have no effect on functional aspects of logging.</simpara>
</listitem>
</itemizedlist>
</note>
<table frame="all" rowsep="1" colsep="1">
<title>Advanced Fluentd Configuration Parameters</title>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Parameter</entry>
<entry align="left" valign="top">Description</entry>
<entry align="left" valign="top">Default</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>chunkLimitSize</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The maximum size of each chunk. Fluentd stops writing data to a chunk when it reaches this size. Then, Fluentd sends the chunk to the queue and opens a new chunk.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>8m</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>totalLimitSize</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The maximum size of the buffer, which is the total size of the stage and the queue. If the buffer size exceeds this value, Fluentd stops adding data to chunks and fails with an error. All data not in chunks is lost.</simpara></entry>
<entry align="left" valign="top"><simpara>Approximately 15% of the node disk distributed across all outputs.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>flushInterval</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The interval between chunk flushes. You can use <literal>s</literal> (seconds), <literal>m</literal> (minutes), <literal>h</literal> (hours), or <literal>d</literal> (days).</simpara></entry>
<entry align="left" valign="top"><simpara><literal>1s</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>flushMode</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The method to perform flushes:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>lazy</literal>: Flush chunks based on the <literal>timekey</literal> parameter. You cannot modify the <literal>timekey</literal> parameter.</simpara>
</listitem>
<listitem>
<simpara><literal>interval</literal>: Flush chunks based on the <literal>flushInterval</literal> parameter.</simpara>
</listitem>
<listitem>
<simpara><literal>immediate</literal>: Flush chunks immediately after data is added to a chunk.</simpara>
</listitem>
</itemizedlist></entry>
<entry align="left" valign="top"><simpara><literal>interval</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>flushThreadCount</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The number of threads that perform chunk flushing. Increasing the number of threads improves the flush throughput, which hides network latency.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>2</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>overflowAction</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The chunking behavior when the queue is full:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>throw_exception</literal>: Raise an exception to show in the log.</simpara>
</listitem>
<listitem>
<simpara><literal>block</literal>: Stop data chunking until the full buffer issue is resolved.</simpara>
</listitem>
<listitem>
<simpara><literal>drop_oldest_chunk</literal>: Drop the oldest chunk to accept new incoming chunks. Older chunks have less value than newer chunks.</simpara>
</listitem>
</itemizedlist></entry>
<entry align="left" valign="top"><simpara><literal>block</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>retryMaxInterval</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The maximum time in seconds for the <literal>exponential_backoff</literal> retry method.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>300s</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>retryType</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The retry method when flushing fails:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>exponential_backoff</literal>: Increase the time between flush retries. Fluentd doubles the time it waits until the next retry until the <literal>retry_max_interval</literal> parameter is reached.</simpara>
</listitem>
<listitem>
<simpara><literal>periodic</literal>: Retries flushes periodically, based on the <literal>retryWait</literal> parameter.</simpara>
</listitem>
</itemizedlist></entry>
<entry align="left" valign="top"><simpara><literal>exponential_backoff</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>retryTimeOut</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The maximum time interval to attempt retries before the record is discarded.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>60m</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>retryWait</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The time in seconds before the next chunk flush.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>1s</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>For more information on the Fluentd chunk lifecycle, see <link xlink:href="https://docs.fluentd.org/buffer">Buffer Plugins</link> in the Fluentd documentation.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Edit the <literal>ClusterLogging</literal> custom resource (CR) in the <literal>openshift-logging</literal> project:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit ClusterLogging instance</programlisting>
</listitem>
<listitem>
<simpara>Add or modify any of the following parameters:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
  name: instance
  namespace: openshift-logging
spec:
  collection:
    fluentd:
      buffer:
        chunkLimitSize: 8m <co xml:id="CO43-1"/>
        flushInterval: 5s <co xml:id="CO43-2"/>
        flushMode: interval <co xml:id="CO43-3"/>
        flushThreadCount: 3 <co xml:id="CO43-4"/>
        overflowAction: throw_exception <co xml:id="CO43-5"/>
        retryMaxInterval: "300s" <co xml:id="CO43-6"/>
        retryType: periodic <co xml:id="CO43-7"/>
        retryWait: 1s <co xml:id="CO43-8"/>
        totalLimitSize: 32m <co xml:id="CO43-9"/>
# ...</programlisting>
<calloutlist>
<callout arearefs="CO43-1">
<para>Specify the maximum size of each chunk before it is queued for flushing.</para>
</callout>
<callout arearefs="CO43-2">
<para>Specify the interval between chunk flushes.</para>
</callout>
<callout arearefs="CO43-3">
<para>Specify the method to perform chunk flushes: <literal>lazy</literal>, <literal>interval</literal>, or <literal>immediate</literal>.</para>
</callout>
<callout arearefs="CO43-4">
<para>Specify the number of threads to use for chunk flushes.</para>
</callout>
<callout arearefs="CO43-5">
<para>Specify the chunking behavior when the queue is full: <literal>throw_exception</literal>, <literal>block</literal>, or <literal>drop_oldest_chunk</literal>.</para>
</callout>
<callout arearefs="CO43-6">
<para>Specify the maximum interval in seconds for the <literal>exponential_backoff</literal> chunk flushing method.</para>
</callout>
<callout arearefs="CO43-7">
<para>Specify the retry type when chunk flushing fails: <literal>exponential_backoff</literal> or <literal>periodic</literal>.</para>
</callout>
<callout arearefs="CO43-8">
<para>Specify the time in seconds before the next chunk flush.</para>
</callout>
<callout arearefs="CO43-9">
<para>Specify the maximum size of the chunk buffer.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Verify that the Fluentd pods are redeployed:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods -l component=collector -n openshift-logging</programlisting>
</listitem>
<listitem>
<simpara>Check that the new values are in the <literal>fluentd</literal> config map:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc extract configmap/collector-config --confirm</programlisting>
<formalpara>
<title>Example fluentd.conf</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">&lt;buffer&gt;
  @type file
  path '/var/lib/fluentd/default'
  flush_mode interval
  flush_interval 5s
  flush_thread_count 3
  retry_type periodic
  retry_wait 1s
  retry_max_interval 300s
  retry_timeout 60m
  queued_chunks_limit_size "#{ENV['BUFFER_QUEUE_LIMIT'] || '32'}"
  total_limit_size "#{ENV['TOTAL_LIMIT_SIZE_PER_BUFFER'] || '8589934592'}"
  chunk_limit_size 8m
  overflow_action throw_exception
  disable_chunk_backup true
&lt;/buffer&gt;</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</section>
</section>
<section xml:id="cluster-logging-eventrouter">
<title>Collecting and storing Kubernetes events</title>

<simpara>The OpenShift Container Platform Event Router is a pod that watches Kubernetes events and logs them for collection by the logging. You must manually deploy the Event Router.</simpara>
<simpara>The Event Router collects events from all projects and writes them to <literal>STDOUT</literal>. The collector then forwards those events to the store defined in the <literal>ClusterLogForwarder</literal> custom resource (CR).</simpara>
<important>
<simpara>The Event Router adds additional load to Fluentd and can impact the number of other log messages that can be processed.</simpara>
</important>
<section xml:id="cluster-logging-eventrouter-deploy_cluster-logging-eventrouter">
<title>Deploying and configuring the Event Router</title>
<simpara>Use the following steps to deploy the Event Router into your cluster. You should always deploy the Event Router to the <literal>openshift-logging</literal> project to ensure it collects events from across the cluster.</simpara>
<note>
<simpara>The Event Router image is not a part of the Red Hat OpenShift Logging Operator and must be downloaded separately.</simpara>
</note>
<simpara>The following <literal>Template</literal> object creates the service account, cluster role, and cluster role binding required for the Event Router. The template also configures and deploys the Event Router pod. You can either use this template without making changes or edit the template to change the deployment object CPU and memory requests.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You need proper permissions to create service accounts and update cluster role bindings. For example, you can run the following template with a user that has the <emphasis role="strong">cluster-admin</emphasis> role.</simpara>
</listitem>
<listitem>
<simpara>The Red Hat OpenShift Logging Operator must be installed.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a template for the Event Router:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: template.openshift.io/v1
kind: Template
metadata:
  name: eventrouter-template
  annotations:
    description: "A pod forwarding kubernetes events to OpenShift Logging stack."
    tags: "events,EFK,logging,cluster-logging"
objects:
  - kind: ServiceAccount <co xml:id="CO44-1"/>
    apiVersion: v1
    metadata:
      name: eventrouter
      namespace: ${NAMESPACE}
  - kind: ClusterRole <co xml:id="CO44-2"/>
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: event-reader
    rules:
    - apiGroups: [""]
      resources: ["events"]
      verbs: ["get", "watch", "list"]
  - kind: ClusterRoleBinding <co xml:id="CO44-3"/>
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: event-reader-binding
    subjects:
    - kind: ServiceAccount
      name: eventrouter
      namespace: ${NAMESPACE}
    roleRef:
      kind: ClusterRole
      name: event-reader
  - kind: ConfigMap <co xml:id="CO44-4"/>
    apiVersion: v1
    metadata:
      name: eventrouter
      namespace: ${NAMESPACE}
    data:
      config.json: |-
        {
          "sink": "stdout"
        }
  - kind: Deployment <co xml:id="CO44-5"/>
    apiVersion: apps/v1
    metadata:
      name: eventrouter
      namespace: ${NAMESPACE}
      labels:
        component: "eventrouter"
        logging-infra: "eventrouter"
        provider: "openshift"
    spec:
      selector:
        matchLabels:
          component: "eventrouter"
          logging-infra: "eventrouter"
          provider: "openshift"
      replicas: 1
      template:
        metadata:
          labels:
            component: "eventrouter"
            logging-infra: "eventrouter"
            provider: "openshift"
          name: eventrouter
        spec:
          serviceAccount: eventrouter
          containers:
            - name: kube-eventrouter
              image: ${IMAGE}
              imagePullPolicy: IfNotPresent
              resources:
                requests:
                  cpu: ${CPU}
                  memory: ${MEMORY}
              volumeMounts:
              - name: config-volume
                mountPath: /etc/eventrouter
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop: ["ALL"]
          securityContext:
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          volumes:
          - name: config-volume
            configMap:
              name: eventrouter
parameters:
  - name: IMAGE <co xml:id="CO44-6"/>
    displayName: Image
    value: "registry.redhat.io/openshift-logging/eventrouter-rhel9:v0.4"
  - name: CPU <co xml:id="CO44-7"/>
    displayName: CPU
    value: "100m"
  - name: MEMORY <co xml:id="CO44-8"/>
    displayName: Memory
    value: "128Mi"
  - name: NAMESPACE
    displayName: Namespace
    value: "openshift-logging" <co xml:id="CO44-9"/></programlisting>
<calloutlist>
<callout arearefs="CO44-1">
<para>Creates a Service Account in the <literal>openshift-logging</literal> project for the Event Router.</para>
</callout>
<callout arearefs="CO44-2">
<para>Creates a ClusterRole to monitor for events in the cluster.</para>
</callout>
<callout arearefs="CO44-3">
<para>Creates a ClusterRoleBinding to bind the ClusterRole to the service account.</para>
</callout>
<callout arearefs="CO44-4">
<para>Creates a config map in the <literal>openshift-logging</literal> project to generate the required <literal>config.json</literal> file.</para>
</callout>
<callout arearefs="CO44-5">
<para>Creates a deployment in the <literal>openshift-logging</literal> project to generate and configure the Event Router pod.</para>
</callout>
<callout arearefs="CO44-6">
<para>Specifies the image, identified by a tag such as <literal>v0.4</literal>.</para>
</callout>
<callout arearefs="CO44-7">
<para>Specifies the minimum amount of CPU to allocate to the Event Router pod. Defaults to <literal>100m</literal>.</para>
</callout>
<callout arearefs="CO44-8">
<para>Specifies the minimum amount of memory to allocate to the Event Router pod. Defaults to <literal>128Mi</literal>.</para>
</callout>
<callout arearefs="CO44-9">
<para>Specifies the <literal>openshift-logging</literal> project to install objects in.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Use the following command to process and apply the template:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc process -f &lt;templatefile&gt; | oc apply -n openshift-logging -f -</programlisting>
<simpara>For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc process -f eventrouter.yaml | oc apply -n openshift-logging -f -</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">serviceaccount/eventrouter created
clusterrole.rbac.authorization.k8s.io/event-reader created
clusterrolebinding.rbac.authorization.k8s.io/event-reader-binding created
configmap/eventrouter created
deployment.apps/eventrouter created</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Validate that the Event Router installed in the <literal>openshift-logging</literal> project:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>View the new Event Router pod:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods --selector  component=eventrouter -o name -n openshift-logging</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">pod/cluster-logging-eventrouter-d649f97c8-qvv8r</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>View the events collected by the Event Router:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc logs &lt;cluster_logging_eventrouter_pod&gt; -n openshift-logging</programlisting>
<simpara>For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc logs cluster-logging-eventrouter-d649f97c8-qvv8r -n openshift-logging</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">{"verb":"ADDED","event":{"metadata":{"name":"openshift-service-catalog-controller-manager-remover.1632d931e88fcd8f","namespace":"openshift-service-catalog-removed","selfLink":"/api/v1/namespaces/openshift-service-catalog-removed/events/openshift-service-catalog-controller-manager-remover.1632d931e88fcd8f","uid":"787d7b26-3d2f-4017-b0b0-420db4ae62c0","resourceVersion":"21399","creationTimestamp":"2020-09-08T15:40:26Z"},"involvedObject":{"kind":"Job","namespace":"openshift-service-catalog-removed","name":"openshift-service-catalog-controller-manager-remover","uid":"fac9f479-4ad5-4a57-8adc-cb25d3d9cf8f","apiVersion":"batch/v1","resourceVersion":"21280"},"reason":"Completed","message":"Job completed","source":{"component":"job-controller"},"firstTimestamp":"2020-09-08T15:40:26Z","lastTimestamp":"2020-09-08T15:40:26Z","count":1,"type":"Normal"}}</programlisting>
</para>
</formalpara>
<simpara>You can also use Kibana to view events by creating an index pattern using the Elasticsearch <literal>infra</literal> index.</simpara>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
</section>
</section>
</chapter>
<chapter xml:id="_log-storage">
<title>Log storage</title>
<section xml:id="about-log-storage">
<title>About log storage</title>

<simpara>You can use an internal Loki or Elasticsearch log store on your cluster for storing logs, or you can use a <link linkend="logging-create-clf_configuring-log-forwarding"><literal>ClusterLogForwarder</literal> custom resource (CR)</link> to forward logs to an external store.</simpara>
<section xml:id="log-storage-overview-types">
<title>Log storage types</title>
<simpara>Loki is a horizontally scalable, highly available, multi-tenant log aggregation system offered as an alternative to Elasticsearch as a log store for the logging.</simpara>
<simpara>Elasticsearch indexes incoming log records completely during ingestion. Loki only indexes a few fixed labels during ingestion and defers more complex parsing until after the logs have been stored. This means Loki can collect logs more quickly.</simpara>
<section xml:id="cluster-logging-about-es-logstore_about-log-storage">
<title>About the Elasticsearch log store</title>
<simpara>The logging Elasticsearch instance is optimized and tested for short term storage, approximately seven days. If you want to retain your logs over a longer term, it is recommended you move the data to a third-party storage system.</simpara>
<simpara>Elasticsearch organizes the log data from Fluentd into datastores, or <emphasis>indices</emphasis>, then subdivides each index into multiple pieces called <emphasis>shards</emphasis>, which it spreads across a set of Elasticsearch nodes in an Elasticsearch cluster. You can configure Elasticsearch to make copies of the shards, called <emphasis>replicas</emphasis>, which Elasticsearch also spreads across the Elasticsearch nodes. The <literal>ClusterLogging</literal> custom resource (CR) allows you to specify how the shards are replicated to provide data redundancy and resilience to failure. You can also specify how long the different types of logs are retained using a retention policy in the <literal>ClusterLogging</literal> CR.</simpara>
<note>
<simpara>The number of primary shards for the index templates is equal to the number of Elasticsearch data nodes.</simpara>
</note>
<simpara>The Red Hat OpenShift Logging Operator and companion OpenShift Elasticsearch Operator ensure that each Elasticsearch node is deployed using a unique deployment that includes its own storage volume.
You can use a <literal>ClusterLogging</literal> custom resource (CR) to increase the number of Elasticsearch nodes, as needed.
See the <link xlink:href="https://www.elastic.co/guide/en/elasticsearch/guide/current/hardware.html">Elasticsearch documentation</link> for considerations involved in configuring storage.</simpara>
<note>
<simpara>A highly-available Elasticsearch environment requires at least three Elasticsearch nodes, each on a different host.</simpara>
</note>
<simpara>Role-based access control (RBAC) applied on the Elasticsearch indices enables the controlled access of the logs to the developers. Administrators can access all logs and developers can access only the logs in their projects.</simpara>
</section>
</section>
<section xml:id="log-storage-overview-querying">
<title>Querying log stores</title>
<simpara>You can query Loki by using the <link xlink:href="https://grafana.com/docs/loki/latest/logql/">LogQL log query language</link>.</simpara>
</section>
<section xml:id="additional-resources_log-storage-overview" role="_additional-resources">
<title>Additional resources</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://grafana.com/docs/loki/latest/get-started/components/">Loki components documentation</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://loki-operator.dev/docs/object_storage.md/">Loki Object Storage documentation</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="installing-log-storage">
<title>Installing log storage</title>

<simpara>You can use the OpenShift CLI (<literal>oc</literal>) or the OpenShift Container Platform web console to deploy a log store on your OpenShift Container Platform cluster.</simpara>
<note>
<simpara>The OpenShift Elasticsearch Operator is deprecated and is planned to be removed in a future release. Red&#160;Hat provides bug fixes and support for this feature during the current release lifecycle, but this feature no longer receives enhancements. As an alternative to using the OpenShift Elasticsearch Operator to manage the default log storage, you can use the Loki Operator.</simpara>
</note>
<section xml:id="installing-log-storage-loki">
<title>Deploying a Loki log store</title>
<simpara>You can use the Loki Operator to deploy an internal Loki log store on your OpenShift Container Platform cluster.
After install the Loki Operator, you must configure Loki object storage by creating a secret, and create a <literal>LokiStack</literal> custom resource (CR).</simpara>
<section xml:id="loki-deployment-sizing_installing-log-storage">
<title>Loki deployment sizing</title>
<simpara>Sizing for Loki follows the format of <literal>&lt;N&gt;x.&lt;size&gt;</literal> where the value <literal>&lt;N&gt;</literal> is number of instances and <literal>&lt;size&gt;</literal> specifies performance capabilities.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Loki sizing</title>
<tgroup cols="5">
<colspec colname="col_1" colwidth="20*"/>
<colspec colname="col_2" colwidth="20*"/>
<colspec colname="col_3" colwidth="20*"/>
<colspec colname="col_4" colwidth="20*"/>
<colspec colname="col_5" colwidth="20*"/>
<thead>
<row>
<entry align="left" valign="top"></entry>
<entry align="left" valign="top">1x.demo</entry>
<entry align="left" valign="top">1x.extra-small</entry>
<entry align="left" valign="top">1x.small</entry>
<entry align="left" valign="top">1x.medium</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Data transfer</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Demo use only</simpara></entry>
<entry align="left" valign="top"><simpara>100GB/day</simpara></entry>
<entry align="left" valign="top"><simpara>500GB/day</simpara></entry>
<entry align="left" valign="top"><simpara>2TB/day</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Queries per second (QPS)</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Demo use only</simpara></entry>
<entry align="left" valign="top"><simpara>1-25 QPS at 200ms</simpara></entry>
<entry align="left" valign="top"><simpara>25-50 QPS at 200ms</simpara></entry>
<entry align="left" valign="top"><simpara>25-75 QPS at 200ms</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Replication factor</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>None</simpara></entry>
<entry align="left" valign="top"><simpara>2</simpara></entry>
<entry align="left" valign="top"><simpara>2</simpara></entry>
<entry align="left" valign="top"><simpara>2</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Total CPU requests</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>None</simpara></entry>
<entry align="left" valign="top"><simpara>14 vCPUs</simpara></entry>
<entry align="left" valign="top"><simpara>34 vCPUs</simpara></entry>
<entry align="left" valign="top"><simpara>54 vCPUs</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Total CPU requests if using the ruler</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>None</simpara></entry>
<entry align="left" valign="top"><simpara>16 vCPUs</simpara></entry>
<entry align="left" valign="top"><simpara>42 vCPUs</simpara></entry>
<entry align="left" valign="top"><simpara>70 vCPUs</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Total memory requests</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>None</simpara></entry>
<entry align="left" valign="top"><simpara>31Gi</simpara></entry>
<entry align="left" valign="top"><simpara>67Gi</simpara></entry>
<entry align="left" valign="top"><simpara>139Gi</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Total memory requests if using the ruler</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>None</simpara></entry>
<entry align="left" valign="top"><simpara>35Gi</simpara></entry>
<entry align="left" valign="top"><simpara>83Gi</simpara></entry>
<entry align="left" valign="top"><simpara>171Gi</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Total disk requests</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>40Gi</simpara></entry>
<entry align="left" valign="top"><simpara>430Gi</simpara></entry>
<entry align="left" valign="top"><simpara>430Gi</simpara></entry>
<entry align="left" valign="top"><simpara>590Gi</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">Total disk requests if using the ruler</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>80Gi</simpara></entry>
<entry align="left" valign="top"><simpara>750Gi</simpara></entry>
<entry align="left" valign="top"><simpara>750Gi</simpara></entry>
<entry align="left" valign="top"><simpara>910Gi</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section xml:id="logging-loki-gui-install_installing-log-storage">
<title>Installing the Loki Operator by using the OpenShift Container Platform web console</title>
<simpara>To install and configure logging on your OpenShift Container Platform cluster, additional Operators must be installed. This can be done from the Operator Hub within the web console.</simpara>
<simpara>OpenShift Container Platform Operators use custom resources (CR) to manage applications and their components. High-level configuration and settings are provided by the user within a CR. The Operator translates high-level directives into low-level actions, based on best practices embedded within the Operator’s logic. A custom resource definition (CRD) defines a CR and lists all the configurations available to users of the Operator. Installing an Operator creates the CRDs, which are then used to generate CRs.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have access to a supported object store (AWS S3, Google Cloud Storage, Azure, Swift, Minio, OpenShift Data Foundation).</simpara>
</listitem>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have access to the OpenShift Container Platform web console.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the OpenShift Container Platform web console <emphasis role="strong">Administrator</emphasis> perspective, go to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">OperatorHub</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Type Loki Operator in the <emphasis role="strong">Filter by keyword</emphasis> field. Click <emphasis role="strong">Loki Operator</emphasis> in the list of available Operators, and then click <emphasis role="strong">Install</emphasis>.</simpara>
<important>
<simpara>The Community Loki Operator is not supported by Red Hat.</simpara>
</important>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">stable</emphasis> or <emphasis role="strong">stable-x.y</emphasis> as the <emphasis role="strong">Update channel</emphasis>.</simpara>
<note>
<simpara>The <emphasis role="strong">stable</emphasis> channel only provides updates to the most recent release of logging. To continue receiving updates for prior releases, you must change your subscription channel to <emphasis role="strong">stable-x.y</emphasis>, where <literal>x.y</literal> represents the major and minor version of logging you have installed. For example, <emphasis role="strong">stable-5.7</emphasis>.</simpara>
</note>
<simpara>The Loki Operator must be deployed to the global operator group namespace <literal>openshift-operators-redhat</literal>, so the <emphasis role="strong">Installation mode</emphasis> and <emphasis role="strong">Installed Namespace</emphasis> are already selected. If this namespace does not already exist, it is created for you.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">Enable operator-recommended cluster monitoring on this namespace.</emphasis></simpara>
<simpara>This option sets the <literal>openshift.io/cluster-monitoring: "true"</literal> label in the <literal>Namespace</literal> object. You must select this option to ensure that cluster monitoring scrapes the <literal>openshift-operators-redhat</literal> namespace.</simpara>
</listitem>
<listitem>
<simpara>For <emphasis role="strong">Update approval</emphasis> select <emphasis role="strong">Automatic</emphasis>, then click <emphasis role="strong">Install</emphasis>.</simpara>
<simpara>If the approval strategy in the subscription is set to <emphasis role="strong">Automatic</emphasis>, the update process initiates as soon as a new Operator version is available in the selected channel. If the approval strategy is set to <emphasis role="strong">Manual</emphasis>, you must manually approve pending updates.</simpara>
</listitem>
</orderedlist>
<orderedlist numeration="arabic">
<title>Verification</title>
<listitem>
<simpara>Go to <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Make sure the <emphasis role="strong">openshift-logging</emphasis> project is selected.</simpara>
</listitem>
<listitem>
<simpara>In the <emphasis role="strong">Status</emphasis> column, verify that you see green checkmarks with <emphasis role="strong">InstallSucceeded</emphasis> and the text <emphasis role="strong">Up to date</emphasis>.</simpara>
</listitem>
</orderedlist>
<note>
<simpara>An Operator might display a <literal>Failed</literal> status before the installation finishes. If the Operator install completes with an <literal>InstallSucceeded</literal> message, refresh the page.</simpara>
</note>
</section>
<section xml:id="loki-create-object-storage-secret-console_installing-log-storage">
<title>Creating a secret for Loki object storage by using the web console</title>
<simpara>To configure Loki object storage, you must create a secret. You can create a secret by using the OpenShift Container Platform web console.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have access to the OpenShift Container Platform web console.</simpara>
</listitem>
<listitem>
<simpara>You installed the Loki Operator.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Go to <emphasis role="strong">Workloads</emphasis> &#8594; <emphasis role="strong">Secrets</emphasis> in the <emphasis role="strong">Administrator</emphasis> perspective of the OpenShift Container Platform web console.</simpara>
</listitem>
<listitem>
<simpara>From the <emphasis role="strong">Create</emphasis> drop-down list, select <emphasis role="strong">From YAML</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Create a secret that uses the <literal>access_key_id</literal> and <literal>access_key_secret</literal> fields to specify your credentials and the <literal>bucketnames</literal>, <literal>endpoint</literal>, and <literal>region</literal> fields to define the object storage location. AWS is used in the following example:</simpara>
<formalpara>
<title>Example <literal>Secret</literal> object</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Secret
metadata:
  name: logging-loki-s3
  namespace: openshift-logging
stringData:
  access_key_id: AKIAIOSFODNN7EXAMPLE
  access_key_secret: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
  bucketnames: s3-bucket-name
  endpoint: https://s3.eu-central-1.amazonaws.com
  region: eu-central-1</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link linkend="logging-loki-storage_installing-log-storage">Loki object storage</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="create-lokistack-cr-console_installing-log-storage">
<title>Creating a LokiStack custom resource by using the web console</title>
<simpara>You can create a <literal>LokiStack</literal> custom resource (CR) by using the OpenShift Container Platform web console.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have access to the OpenShift Container Platform web console.</simpara>
</listitem>
<listitem>
<simpara>You installed the Loki Operator.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Go to the <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis> page. Click the <emphasis role="strong">All instances</emphasis> tab.</simpara>
</listitem>
<listitem>
<simpara>From the <emphasis role="strong">Create new</emphasis> drop-down list, select <emphasis role="strong">LokiStack</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">YAML view</emphasis>, and then use the following template to create a <literal>LokiStack</literal> CR:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: logging-loki <co xml:id="CO45-1"/>
  namespace: openshift-logging
spec:
  size: 1x.small <co xml:id="CO45-2"/>
  storage:
    schemas:
    - version: v12
      effectiveDate: '2022-06-01'
    secret:
      name: logging-loki-s3 <co xml:id="CO45-3"/>
      type: s3 <co xml:id="CO45-4"/>
  storageClassName: &lt;storage_class_name&gt; <co xml:id="CO45-5"/>
  tenants:
    mode: openshift-logging</programlisting>
<calloutlist>
<callout arearefs="CO45-1">
<para>Use the name <literal>logging-loki</literal>.</para>
</callout>
<callout arearefs="CO45-2">
<para>Specify the deployment size. In the logging 5.8 and later versions, the supported size options for production instances of Loki are <literal>1x.extra-small</literal>, <literal>1x.small</literal>, or <literal>1x.medium</literal>.</para>
</callout>
<callout arearefs="CO45-3">
<para>Specify the secret used for your log storage.</para>
</callout>
<callout arearefs="CO45-4">
<para>Specify the corresponding storage type.</para>
</callout>
<callout arearefs="CO45-5">
<para>Enter the name of a storage class for temporary storage. For best performance, specify a storage class that allocates block storage. Available storage classes for your cluster can be listed by using the <literal>oc get storageclasses</literal> command.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
</section>
<section xml:id="logging-loki-cli-install_installing-log-storage">
<title>Installing Loki Operator by using the CLI</title>
<simpara>To install and configure logging on your OpenShift Container Platform cluster, additional Operators must be installed. This can be done from the OpenShift Container Platform CLI.</simpara>
<simpara>OpenShift Container Platform Operators use custom resources (CR) to manage applications and their components. High-level configuration and settings are provided by the user within a CR. The Operator translates high-level directives into low-level actions, based on best practices embedded within the Operator’s logic. A custom resource definition (CRD) defines a CR and lists all the configurations available to users of the Operator. Installing an Operator creates the CRDs, which are then used to generate CRs.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
<listitem>
<simpara>You have access to a supported object store. For example: AWS S3, Google Cloud Storage, Azure, Swift, Minio, or OpenShift Data Foundation.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a <literal>Subscription</literal> object:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: loki-operator
  namespace: openshift-operators-redhat <co xml:id="CO46-1"/>
spec:
  channel: stable <co xml:id="CO46-2"/>
  name: loki-operator
  source: redhat-operators <co xml:id="CO46-3"/>
  sourceNamespace: openshift-marketplace</programlisting>
<calloutlist>
<callout arearefs="CO46-1">
<para>You must specify the <literal>openshift-operators-redhat</literal> namespace.</para>
</callout>
<callout arearefs="CO46-2">
<para>Specify <literal>stable</literal>, or <literal>stable-5.&lt;y&gt;</literal> as the channel.</para>
</callout>
<callout arearefs="CO46-3">
<para>Specify <literal>redhat-operators</literal>. If your OpenShift Container Platform cluster is installed on a restricted network, also known as a disconnected cluster, specify the name of the <literal>CatalogSource</literal> object you created when you configured the Operator Lifecycle Manager (OLM).</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>Subscription</literal> object:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="loki-create-object-storage-secret-cli_installing-log-storage">
<title>Creating a secret for Loki object storage by using the CLI</title>
<simpara>To configure Loki object storage, you must create a secret. You can do this by using the OpenShift CLI (<literal>oc</literal>).</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You installed the Loki Operator.</simpara>
</listitem>
<listitem>
<simpara>You installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
</itemizedlist>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>Create a secret in the directory that contains your certificate and key files by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create secret generic -n openshift-logging &lt;your_secret_name&gt; \
 --from-file=tls.key=&lt;your_key_file&gt;
 --from-file=tls.crt=&lt;your_crt_file&gt;
 --from-file=ca-bundle.crt=&lt;your_bundle_file&gt;
 --from-literal=username=&lt;your_username&gt;
 --from-literal=password=&lt;your_password&gt;</programlisting>
</listitem>
</itemizedlist>
<note>
<simpara>Use generic or opaque secrets for best results.</simpara>
</note>
<itemizedlist>
<title>Verification</title>
<listitem>
<simpara>Verify that a secret was created by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get secrets</programlisting>
</listitem>
</itemizedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link linkend="logging-loki-storage_installing-log-storage">Loki object storage</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="create-lokistack-cr-cli_installing-log-storage">
<title>Creating a LokiStack custom resource by using the CLI</title>
<simpara>You can create a <literal>LokiStack</literal> custom resource (CR) by using the OpenShift CLI (<literal>oc</literal>).</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You installed the Loki Operator.</simpara>
</listitem>
<listitem>
<simpara>You installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a <literal>LokiStack</literal> CR:</simpara>
<formalpara>
<title>Example <literal>LokiStack</literal> CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: logging-loki
  namespace: openshift-logging
spec:
  size: 1x.small <co xml:id="CO47-1"/>
  storage:
    schemas:
    - version: v12
      effectiveDate: "2022-06-01"
    secret:
      name: logging-loki-s3 <co xml:id="CO47-2"/>
      type: s3 <co xml:id="CO47-3"/>
  storageClassName: &lt;storage_class_name&gt; <co xml:id="CO47-4"/>
  tenants:
    mode: openshift-logging</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO47-1">
<para>Specify the deployment size. In the logging 5.8 and later versions, the supported size options for production instances of Loki are <literal>1x.extra-small</literal>, <literal>1x.small</literal>, or <literal>1x.medium</literal>.</para>
</callout>
<callout arearefs="CO47-2">
<para>Specify the name of your log store secret.</para>
</callout>
<callout arearefs="CO47-3">
<para>Specify the type of your log store secret.</para>
</callout>
<callout arearefs="CO47-4">
<para>Specify the name of a storage class for temporary storage. For best performance, specify a storage class that allocates block storage. Available storage classes for your cluster can be listed by using the <literal>oc get storageclasses</literal> command.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>LokiStack</literal> CR:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
<itemizedlist>
<title>Verification</title>
<listitem>
<simpara>Verify the installation by listing the pods in the <literal>openshift-logging</literal> project by running the following command and observing the output:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods -n openshift-logging</programlisting>
<simpara>Confirm that you see several pods for components of the logging, similar to the following list:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                                           READY   STATUS    RESTARTS   AGE
cluster-logging-operator-78fddc697-mnl82       1/1     Running   0          14m
collector-6cglq                                2/2     Running   0          45s
collector-8r664                                2/2     Running   0          45s
collector-8z7px                                2/2     Running   0          45s
collector-pdxl9                                2/2     Running   0          45s
collector-tc9dx                                2/2     Running   0          45s
collector-xkd76                                2/2     Running   0          45s
logging-loki-compactor-0                       1/1     Running   0          8m2s
logging-loki-distributor-b85b7d9fd-25j9g       1/1     Running   0          8m2s
logging-loki-distributor-b85b7d9fd-xwjs6       1/1     Running   0          8m2s
logging-loki-gateway-7bb86fd855-hjhl4          2/2     Running   0          8m2s
logging-loki-gateway-7bb86fd855-qjtlb          2/2     Running   0          8m2s
logging-loki-index-gateway-0                   1/1     Running   0          8m2s
logging-loki-index-gateway-1                   1/1     Running   0          7m29s
logging-loki-ingester-0                        1/1     Running   0          8m2s
logging-loki-ingester-1                        1/1     Running   0          6m46s
logging-loki-querier-f5cf9cb87-9fdjd           1/1     Running   0          8m2s
logging-loki-querier-f5cf9cb87-fp9v5           1/1     Running   0          8m2s
logging-loki-query-frontend-58c579fcb7-lfvbc   1/1     Running   0          8m2s
logging-loki-query-frontend-58c579fcb7-tjf9k   1/1     Running   0          8m2s
logging-view-plugin-79448d8df6-ckgmx           1/1     Running   0          46s</programlisting>
</para>
</formalpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="logging-loki-storage_installing-log-storage">
<title>Loki object storage</title>
<simpara>The Loki Operator supports <link xlink:href="https://aws.amazon.com/">AWS S3</link>, as well as other S3 compatible object stores such as <link xlink:href="https://min.io/">Minio</link> and <link xlink:href="https://www.redhat.com/en/technologies/cloud-computing/openshift-data-foundation">OpenShift Data Foundation</link>. <link xlink:href="https://azure.microsoft.com">Azure</link>, <link xlink:href="https://cloud.google.com/">GCS</link>, and <link xlink:href="https://docs.openstack.org/swift/latest/">Swift</link> are also supported.</simpara>
<simpara>The recommended nomenclature for Loki storage is <literal>logging-loki-<emphasis>&lt;your_storage_provider&gt;</emphasis></literal>.</simpara>
<simpara>The following table shows the <literal>type</literal> values within the <literal>LokiStack</literal> custom resource (CR) for each storage provider. For more information, see the section on your storage provider.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Secret type quick reference</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Storage provider</entry>
<entry align="left" valign="top">Secret <literal>type</literal> value</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>AWS</simpara></entry>
<entry align="left" valign="top"><simpara>s3</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Azure</simpara></entry>
<entry align="left" valign="top"><simpara>azure</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Google Cloud</simpara></entry>
<entry align="left" valign="top"><simpara>gcs</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Minio</simpara></entry>
<entry align="left" valign="top"><simpara>s3</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>OpenShift Data Foundation</simpara></entry>
<entry align="left" valign="top"><simpara>s3</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Swift</simpara></entry>
<entry align="left" valign="top"><simpara>swift</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<section xml:id="logging-loki-storage-aws_installing-log-storage">
<title>AWS storage</title>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You installed the Loki Operator.</simpara>
</listitem>
<listitem>
<simpara>You installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
<listitem>
<simpara>You created a <link xlink:href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-overview.html">bucket</link> on AWS.</simpara>
</listitem>
<listitem>
<simpara>You created an <link xlink:href="https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html#policies_resource-based">AWS IAM Policy and IAM User</link>.</simpara>
</listitem>
</itemizedlist>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>Create an object storage secret with the name <literal>logging-loki-aws</literal> by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create secret generic logging-loki-aws \
  --from-literal=bucketnames="&lt;bucket_name&gt;" \
  --from-literal=endpoint="&lt;aws_bucket_endpoint&gt;" \
  --from-literal=access_key_id="&lt;aws_access_key_id&gt;" \
  --from-literal=access_key_secret="&lt;aws_access_key_secret&gt;" \
  --from-literal=region="&lt;aws_region_of_your_bucket&gt;"</programlisting>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-loki-storage-azure_installing-log-storage">
<title>Azure storage</title>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You installed the Loki Operator.</simpara>
</listitem>
<listitem>
<simpara>You installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
<listitem>
<simpara>You created a <link xlink:href="https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction">bucket</link> on Azure.</simpara>
</listitem>
</itemizedlist>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>Create an object storage secret with the name <literal>logging-loki-azure</literal> by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create secret generic logging-loki-azure \
  --from-literal=container="&lt;azure_container_name&gt;" \
  --from-literal=environment="&lt;azure_environment&gt;" \ <co xml:id="CO48-1"/>
  --from-literal=account_name="&lt;azure_account_name&gt;" \
  --from-literal=account_key="&lt;azure_account_key&gt;"</programlisting>
<calloutlist>
<callout arearefs="CO48-1">
<para>Supported environment values are <literal>AzureGlobal</literal>, <literal>AzureChinaCloud</literal>, <literal>AzureGermanCloud</literal>, or <literal>AzureUSGovernment</literal>.</para>
</callout>
</calloutlist>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-loki-storage-gcp_installing-log-storage">
<title>Google Cloud Platform storage</title>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You installed the Loki Operator.</simpara>
</listitem>
<listitem>
<simpara>You installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
<listitem>
<simpara>You created a <link xlink:href="https://cloud.google.com/resource-manager/docs/creating-managing-projects">project</link> on Google Cloud Platform (GCP).</simpara>
</listitem>
<listitem>
<simpara>You created a <link xlink:href="https://cloud.google.com/storage/docs/creating-buckets">bucket</link> in the same project.</simpara>
</listitem>
<listitem>
<simpara>You created a <link xlink:href="https://cloud.google.com/docs/authentication/getting-started#creating_a_service_account">service account</link> in the same project for GCP authentication.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Copy the service account credentials received from GCP into a file called <literal>key.json</literal>.</simpara>
</listitem>
<listitem>
<simpara>Create an object storage secret with the name <literal>logging-loki-gcs</literal> by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create secret generic logging-loki-gcs \
  --from-literal=bucketname="&lt;bucket_name&gt;" \
  --from-file=key.json="&lt;path/to/key.json&gt;"</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="logging-loki-storage-minio_installing-log-storage">
<title>Minio storage</title>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You installed the Loki Operator.</simpara>
</listitem>
<listitem>
<simpara>You installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
<listitem>
<simpara>You have <link xlink:href="https://operator.min.io/">Minio</link> deployed on your cluster.</simpara>
</listitem>
<listitem>
<simpara>You created a <link xlink:href="https://docs.min.io/docs/minio-client-complete-guide.html">bucket</link> on Minio.</simpara>
</listitem>
</itemizedlist>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>Create an object storage secret with the name <literal>logging-loki-minio</literal> by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create secret generic logging-loki-minio \
  --from-literal=bucketnames="&lt;bucket_name&gt;" \
  --from-literal=endpoint="&lt;minio_bucket_endpoint&gt;" \
  --from-literal=access_key_id="&lt;minio_access_key_id&gt;" \
  --from-literal=access_key_secret="&lt;minio_access_key_secret&gt;"</programlisting>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-loki-storage-odf_installing-log-storage">
<title>OpenShift Data Foundation storage</title>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You installed the Loki Operator.</simpara>
</listitem>
<listitem>
<simpara>You installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
<listitem>
<simpara>You deployed <link xlink:href="https://access.redhat.com/documentation/en-us/red_hat_openshift_data_foundation/">OpenShift Data Foundation</link>.</simpara>
</listitem>
<listitem>
<simpara>You configured your OpenShift Data Foundation cluster <link xlink:href="https://access.redhat.com/documentation/en-us/red_hat_openshift_data_foundation/4.15/html/managing_and_allocating_storage_resources/adding-file-and-object-storage-to-an-existing-external-ocs-cluster">for object storage</link>.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create an <literal>ObjectBucketClaim</literal> custom resource in the <literal>openshift-logging</literal> namespace:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: objectbucket.io/v1alpha1
kind: ObjectBucketClaim
metadata:
  name: loki-bucket-odf
  namespace: openshift-logging
spec:
  generateBucketName: loki-bucket-odf
  storageClassName: openshift-storage.noobaa.io</programlisting>
</listitem>
<listitem>
<simpara>Get bucket properties from the associated <literal>ConfigMap</literal> object by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">BUCKET_HOST=$(oc get -n openshift-logging configmap loki-bucket-odf -o jsonpath='{.data.BUCKET_HOST}')
BUCKET_NAME=$(oc get -n openshift-logging configmap loki-bucket-odf -o jsonpath='{.data.BUCKET_NAME}')
BUCKET_PORT=$(oc get -n openshift-logging configmap loki-bucket-odf -o jsonpath='{.data.BUCKET_PORT}')</programlisting>
</listitem>
<listitem>
<simpara>Get bucket access key from the associated secret by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">ACCESS_KEY_ID=$(oc get -n openshift-logging secret loki-bucket-odf -o jsonpath='{.data.AWS_ACCESS_KEY_ID}' | base64 -d)
SECRET_ACCESS_KEY=$(oc get -n openshift-logging secret loki-bucket-odf -o jsonpath='{.data.AWS_SECRET_ACCESS_KEY}' | base64 -d)</programlisting>
</listitem>
<listitem>
<simpara>Create an object storage secret with the name <literal>logging-loki-odf</literal> by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create -n openshift-logging secret generic logging-loki-odf \
--from-literal=access_key_id="&lt;access_key_id&gt;" \
--from-literal=access_key_secret="&lt;secret_access_key&gt;" \
--from-literal=bucketnames="&lt;bucket_name&gt;" \
--from-literal=endpoint="https://&lt;bucket_host&gt;:&lt;bucket_port&gt;"</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="logging-loki-storage-swift_installing-log-storage">
<title>Swift storage</title>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You installed the Loki Operator.</simpara>
</listitem>
<listitem>
<simpara>You installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
<listitem>
<simpara>You created a <link xlink:href="https://docs.openstack.org/newton/user-guide/cli-swift-create-containers.html">bucket</link> on Swift.</simpara>
</listitem>
</itemizedlist>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>Create an object storage secret with the name <literal>logging-loki-swift</literal> by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create secret generic logging-loki-swift \
  --from-literal=auth_url="&lt;swift_auth_url&gt;" \
  --from-literal=username="&lt;swift_usernameclaim&gt;" \
  --from-literal=user_domain_name="&lt;swift_user_domain_name&gt;" \
  --from-literal=user_domain_id="&lt;swift_user_domain_id&gt;" \
  --from-literal=user_id="&lt;swift_user_id&gt;" \
  --from-literal=password="&lt;swift_password&gt;" \
  --from-literal=domain_id="&lt;swift_domain_id&gt;" \
  --from-literal=domain_name="&lt;swift_domain_name&gt;" \
  --from-literal=container_name="&lt;swift_container_name&gt;"</programlisting>
</listitem>
<listitem>
<simpara>You can optionally provide project-specific data, region, or both by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create secret generic logging-loki-swift \
  --from-literal=auth_url="&lt;swift_auth_url&gt;" \
  --from-literal=username="&lt;swift_usernameclaim&gt;" \
  --from-literal=user_domain_name="&lt;swift_user_domain_name&gt;" \
  --from-literal=user_domain_id="&lt;swift_user_domain_id&gt;" \
  --from-literal=user_id="&lt;swift_user_id&gt;" \
  --from-literal=password="&lt;swift_password&gt;" \
  --from-literal=domain_id="&lt;swift_domain_id&gt;" \
  --from-literal=domain_name="&lt;swift_domain_name&gt;" \
  --from-literal=container_name="&lt;swift_container_name&gt;" \
  --from-literal=project_id="&lt;swift_project_id&gt;" \
  --from-literal=project_name="&lt;swift_project_name&gt;" \
  --from-literal=project_domain_id="&lt;swift_project_domain_id&gt;" \
  --from-literal=project_domain_name="&lt;swift_project_domain_name&gt;" \
  --from-literal=region="&lt;swift_region&gt;"</programlisting>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="installing-log-storage-es">
<title>Deploying an Elasticsearch log store</title>
<simpara>You can use the OpenShift Elasticsearch Operator to deploy an internal Elasticsearch log store on your OpenShift Container Platform cluster.</simpara>
<note>
<simpara>The OpenShift Elasticsearch Operator is deprecated and is planned to be removed in a future release. Red&#160;Hat provides bug fixes and support for this feature during the current release lifecycle, but this feature no longer receives enhancements. As an alternative to using the OpenShift Elasticsearch Operator to manage the default log storage, you can use the Loki Operator.</simpara>
</note>
<section xml:id="logging-es-storage-considerations_installing-log-storage">
<title>Storage considerations for Elasticsearch</title>
<simpara>A persistent volume is required for each Elasticsearch deployment configuration. On OpenShift Container Platform this is achieved using persistent volume claims (PVCs).</simpara>
<note>
<simpara>If you use a local volume for persistent storage, do not use a raw block volume, which is described with <literal>volumeMode: block</literal> in the <literal>LocalVolume</literal> object. Elasticsearch cannot use raw block volumes.</simpara>
</note>
<simpara>The OpenShift Elasticsearch Operator names the PVCs using the Elasticsearch resource name.</simpara>
<simpara>Fluentd ships any logs from <emphasis role="strong">systemd journal</emphasis> and <emphasis role="strong">/var/log/containers/*.log</emphasis> to Elasticsearch.</simpara>
<simpara>Elasticsearch requires sufficient memory to perform large merge operations. If it does not have enough memory, it becomes unresponsive. To avoid this problem, evaluate how much application log data you need, and allocate approximately double that amount of free storage capacity.</simpara>
<simpara>By default, when storage capacity is 85% full, Elasticsearch stops allocating new data to the node. At 90%, Elasticsearch attempts to relocate existing shards from that node to other nodes if possible. But if no nodes have a free capacity below 85%, Elasticsearch effectively rejects creating new indices and becomes RED.</simpara>
<note>
<simpara>These low and high watermark values are Elasticsearch defaults in the current release. You can modify these default values. Although the alerts use the same default values, you cannot change these values in the alerts.</simpara>
</note>
</section>
<section xml:id="logging-install-es-operator_installing-log-storage">
<title>Installing the OpenShift Elasticsearch Operator by using the web console</title>
<simpara>The OpenShift Elasticsearch Operator creates and manages the Elasticsearch cluster used by OpenShift Logging.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Elasticsearch is a memory-intensive application. Each Elasticsearch node needs at least 16GB of memory for both memory requests and limits, unless you specify otherwise in the <literal>ClusterLogging</literal> custom resource.</simpara>
<simpara>The initial set of OpenShift Container Platform nodes might not be large enough to support the Elasticsearch cluster. You must add additional nodes to the OpenShift Container Platform cluster to run with the recommended or higher memory, up to a maximum of 64GB for each Elasticsearch node.</simpara>
<simpara>Elasticsearch nodes can operate with a lower memory setting, though this is not recommended for production environments.</simpara>
</listitem>
<listitem>
<simpara>Ensure that you have the necessary persistent storage for Elasticsearch. Note that each Elasticsearch node
requires its own storage volume.</simpara>
<note>
<simpara>If you use a local volume for persistent storage, do not use a raw block volume, which is described with <literal>volumeMode: block</literal> in the <literal>LocalVolume</literal> object. Elasticsearch cannot use raw block volumes.</simpara>
</note>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>In the OpenShift Container Platform web console, click <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">OperatorHub</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">OpenShift Elasticsearch Operator</emphasis> from the list of available Operators, and click <emphasis role="strong">Install</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Ensure that the <emphasis role="strong">All namespaces on the cluster</emphasis> is selected under <emphasis role="strong">Installation mode</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Ensure that <emphasis role="strong">openshift-operators-redhat</emphasis> is selected under <emphasis role="strong">Installed Namespace</emphasis>.</simpara>
<simpara>You must specify the <literal>openshift-operators-redhat</literal> namespace. The <literal>openshift-operators</literal> namespace might contain Community Operators, which are untrusted and could publish a metric with the same name as OpenShift Container Platform metric, which would cause conflicts.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">Enable operator recommended cluster monitoring on this namespace</emphasis>.</simpara>
<simpara>This option sets the <literal>openshift.io/cluster-monitoring: "true"</literal> label in the <literal>Namespace</literal> object. You must select this option to ensure that cluster monitoring scrapes the <literal>openshift-operators-redhat</literal> namespace.</simpara>
</listitem>
<listitem>
<simpara>Select <emphasis role="strong">stable-5.x</emphasis> as the <emphasis role="strong">Update channel</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Select an <emphasis role="strong">Update approval</emphasis> strategy:</simpara>
<itemizedlist>
<listitem>
<simpara>The <emphasis role="strong">Automatic</emphasis> strategy allows Operator Lifecycle Manager (OLM) to automatically update the Operator when a new version is available.</simpara>
</listitem>
<listitem>
<simpara>The <emphasis role="strong">Manual</emphasis> strategy requires a user with appropriate credentials to approve the Operator update.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>Click <emphasis role="strong">Install</emphasis>.</simpara>
</listitem>
</orderedlist>
<orderedlist numeration="arabic">
<title>Verification</title>
<listitem>
<simpara>Verify that the OpenShift Elasticsearch Operator installed by switching to the <emphasis role="strong">Operators</emphasis> → <emphasis role="strong">Installed Operators</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Ensure that <emphasis role="strong">OpenShift Elasticsearch Operator</emphasis> is listed in all projects with a <emphasis role="strong">Status</emphasis> of <emphasis role="strong">Succeeded</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="cluster-logging-deploy-es-cli_installing-log-storage">
<title>Installing the OpenShift Elasticsearch Operator by using the CLI</title>
<simpara>You can use the OpenShift CLI (<literal>oc</literal>) to install the OpenShift Elasticsearch Operator.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Ensure that you have the necessary persistent storage for Elasticsearch. Note that each Elasticsearch node requires its own storage volume.</simpara>
<note>
<simpara>If you use a local volume for persistent storage, do not use a raw block volume, which is described with <literal>volumeMode: block</literal> in the <literal>LocalVolume</literal> object. Elasticsearch cannot use raw block volumes.</simpara>
</note>
<simpara>Elasticsearch is a memory-intensive application. By default, OpenShift Container Platform installs three Elasticsearch nodes with memory requests and limits of 16 GB. This initial set of three OpenShift Container Platform nodes might not have enough memory to run Elasticsearch within your cluster. If you experience memory issues that are related to Elasticsearch, add more Elasticsearch nodes to your cluster rather than increasing the memory on existing nodes.</simpara>
</listitem>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a <literal>Namespace</literal> object as a YAML file:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Namespace
metadata:
  name: openshift-operators-redhat <co xml:id="CO49-1"/>
  annotations:
    openshift.io/node-selector: ""
  labels:
    openshift.io/cluster-monitoring: "true" <co xml:id="CO49-2"/></programlisting>
<calloutlist>
<callout arearefs="CO49-1">
<para>You must specify the <literal>openshift-operators-redhat</literal> namespace. To prevent possible conflicts with metrics, configure the Prometheus Cluster Monitoring stack to scrape metrics from the <literal>openshift-operators-redhat</literal> namespace and not the <literal>openshift-operators</literal> namespace. The <literal>openshift-operators</literal> namespace might contain community Operators, which are untrusted and could publish a metric with the same name as
metric, which would cause conflicts.</para>
</callout>
<callout arearefs="CO49-2">
<para>String. You must specify this label as shown to ensure that cluster monitoring scrapes the <literal>openshift-operators-redhat</literal> namespace.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>Namespace</literal> object by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
<listitem>
<simpara>Create an <literal>OperatorGroup</literal> object  as a YAML file:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: openshift-operators-redhat
  namespace: openshift-operators-redhat <co xml:id="CO50-1"/>
spec: {}</programlisting>
<calloutlist>
<callout arearefs="CO50-1">
<para>You must specify the <literal>openshift-operators-redhat</literal> namespace.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>OperatorGroup</literal> object by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
<listitem>
<simpara>Create a <literal>Subscription</literal> object to subscribe the namespace to the OpenShift Elasticsearch Operator:</simpara>
<formalpara>
<title>Example Subscription</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: elasticsearch-operator
  namespace: openshift-operators-redhat <co xml:id="CO51-1"/>
spec:
  channel: stable-x.y <co xml:id="CO51-2"/>
  installPlanApproval: Automatic <co xml:id="CO51-3"/>
  source: redhat-operators <co xml:id="CO51-4"/>
  sourceNamespace: openshift-marketplace
  name: elasticsearch-operator</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO51-1">
<para>You must specify the <literal>openshift-operators-redhat</literal> namespace.</para>
</callout>
<callout arearefs="CO51-2">
<para>Specify <literal>stable</literal>, or <literal>stable-x.y</literal> as the channel. See the following note.</para>
</callout>
<callout arearefs="CO51-3">
<para><literal>Automatic</literal> allows the Operator Lifecycle Manager (OLM) to automatically update the Operator when a new version is available. <literal>Manual</literal> requires a user with appropriate credentials to approve the Operator update.</para>
</callout>
<callout arearefs="CO51-4">
<para>Specify <literal>redhat-operators</literal>. If your OpenShift Container Platform cluster is installed on a restricted network, also known as a disconnected cluster,
specify the name of the <literal>CatalogSource</literal> object created when you configured the Operator Lifecycle Manager (OLM).</para>
</callout>
</calloutlist>
<note>
<simpara>Specifying <literal>stable</literal> installs the current version of the latest stable release. Using <literal>stable</literal> with <literal>installPlanApproval: "Automatic"</literal> automatically upgrades your Operators to the latest stable major and minor release.</simpara>
<simpara>Specifying <literal>stable-x.y</literal> installs the current minor version of a specific major release. Using <literal>stable-x.y</literal> with <literal>installPlanApproval: "Automatic"</literal> automatically upgrades your Operators to the latest stable minor release within the major release.</simpara>
</note>
</listitem>
<listitem>
<simpara>Apply the subscription by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
<simpara>The OpenShift Elasticsearch Operator is installed to the <literal>openshift-operators-redhat</literal> namespace and copied to each project in the cluster.</simpara>
</listitem>
</orderedlist>
<orderedlist numeration="arabic">
<title>Verification</title>
<listitem>
<simpara>Run the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get csv -n --all-namespaces</programlisting>
</listitem>
<listitem>
<simpara>Observe the output and confirm that pods for the OpenShift Elasticsearch Operator exist in each namespace</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAMESPACE                                          NAME                            DISPLAY                            VERSION          REPLACES                        PHASE
default                                            elasticsearch-operator.v5.8.1   OpenShift Elasticsearch Operator   5.8.1            elasticsearch-operator.v5.8.0   Succeeded
kube-node-lease                                    elasticsearch-operator.v5.8.1   OpenShift Elasticsearch Operator   5.8.1            elasticsearch-operator.v5.8.0   Succeeded
kube-public                                        elasticsearch-operator.v5.8.1   OpenShift Elasticsearch Operator   5.8.1            elasticsearch-operator.v5.8.0   Succeeded
kube-system                                        elasticsearch-operator.v5.8.1   OpenShift Elasticsearch Operator   5.8.1            elasticsearch-operator.v5.8.0   Succeeded
non-destructive-test                               elasticsearch-operator.v5.8.1   OpenShift Elasticsearch Operator   5.8.1            elasticsearch-operator.v5.8.0   Succeeded
openshift-apiserver-operator                       elasticsearch-operator.v5.8.1   OpenShift Elasticsearch Operator   5.8.1            elasticsearch-operator.v5.8.0   Succeeded
openshift-apiserver                                elasticsearch-operator.v5.8.1   OpenShift Elasticsearch Operator   5.8.1            elasticsearch-operator.v5.8.0   Succeeded
...</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</section>
</section>
<section xml:id="configuring-log-storage-cr_installing-log-storage">
<title>Configuring log storage</title>
<simpara>You can configure which log storage type your logging uses by modifying the <literal>ClusterLogging</literal> custom resource (CR).</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator and an internal log store that is either the LokiStack or Elasticsearch.</simpara>
</listitem>
<listitem>
<simpara>You have created a <literal>ClusterLogging</literal> CR.</simpara>
</listitem>
</itemizedlist>
<note>
<simpara>The OpenShift Elasticsearch Operator is deprecated and is planned to be removed in a future release. Red&#160;Hat provides bug fixes and support for this feature during the current release lifecycle, but this feature no longer receives enhancements. As an alternative to using the OpenShift Elasticsearch Operator to manage the default log storage, you can use the Loki Operator.</simpara>
</note>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Modify the <literal>ClusterLogging</literal> CR <literal>logStore</literal> spec:</simpara>
<formalpara>
<title><literal>ClusterLogging</literal> CR example</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
# ...
spec:
# ...
  logStore:
    type: &lt;log_store_type&gt; <co xml:id="CO52-1"/>
    elasticsearch: <co xml:id="CO52-2"/>
      nodeCount: &lt;integer&gt;
      resources: {}
      storage: {}
      redundancyPolicy: &lt;redundancy_type&gt; <co xml:id="CO52-3"/>
    lokistack: <co xml:id="CO52-4"/>
      name: {}
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO52-1">
<para>Specify the log store type. This can be either <literal>lokistack</literal> or <literal>elasticsearch</literal>.</para>
</callout>
<callout arearefs="CO52-2">
<para>Optional configuration options for the Elasticsearch log store.</para>
</callout>
<callout arearefs="CO52-3">
<para>Specify the redundancy type. This value can be <literal>ZeroRedundancy</literal>, <literal>SingleRedundancy</literal>, <literal>MultipleRedundancy</literal>, or <literal>FullRedundancy</literal>.</para>
</callout>
<callout arearefs="CO52-4">
<para>Optional configuration options for LokiStack.</para>
</callout>
</calloutlist>
<formalpara>
<title>Example <literal>ClusterLogging</literal> CR to specify LokiStack as the log store</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
  name: instance
  namespace: openshift-logging
spec:
  managementState: Managed
  logStore:
    type: lokistack
    lokistack:
      name: logging-loki
# ...</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Apply the <literal>ClusterLogging</literal> CR by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
</section>
</section>
<section xml:id="cluster-logging-loki">
<title>Configuring the LokiStack log store</title>

<simpara>In logging documentation, <emphasis>LokiStack</emphasis> refers to the logging supported combination of Loki and web proxy with OpenShift Container Platform authentication integration. LokiStack&#8217;s proxy uses OpenShift Container Platform authentication to enforce multi-tenancy. <emphasis>Loki</emphasis> refers to the log store as either the individual component or an external store.</simpara>
<section xml:id="logging-creating-new-group-cluster-admin-user-role_cluster-logging-loki">
<title>Creating a new group for the cluster-admin user role</title>
<important>
<simpara>Querying application logs for multiple namespaces as a <literal>cluster-admin</literal> user, where the sum total of characters of all of the namespaces in the cluster is greater than 5120, results in the error <literal>Parse error: input size too long (XXXX &gt; 5120)</literal>. For better control over access to logs in LokiStack, make the <literal>cluster-admin</literal> user a member of the <literal>cluster-admin</literal> group. If the <literal>cluster-admin</literal> group does not exist, create it and add the desired users to it.</simpara>
</important>
<simpara>Use the following procedure to create a new group for users with <literal>cluster-admin</literal> permissions.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Enter the following command to create a new group:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm groups new cluster-admin</programlisting>
</listitem>
<listitem>
<simpara>Enter the following command to add the desired user to the <literal>cluster-admin</literal> group:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm groups add-users cluster-admin &lt;username&gt;</programlisting>
</listitem>
<listitem>
<simpara>Enter the following command to add <literal>cluster-admin</literal> user role to the group:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm policy add-cluster-role-to-group cluster-admin cluster-admin</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="logging-loki-restart-hardening_cluster-logging-loki">
<title>LokiStack behavior during cluster restarts</title>
<simpara>In logging version 5.8 and newer versions, when an OpenShift Container Platform cluster is restarted, LokiStack ingestion and the query path continue to operate within the available CPU and memory resources available for the node. This means that there is no downtime for the LokiStack during OpenShift Container Platform cluster updates. This behavior is achieved by using <literal>PodDisruptionBudget</literal> resources. The Loki Operator provisions <literal>PodDisruptionBudget</literal> resources for Loki, which determine the minimum number of pods that must be available per component to ensure normal operations under certain conditions.</simpara>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://kubernetes.io/docs/concepts/workloads/pods/disruptions/#pod-disruption-budgets">Pod disruption budgets Kubernetes documentation</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-loki-reliability-hardening_cluster-logging-loki">
<title>Configuring Loki to tolerate node failure</title>
<simpara>In the logging 5.8 and later versions, the Loki Operator supports setting pod anti-affinity rules to request that pods of the same component are scheduled on different available nodes in the cluster.</simpara>
<simpara>Affinity is a property of pods that controls the nodes on which they prefer to be scheduled. Anti-affinity is a property of pods
that prevents a pod from being scheduled on a node.</simpara>
<simpara>In OpenShift Container Platform, <emphasis>pod affinity</emphasis> and <emphasis>pod anti-affinity</emphasis> allow you to constrain which nodes your pod is eligible to be scheduled on based on the key-value labels on other pods.</simpara>
<simpara>The Operator sets default, preferred <literal>podAntiAffinity</literal> rules for all Loki components, which includes the <literal>compactor</literal>, <literal>distributor</literal>, <literal>gateway</literal>, <literal>indexGateway</literal>, <literal>ingester</literal>, <literal>querier</literal>, <literal>queryFrontend</literal>, and <literal>ruler</literal> components.</simpara>
<simpara>You can override the preferred <literal>podAntiAffinity</literal> settings for Loki components by configuring required settings in the <literal>requiredDuringSchedulingIgnoredDuringExecution</literal> field:</simpara>
<formalpara>
<title>Example user settings for the ingester component</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: logging-loki
  namespace: openshift-logging
spec:
# ...
  template:
    ingester:
      podAntiAffinity:
      # ...
        requiredDuringSchedulingIgnoredDuringExecution: <co xml:id="CO53-1"/>
        - labelSelector:
            matchLabels: <co xml:id="CO53-2"/>
              app.kubernetes.io/component: ingester
          topologyKey: kubernetes.io/hostname
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO53-1">
<para>The stanza to define a required rule.</para>
</callout>
<callout arearefs="CO53-2">
<para>The key-value pair (label) that must be matched to apply the rule.</para>
</callout>
</calloutlist>
</section>
<section xml:id="logging-loki-pod-placement_cluster-logging-loki">
<title>Loki pod placement</title>
<simpara>You can control which nodes the Loki pods run on, and prevent other workloads from using those nodes, by using tolerations or node selectors on the pods.</simpara>
<simpara>You can apply tolerations to the log store pods with the LokiStack custom resource (CR) and apply taints to a node with the node specification. A taint on a node is a <literal>key:value</literal> pair that instructs the node to repel all pods that do not allow the taint. Using a specific <literal>key:value</literal> pair that is not on other pods ensures that only the log store pods can run on that node.</simpara>
<formalpara>
<title>Example LokiStack with node selectors</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: logging-loki
  namespace: openshift-logging
spec:
# ...
  template:
    compactor: <co xml:id="CO54-1"/>
      nodeSelector:
        node-role.kubernetes.io/infra: "" <co xml:id="CO54-2"/>
    distributor:
      nodeSelector:
        node-role.kubernetes.io/infra: ""
    gateway:
      nodeSelector:
        node-role.kubernetes.io/infra: ""
    indexGateway:
      nodeSelector:
        node-role.kubernetes.io/infra: ""
    ingester:
      nodeSelector:
        node-role.kubernetes.io/infra: ""
    querier:
      nodeSelector:
        node-role.kubernetes.io/infra: ""
    queryFrontend:
      nodeSelector:
        node-role.kubernetes.io/infra: ""
    ruler:
      nodeSelector:
        node-role.kubernetes.io/infra: ""
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO54-1">
<para>Specifies the component pod type that applies to the node selector.</para>
</callout>
<callout arearefs="CO54-2">
<para>Specifies the pods that are moved to nodes containing the defined label.</para>
</callout>
</calloutlist>
<simpara>In the previous example configuration, all Loki pods are moved to nodes containing the <literal>node-role.kubernetes.io/infra: ""</literal> label.</simpara>
<formalpara>
<title>Example LokiStack CR with node selectors and tolerations</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: logging-loki
  namespace: openshift-logging
spec:
# ...
  template:
    compactor:
      nodeSelector:
        node-role.kubernetes.io/infra: ""
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/infra
        value: reserved
      - effect: NoExecute
        key: node-role.kubernetes.io/infra
        value: reserved
    distributor:
      nodeSelector:
        node-role.kubernetes.io/infra: ""
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/infra
        value: reserved
      - effect: NoExecute
        key: node-role.kubernetes.io/infra
        value: reserved
      nodeSelector:
        node-role.kubernetes.io/infra: ""
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/infra
        value: reserved
      - effect: NoExecute
        key: node-role.kubernetes.io/infra
        value: reserved
    indexGateway:
      nodeSelector:
        node-role.kubernetes.io/infra: ""
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/infra
        value: reserved
      - effect: NoExecute
        key: node-role.kubernetes.io/infra
        value: reserved
    ingester:
      nodeSelector:
        node-role.kubernetes.io/infra: ""
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/infra
        value: reserved
      - effect: NoExecute
        key: node-role.kubernetes.io/infra
        value: reserved
    querier:
      nodeSelector:
        node-role.kubernetes.io/infra: ""
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/infra
        value: reserved
      - effect: NoExecute
        key: node-role.kubernetes.io/infra
        value: reserved
    queryFrontend:
      nodeSelector:
        node-role.kubernetes.io/infra: ""
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/infra
        value: reserved
      - effect: NoExecute
        key: node-role.kubernetes.io/infra
        value: reserved
    ruler:
      nodeSelector:
        node-role.kubernetes.io/infra: ""
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/infra
        value: reserved
      - effect: NoExecute
        key: node-role.kubernetes.io/infra
        value: reserved
    gateway:
      nodeSelector:
        node-role.kubernetes.io/infra: ""
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/infra
        value: reserved
      - effect: NoExecute
        key: node-role.kubernetes.io/infra
        value: reserved
# ...</programlisting>
</para>
</formalpara>
<simpara>To configure the <literal>nodeSelector</literal> and <literal>tolerations</literal> fields of the LokiStack (CR), you can use the <literal role="command">oc explain</literal> command to view the description and fields for a particular resource:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc explain lokistack.spec.template</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="text" linenumbering="unnumbered">KIND:     LokiStack
VERSION:  loki.grafana.com/v1

RESOURCE: template &lt;Object&gt;

DESCRIPTION:
     Template defines the resource/limits/tolerations/nodeselectors per
     component

FIELDS:
   compactor	&lt;Object&gt;
     Compactor defines the compaction component spec.

   distributor	&lt;Object&gt;
     Distributor defines the distributor component spec.
...</programlisting>
</para>
</formalpara>
<simpara>For more detailed information, you can add a specific field:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc explain lokistack.spec.template.compactor</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="text" linenumbering="unnumbered">KIND:     LokiStack
VERSION:  loki.grafana.com/v1

RESOURCE: compactor &lt;Object&gt;

DESCRIPTION:
     Compactor defines the compaction component spec.

FIELDS:
   nodeSelector	&lt;map[string]string&gt;
     NodeSelector defines the labels required by a node to schedule the
     component onto it.
...</programlisting>
</para>
</formalpara>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podantiaffinity-v1-core"><literal>PodAntiAffinity</literal> v1 core Kubernetes documentation</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity">Assigning Pods to Nodes Kubernetes documentation</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/nodes/#nodes-scheduler-pod-affinity">Placing pods relative to other pods using affinity and anti-affinity rules</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-loki-zone-aware-rep_cluster-logging-loki">
<title>Zone aware data replication</title>
<simpara>In the logging 5.8 and later versions, the Loki Operator offers support for zone-aware data replication through pod topology spread constraints. Enabling this feature enhances reliability and safeguards against log loss in the event of a single zone failure. When configuring the deployment size as <literal>1x.extra.small</literal>, <literal>1x.small</literal>, or <literal>1x.medium,</literal> the <literal>replication.factor</literal> field is automatically set to 2.</simpara>
<simpara>To ensure proper replication, you need to have at least as many availability zones as the replication factor specifies. While it is possible to have more availability zones than the replication factor, having fewer zones can lead to write failures. Each zone should host an equal number of instances for optimal operation.</simpara>
<formalpara>
<title>Example LokiStack CR with zone replication enabled</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
 name: logging-loki
 namespace: openshift-logging
spec:
 replicationFactor: 2 <co xml:id="CO55-1"/>
 replication:
   factor: 2 <co xml:id="CO55-2"/>
   zones:
   -  maxSkew: 1 <co xml:id="CO55-3"/>
      topologyKey: topology.kubernetes.io/zone <co xml:id="CO55-4"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO55-1">
<para>Deprecated field, values entered are overwritten by <literal>replication.factor</literal>.</para>
</callout>
<callout arearefs="CO55-2">
<para>This value is automatically set when deployment size is selected at setup.</para>
</callout>
<callout arearefs="CO55-3">
<para>The maximum difference in number of pods between any two topology domains. The default is 1, and you cannot specify a value of 0.</para>
</callout>
<callout arearefs="CO55-4">
<para>Defines zones in the form of a topology key that corresponds to a node label.</para>
</callout>
</calloutlist>
<section xml:id="logging-loki-zone-fail-recovery_cluster-logging-loki">
<title>Recovering Loki pods from failed zones</title>
<simpara>In OpenShift Container Platform a zone failure happens when specific availability zone resources become inaccessible. Availability zones are isolated areas within a cloud provider&#8217;s data center, aimed at enhancing redundancy and fault tolerance. If your OpenShift Container Platform cluster isn&#8217;t configured to handle this, a zone failure can lead to service or data loss.</simpara>
<simpara>Loki pods are part of a <link xlink:href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/">StatefulSet</link>, and they come with Persistent Volume Claims (PVCs) provisioned by a <literal>StorageClass</literal> object. Each Loki pod and its PVCs reside in the same zone. When a zone failure occurs in a cluster, the StatefulSet controller automatically attempts to recover the affected pods in the failed zone.</simpara>
<warning>
<simpara>The following procedure will delete the PVCs in the failed zone, and all data contained therein.  To avoid complete data loss the replication factor field of the <literal>LokiStack</literal> CR should always be set to a value greater than 1 to ensure that Loki is replicating.</simpara>
</warning>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Logging version 5.8 or later.</simpara>
</listitem>
<listitem>
<simpara>Verify your <literal>LokiStack</literal> CR has a replication factor greater than 1.</simpara>
</listitem>
<listitem>
<simpara>Zone failure detected by the control plane, and nodes in the failed zone are marked by cloud provider integration.</simpara>
</listitem>
</itemizedlist>
<simpara>The StatefulSet controller automatically attempts to reschedule pods in a failed zone. Because the associated PVCs are also in the failed zone, automatic rescheduling to a different zone does not work. You must manually delete the PVCs in the failed zone to allow successful re-creation of the stateful Loki Pod and its provisioned PVC in the new zone.</simpara>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>List the pods in <literal>Pending</literal> status by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">oc get pods --field-selector status.phase==Pending -n openshift-logging</programlisting>
<formalpara>
<title>Example <literal>oc get pods</literal> output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                           READY   STATUS    RESTARTS   AGE <co xml:id="CO56-1"/>
logging-loki-index-gateway-1   0/1     Pending   0          17m
logging-loki-ingester-1        0/1     Pending   0          16m
logging-loki-ruler-1           0/1     Pending   0          16m</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO56-1">
<para>These pods are in <literal>Pending</literal> status because their corresponding PVCs are in the failed zone.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>List the PVCs in <literal>Pending</literal> status by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">oc get pvc -o=json -n openshift-logging | jq '.items[] | select(.status.phase == "Pending") | .metadata.name' -r</programlisting>
<formalpara>
<title>Example <literal>oc get pvc</literal> output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">storage-logging-loki-index-gateway-1
storage-logging-loki-ingester-1
wal-logging-loki-ingester-1
storage-logging-loki-ruler-1
wal-logging-loki-ruler-1</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Delete the PVC(s) for a pod by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">oc delete pvc __&lt;pvc_name&gt;__  -n openshift-logging</programlisting>
</listitem>
<listitem>
<simpara>Then delete the pod(s) by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">oc delete pod __&lt;pod_name&gt;__  -n openshift-logging</programlisting>
</listitem>
</orderedlist>
<simpara>Once these objects have been successfully deleted, they should automatically be rescheduled in an available zone.</simpara>
<section xml:id="logging-loki-zone-fail-term-state_cluster-logging-loki">
<title>Troubleshooting PVC in a terminating state</title>
<simpara>The PVCs might hang in the terminating state without being deleted, if PVC metadata finalizers are set to <literal>kubernetes.io/pv-protection</literal>. Removing the finalizers should allow the PVCs to delete successfully.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Remove the finalizer for each PVC by running the command below, then retry deletion.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">oc patch pvc __&lt;pvc_name&gt;__ -p '{"metadata":{"finalizers":null}}' -n openshift-logging</programlisting>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/#spread-constraint-definition">Topology spread constraints Kubernetes documentation</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://kubernetes.io/docs/setup/best-practices/multiple-zones/#storage-access-for-zones">Kubernetes storage documentation</link>.</simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/nodes/#nodes-scheduler-pod-topology-spread-constraints-configuring">Controlling pod placement by using pod topology spread constraints</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="logging-loki-log-access_cluster-logging-loki">
<title>Fine grained access for Loki logs</title>
<simpara>In logging 5.8 and later, the Red Hat OpenShift Logging Operator does not grant all users access to logs by default. As an administrator, you must configure your users' access unless the Operator was upgraded and prior configurations are in place. Depending on your configuration and need, you can configure fine grain access to logs using the following:</simpara>
<itemizedlist>
<listitem>
<simpara>Cluster wide policies</simpara>
</listitem>
<listitem>
<simpara>Namespace scoped policies</simpara>
</listitem>
<listitem>
<simpara>Creation of custom admin groups</simpara>
</listitem>
</itemizedlist>
<simpara>As an administrator, you need to create the role bindings and cluster role bindings appropriate for your deployment. The Red Hat OpenShift Logging Operator provides the following cluster roles:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>cluster-logging-application-view</literal> grants permission to read application logs.</simpara>
</listitem>
<listitem>
<simpara><literal>cluster-logging-infrastructure-view</literal> grants permission to read infrastructure logs.</simpara>
</listitem>
<listitem>
<simpara><literal>cluster-logging-audit-view</literal> grants permission to read audit logs.</simpara>
</listitem>
</itemizedlist>
<simpara>If you have upgraded from a prior version, an additional cluster role <literal>logging-application-logs-reader</literal> and associated cluster role binding <literal>logging-all-authenticated-application-logs-reader</literal> provide backward compatibility, allowing any authenticated user read access in their namespaces.</simpara>
<note>
<simpara>Users with access by namespace must provide a namespace when querying application logs.</simpara>
</note>
<section xml:id="_cluster-wide-access">
<title>Cluster wide access</title>
<simpara>Cluster role binding resources reference cluster roles, and set permissions cluster wide.</simpara>
<formalpara>
<title>Example ClusterRoleBinding</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: logging-all-application-logs-reader
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-logging-application-view <co xml:id="CO57-1"/>
subjects: <co xml:id="CO57-2"/>
- kind: Group
  name: system:authenticated
  apiGroup: rbac.authorization.k8s.io</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO57-1">
<para>Additional <literal>ClusterRoles</literal> are <literal>cluster-logging-infrastructure-view</literal>, and <literal>cluster-logging-audit-view</literal>.</para>
</callout>
<callout arearefs="CO57-2">
<para>Specifies the users or groups this object applies to.</para>
</callout>
</calloutlist>
</section>
<section xml:id="_namespaced-access">
<title>Namespaced access</title>
<simpara><literal>RoleBinding</literal> resources can be used with <literal>ClusterRole</literal> objects to define the namespace a user or group has access to logs for.</simpara>
<formalpara>
<title>Example RoleBinding</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: allow-read-logs
  namespace: log-test-0 <co xml:id="CO58-1"/>
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-logging-application-view
subjects:
- kind: User
  apiGroup: rbac.authorization.k8s.io
  name: testuser-0</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO58-1">
<para>Specifies the namespace this <literal>RoleBinding</literal> applies to.</para>
</callout>
</calloutlist>
</section>
<section xml:id="_custom-admin-group-access">
<title>Custom admin group access</title>
<simpara>If you have a large deployment with a number of users who require broader permissions, you can create a custom group using the <literal>adminGroup</literal> field. Users who are members of any group specified in the <literal>adminGroups</literal> field of the <literal>LokiStack</literal> CR are considered admins. Admin users have access to all application logs in all namespaces, if they also get assigned the <literal>cluster-logging-application-view</literal> role.</simpara>
<formalpara>
<title>Example LokiStack CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: logging-loki
  namespace: openshift-logging
spec:
  tenants:
    mode: openshift-logging <co xml:id="CO59-1"/>
    openshift:
      adminGroups: <co xml:id="CO59-2"/>
      - cluster-admin
      - custom-admin-group <co xml:id="CO59-3"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO59-1">
<para>Custom admin groups are only available in this mode.</para>
</callout>
<callout arearefs="CO59-2">
<para>Entering an empty list <literal>[]</literal> value for this field disables admin groups.</para>
</callout>
<callout arearefs="CO59-3">
<para>Overrides the default groups (<literal>system:cluster-admins</literal>, <literal>cluster-admin</literal>, <literal>dedicated-admin</literal>)</para>
</callout>
</calloutlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/authentication_and_authorization/#">Using RBAC to define and apply permissions</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="logging-loki-retention_cluster-logging-loki">
<title>Enabling stream-based retention with Loki</title>
<simpara>With Logging version 5.6 and higher, you can configure retention policies based on log streams. Rules for these may be set globally, per tenant, or both. If you configure both, tenant rules apply before global rules.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>To enable stream-based retention, create a <literal>LokiStack</literal> custom resource (CR):</simpara>
<formalpara>
<title>Example global stream-based retention</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: logging-loki
  namespace: openshift-logging
spec:
  limits:
    global: <co xml:id="CO60-1"/>
      retention: <co xml:id="CO60-2"/>
        days: 20
        streams:
        - days: 4
          priority: 1
          selector: '{kubernetes_namespace_name=~"test.+"}' <co xml:id="CO60-3"/>
        - days: 1
          priority: 1
          selector: '{log_type="infrastructure"}'
  managementState: Managed
  replicationFactor: 1
  size: 1x.small
  storage:
    schemas:
    - effectiveDate: "2020-10-11"
      version: v11
    secret:
      name: logging-loki-s3
      type: aws
  storageClassName: standard
  tenants:
    mode: openshift-logging</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO60-1">
<para>Sets retention policy for all log streams. <emphasis role="strong">Note: This field does not impact the retention period for stored logs in object storage.</emphasis></para>
</callout>
<callout arearefs="CO60-2">
<para>Retention is enabled in the cluster when this block is added to the CR.</para>
</callout>
<callout arearefs="CO60-3">
<para>Contains the <link xlink:href="https://grafana.com/docs/loki/latest/logql/query_examples/#query-examples">LogQL query</link> used to define the log stream.</para>
</callout>
</calloutlist>
<formalpara>
<title>Example per-tenant stream-based retention</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: logging-loki
  namespace: openshift-logging
spec:
  limits:
    global:
      retention:
        days: 20
    tenants: <co xml:id="CO61-1"/>
      application:
        retention:
          days: 1
          streams:
            - days: 4
              selector: '{kubernetes_namespace_name=~"test.+"}' <co xml:id="CO61-2"/>
      infrastructure:
        retention:
          days: 5
          streams:
            - days: 1
              selector: '{kubernetes_namespace_name=~"openshift-cluster.+"}'
  managementState: Managed
  replicationFactor: 1
  size: 1x.small
  storage:
    schemas:
    - effectiveDate: "2020-10-11"
      version: v11
    secret:
      name: logging-loki-s3
      type: aws
  storageClassName: standard
  tenants:
    mode: openshift-logging</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO61-1">
<para>Sets retention policy by tenant. Valid tenant types are <literal>application</literal>, <literal>audit</literal>, and <literal>infrastructure</literal>.</para>
</callout>
<callout arearefs="CO61-2">
<para>Contains the <link xlink:href="https://grafana.com/docs/loki/latest/logql/query_examples/#query-examples">LogQL query</link> used to define the log stream.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>LokiStack</literal> CR:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
<note>
<simpara>This is not for managing the retention for stored logs. Global retention periods for stored logs to a supported maximum of 30 days is configured with your object storage.</simpara>
</note>
</section>
<section xml:id="loki-rate-limit-errors_cluster-logging-loki">
<title>Troubleshooting Loki rate limit errors</title>
<simpara>If the Log Forwarder API forwards a large block of messages that exceeds the rate limit to Loki, Loki generates rate limit (<literal>429</literal>) errors.</simpara>
<simpara>These errors can occur during normal operation. For example, when adding the logging to a cluster that already has some logs, rate limit errors might occur while the logging tries to ingest all of the existing log entries. In this case, if the rate of addition of new logs is less than the total rate limit, the historical data is eventually ingested, and the rate limit errors are resolved without requiring user intervention.</simpara>
<simpara>In cases where the rate limit errors continue to occur, you can fix the issue by modifying the <literal>LokiStack</literal> custom resource (CR).</simpara>
<important>
<simpara>The <literal>LokiStack</literal> CR is not available on Grafana-hosted Loki. This topic does not apply to Grafana-hosted Loki servers.</simpara>
</important>
<itemizedlist>
<title>Conditions</title>
<listitem>
<simpara>The Log Forwarder API is configured to forward logs to Loki.</simpara>
</listitem>
<listitem>
<simpara>Your system sends a block of messages that is larger than 2 MB to Loki. For example:</simpara>
<programlisting language="text" linenumbering="unnumbered">"values":[["1630410392689800468","{\"kind\":\"Event\",\"apiVersion\":\
.......
......
......
......
\"received_at\":\"2021-08-31T11:46:32.800278+00:00\",\"version\":\"1.7.4 1.6.0\"}},\"@timestamp\":\"2021-08-31T11:46:32.799692+00:00\",\"viaq_index_name\":\"audit-write\",\"viaq_msg_id\":\"MzFjYjJkZjItNjY0MC00YWU4LWIwMTEtNGNmM2E5ZmViMGU4\",\"log_type\":\"audit\"}"]]}]}</programlisting>
</listitem>
<listitem>
<simpara>After you enter <literal>oc logs -n openshift-logging -l component=collector</literal>, the collector logs in your cluster show a line containing one of the following error messages:</simpara>
<programlisting language="text" linenumbering="unnumbered">429 Too Many Requests Ingestion rate limit exceeded</programlisting>
<formalpara>
<title>Example Vector error message</title>
<para>
<programlisting language="text" linenumbering="unnumbered">2023-08-25T16:08:49.301780Z  WARN sink{component_kind="sink" component_id=default_loki_infra component_type=loki component_name=default_loki_infra}: vector::sinks::util::retries: Retrying after error. error=Server responded with an error: 429 Too Many Requests internal_log_rate_limit=true</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example Fluentd error message</title>
<para>
<programlisting language="text" linenumbering="unnumbered">2023-08-30 14:52:15 +0000 [warn]: [default_loki_infra] failed to flush the buffer. retry_times=2 next_retry_time=2023-08-30 14:52:19 +0000 chunk="604251225bf5378ed1567231a1c03b8b" error_class=Fluent::Plugin::LokiOutput::LogPostError error="429 Too Many Requests Ingestion rate limit exceeded for user infrastructure (limit: 4194304 bytes/sec) while attempting to ingest '4082' lines totaling '7820025' bytes, reduce log volume or contact your Loki administrator to see if the limit can be increased\n"</programlisting>
</para>
</formalpara>
<simpara>The error is also visible on the receiving end. For example, in the LokiStack ingester pod:</simpara>
<formalpara>
<title>Example Loki ingester error message</title>
<para>
<programlisting language="text" linenumbering="unnumbered">level=warn ts=2023-08-30T14:57:34.155592243Z caller=grpc_logging.go:43 duration=1.434942ms method=/logproto.Pusher/Push err="rpc error: code = Code(429) desc = entry with timestamp 2023-08-30 14:57:32.012778399 +0000 UTC ignored, reason: 'Per stream rate limit exceeded (limit: 3MB/sec) while attempting to ingest for stream</programlisting>
</para>
</formalpara>
</listitem>
</itemizedlist>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>Update the <literal>ingestionBurstSize</literal> and <literal>ingestionRate</literal> fields in the <literal>LokiStack</literal> CR:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: logging-loki
  namespace: openshift-logging
spec:
  limits:
    global:
      ingestion:
        ingestionBurstSize: 16 <co xml:id="CO62-1"/>
        ingestionRate: 8 <co xml:id="CO62-2"/>
# ...</programlisting>
<calloutlist>
<callout arearefs="CO62-1">
<para>The <literal>ingestionBurstSize</literal> field defines the maximum local rate-limited sample size per distributor replica in MB. This value is a hard limit. Set this value to at least the maximum logs size expected in a single push request. Single requests that are larger than the <literal>ingestionBurstSize</literal> value are not permitted.</para>
</callout>
<callout arearefs="CO62-2">
<para>The <literal>ingestionRate</literal> field is a soft limit on the maximum amount of ingested samples per second in MB. Rate limit errors occur if the rate of logs exceeds the limit, but the collector retries sending the logs. As long as the total average is lower than the limit, the system recovers and errors are resolved without user intervention.</para>
</callout>
</calloutlist>
</listitem>
</itemizedlist>
</section>
<section xml:id="additional-resources_cluster-logging-loki" role="_additional-resources">
<title>Additional Resources</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://grafana.com/docs/loki/latest/get-started/components/">Loki components documentation</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://grafana.com/docs/loki/latest/logql/">Loki Query Language (LogQL) documentation</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://loki-operator.dev/docs/howto_connect_grafana.md/">Grafana Dashboard documentation</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://loki-operator.dev/docs/object_storage.md/">Loki Object Storage documentation</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://loki-operator.dev/docs/api.md/#loki-grafana-com-v1-IngestionLimitSpec">Loki Operator <literal>IngestionLimitSpec</literal> documentation</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://grafana.com/docs/loki/latest/operations/storage/schema/#changing-the-schema">Loki Storage Schema documentation</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="logging-config-es-store">
<title>Configuring the Elasticsearch log store</title>

<simpara>You can use Elasticsearch 6 to store and organize log data.</simpara>
<simpara>You can make modifications to your log store, including:</simpara>
<itemizedlist>
<listitem>
<simpara>Storage for your Elasticsearch cluster</simpara>
</listitem>
<listitem>
<simpara>Shard replication across data nodes in the cluster, from full replication to no replication</simpara>
</listitem>
<listitem>
<simpara>External access to Elasticsearch data</simpara>
</listitem>
</itemizedlist>
<section xml:id="configuring-log-storage-cr_logging-config-es-store">
<title>Configuring log storage</title>
<simpara>You can configure which log storage type your logging uses by modifying the <literal>ClusterLogging</literal> custom resource (CR).</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator and an internal log store that is either the LokiStack or Elasticsearch.</simpara>
</listitem>
<listitem>
<simpara>You have created a <literal>ClusterLogging</literal> CR.</simpara>
</listitem>
</itemizedlist>
<note>
<simpara>The OpenShift Elasticsearch Operator is deprecated and is planned to be removed in a future release. Red&#160;Hat provides bug fixes and support for this feature during the current release lifecycle, but this feature no longer receives enhancements. As an alternative to using the OpenShift Elasticsearch Operator to manage the default log storage, you can use the Loki Operator.</simpara>
</note>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Modify the <literal>ClusterLogging</literal> CR <literal>logStore</literal> spec:</simpara>
<formalpara>
<title><literal>ClusterLogging</literal> CR example</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
# ...
spec:
# ...
  logStore:
    type: &lt;log_store_type&gt; <co xml:id="CO63-1"/>
    elasticsearch: <co xml:id="CO63-2"/>
      nodeCount: &lt;integer&gt;
      resources: {}
      storage: {}
      redundancyPolicy: &lt;redundancy_type&gt; <co xml:id="CO63-3"/>
    lokistack: <co xml:id="CO63-4"/>
      name: {}
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO63-1">
<para>Specify the log store type. This can be either <literal>lokistack</literal> or <literal>elasticsearch</literal>.</para>
</callout>
<callout arearefs="CO63-2">
<para>Optional configuration options for the Elasticsearch log store.</para>
</callout>
<callout arearefs="CO63-3">
<para>Specify the redundancy type. This value can be <literal>ZeroRedundancy</literal>, <literal>SingleRedundancy</literal>, <literal>MultipleRedundancy</literal>, or <literal>FullRedundancy</literal>.</para>
</callout>
<callout arearefs="CO63-4">
<para>Optional configuration options for LokiStack.</para>
</callout>
</calloutlist>
<formalpara>
<title>Example <literal>ClusterLogging</literal> CR to specify LokiStack as the log store</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
  name: instance
  namespace: openshift-logging
spec:
  managementState: Managed
  logStore:
    type: lokistack
    lokistack:
      name: logging-loki
# ...</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Apply the <literal>ClusterLogging</literal> CR by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="cluster-logging-elasticsearch-audit_logging-config-es-store">
<title>Forwarding audit logs to the log store</title>
<simpara>By default, OpenShift Logging does not store audit logs in the internal OpenShift Container Platform Elasticsearch log store. You can send audit logs to this log store so, for example, you can view them in Kibana.</simpara>
<simpara>To send the audit logs to the default internal Elasticsearch log store, for example to view the audit logs in Kibana, you must use the Log Forwarding API.</simpara>
<important>
<simpara>The internal OpenShift Container Platform Elasticsearch log store does not provide secure storage for audit logs. Verify that the system to which you forward audit logs complies with your organizational and governmental regulations and is properly secured. Logging does not comply with those regulations.</simpara>
</important>
<formalpara>
<title>Procedure</title>
<para>To use the Log Forwarding API to forward audit logs to the internal Elasticsearch instance:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Create or edit a YAML file that defines the <literal>ClusterLogForwarder</literal> CR object:</simpara>
<itemizedlist>
<listitem>
<simpara>Create a CR to send all log types to the internal Elasticsearch instance. You can use the following example without making any changes:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging
spec:
  pipelines: <co xml:id="CO64-1"/>
  - name: all-to-default
    inputRefs:
    - infrastructure
    - application
    - audit
    outputRefs:
    - default</programlisting>
<calloutlist>
<callout arearefs="CO64-1">
<para>A pipeline defines the type of logs to forward using the specified output. The default output forwards logs to the internal Elasticsearch instance.</para>
</callout>
</calloutlist>
<note>
<simpara>You must specify all three types of logs in the pipeline: application, infrastructure, and audit. If you do not specify a log type, those logs are not stored and will be lost.</simpara>
</note>
</listitem>
<listitem>
<simpara>If you have an existing <literal>ClusterLogForwarder</literal> CR, add a pipeline to the default output for the audit logs. You do not need to define the default output. For example:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: "logging.openshift.io/v1"
kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging
spec:
  outputs:
   - name: elasticsearch-insecure
     type: "elasticsearch"
     url: http://elasticsearch-insecure.messaging.svc.cluster.local
     insecure: true
   - name: elasticsearch-secure
     type: "elasticsearch"
     url: https://elasticsearch-secure.messaging.svc.cluster.local
     secret:
       name: es-audit
   - name: secureforward-offcluster
     type: "fluentdForward"
     url: https://secureforward.offcluster.com:24224
     secret:
       name: secureforward
  pipelines:
   - name: container-logs
     inputRefs:
     - application
     outputRefs:
     - secureforward-offcluster
   - name: infra-logs
     inputRefs:
     - infrastructure
     outputRefs:
     - elasticsearch-insecure
   - name: audit-logs
     inputRefs:
     - audit
     outputRefs:
     - elasticsearch-secure
     - default <co xml:id="CO65-1"/></programlisting>
<calloutlist>
<callout arearefs="CO65-1">
<para>This pipeline sends the audit logs to the internal Elasticsearch instance in addition to an external instance.</para>
</callout>
</calloutlist>
</listitem>
</itemizedlist>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link linkend="log-forwarding">About log collection and forwarding</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="cluster-logging-elasticsearch-retention_logging-config-es-store">
<title>Configuring log retention time</title>
<simpara>You can configure a <emphasis>retention policy</emphasis> that specifies how long the default Elasticsearch log store keeps indices for each of the three log sources: infrastructure logs, application logs, and audit logs.</simpara>
<simpara>To configure the retention policy, you set a <literal>maxAge</literal> parameter for each log source in the <literal>ClusterLogging</literal> custom resource (CR). The CR applies these values to the Elasticsearch rollover schedule, which determines when Elasticsearch deletes the rolled-over indices.</simpara>
<simpara>Elasticsearch rolls over an index, moving the current index and creating a new index, when an index matches any of the following conditions:</simpara>
<itemizedlist>
<listitem>
<simpara>The index is older than the <literal>rollover.maxAge</literal> value in the <literal>Elasticsearch</literal> CR.</simpara>
</listitem>
<listitem>
<simpara>The index size is greater than 40 GB × the number of primary shards.</simpara>
</listitem>
<listitem>
<simpara>The index doc count is greater than 40960 KB × the number of primary shards.</simpara>
</listitem>
</itemizedlist>
<simpara>Elasticsearch deletes the rolled-over indices based on the retention policy you configure. If you do not create a retention policy for any log sources, logs are deleted after seven days by default.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>The Red Hat OpenShift Logging Operator and the OpenShift Elasticsearch Operator must be installed.</simpara>
</listitem>
</itemizedlist>
<formalpara>
<title>Procedure</title>
<para>To configure the log retention time:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Edit the <literal>ClusterLogging</literal> CR to add or modify the <literal>retentionPolicy</literal> parameter:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
...
spec:
  managementState: "Managed"
  logStore:
    type: "elasticsearch"
    retentionPolicy: <co xml:id="CO66-1"/>
      application:
        maxAge: 1d
      infra:
        maxAge: 7d
      audit:
        maxAge: 7d
    elasticsearch:
      nodeCount: 3
...</programlisting>
<calloutlist>
<callout arearefs="CO66-1">
<para>Specify the time that Elasticsearch should retain each log source. Enter an integer and a time designation: weeks(w), hours(h/H), minutes(m) and seconds(s). For example, <literal>1d</literal> for one day. Logs older than the <literal>maxAge</literal> are deleted. By default, logs are retained for seven days.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>You can verify the settings in the <literal>Elasticsearch</literal> custom resource (CR).</simpara>
<simpara>For example, the Red Hat OpenShift Logging Operator updated the following <literal>Elasticsearch</literal> CR to configure a retention policy that includes settings to roll over active indices for the infrastructure logs every eight hours and the rolled-over indices are deleted seven days after rollover. OpenShift Container Platform checks every 15 minutes to determine if the indices need to be rolled over.</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: "logging.openshift.io/v1"
kind: "Elasticsearch"
metadata:
  name: "elasticsearch"
spec:
...
  indexManagement:
    policies: <co xml:id="CO67-1"/>
      - name: infra-policy
        phases:
          delete:
            minAge: 7d <co xml:id="CO67-2"/>
          hot:
            actions:
              rollover:
                maxAge: 8h <co xml:id="CO67-3"/>
        pollInterval: 15m <co xml:id="CO67-4"/>
...</programlisting>
<calloutlist>
<callout arearefs="CO67-1">
<para>For each log source, the retention policy indicates when to delete and roll over logs for that source.</para>
</callout>
<callout arearefs="CO67-2">
<para>When OpenShift Container Platform deletes the rolled-over indices. This setting is the <literal>maxAge</literal> you set in the <literal>ClusterLogging</literal> CR.</para>
</callout>
<callout arearefs="CO67-3">
<para>The index age for OpenShift Container Platform to consider when rolling over the indices. This value is determined from the <literal>maxAge</literal> you set in the <literal>ClusterLogging</literal> CR.</para>
</callout>
<callout arearefs="CO67-4">
<para>When OpenShift Container Platform checks if the indices should be rolled over. This setting is the default and cannot be changed.</para>
</callout>
</calloutlist>
<note>
<simpara>Modifying the <literal>Elasticsearch</literal> CR is not supported. All changes to the retention policies must be made in the <literal>ClusterLogging</literal> CR.</simpara>
</note>
<simpara>The OpenShift Elasticsearch Operator deploys a cron job to roll over indices for each mapping using the defined policy, scheduled using the <literal>pollInterval</literal>.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get cronjob</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                     SCHEDULE       SUSPEND   ACTIVE   LAST SCHEDULE   AGE
elasticsearch-im-app     */15 * * * *   False     0        &lt;none&gt;          4s
elasticsearch-im-audit   */15 * * * *   False     0        &lt;none&gt;          4s
elasticsearch-im-infra   */15 * * * *   False     0        &lt;none&gt;          4s</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</section>
<section xml:id="cluster-logging-logstore-limits_logging-config-es-store">
<title>Configuring CPU and memory requests for the log store</title>
<simpara>Each component specification allows for adjustments to both the CPU and memory requests.
You should not have to manually adjust these values as the OpenShift Elasticsearch
Operator sets values sufficient for your environment.</simpara>
<note>
<simpara>In large-scale clusters, the default memory limit for the Elasticsearch proxy container might not be sufficient, causing the proxy container to be OOMKilled. If you experience this issue, increase the memory requests and limits for the Elasticsearch proxy.</simpara>
</note>
<simpara>Each Elasticsearch node can operate with a lower memory setting though this is <emphasis role="strong">not</emphasis> recommended for production deployments.
For production use, you should have no less than the default 16Gi allocated to each pod. Preferably you should allocate as much as possible, up to 64Gi per pod.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>The Red Hat OpenShift Logging and Elasticsearch Operators must be installed.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Edit the <literal>ClusterLogging</literal> custom resource (CR) in the <literal>openshift-logging</literal> project:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit ClusterLogging instance</programlisting>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"
....
spec:
    logStore:
      type: "elasticsearch"
      elasticsearch:<co xml:id="CO68-1"/>
        resources:
          limits: <co xml:id="CO68-2"/>
            memory: "32Gi"
          requests: <co xml:id="CO68-3"/>
            cpu: "1"
            memory: "16Gi"
        proxy: <co xml:id="CO68-4"/>
          resources:
            limits:
              memory: 100Mi
            requests:
              memory: 100Mi</programlisting>
<calloutlist>
<callout arearefs="CO68-1">
<para>Specify the CPU and memory requests for Elasticsearch as needed. If you leave these values blank,
the OpenShift Elasticsearch Operator sets default values that should be sufficient for most deployments. The default values are <literal>16Gi</literal> for the memory request and <literal>1</literal> for the CPU request.</para>
</callout>
<callout arearefs="CO68-2">
<para>The maximum amount of resources a pod can use.</para>
</callout>
<callout arearefs="CO68-3">
<para>The minimum resources required to schedule a pod.</para>
</callout>
<callout arearefs="CO68-4">
<para>Specify the CPU and memory requests for the Elasticsearch proxy as needed. If you leave these values blank, the OpenShift Elasticsearch Operator sets default values that are sufficient for most deployments. The default values are <literal>256Mi</literal> for the memory request and <literal>100m</literal> for the CPU request.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
<simpara>When adjusting the amount of Elasticsearch memory, the same value should be used for both <literal>requests</literal> and <literal>limits</literal>.</simpara>
<simpara>For example:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">      resources:
        limits: <co xml:id="CO69-1"/>
          memory: "32Gi"
        requests: <co xml:id="CO69-2"/>
          cpu: "8"
          memory: "32Gi"</programlisting>
<calloutlist>
<callout arearefs="CO69-1">
<para>The maximum amount of the resource.</para>
</callout>
<callout arearefs="CO69-2">
<para>The minimum amount required.</para>
</callout>
</calloutlist>
<simpara>Kubernetes generally adheres the node configuration and does not allow Elasticsearch to use the specified limits.
Setting the same value for the <literal>requests</literal> and <literal>limits</literal> ensures that Elasticsearch can use the memory you want, assuming the node has the memory available.</simpara>
</section>
<section xml:id="cluster-logging-elasticsearch-ha_logging-config-es-store">
<title>Configuring replication policy for the log store</title>
<simpara>You can define how Elasticsearch shards are replicated across data nodes in the cluster.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>The Red Hat OpenShift Logging and Elasticsearch Operators must be installed.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Edit the <literal>ClusterLogging</literal> custom resource (CR) in the <literal>openshift-logging</literal> project:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit clusterlogging instance</programlisting>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"

....

spec:
  logStore:
    type: "elasticsearch"
    elasticsearch:
      redundancyPolicy: "SingleRedundancy" <co xml:id="CO70-1"/></programlisting>
<calloutlist>
<callout arearefs="CO70-1">
<para>Specify a redundancy policy for the shards. The change is applied upon saving the changes.</para>
<itemizedlist>
<listitem>
<simpara><emphasis role="strong">FullRedundancy</emphasis>. Elasticsearch fully replicates the primary shards for each index
to every data node. This provides the highest safety, but at the cost of the highest amount of disk required and the poorest performance.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">MultipleRedundancy</emphasis>. Elasticsearch fully replicates the primary shards for each index to half of the data nodes.
This provides a good tradeoff between safety and performance.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">SingleRedundancy</emphasis>. Elasticsearch makes one copy of the primary shards for each index.
Logs are always available and recoverable as long as at least two data nodes exist.
Better performance than MultipleRedundancy, when using 5 or more nodes. You cannot
apply this policy on deployments of single Elasticsearch node.</simpara>
</listitem>
<listitem>
<simpara><emphasis role="strong">ZeroRedundancy</emphasis>. Elasticsearch does not make copies of the primary shards.
Logs might be unavailable or lost in the event a node is down or fails.
Use this mode when you are more concerned with performance than safety, or have
implemented your own disk/PVC backup/restore strategy.</simpara>
</listitem>
</itemizedlist>
</callout>
</calloutlist>
</listitem>
</orderedlist>
<note>
<simpara>The number of primary shards for the index templates is equal to the number of Elasticsearch data nodes.</simpara>
</note>
</section>
<section xml:id="cluster-logging-elasticsearch-scaledown_logging-config-es-store">
<title>Scaling down Elasticsearch pods</title>
<simpara>Reducing the number of Elasticsearch pods in your cluster can result in data loss or Elasticsearch performance degradation.</simpara>
<simpara>If you scale down, you should scale down by one pod at a time and allow the cluster to re-balance the shards and replicas. After the Elasticsearch health status returns to <literal>green</literal>, you can scale down by another pod.</simpara>
<note>
<simpara>If your Elasticsearch cluster is set to <literal>ZeroRedundancy</literal>, you should not scale down your Elasticsearch pods.</simpara>
</note>
</section>
<section xml:id="cluster-logging-elasticsearch-storage_logging-config-es-store">
<title>Configuring persistent storage for the log store</title>
<simpara>Elasticsearch requires persistent storage. The faster the storage, the faster the Elasticsearch performance.</simpara>
<warning>
<simpara>Using NFS storage as a volume or a persistent volume (or via NAS such as
Gluster) is not supported for Elasticsearch storage, as Lucene relies on file
system behavior that NFS does not supply. Data corruption and other problems can
occur.</simpara>
</warning>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>The Red Hat OpenShift Logging and Elasticsearch Operators must be installed.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Edit the <literal>ClusterLogging</literal> CR to specify that each data node in the cluster is bound to a Persistent Volume Claim.</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"
# ...
spec:
  logStore:
    type: "elasticsearch"
    elasticsearch:
      nodeCount: 3
      storage:
        storageClassName: "gp2"
        size: "200G"</programlisting>
</listitem>
</orderedlist>
<simpara>This example specifies each data node in the cluster is bound to a Persistent Volume Claim that requests "200G" of AWS General Purpose SSD (gp2) storage.</simpara>
<note>
<simpara>If you use a local volume for persistent storage, do not use a raw block volume, which is described with <literal>volumeMode: block</literal> in the <literal>LocalVolume</literal> object. Elasticsearch cannot use raw block volumes.</simpara>
</note>
</section>
<section xml:id="cluster-logging-elasticsearch-persistent-storage-empty_logging-config-es-store">
<title>Configuring the log store for emptyDir storage</title>
<simpara>You can use emptyDir with your log store, which creates an ephemeral
deployment in which all of a pod&#8217;s data is lost upon restart.</simpara>
<note>
<simpara>When using emptyDir, if log storage is restarted or redeployed, you will lose data.</simpara>
</note>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>The Red Hat OpenShift Logging and Elasticsearch Operators must be installed.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Edit the <literal>ClusterLogging</literal> CR to specify emptyDir:</simpara>
<programlisting language="yaml" linenumbering="unnumbered"> spec:
    logStore:
      type: "elasticsearch"
      elasticsearch:
        nodeCount: 3
        storage: {}</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="cluster-logging-manual-rollout-rolling_logging-config-es-store">
<title>Performing an Elasticsearch rolling cluster restart</title>
<simpara>Perform a rolling restart when you change the <literal>elasticsearch</literal> config map or any of the <literal>elasticsearch-*</literal> deployment configurations.</simpara>
<simpara>Also, a rolling restart is recommended if the nodes on which an Elasticsearch pod runs requires a reboot.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>The Red Hat OpenShift Logging and Elasticsearch Operators must be installed.</simpara>
</listitem>
</itemizedlist>
<formalpara>
<title>Procedure</title>
<para>To perform a rolling cluster restart:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Change to the <literal>openshift-logging</literal> project:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc project openshift-logging</programlisting>
</listitem>
<listitem>
<simpara>Get the names of the Elasticsearch pods:</simpara>
<screen>$ oc get pods -l component=elasticsearch</screen>
</listitem>
<listitem>
<simpara>Scale down the collector pods so they stop sending new logs to Elasticsearch:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging patch daemonset/collector -p '{"spec":{"template":{"spec":{"nodeSelector":{"logging-infra-collector": "false"}}}}}'</programlisting>
</listitem>
<listitem>
<simpara>Perform a shard synced flush using the OpenShift Container Platform <link xlink:href="https://github.com/openshift/origin-aggregated-logging/tree/master/elasticsearch#es_util"><emphasis role="strong">es_util</emphasis></link> tool to ensure there are no pending operations waiting to be written to disk prior to shutting down:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec &lt;any_es_pod_in_the_cluster&gt; -c elasticsearch -- es_util --query="_flush/synced" -XPOST</programlisting>
<simpara>For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec -c elasticsearch-cdm-5ceex6ts-1-dcd6c4c7c-jpw6  -c elasticsearch -- es_util --query="_flush/synced" -XPOST</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">{"_shards":{"total":4,"successful":4,"failed":0},".security":{"total":2,"successful":2,"failed":0},".kibana_1":{"total":2,"successful":2,"failed":0}}</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Prevent shard balancing when purposely bringing down nodes using the OpenShift Container Platform
<link xlink:href="https://github.com/openshift/origin-aggregated-logging/tree/master/elasticsearch#es_util"><emphasis role="strong">es_util</emphasis></link> tool:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec &lt;any_es_pod_in_the_cluster&gt; -c elasticsearch -- es_util --query="_cluster/settings" -XPUT -d '{ "persistent": { "cluster.routing.allocation.enable" : "primaries" } }'</programlisting>
<simpara>For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec elasticsearch-cdm-5ceex6ts-1-dcd6c4c7c-jpw6 -c elasticsearch -- es_util --query="_cluster/settings" -XPUT -d '{ "persistent": { "cluster.routing.allocation.enable" : "primaries" } }'</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">{"acknowledged":true,"persistent":{"cluster":{"routing":{"allocation":{"enable":"primaries"}}}},"transient":</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>After the command is complete, for each deployment you have for an ES cluster:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>By default, the OpenShift Container Platform Elasticsearch cluster blocks rollouts to their nodes. Use the following command to allow rollouts
and allow the pod to pick up the changes:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc rollout resume deployment/&lt;deployment-name&gt;</programlisting>
<simpara>For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc rollout resume deployment/elasticsearch-cdm-0-1</programlisting>
<programlisting language="terminal" linenumbering="unnumbered">deployment.extensions/elasticsearch-cdm-0-1 resumed</programlisting>
<simpara>A new pod is deployed. After the pod has a ready container, you can
move on to the next deployment.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods -l component=elasticsearch-</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                                            READY   STATUS    RESTARTS   AGE
elasticsearch-cdm-5ceex6ts-1-dcd6c4c7c-jpw6k    2/2     Running   0          22h
elasticsearch-cdm-5ceex6ts-2-f799564cb-l9mj7    2/2     Running   0          22h
elasticsearch-cdm-5ceex6ts-3-585968dc68-k7kjr   2/2     Running   0          22h</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>After the deployments are complete, reset the pod to disallow rollouts:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc rollout pause deployment/&lt;deployment-name&gt;</programlisting>
<simpara>For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc rollout pause deployment/elasticsearch-cdm-0-1</programlisting>
<programlisting language="terminal" linenumbering="unnumbered">deployment.extensions/elasticsearch-cdm-0-1 paused</programlisting>
</listitem>
<listitem>
<simpara>Check that the Elasticsearch cluster is in a <literal>green</literal> or <literal>yellow</literal> state:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec &lt;any_es_pod_in_the_cluster&gt; -c elasticsearch -- es_util --query=_cluster/health?pretty=true</programlisting>
<note>
<simpara>If you performed a rollout on the Elasticsearch pod you used in the previous commands, the pod no longer exists and you need a new pod name here.</simpara>
</note>
<simpara>For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec elasticsearch-cdm-5ceex6ts-1-dcd6c4c7c-jpw6 -c elasticsearch -- es_util --query=_cluster/health?pretty=true</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="json" linenumbering="unnumbered">{
  "cluster_name" : "elasticsearch",
  "status" : "yellow", <co xml:id="CO71-1"/>
  "timed_out" : false,
  "number_of_nodes" : 3,
  "number_of_data_nodes" : 3,
  "active_primary_shards" : 8,
  "active_shards" : 16,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 1,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO71-1">
<para>Make sure this parameter value is <literal>green</literal> or <literal>yellow</literal> before proceeding.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>If you changed the Elasticsearch configuration map, repeat these steps for each Elasticsearch pod.</simpara>
</listitem>
<listitem>
<simpara>After all the deployments for the cluster have been rolled out, re-enable shard balancing:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec &lt;any_es_pod_in_the_cluster&gt; -c elasticsearch -- es_util --query="_cluster/settings" -XPUT -d '{ "persistent": { "cluster.routing.allocation.enable" : "all" } }'</programlisting>
<simpara>For example:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec elasticsearch-cdm-5ceex6ts-1-dcd6c4c7c-jpw6 -c elasticsearch -- es_util --query="_cluster/settings" -XPUT -d '{ "persistent": { "cluster.routing.allocation.enable" : "all" } }'</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">{
  "acknowledged" : true,
  "persistent" : { },
  "transient" : {
    "cluster" : {
      "routing" : {
        "allocation" : {
          "enable" : "all"
        }
      }
    }
  }
}</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Scale up the collector pods so they send new logs to Elasticsearch.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc -n openshift-logging patch daemonset/collector -p '{"spec":{"template":{"spec":{"nodeSelector":{"logging-infra-collector": "true"}}}}}'</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="cluster-logging-elasticsearch-exposing_logging-config-es-store">
<title>Exposing the log store service as a route</title>
<simpara>By default, the log store that is deployed with logging is not accessible from outside the logging cluster. You can enable a route with re-encryption termination for external access to the log store service for those tools that access its data.</simpara>
<simpara>Externally, you can access the log store by creating a reencrypt route, your OpenShift Container Platform token and the installed log store CA certificate. Then, access a node that hosts the log store service with a cURL request that contains:</simpara>
<itemizedlist>
<listitem>
<simpara>The <literal>Authorization: Bearer ${token}</literal></simpara>
</listitem>
<listitem>
<simpara>The Elasticsearch reencrypt route and an <link xlink:href="https://www.elastic.co/guide/en/elasticsearch/reference/current/api-conventions.html">Elasticsearch API request</link>.</simpara>
</listitem>
</itemizedlist>
<simpara>Internally, you can access the log store service using the log store cluster IP,
which you can get by using either of the following commands:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get service elasticsearch -o jsonpath={.spec.clusterIP} -n openshift-logging</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">172.30.183.229</programlisting>
</para>
</formalpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get service elasticsearch -n openshift-logging</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
elasticsearch   ClusterIP   172.30.183.229   &lt;none&gt;        9200/TCP   22h</programlisting>
</para>
</formalpara>
<simpara>You can check the cluster IP address with a command similar to the following:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc exec elasticsearch-cdm-oplnhinv-1-5746475887-fj2f8 -n openshift-logging -- curl -tlsv1.2 --insecure -H "Authorization: Bearer ${token}" "https://172.30.183.229:9200/_cat/health"</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    29  100    29    0     0    108      0 --:--:-- --:--:-- --:--:--   108</programlisting>
</para>
</formalpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>The Red Hat OpenShift Logging and Elasticsearch Operators must be installed.</simpara>
</listitem>
<listitem>
<simpara>You must have access to the project to be able to access to the logs.</simpara>
</listitem>
</itemizedlist>
<formalpara>
<title>Procedure</title>
<para>To expose  the log store externally:</para>
</formalpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>Change to the <literal>openshift-logging</literal> project:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc project openshift-logging</programlisting>
</listitem>
<listitem>
<simpara>Extract the CA certificate from the log store and write to the <emphasis role="strong"><emphasis>admin-ca</emphasis></emphasis> file:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc extract secret/elasticsearch --to=. --keys=admin-ca</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">admin-ca</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Create the route for the log store service as a YAML file:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Create a YAML file with the following:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: elasticsearch
  namespace: openshift-logging
spec:
  host:
  to:
    kind: Service
    name: elasticsearch
  tls:
    termination: reencrypt
    destinationCACertificate: | <co xml:id="CO72-1"/></programlisting>
<calloutlist>
<callout arearefs="CO72-1">
<para>Add the log store CA certifcate or use the command in the next step. You do not have to set the <literal>spec.tls.key</literal>, <literal>spec.tls.certificate</literal>, and <literal>spec.tls.caCertificate</literal> parameters required by some reencrypt routes.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Run the following command to add the log store CA certificate to the route YAML you created in the previous step:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ cat ./admin-ca | sed -e "s/^/      /" &gt;&gt; &lt;file-name&gt;.yaml</programlisting>
</listitem>
<listitem>
<simpara>Create the route:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc create -f &lt;file-name&gt;.yaml</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">route.route.openshift.io/elasticsearch created</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>Check that the Elasticsearch service is exposed:</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Get the token of this service account to be used in the request:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ token=$(oc whoami -t)</programlisting>
</listitem>
<listitem>
<simpara>Set the <emphasis role="strong">elasticsearch</emphasis> route you created as an environment variable.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ routeES=`oc get route elasticsearch -o jsonpath={.spec.host}`</programlisting>
</listitem>
<listitem>
<simpara>To verify the route was successfully created, run the following command that accesses Elasticsearch through the exposed route:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">curl -tlsv1.2 --insecure -H "Authorization: Bearer ${token}" "https://${routeES}"</programlisting>
<simpara>The response appears similar to the following:</simpara>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="json" linenumbering="unnumbered">{
  "name" : "elasticsearch-cdm-i40ktba0-1",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "0eY-tJzcR3KOdpgeMJo-MQ",
  "version" : {
  "number" : "6.8.1",
  "build_flavor" : "oss",
  "build_type" : "zip",
  "build_hash" : "Unknown",
  "build_date" : "Unknown",
  "build_snapshot" : true,
  "lucene_version" : "7.7.0",
  "minimum_wire_compatibility_version" : "5.6.0",
  "minimum_index_compatibility_version" : "5.0.0"
},
  "&lt;tagline&gt;" : "&lt;for search&gt;"
}</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
</section>
<section xml:id="cluster-logging-removing-unused-components-if-no-elasticsearch_logging-config-es-store">
<title>Removing unused components if you do not use the default Elasticsearch log store</title>
<simpara>As an administrator, in the rare case that you forward logs to a third-party log store and do not use the default Elasticsearch log store, you can remove several unused components from your logging cluster.</simpara>
<simpara>In other words, if you do not use the default Elasticsearch log store, you can remove the internal Elasticsearch <literal>logStore</literal> and Kibana <literal>visualization</literal> components from the <literal>ClusterLogging</literal> custom resource (CR). Removing these components is optional but saves resources.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Verify that your log forwarder does not send log data to the default internal Elasticsearch cluster. Inspect the <literal>ClusterLogForwarder</literal> CR YAML file that you used to configure log forwarding. Verify that it <emphasis>does not</emphasis> have an <literal>outputRefs</literal> element that specifies <literal>default</literal>. For example:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">outputRefs:
- default</programlisting>
</listitem>
</itemizedlist>
<warning>
<simpara>Suppose the <literal>ClusterLogForwarder</literal> CR forwards log data to the internal Elasticsearch cluster, and you remove the <literal>logStore</literal> component from the <literal>ClusterLogging</literal> CR. In that case, the internal Elasticsearch cluster will not be present to store the log data. This absence can cause data loss.</simpara>
</warning>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Edit the <literal>ClusterLogging</literal> custom resource (CR) in the <literal>openshift-logging</literal> project:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit ClusterLogging instance</programlisting>
</listitem>
<listitem>
<simpara>If they are present, remove the <literal>logStore</literal> and <literal>visualization</literal> stanzas from the <literal>ClusterLogging</literal> CR.</simpara>
</listitem>
<listitem>
<simpara>Preserve the <literal>collection</literal> stanza of the <literal>ClusterLogging</literal> CR. The result should look similar to the following example:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"
  namespace: "openshift-logging"
spec:
  managementState: "Managed"
  collection:
    type: "fluentd"
    fluentd: {}</programlisting>
</listitem>
<listitem>
<simpara>Verify that the collector pods are redeployed:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods -l component=collector -n openshift-logging</programlisting>
</listitem>
</orderedlist>
</section>
</section>
</chapter>
<chapter xml:id="_logging-alerts">
<title>Logging alerts</title>
<section xml:id="default-logging-alerts">
<title>Default logging alerts</title>

<simpara>Logging alerts are installed as part of the Red Hat OpenShift Logging Operator installation. Alerts depend on metrics exported by the log collection and log storage backends. These metrics are enabled if you selected the option to <emphasis role="strong">Enable operator recommended cluster monitoring on this namespace</emphasis> when installing the Red Hat OpenShift Logging Operator. For more information about installing logging Operators, see <link xlink:href="../../logging/cluster-logging-deploying.xml#cluster-logging-deploy-console_cluster-logging-deploying">Installing logging using the web console</link>.</simpara>
<simpara>Default logging alerts are sent to the OpenShift Container Platform monitoring stack Alertmanager in the <literal>openshift-monitoring</literal> namespace, unless you have disabled the local Alertmanager instance.</simpara>
<section xml:id="monitoring-accessing-the-alerting-ui_default-logging-alerts">
<title>Accessing the Alerting UI in the Administrator and Developer perspectives</title>
<simpara>The Alerting UI is accessible through the Administrator perspective and the Developer perspective in the OpenShift Container Platform web console.</simpara>
<itemizedlist>
<listitem>
<simpara>In the <emphasis role="strong">Administrator</emphasis> perspective, select <emphasis role="strong">Observe</emphasis> &#8594; <emphasis role="strong">Alerting</emphasis>. The three main pages in the Alerting UI in this perspective are the <emphasis role="strong">Alerts</emphasis>, <emphasis role="strong">Silences</emphasis>, and <emphasis role="strong">Alerting Rules</emphasis> pages.</simpara>
</listitem>
</itemizedlist>
<itemizedlist>
<listitem>
<simpara>In the <emphasis role="strong">Developer</emphasis> perspective, select <emphasis role="strong">Observe</emphasis> &#8594; <emphasis role="strong">&lt;project_name&gt;</emphasis> &#8594; <emphasis role="strong">Alerts</emphasis>. In this perspective, alerts, silences, and alerting rules are all managed from the <emphasis role="strong">Alerts</emphasis> page. The results shown in the <emphasis role="strong">Alerts</emphasis> page are specific to the selected project.</simpara>
</listitem>
</itemizedlist>
<note>
<simpara>In the <emphasis role="strong">Developer</emphasis> perspective, you can select from core OpenShift Container Platform and user-defined projects that you have access to in the <emphasis role="strong">Project:</emphasis> list. However, alerts, silences, and alerting rules relating to core OpenShift Container Platform projects are not displayed if you are not logged in as a cluster administrator.</simpara>
</note>
</section>
<section xml:id="logging-vector-collector-alerts_default-logging-alerts">
<title>Vector collector alerts</title>
<simpara>In logging 5.7 and later versions, the following alerts are generated by the Vector collector. You can view these alerts in the OpenShift Container Platform web console.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Vector collector alerts</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="28.5714*"/>
<colspec colname="col_2" colwidth="28.5714*"/>
<colspec colname="col_3" colwidth="28.5714*"/>
<colspec colname="col_4" colwidth="14.2858*"/>
<thead>
<row>
<entry align="left" valign="top">Alert</entry>
<entry align="left" valign="top">Message</entry>
<entry align="left" valign="top">Description</entry>
<entry align="left" valign="top">Severity</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>CollectorHighErrorRate</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>&lt;value&gt; of records have resulted in an error by vector &lt;instance&gt;.</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The number of vector output errors is high, by default more than 10 in the previous 15 minutes.</simpara></entry>
<entry align="left" valign="top"><simpara>Warning</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>CollectorNodeDown</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>Prometheus could not scrape vector &lt;instance&gt; for more than 10m.</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Vector is reporting that Prometheus could not scrape a specific Vector instance.</simpara></entry>
<entry align="left" valign="top"><simpara>Critical</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>CollectorVeryHighErrorRate</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>&lt;value&gt; of records have resulted in an error by vector &lt;instance&gt;.</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The number of Vector component errors are very high, by default more than 25 in the previous 15 minutes.</simpara></entry>
<entry align="left" valign="top"><simpara>Critical</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>FluentdQueueLengthIncreasing</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>In the last 1h, fluentd &lt;instance&gt; buffer queue length constantly increased more than 1. Current value is &lt;value&gt;.</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Fluentd is reporting that the queue size is increasing.</simpara></entry>
<entry align="left" valign="top"><simpara>Warning</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section xml:id="logging-fluentd-collector-alerts_default-logging-alerts">
<title>Fluentd collector alerts</title>
<simpara>The following alerts are generated by the legacy Fluentd log collector. You can view these alerts in the OpenShift Container Platform web console.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Fluentd collector alerts</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="28.5714*"/>
<colspec colname="col_2" colwidth="28.5714*"/>
<colspec colname="col_3" colwidth="28.5714*"/>
<colspec colname="col_4" colwidth="14.2858*"/>
<thead>
<row>
<entry align="left" valign="top">Alert</entry>
<entry align="left" valign="top">Message</entry>
<entry align="left" valign="top">Description</entry>
<entry align="left" valign="top">Severity</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>FluentDHighErrorRate</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>&lt;value&gt; of records have resulted in an error by fluentd &lt;instance&gt;.</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The number of FluentD output errors is high, by default more than 10 in the previous 15 minutes.</simpara></entry>
<entry align="left" valign="top"><simpara>Warning</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>FluentdNodeDown</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>Prometheus could not scrape fluentd &lt;instance&gt; for more than 10m.</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Fluentd is reporting that Prometheus could not scrape a specific Fluentd instance.</simpara></entry>
<entry align="left" valign="top"><simpara>Critical</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>FluentdQueueLengthIncreasing</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>In the last 1h, fluentd &lt;instance&gt; buffer queue length constantly increased more than 1. Current value is &lt;value&gt;.</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Fluentd is reporting that the queue size is increasing.</simpara></entry>
<entry align="left" valign="top"><simpara>Warning</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>FluentDVeryHighErrorRate</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>&lt;value&gt; of records have resulted in an error by fluentd &lt;instance&gt;.</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The number of FluentD output errors is very high, by default more than 25 in the previous 15 minutes.</simpara></entry>
<entry align="left" valign="top"><simpara>Critical</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section xml:id="cluster-logging-elasticsearch-rules_default-logging-alerts">
<title>Elasticsearch alerting rules</title>
<simpara>You can view these alerting rules in the OpenShift Container Platform web console.</simpara>
<table frame="all" rowsep="1" colsep="1">
<title>Alerting rules</title>
<tgroup cols="3">
<colspec colname="col_1" colwidth="30*"/>
<colspec colname="col_2" colwidth="60*"/>
<colspec colname="col_3" colwidth="10*"/>
<thead>
<row>
<entry align="left" valign="top">Alert</entry>
<entry align="left" valign="top">Description</entry>
<entry align="left" valign="top">Severity</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>ElasticsearchClusterNotHealthy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The cluster health status has been RED for at least 2 minutes. The cluster does not accept writes, shards may be missing, or the master
 node hasn&#8217;t been elected yet.</simpara></entry>
<entry align="left" valign="top"><simpara>Critical</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ElasticsearchClusterNotHealthy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The cluster health status has been YELLOW for at least 20 minutes. Some shard replicas are not allocated.</simpara></entry>
<entry align="left" valign="top"><simpara>Warning</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ElasticsearchDiskSpaceRunningLow</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The cluster is expected to be out of disk space within the next 6 hours.</simpara></entry>
<entry align="left" valign="top"><simpara>Critical</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ElasticsearchHighFileDescriptorUsage</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The cluster is predicted to be out of file descriptors within the next hour.</simpara></entry>
<entry align="left" valign="top"><simpara>Warning</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ElasticsearchJVMHeapUseHigh</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The JVM Heap usage on the specified node is high.</simpara></entry>
<entry align="left" valign="top"><simpara>Alert</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ElasticsearchNodeDiskWatermarkReached</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The specified node has hit the low watermark due to low free disk space. Shards can not be allocated to this node anymore. You should consider adding more disk space to the node.</simpara></entry>
<entry align="left" valign="top"><simpara>Info</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ElasticsearchNodeDiskWatermarkReached</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The specified node has hit the high watermark due to low free disk space. Some shards will be re-allocated to different
nodes if possible. Make sure more disk space is added to the node or drop old indices allocated to this node.</simpara></entry>
<entry align="left" valign="top"><simpara>Warning</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ElasticsearchNodeDiskWatermarkReached</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The specified node has hit the flood watermark due to low free disk space. Every index that has a shard allocated on this node is enforced a read-only block. The index block must be manually released when the disk use falls below the high watermark.</simpara></entry>
<entry align="left" valign="top"><simpara>Critical</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ElasticsearchJVMHeapUseHigh</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The JVM Heap usage on the specified node is too high.</simpara></entry>
<entry align="left" valign="top"><simpara>Alert</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ElasticsearchWriteRequestsRejectionJumps</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Elasticsearch is experiencing an increase in write rejections on the specified node. This node might not be keeping up with the indexing speed.</simpara></entry>
<entry align="left" valign="top"><simpara>Warning</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>AggregatedLoggingSystemCPUHigh</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The CPU used by the system on the specified node is too high.</simpara></entry>
<entry align="left" valign="top"><simpara>Alert</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ElasticsearchProcessCPUHigh</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The CPU used by Elasticsearch on the specified node is too high.</simpara></entry>
<entry align="left" valign="top"><simpara>Alert</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section xml:id="additional-resources_default-logging-alerts" role="_additional-resources">
<title>Additional resources</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/monitoring/#modifying-core-platform-alerting-rules_managing-alerts">Modifying core platform alerting rules</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="custom-logging-alerts">
<title>Custom logging alerts</title>

<simpara>In logging 5.7 and later versions, users can configure the LokiStack deployment to produce customized alerts and recorded metrics. If you want to use customized <link xlink:href="https://grafana.com/docs/loki/latest/alert/">alerting and recording rules</link>, you must enable the LokiStack ruler component.</simpara>
<simpara>LokiStack log-based alerts and recorded metrics are triggered by providing <link xlink:href="https://grafana.com/docs/loki/latest/query/">LogQL</link> expressions to the ruler component. The Loki Operator manages a ruler that is optimized for the selected LokiStack size, which can be <literal>1x.extra-small</literal>, <literal>1x.small</literal>, or <literal>1x.medium</literal>.</simpara>
<simpara>To provide these expressions, you must create an <literal>AlertingRule</literal> custom resource (CR) containing Prometheus-compatible <link xlink:href="https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/">alerting rules</link>, or a <literal>RecordingRule</literal> CR containing Prometheus-compatible <link xlink:href="https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/">recording rules</link>.</simpara>
<simpara>Administrators can configure log-based alerts or recorded metrics for <literal>application</literal>, <literal>audit</literal>, or <literal>infrastructure</literal> tenants. Users without administrator permissions can configure log-based alerts or recorded metrics for <literal>application</literal> tenants of the applications that they have access to.</simpara>
<simpara>Application, audit, and infrastructure alerts are sent by default to the OpenShift Container Platform monitoring stack Alertmanager in the <literal>openshift-monitoring</literal> namespace, unless you have disabled the local Alertmanager instance. If the Alertmanager that is used to monitor user-defined projects in the <literal>openshift-user-workload-monitoring</literal> namespace is enabled, application alerts are sent to the Alertmanager in this namespace by default.</simpara>
<section xml:id="configuring-logging-loki-ruler_custom-logging-alerts">
<title>Configuring the ruler</title>
<simpara>When the LokiStack ruler component is enabled, users can define a group of <link xlink:href="https://grafana.com/docs/loki/latest/query/">LogQL</link> expressions that trigger logging alerts or recorded metrics.</simpara>
<simpara>Administrators can enable the ruler by modifying the <literal>LokiStack</literal> custom resource (CR).</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator and the Loki Operator.</simpara>
</listitem>
<listitem>
<simpara>You have created a <literal>LokiStack</literal> CR.</simpara>
</listitem>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
</itemizedlist>
<itemizedlist>
<title>Procedure</title>
<listitem>
<simpara>Enable the ruler by ensuring that the <literal>LokiStack</literal> CR contains the following spec configuration:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: loki.grafana.com/v1
kind: LokiStack
metadata:
  name: &lt;name&gt;
  namespace: &lt;namespace&gt;
spec:
# ...
  rules:
    enabled: true <co xml:id="CO73-1"/>
    selector:
      matchLabels:
        openshift.io/&lt;label_name&gt;: "true" <co xml:id="CO73-2"/>
    namespaceSelector:
      matchLabels:
        openshift.io/&lt;label_name&gt;: "true" <co xml:id="CO73-3"/></programlisting>
<calloutlist>
<callout arearefs="CO73-1">
<para>Enable Loki alerting and recording rules in your cluster.</para>
</callout>
<callout arearefs="CO73-2">
<para>Add a custom label that can be added to namespaces where you want to enable the use of logging alerts and metrics.</para>
</callout>
<callout arearefs="CO73-3">
<para>Add a custom label that can be added to namespaces where you want to enable the use of logging alerts and metrics.</para>
</callout>
</calloutlist>
</listitem>
</itemizedlist>
</section>
<section xml:id="loki-rbac-permissions_custom-logging-alerts">
<title>Authorizing Loki rules RBAC permissions</title>
<simpara>Administrators can allow users to create and manage their own alerting rules by creating a <literal>ClusterRole</literal> object and binding this role to usernames. The <literal>ClusterRole</literal> object defines the necessary role-based access control (RBAC) permissions for users.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>The Red Hat OpenShift Logging Operator is installed in the <literal>openshift-logging</literal> namespace.</simpara>
</listitem>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create a cluster role that defines the necessary RBAC permissions.</simpara>
</listitem>
<listitem>
<simpara>Bind the appropriate cluster roles to the username:</simpara>
<formalpara>
<title>Example binding command</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm policy add-role-to-user &lt;cluster_role_name&gt; -n &lt;namespace&gt; &lt;username&gt;</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/authentication_and_authorization/#using-rbac">Using RBAC to define and apply permissions</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-enabling-loki-alerts_custom-logging-alerts">
<title>Creating a log-based alerting rule with Loki</title>
<simpara>The <literal>AlertingRule</literal> CR contains a set of specifications and webhook validation definitions to declare groups of alerting rules for a single <literal>LokiStack</literal> instance. In addition, the webhook validation definition provides support for rule validation conditions:</simpara>
<itemizedlist>
<listitem>
<simpara>If an <literal>AlertingRule</literal> CR includes an invalid <literal>interval</literal> period, it is an invalid alerting rule</simpara>
</listitem>
<listitem>
<simpara>If an <literal>AlertingRule</literal> CR includes an invalid <literal>for</literal> period, it is an invalid alerting rule.</simpara>
</listitem>
<listitem>
<simpara>If an <literal>AlertingRule</literal> CR includes an invalid LogQL <literal>expr</literal>, it is an invalid alerting rule.</simpara>
</listitem>
<listitem>
<simpara>If an <literal>AlertingRule</literal> CR includes two groups with the same name, it is an invalid alerting rule.</simpara>
</listitem>
<listitem>
<simpara>If none of above applies, an alerting rule is considered valid.</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Tenant type</entry>
<entry align="left" valign="top">Valid namespaces for <literal>AlertingRule</literal> CRs</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>application</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>audit</simpara></entry>
<entry align="left" valign="top"><simpara><literal>openshift-logging</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>infrastructure</simpara></entry>
<entry align="left" valign="top"><simpara><literal>openshift-/*</literal>, <literal>kube-/\*</literal>, <literal>default</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>Red Hat OpenShift Logging Operator 5.7 and later</simpara>
</listitem>
<listitem>
<simpara>OpenShift Container Platform 4.13 and later</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Create an <literal>AlertingRule</literal> custom resource (CR):</simpara>
<formalpara>
<title>Example infrastructure AlertingRule CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">  apiVersion: loki.grafana.com/v1
  kind: AlertingRule
  metadata:
    name: loki-operator-alerts
    namespace: openshift-operators-redhat <co xml:id="CO74-1"/>
    labels: <co xml:id="CO74-2"/>
      openshift.io/&lt;label_name&gt;: "true"
  spec:
    tenantID: "infrastructure" <co xml:id="CO74-3"/>
    groups:
      - name: LokiOperatorHighReconciliationError
        rules:
          - alert: HighPercentageError
            expr: | <co xml:id="CO74-4"/>
              sum(rate({kubernetes_namespace_name="openshift-operators-redhat", kubernetes_pod_name=~"loki-operator-controller-manager.*"} |= "error" [1m])) by (job)
                /
              sum(rate({kubernetes_namespace_name="openshift-operators-redhat", kubernetes_pod_name=~"loki-operator-controller-manager.*"}[1m])) by (job)
                &gt; 0.01
            for: 10s
            labels:
              severity: critical <co xml:id="CO74-5"/>
            annotations:
              summary: High Loki Operator Reconciliation Errors <co xml:id="CO74-6"/>
              description: High Loki Operator Reconciliation Errors <co xml:id="CO74-7"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO74-1">
<para>The namespace where this <literal>AlertingRule</literal> CR is created must have a label matching the LokiStack <literal>spec.rules.namespaceSelector</literal> definition.</para>
</callout>
<callout arearefs="CO74-2">
<para>The <literal>labels</literal> block must match the LokiStack <literal>spec.rules.selector</literal> definition.</para>
</callout>
<callout arearefs="CO74-3">
<para><literal>AlertingRule</literal> CRs for <literal>infrastructure</literal> tenants are only supported in the <literal>openshift-*</literal>, <literal>kube-\*</literal>, or <literal>default</literal> namespaces.</para>
</callout>
<callout arearefs="CO74-4">
<para>The value for <literal>kubernetes_namespace_name:</literal> must match the value for <literal>metadata.namespace</literal>.</para>
</callout>
<callout arearefs="CO74-5">
<para>The value of this mandatory field must be <literal>critical</literal>, <literal>warning</literal>, or <literal>info</literal>.</para>
</callout>
<callout arearefs="CO74-6">
<para>This field is mandatory.</para>
</callout>
<callout arearefs="CO74-7">
<para>This field is mandatory.</para>
</callout>
</calloutlist>
<formalpara>
<title>Example application AlertingRule CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">  apiVersion: loki.grafana.com/v1
  kind: AlertingRule
  metadata:
    name: app-user-workload
    namespace: app-ns <co xml:id="CO75-1"/>
    labels: <co xml:id="CO75-2"/>
      openshift.io/&lt;label_name&gt;: "true"
  spec:
    tenantID: "application"
    groups:
      - name: AppUserWorkloadHighError
        rules:
          - alert:
            expr: | <co xml:id="CO75-3"/>
            sum(rate({kubernetes_namespace_name="app-ns", kubernetes_pod_name=~"podName.*"} |= "error" [1m])) by (job)
            for: 10s
            labels:
              severity: critical <co xml:id="CO75-4"/>
            annotations:
              summary:  <co xml:id="CO75-5"/>
              description:  <co xml:id="CO75-6"/></programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO75-1">
<para>The namespace where this <literal>AlertingRule</literal> CR is created must have a label matching the LokiStack <literal>spec.rules.namespaceSelector</literal> definition.</para>
</callout>
<callout arearefs="CO75-2">
<para>The <literal>labels</literal> block must match the LokiStack <literal>spec.rules.selector</literal> definition.</para>
</callout>
<callout arearefs="CO75-3">
<para>Value for <literal>kubernetes_namespace_name:</literal> must match the value for <literal>metadata.namespace</literal>.</para>
</callout>
<callout arearefs="CO75-4">
<para>The value of this mandatory field must be <literal>critical</literal>, <literal>warning</literal>, or <literal>info</literal>.</para>
</callout>
<callout arearefs="CO75-5">
<para>The value of this mandatory field is a summary of the rule.</para>
</callout>
<callout arearefs="CO75-6">
<para>The value of this mandatory field is a detailed description of the rule.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>AlertingRule</literal> CR:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</listitem>
</orderedlist>
</section>
<section xml:id="additional-resources_custom-logging-alerts" role="_additional-resources">
<title>Additional resources</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/monitoring/#about-openshift-monitoring_monitoring-overview">About OpenShift Container Platform monitoring</link></simpara>
</listitem>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/postinstallation_configuration/#configuring-alert-notifications">Configuring alert notifications</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
</chapter>
<chapter xml:id="_performance-and-reliability-tuning">
<title>Performance and reliability tuning</title>
<section xml:id="logging-flow-control-mechanisms">
<title>Flow control mechanisms</title>

<simpara>If logs are produced faster than they can be collected, it can be difficult to predict or control the volume of logs being sent to an output.
Not being able to predict or control the volume of logs being sent to an output can result in logs being lost. If there is a system outage and log buffers are accumulated without user control, this can also cause long recovery times and high latency when the connection is restored.</simpara>
<simpara>As an administrator, you can limit logging rates by configuring flow control mechanisms for your logging.</simpara>
<section xml:id="logging-configuring-flow-control-benefits">
<title>Benefits of flow control mechanisms</title>
<itemizedlist>
<listitem>
<simpara>The cost and volume of logging can be predicted more accurately in advance.</simpara>
</listitem>
<listitem>
<simpara>Noisy containers cannot produce unbounded log traffic that drowns out other containers.</simpara>
</listitem>
<listitem>
<simpara>Ignoring low-value logs reduces the load on the logging infrastructure.</simpara>
</listitem>
<listitem>
<simpara>High-value logs can be preferred over low-value logs by assigning higher rate limits.</simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-configuring-flow-control-about-rate-limits">
<title>Configuring rate limits</title>
<simpara>Rate limits are configured per collector, which means that the maximum rate of log collection is the number of collector instances multiplied by the rate limit.</simpara>
<simpara>Because logs are collected from each node&#8217;s file system, a collector is deployed on each cluster node. For example, in a 3-node cluster, with a maximum rate limit of 10 records per second per collector, the maximum rate of log collection is 30 records per second.</simpara>
<simpara>Because the exact byte size of a record as written to an output can vary due to transformations, different encodings, or other factors, rate limits are set in number of records instead of bytes.</simpara>
<simpara>You can configure rate limits in the <literal>ClusterLogForwarder</literal> custom resource (CR) in two ways:</simpara>
<variablelist>
<varlistentry>
<term>Output rate limit</term>
<listitem>
<simpara>Limit the rate of outbound logs to selected outputs, for example, to match the network or storage capacity of an output. The output rate limit controls the aggregated per-output rate.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Input rate limit</term>
<listitem>
<simpara>Limit the per-container rate of log collection for selected containers.</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section xml:id="logging-set-output-rate-limit_logging-flow-control-mechanisms">
<title>Configuring log forwarder output rate limits</title>
<simpara>You can limit the rate of outbound logs to a specified output by configuring the <literal>ClusterLogForwarder</literal> custom resource (CR).</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator.</simpara>
</listitem>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Add a <literal>maxRecordsPerSecond</literal> limit value to the <literal>ClusterLogForwarder</literal> CR for a specified output.</simpara>
<simpara>The following example shows how to configure a per collector output rate limit for a Kafka broker output named <literal>kafka-example</literal>:</simpara>
<formalpara>
<title>Example <literal>ClusterLogForwarder</literal> CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
# ...
spec:
# ...
  outputs:
    - name: kafka-example <co xml:id="CO76-1"/>
      type: kafka <co xml:id="CO76-2"/>
      limit:
        maxRecordsPerSecond: 1000000 <co xml:id="CO76-3"/>
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO76-1">
<para>The output name.</para>
</callout>
<callout arearefs="CO76-2">
<para>The type of output.</para>
</callout>
<callout arearefs="CO76-3">
<para>The log output rate limit. This value sets the maximum <link xlink:href="https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/quantity/">Quantity</link> of logs that can be sent to the Kafka broker per second. This value is not set by default. The default behavior is best effort, and records are dropped if the log forwarder cannot keep up. If this value is <literal>0</literal>, no logs are forwarded.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>ClusterLogForwarder</literal> CR:</simpara>
<formalpara>
<title>Example command</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link linkend="logging-output-types">Log output types</link></simpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="logging-set-input-rate-limit_logging-flow-control-mechanisms">
<title>Configuring log forwarder input rate limits</title>
<simpara>You can limit the rate of incoming logs that are collected by configuring the <literal>ClusterLogForwarder</literal> custom resource (CR). You can set input limits on a per-container or per-namespace basis.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator.</simpara>
</listitem>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Add a <literal>maxRecordsPerSecond</literal> limit value to the <literal>ClusterLogForwarder</literal> CR for a specified input.</simpara>
<simpara>The following examples show how to configure input rate limits for different scenarios:</simpara>
<formalpara>
<title>Example <literal>ClusterLogForwarder</literal> CR that sets a per-container limit for containers with certain labels</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
# ...
spec:
# ...
  inputs:
    - name: &lt;input_name&gt; <co xml:id="CO77-1"/>
      application:
        selector:
          matchLabels: { example: label } <co xml:id="CO77-2"/>
      limitPerContainer:
          maxRecordsPerSecond: 0 <co xml:id="CO77-3"/>
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO77-1">
<para>The input name.</para>
</callout>
<callout arearefs="CO77-2">
<para>A list of labels. If these labels match labels that are applied to a pod, the per-container limit specified in the <literal>maxRecordsPerSecond</literal> field is applied to those containers.</para>
</callout>
<callout arearefs="CO77-3">
<para>Configures the rate limit. Setting the <literal>maxRecordsPerSecond</literal> field to <literal>0</literal> means that no logs are collected for the container. Setting the <literal>maxRecordsPerSecond</literal> field to some other value means that a maximum of that number of records per second are collected for the container.</para>
</callout>
</calloutlist>
<formalpara>
<title>Example <literal>ClusterLogForwarder</literal> CR that sets a per-container limit for containers in selected namespaces</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
# ...
spec:
# ...
  inputs:
    - name: &lt;input_name&gt; <co xml:id="CO78-1"/>
      application:
        namespaces: [ example-ns-1, example-ns-2 ] <co xml:id="CO78-2"/>
      limitPerContainer:
        maxRecordsPerSecond: 10 <co xml:id="CO78-3"/>
    - name: &lt;input_name&gt;
      application:
        namespaces: [ test ]
      limitPerContainer:
          maxRecordsPerSecond: 1000
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO78-1">
<para>The input name.</para>
</callout>
<callout arearefs="CO78-2">
<para>A list of namespaces. The per-container limit specified in the <literal>maxRecordsPerSecond</literal> field is applied to all containers in the namespaces listed.</para>
</callout>
<callout arearefs="CO78-3">
<para>Configures the rate limit. Setting the <literal>maxRecordsPerSecond</literal> field to <literal>10</literal> means that a maximum of 10 records per second are collected for each container in the namespaces listed.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>Apply the <literal>ClusterLogForwarder</literal> CR:</simpara>
<formalpara>
<title>Example command</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">$ oc apply -f &lt;filename&gt;.yaml</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
</section>
</section>
</chapter>
<chapter xml:id="_scheduling-resources">
<title>Scheduling resources</title>
<section xml:id="logging-node-selectors">
<title>Using node selectors to move logging resources</title>

<simpara>A <emphasis>node selector</emphasis> specifies a map of key/value pairs that are defined using custom labels on nodes and selectors specified in pods.</simpara>
<simpara>For the pod to be eligible to run on a node, the pod must have the same key/value node selector as the label on the node.</simpara>
<section xml:id="nodes-scheduler-node-selectors-about_logging-node-selectors">
<title>About node selectors</title>
<simpara>You can use node selectors on pods and labels on nodes to control where the pod is scheduled. With node selectors, OpenShift Container Platform schedules the pods on nodes that contain matching labels.</simpara>
<simpara>You can use a node selector to place specific pods on specific nodes, cluster-wide node selectors to place new pods on specific nodes anywhere in the cluster, and project node selectors to place new pods in a project on specific nodes.</simpara>
<simpara>For example, as a cluster administrator, you can create an infrastructure where application developers can deploy pods only onto the nodes closest to their geographical location by including a node selector in every pod they create. In this example, the cluster consists of five data centers spread across two regions. In the U.S., label the nodes as <literal>us-east</literal>, <literal>us-central</literal>, or <literal>us-west</literal>. In the Asia-Pacific region (APAC), label the nodes as <literal>apac-east</literal> or <literal>apac-west</literal>. The developers can add a node selector to the pods they create to ensure the pods get scheduled on those nodes.</simpara>
<simpara>A pod is not scheduled if the <literal>Pod</literal> object contains a node selector, but no node has a matching label.</simpara>
<important>
<simpara>If you are using node selectors and node affinity in the same pod configuration, the following rules control pod placement onto nodes:</simpara>
<itemizedlist>
<listitem>
<simpara>If you configure both <literal>nodeSelector</literal> and <literal>nodeAffinity</literal>, both conditions must be satisfied for the pod to be scheduled onto a candidate node.</simpara>
</listitem>
<listitem>
<simpara>If you specify multiple <literal>nodeSelectorTerms</literal> associated with <literal>nodeAffinity</literal> types, then the pod can be scheduled onto a node if one of the <literal>nodeSelectorTerms</literal> is satisfied.</simpara>
</listitem>
<listitem>
<simpara>If you specify multiple <literal>matchExpressions</literal> associated with <literal>nodeSelectorTerms</literal>, then the pod can be scheduled onto a node only if all <literal>matchExpressions</literal> are satisfied.</simpara>
</listitem>
</itemizedlist>
</important>
<variablelist>
<varlistentry>
<term>Node selectors on specific pods and nodes</term>
<listitem>
<simpara>You can control which node a specific pod is scheduled on by using node selectors and labels.</simpara>
<simpara>To use node selectors and labels, first label the node to avoid pods being descheduled, then add the node selector to the pod.</simpara>
<note>
<simpara>You cannot add a node selector directly to an existing scheduled pod. You must label the object that controls the pod, such as deployment config.</simpara>
</note>
<simpara>For example, the following <literal>Node</literal> object has the <literal>region: east</literal> label:</simpara>
<formalpara>
<title>Sample <literal>Node</literal> object with a label</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">kind: Node
apiVersion: v1
metadata:
  name: ip-10-0-131-14.ec2.internal
  selfLink: /api/v1/nodes/ip-10-0-131-14.ec2.internal
  uid: 7bc2580a-8b8e-11e9-8e01-021ab4174c74
  resourceVersion: '478704'
  creationTimestamp: '2019-06-10T14:46:08Z'
  labels:
    kubernetes.io/os: linux
    topology.kubernetes.io/zone: us-east-1a
    node.openshift.io/os_version: '4.5'
    node-role.kubernetes.io/worker: ''
    topology.kubernetes.io/region: us-east-1
    node.openshift.io/os_id: rhcos
    node.kubernetes.io/instance-type: m4.large
    kubernetes.io/hostname: ip-10-0-131-14
    kubernetes.io/arch: amd64
    region: east <co xml:id="CO79-1"/>
    type: user-node
#...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO79-1">
<para>Labels to match the pod node selector.</para>
</callout>
</calloutlist>
<simpara>A pod has the <literal>type: user-node,region: east</literal> node selector:</simpara>
<formalpara>
<title>Sample <literal>Pod</literal> object with node selectors</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  name: s1
#...
spec:
  nodeSelector: <co xml:id="CO80-1"/>
    region: east
    type: user-node
#...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO80-1">
<para>Node selectors to match the node label. The node must have a label for each node selector.</para>
</callout>
</calloutlist>
<simpara>When you create the pod using the example pod spec, it can be scheduled on the example node.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Default cluster-wide node selectors</term>
<listitem>
<simpara>With default cluster-wide node selectors, when you create a pod in that cluster, OpenShift Container Platform adds the default node selectors to the pod and schedules
the pod on nodes with matching labels.</simpara>
<simpara>For example, the following <literal>Scheduler</literal> object has the default cluster-wide <literal>region=east</literal> and <literal>type=user-node</literal> node selectors:</simpara>
<formalpara>
<title>Example Scheduler Operator Custom Resource</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: config.openshift.io/v1
kind: Scheduler
metadata:
  name: cluster
#...
spec:
  defaultNodeSelector: type=user-node,region=east
#...</programlisting>
</para>
</formalpara>
<simpara>A node in that cluster has the <literal>type=user-node,region=east</literal> labels:</simpara>
<formalpara>
<title>Example <literal>Node</literal> object</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Node
metadata:
  name: ci-ln-qg1il3k-f76d1-hlmhl-worker-b-df2s4
#...
  labels:
    region: east
    type: user-node
#...</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example <literal>Pod</literal> object with a node selector</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  name: s1
#...
spec:
  nodeSelector:
    region: east
#...</programlisting>
</para>
</formalpara>
<simpara>When you create the pod using the example pod spec in the example cluster, the pod is created with the cluster-wide node selector and is scheduled on the labeled node:</simpara>
<formalpara>
<title>Example pod list with the pod on the labeled node</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME     READY   STATUS    RESTARTS   AGE   IP           NODE                                       NOMINATED NODE   READINESS GATES
pod-s1   1/1     Running   0          20s   10.131.2.6   ci-ln-qg1il3k-f76d1-hlmhl-worker-b-df2s4   &lt;none&gt;           &lt;none&gt;</programlisting>
</para>
</formalpara>
<note>
<simpara>If the project where you create the pod has a project node selector, that selector takes preference over a cluster-wide node selector. Your pod is not created or scheduled if the pod does not have the project node selector.</simpara>
</note>
</listitem>
</varlistentry>
</variablelist>
<variablelist xml:id="project-node-selectors_logging-node-selectors">
<varlistentry>
<term>Project node selectors</term>
<listitem>
<simpara>With project node selectors, when you create a pod in this project, OpenShift Container Platform adds the node selectors to the pod and schedules the pods on a node with matching labels. If there is a cluster-wide default node selector, a project node selector takes preference.</simpara>
<simpara>For example, the following project has the <literal>region=east</literal> node selector:</simpara>
<formalpara>
<title>Example <literal>Namespace</literal> object</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Namespace
metadata:
  name: east-region
  annotations:
    openshift.io/node-selector: "region=east"
#...</programlisting>
</para>
</formalpara>
<simpara>The following node has the <literal>type=user-node,region=east</literal> labels:</simpara>
<formalpara>
<title>Example <literal>Node</literal> object</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Node
metadata:
  name: ci-ln-qg1il3k-f76d1-hlmhl-worker-b-df2s4
#...
  labels:
    region: east
    type: user-node
#...</programlisting>
</para>
</formalpara>
<simpara>When you create the pod using the example pod spec in this example project, the pod is created with the project node selectors and is scheduled on the labeled node:</simpara>
<formalpara>
<title>Example <literal>Pod</literal> object</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  namespace: east-region
#...
spec:
  nodeSelector:
    region: east
    type: user-node
#...</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example pod list with the pod on the labeled node</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME     READY   STATUS    RESTARTS   AGE   IP           NODE                                       NOMINATED NODE   READINESS GATES
pod-s1   1/1     Running   0          20s   10.131.2.6   ci-ln-qg1il3k-f76d1-hlmhl-worker-b-df2s4   &lt;none&gt;           &lt;none&gt;</programlisting>
</para>
</formalpara>
<simpara>A pod in the project is not created or scheduled if the pod contains different node selectors. For example, if you deploy the following pod into the example project, it is not be created:</simpara>
<formalpara>
<title>Example <literal>Pod</literal> object with an invalid node selector</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  name: west-region
#...
spec:
  nodeSelector:
    region: west
#...</programlisting>
</para>
</formalpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section xml:id="infrastructure-moving-logging_logging-node-selectors">
<title>Moving logging resources</title>
<simpara>You can configure the Red Hat OpenShift Logging Operator to deploy the pods for logging components, such as Elasticsearch and Kibana, to different nodes. You cannot move the Red Hat OpenShift Logging Operator pod from its installed location.</simpara>
<simpara>For example, you can move the Elasticsearch pods to a separate node because of high CPU, memory, and disk requirements.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator and the OpenShift Elasticsearch Operator.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Edit the <literal>ClusterLogging</literal> custom resource (CR) in the <literal>openshift-logging</literal> project:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc edit ClusterLogging instance</programlisting>
<formalpara>
<title>Example <literal>ClusterLogging</literal> CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
# ...
spec:
  logStore:
    elasticsearch:
      nodeCount: 3
      nodeSelector: <co xml:id="CO81-1"/>
        node-role.kubernetes.io/infra: ''
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/infra
        value: reserved
      - effect: NoExecute
        key: node-role.kubernetes.io/infra
        value: reserved
      redundancyPolicy: SingleRedundancy
      resources:
        limits:
          cpu: 500m
          memory: 16Gi
        requests:
          cpu: 500m
          memory: 16Gi
      storage: {}
    type: elasticsearch
  managementState: Managed
  visualization:
    kibana:
      nodeSelector: <co xml:id="CO81-2"/>
        node-role.kubernetes.io/infra: ''
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/infra
        value: reserved
      - effect: NoExecute
        key: node-role.kubernetes.io/infra
        value: reserved
      proxy:
        resources: null
      replicas: 1
      resources: null
    type: kibana
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO81-1 CO81-2">
<para>Add a <literal>nodeSelector</literal> parameter with the appropriate value to the component you want to move. You can use a <literal>nodeSelector</literal> in the format shown or use <literal>&lt;key&gt;: &lt;value&gt;</literal> pairs, based on the value specified for the node.  If you added a taint to the infrasructure node, also add a matching toleration.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
<formalpara>
<title>Verification</title>
<para>To verify that a component has moved, you can use the <literal>oc get pod -o wide</literal> command.</para>
</formalpara>
<simpara>For example:</simpara>
<itemizedlist>
<listitem>
<simpara>You want to move the Kibana pod from the <literal>ip-10-0-147-79.us-east-2.compute.internal</literal> node:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pod kibana-5b8bdf44f9-ccpq9 -o wide</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                      READY   STATUS    RESTARTS   AGE   IP            NODE                                        NOMINATED NODE   READINESS GATES
kibana-5b8bdf44f9-ccpq9   2/2     Running   0          27s   10.129.2.18   ip-10-0-147-79.us-east-2.compute.internal   &lt;none&gt;           &lt;none&gt;</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>You want to move the Kibana pod to the <literal>ip-10-0-139-48.us-east-2.compute.internal</literal> node, a dedicated infrastructure node:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get nodes</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                                         STATUS   ROLES          AGE   VERSION
ip-10-0-133-216.us-east-2.compute.internal   Ready    master         60m   v1.28.5
ip-10-0-139-146.us-east-2.compute.internal   Ready    master         60m   v1.28.5
ip-10-0-139-192.us-east-2.compute.internal   Ready    worker         51m   v1.28.5
ip-10-0-139-241.us-east-2.compute.internal   Ready    worker         51m   v1.28.5
ip-10-0-147-79.us-east-2.compute.internal    Ready    worker         51m   v1.28.5
ip-10-0-152-241.us-east-2.compute.internal   Ready    master         60m   v1.28.5
ip-10-0-139-48.us-east-2.compute.internal    Ready    infra          51m   v1.28.5</programlisting>
</para>
</formalpara>
<simpara>Note that the node has a <literal>node-role.kubernetes.io/infra: ''</literal> label:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get node ip-10-0-139-48.us-east-2.compute.internal -o yaml</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">kind: Node
apiVersion: v1
metadata:
  name: ip-10-0-139-48.us-east-2.compute.internal
  selfLink: /api/v1/nodes/ip-10-0-139-48.us-east-2.compute.internal
  uid: 62038aa9-661f-41d7-ba93-b5f1b6ef8751
  resourceVersion: '39083'
  creationTimestamp: '2020-04-13T19:07:55Z'
  labels:
    node-role.kubernetes.io/infra: ''
...</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>To move the Kibana pod, edit the <literal>ClusterLogging</literal> CR to add a node selector:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
# ...
spec:
# ...
  visualization:
    kibana:
      nodeSelector: <co xml:id="CO82-1"/>
        node-role.kubernetes.io/infra: ''
      proxy:
        resources: null
      replicas: 1
      resources: null
    type: kibana</programlisting>
<calloutlist>
<callout arearefs="CO82-1">
<para>Add a node selector to match the label in the node specification.</para>
</callout>
</calloutlist>
</listitem>
<listitem>
<simpara>After you save the CR, the current Kibana pod is terminated and new pod is deployed:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                                            READY   STATUS        RESTARTS   AGE
cluster-logging-operator-84d98649c4-zb9g7       1/1     Running       0          29m
elasticsearch-cdm-hwv01pf7-1-56588f554f-kpmlg   2/2     Running       0          28m
elasticsearch-cdm-hwv01pf7-2-84c877d75d-75wqj   2/2     Running       0          28m
elasticsearch-cdm-hwv01pf7-3-f5d95b87b-4nx78    2/2     Running       0          28m
collector-42dzz                                 1/1     Running       0          28m
collector-d74rq                                 1/1     Running       0          28m
collector-m5vr9                                 1/1     Running       0          28m
collector-nkxl7                                 1/1     Running       0          28m
collector-pdvqb                                 1/1     Running       0          28m
collector-tflh6                                 1/1     Running       0          28m
kibana-5b8bdf44f9-ccpq9                         2/2     Terminating   0          4m11s
kibana-7d85dcffc8-bfpfp                         2/2     Running       0          33s</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>The new pod is on the <literal>ip-10-0-139-48.us-east-2.compute.internal</literal> node:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pod kibana-7d85dcffc8-bfpfp -o wide</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                      READY   STATUS        RESTARTS   AGE   IP            NODE                                        NOMINATED NODE   READINESS GATES
kibana-7d85dcffc8-bfpfp   2/2     Running       0          43s   10.131.0.22   ip-10-0-139-48.us-east-2.compute.internal   &lt;none&gt;           &lt;none&gt;</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>After a few moments, the original Kibana pod is removed.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get pods</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">NAME                                            READY   STATUS    RESTARTS   AGE
cluster-logging-operator-84d98649c4-zb9g7       1/1     Running   0          30m
elasticsearch-cdm-hwv01pf7-1-56588f554f-kpmlg   2/2     Running   0          29m
elasticsearch-cdm-hwv01pf7-2-84c877d75d-75wqj   2/2     Running   0          29m
elasticsearch-cdm-hwv01pf7-3-f5d95b87b-4nx78    2/2     Running   0          29m
collector-42dzz                                 1/1     Running   0          29m
collector-d74rq                                 1/1     Running   0          29m
collector-m5vr9                                 1/1     Running   0          29m
collector-nkxl7                                 1/1     Running   0          29m
collector-pdvqb                                 1/1     Running   0          29m
collector-tflh6                                 1/1     Running   0          29m
kibana-7d85dcffc8-bfpfp                         2/2     Running   0          62s</programlisting>
</para>
</formalpara>
</listitem>
</itemizedlist>
</section>
<section xml:id="additional-resources_logging-node-selection" role="_additional-resources">
<title>Additional resources</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/nodes/#nodes-scheduler-node-selectors">Placing pods on specific nodes using node selectors</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section xml:id="logging-taints-tolerations">
<title>Using taints and tolerations to control logging pod placement</title>

<simpara>Taints and tolerations allow the node to control which pods should (or should not) be scheduled on them.</simpara>
<section xml:id="nodes-scheduler-taints-tolerations-about_logging-taints-tolerations">
<title>Understanding taints and tolerations</title>
<simpara>A <emphasis>taint</emphasis> allows a node to refuse a pod to be scheduled unless that pod has a matching <emphasis>toleration</emphasis>.</simpara>
<simpara>You apply taints to a node through the <literal>Node</literal> specification (<literal>NodeSpec</literal>) and apply tolerations to a pod through the <literal>Pod</literal> specification (<literal>PodSpec</literal>). When you apply a taint a node, the scheduler cannot place a pod on that node unless the pod can tolerate the taint.</simpara>
<formalpara>
<title>Example taint in a node specification</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Node
metadata:
  name: my-node
#...
spec:
  taints:
  - effect: NoExecute
    key: key1
    value: value1
#...</programlisting>
</para>
</formalpara>
<formalpara>
<title>Example toleration in a <literal>Pod</literal> spec</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  name: my-pod
#...
spec:
  tolerations:
  - key: "key1"
    operator: "Equal"
    value: "value1"
    effect: "NoExecute"
    tolerationSeconds: 3600
#...</programlisting>
</para>
</formalpara>
<simpara>Taints and tolerations consist of a key, value, and effect.</simpara>
<table xml:id="taint-components-table_logging-taints-tolerations" frame="all" rowsep="1" colsep="1">
<title>Taint and toleration components</title>
<tgroup cols="2">
<colspec colname="col_1" colwidth="27.2727*"/>
<colspec colname="col_2" colwidth="72.7273*"/>
<thead>
<row>
<entry align="left" valign="top">Parameter</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>key</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The <literal>key</literal> is any string, up to 253 characters. The key must begin with a letter or number, and may contain letters, numbers, hyphens, dots, and underscores.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>value</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The <literal>value</literal> is any string, up to 63 characters. The value must begin with a letter or number, and may contain letters, numbers, hyphens, dots, and underscores.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>effect</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The effect is one of the following:</simpara>
<informaltable frame="none" rowsep="1" colsep="1">
<tgroup cols="2">
<colspec colname="col_1" colwidth="40*"/>
<colspec colname="col_2" colwidth="60*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>NoSchedule</literal> <superscript>[1]</superscript></simpara></entry>
<entry align="left" valign="top"><itemizedlist>
<listitem>
<simpara>New pods that do not match the taint are not scheduled onto that node.</simpara>
</listitem>
<listitem>
<simpara>Existing pods on the node remain.</simpara>
</listitem>
</itemizedlist></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>PreferNoSchedule</literal></simpara></entry>
<entry align="left" valign="top"><itemizedlist>
<listitem>
<simpara>New pods that do not match the taint might be scheduled onto that node, but the scheduler tries not to.</simpara>
</listitem>
<listitem>
<simpara>Existing pods on the node remain.</simpara>
</listitem>
</itemizedlist></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>NoExecute</literal></simpara></entry>
<entry align="left" valign="top"><itemizedlist>
<listitem>
<simpara>New pods that do not match the taint cannot be scheduled onto that node.</simpara>
</listitem>
<listitem>
<simpara>Existing pods on the node that do not have a matching toleration  are removed.</simpara>
</listitem>
</itemizedlist></entry>
</row>
</tbody>
</tgroup>
</informaltable></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>operator</literal></simpara></entry>
<entry align="left" valign="top"><informaltable frame="none" rowsep="1" colsep="1">
<tgroup cols="2">
<colspec colname="col_1" colwidth="40*"/>
<colspec colname="col_2" colwidth="60*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>Equal</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The <literal>key</literal>/<literal>value</literal>/<literal>effect</literal> parameters must match. This is the default.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>Exists</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The <literal>key</literal>/<literal>effect</literal> parameters must match. You must leave a blank <literal>value</literal> parameter, which matches any.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable></entry>
</row>
</tbody>
</tgroup>
</table>
<para role="small">
<orderedlist numeration="arabic">
<listitem>
<simpara>If you add a <literal>NoSchedule</literal> taint to a control plane node, the node must have the <literal>node-role.kubernetes.io/master=:NoSchedule</literal> taint, which is added by default.</simpara>
<simpara>For example:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Node
metadata:
  annotations:
    machine.openshift.io/machine: openshift-machine-api/ci-ln-62s7gtb-f76d1-v8jxv-master-0
    machineconfiguration.openshift.io/currentConfig: rendered-master-cdc1ab7da414629332cc4c3926e6e59c
  name: my-node
#...
spec:
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
#...</programlisting>
</listitem>
</orderedlist>
</para>
<simpara>A toleration matches a taint:</simpara>
<itemizedlist>
<listitem>
<simpara>If the <literal>operator</literal> parameter is set to <literal>Equal</literal>:</simpara>
<itemizedlist>
<listitem>
<simpara>the <literal>key</literal> parameters are the same;</simpara>
</listitem>
<listitem>
<simpara>the <literal>value</literal> parameters are the same;</simpara>
</listitem>
<listitem>
<simpara>the <literal>effect</literal> parameters are the same.</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>If the <literal>operator</literal> parameter is set to <literal>Exists</literal>:</simpara>
<itemizedlist>
<listitem>
<simpara>the <literal>key</literal> parameters are the same;</simpara>
</listitem>
<listitem>
<simpara>the <literal>effect</literal> parameters are the same.</simpara>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist>
<simpara>The following taints are built into OpenShift Container Platform:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>node.kubernetes.io/not-ready</literal>: The node is not ready. This corresponds to the node condition <literal>Ready=False</literal>.</simpara>
</listitem>
<listitem>
<simpara><literal>node.kubernetes.io/unreachable</literal>: The node is unreachable from the node controller. This corresponds to the node condition <literal>Ready=Unknown</literal>.</simpara>
</listitem>
<listitem>
<simpara><literal>node.kubernetes.io/memory-pressure</literal>: The node has memory pressure issues. This corresponds to the node condition <literal>MemoryPressure=True</literal>.</simpara>
</listitem>
<listitem>
<simpara><literal>node.kubernetes.io/disk-pressure</literal>: The node has disk pressure issues. This corresponds to the node condition <literal>DiskPressure=True</literal>.</simpara>
</listitem>
<listitem>
<simpara><literal>node.kubernetes.io/network-unavailable</literal>: The node network is unavailable.</simpara>
</listitem>
<listitem>
<simpara><literal>node.kubernetes.io/unschedulable</literal>: The node is unschedulable.</simpara>
</listitem>
<listitem>
<simpara><literal>node.cloudprovider.kubernetes.io/uninitialized</literal>: When the node controller is started with an external cloud provider, this taint is set on a node to mark it as unusable. After a controller from the cloud-controller-manager initializes this node, the kubelet removes this taint.</simpara>
</listitem>
<listitem>
<simpara><literal>node.kubernetes.io/pid-pressure</literal>: The node has pid pressure. This corresponds to the node condition <literal>PIDPressure=True</literal>.</simpara>
<important>
<simpara>OpenShift Container Platform does not set a default pid.available <literal>evictionHard</literal>.</simpara>
</important>
</listitem>
</itemizedlist>
</section>
<section xml:id="cluster-logging-logstore-tolerations_logging-taints-tolerations">
<title>Using tolerations to control log store pod placement</title>
<simpara>By default, log store pods have the following toleration configurations:</simpara>
<formalpara>
<title>Elasticsearch log store pods default tolerations</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  name: elasticsearch-example
  namespace: openshift-logging
spec:
# ...
  tolerations:
  - effect: NoSchedule
    key: node.kubernetes.io/disk-pressure
    operator: Exists
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  - effect: NoSchedule
    key: node.kubernetes.io/memory-pressure
    operator: Exists
# ...</programlisting>
</para>
</formalpara>
<formalpara>
<title>LokiStack log store pods default tolerations</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  name: lokistack-example
  namespace: openshift-logging
spec:
# ...
  tolerations:
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  - effect: NoSchedule
    key: node.kubernetes.io/memory-pressure
    operator: Exists
# ...</programlisting>
</para>
</formalpara>
<simpara>You can configure a toleration for log store pods by adding a taint and then modifying the <literal>tolerations</literal> syntax in the <literal>ClusterLogging</literal> custom resource (CR).</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator.</simpara>
</listitem>
<listitem>
<simpara>You have installed the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
<listitem>
<simpara>You have deployed an internal log store that is either Elasticsearch or LokiStack.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Add a taint to a node where you want to schedule the logging pods, by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm taint nodes &lt;node_name&gt; &lt;key&gt;=&lt;value&gt;:&lt;effect&gt;</programlisting>
<formalpara>
<title>Example command</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm taint nodes node1 lokistack=node:NoExecute</programlisting>
</para>
</formalpara>
<simpara>This example places a taint on <literal>node1</literal> that has key <literal>lokistack</literal>, value <literal>node</literal>, and taint effect <literal>NoExecute</literal>. Nodes with the <literal>NoExecute</literal> effect schedule only pods that match the taint and remove existing pods that do not match.</simpara>
</listitem>
<listitem>
<simpara>Edit the <literal>logstore</literal> section of the <literal>ClusterLogging</literal> CR to configure a toleration for the log store pods:</simpara>
<formalpara>
<title>Example <literal>ClusterLogging</literal> CR</title>
<para>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
# ...
spec:
# ...
  logStore:
    type: lokistack
    elasticsearch:
      nodeCount: 1
      tolerations:
      - key: lokistack <co xml:id="CO83-1"/>
        operator: Exists <co xml:id="CO83-2"/>
        effect: NoExecute <co xml:id="CO83-3"/>
        tolerationSeconds: 6000 <co xml:id="CO83-4"/>
# ...</programlisting>
</para>
</formalpara>
<calloutlist>
<callout arearefs="CO83-1">
<para>Specify the key that you added to the node.</para>
</callout>
<callout arearefs="CO83-2">
<para>Specify the <literal>Exists</literal> operator to require a taint with the key <literal>lokistack</literal> to be present on the node.</para>
</callout>
<callout arearefs="CO83-3">
<para>Specify the <literal>NoExecute</literal> effect.</para>
</callout>
<callout arearefs="CO83-4">
<para>Optional: Specify the <literal>tolerationSeconds</literal> parameter to set how long a pod can remain bound to a node before being evicted.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
<simpara>This toleration matches the taint created by the <literal>oc adm taint</literal> command. A pod with this toleration can be scheduled onto <literal>node1</literal>.</simpara>
</section>
<section xml:id="cluster-logging-kibana-tolerations_logging-taints-tolerations">
<title>Using tolerations to control the log visualizer pod placement</title>
<simpara>You can use a specific key/value pair that is not on other pods to ensure that only the Kibana pod can run on the specified node.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator, the OpenShift Elasticsearch Operator, and the OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Add a taint to a node where you want to schedule the log visualizer pod by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm taint nodes &lt;node_name&gt; &lt;key&gt;=&lt;value&gt;:&lt;effect&gt;</programlisting>
<formalpara>
<title>Example command</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm taint nodes node1 kibana=node:NoExecute</programlisting>
</para>
</formalpara>
<simpara>This example places a taint on <literal>node1</literal> that has key <literal>kibana</literal>, value <literal>node</literal>, and taint effect <literal>NoExecute</literal>. You must use the <literal>NoExecute</literal> taint effect. <literal>NoExecute</literal> schedules only pods that match the taint and remove existing pods that do not match.</simpara>
</listitem>
<listitem>
<simpara>Edit the <literal>visualization</literal> section of the <literal>ClusterLogging</literal> CR to configure a toleration for the Kibana pod:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
# ...
spec:
# ...
  visualization:
    type: kibana
    kibana:
      tolerations:
      - key: kibana  <co xml:id="CO84-1"/>
        operator: Exists <co xml:id="CO84-2"/>
        effect: NoExecute <co xml:id="CO84-3"/>
        tolerationSeconds: 6000 <co xml:id="CO84-4"/>
      resources:
        limits:
          memory: 2Gi
        requests:
          cpu: 100m
          memory: 1Gi
      replicas: 1
# ...</programlisting>
<calloutlist>
<callout arearefs="CO84-1">
<para>Specify the key that you added to the node.</para>
</callout>
<callout arearefs="CO84-2">
<para>Specify the <literal>Exists</literal> operator to require the <literal>key</literal>, value, and <literal>effect</literal> parameters to match.</para>
</callout>
<callout arearefs="CO84-3">
<para>Specify the <literal>NoExecute</literal> effect.</para>
</callout>
<callout arearefs="CO84-4">
<para>Optionally, specify the <literal>tolerationSeconds</literal> parameter to set how long a pod can remain bound to a node before being evicted.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
<simpara>This toleration matches the taint created by the <literal>oc adm taint</literal> command. A pod with this toleration would be able to schedule onto <literal>node1</literal>.</simpara>
</section>
<section xml:id="cluster-logging-collector-tolerations_logging-taints-tolerations">
<title>Using tolerations to control log collector pod placement</title>
<simpara>By default, log collector pods have the following <literal>tolerations</literal> configuration:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: v1
kind: Pod
metadata:
  name: collector-example
  namespace: openshift-logging
spec:
# ...
  collection:
    type: vector
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
# ...</programlisting>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have installed the Red Hat OpenShift Logging Operator and OpenShift CLI (<literal>oc</literal>).</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Add a taint to a node where you want logging collector pods to schedule logging collector pods by running the following command:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm taint nodes &lt;node_name&gt; &lt;key&gt;=&lt;value&gt;:&lt;effect&gt;</programlisting>
<formalpara>
<title>Example command</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">$ oc adm taint nodes node1 collector=node:NoExecute</programlisting>
</para>
</formalpara>
<simpara>This example places a taint on <literal>node1</literal> that has key <literal>collector</literal>, value <literal>node</literal>, and taint effect <literal>NoExecute</literal>. You must use the <literal>NoExecute</literal> taint effect. <literal>NoExecute</literal> schedules only pods that match the taint and removes existing pods that do not match.</simpara>
</listitem>
<listitem>
<simpara>Edit the <literal>collection</literal> stanza of the <literal>ClusterLogging</literal> custom resource (CR) to configure a toleration for the logging collector pods:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
# ...
spec:
# ...
  collection:
    type: vector
    tolerations:
    - key: collector <co xml:id="CO85-1"/>
      operator: Exists <co xml:id="CO85-2"/>
      effect: NoExecute <co xml:id="CO85-3"/>
      tolerationSeconds: 6000 <co xml:id="CO85-4"/>
    resources:
      limits:
        memory: 2Gi
      requests:
        cpu: 100m
        memory: 1Gi
# ...</programlisting>
<calloutlist>
<callout arearefs="CO85-1">
<para>Specify the key that you added to the node.</para>
</callout>
<callout arearefs="CO85-2">
<para>Specify the <literal>Exists</literal> operator to require the <literal>key</literal>/<literal>value</literal>/<literal>effect</literal> parameters to match.</para>
</callout>
<callout arearefs="CO85-3">
<para>Specify the <literal>NoExecute</literal> effect.</para>
</callout>
<callout arearefs="CO85-4">
<para>Optionally, specify the <literal>tolerationSeconds</literal> parameter to set how long a pod can remain bound to a node before being evicted.</para>
</callout>
</calloutlist>
</listitem>
</orderedlist>
<simpara>This toleration matches the taint created by the <literal>oc adm taint</literal> command. A pod with this toleration can be scheduled onto <literal>node1</literal>.</simpara>
</section>
<section xml:id="additional-resources_cluster-logging-tolerations" role="_additional-resources">
<title>Additional resources</title>
<itemizedlist>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/nodes/#nodes-scheduler-taints-tolerations">Controlling pod placement using node taints</link></simpara>
</listitem>
</itemizedlist>
</section>
</section>
</chapter>
<chapter xml:id="cluster-logging-uninstall">
<title>Uninstalling Logging</title>

<simpara>You can remove logging from your OpenShift Container Platform cluster by removing installed Operators and related custom resources (CRs).</simpara>
<section xml:id="uninstall-cluster-logging-operator_cluster-logging-uninstall">
<title>Uninstalling the logging</title>
<simpara>You can stop aggregating logs by deleting the Red Hat OpenShift Logging Operator and the <literal>ClusterLogging</literal> custom resource (CR).</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have access to the <emphasis role="strong">Administrator</emphasis> perspective of the OpenShift Container Platform web console.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Go to the <emphasis role="strong">Administration</emphasis> &#8594; <emphasis role="strong">Custom Resource Definitions</emphasis> page, and click <emphasis role="strong">ClusterLogging</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>On the <emphasis role="strong">Custom Resource Definition Details</emphasis> page, click <emphasis role="strong">Instances</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click the options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> next to the instance, and click <emphasis role="strong">Delete ClusterLogging</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Go to the <emphasis role="strong">Administration</emphasis> &#8594; <emphasis role="strong">Custom Resource Definitions</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Click the options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> next to <emphasis role="strong">ClusterLogging</emphasis>, and select <emphasis role="strong">Delete Custom Resource Definition</emphasis>.</simpara>
<warning>
<simpara>Deleting the <literal>ClusterLogging</literal> CR does not remove the persistent volume claims (PVCs). To delete the remaining PVCs, persistent volumes (PVs), and associated data, you must take further action. Releasing or deleting PVCs can delete PVs and cause data loss.</simpara>
</warning>
</listitem>
<listitem>
<simpara>If you have created a <literal>ClusterLogForwarder</literal> CR, click the options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> next to <emphasis role="strong">ClusterLogForwarder</emphasis>, and then click <emphasis role="strong">Delete Custom Resource Definition</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Go to the <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Click the options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> next to the Red Hat OpenShift Logging Operator, and then click <emphasis role="strong">Uninstall Operator</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Optional: Delete the <literal>openshift-logging</literal> project.</simpara>
<warning>
<simpara>Deleting the <literal>openshift-logging</literal> project deletes everything in that namespace, including any persistent volume claims (PVCs). If you want to preserve logging data, do not delete the <literal>openshift-logging</literal> project.</simpara>
</warning>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Go to the <emphasis role="strong">Home</emphasis> &#8594; <emphasis role="strong">Projects</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Click the options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> next to the <emphasis role="strong">openshift-logging</emphasis> project, and then click <emphasis role="strong">Delete Project</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Confirm the deletion by typing <literal>openshift-logging</literal> in the dialog box, and then click <emphasis role="strong">Delete</emphasis>.</simpara>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
</section>
<section xml:id="uninstall-logging-delete-pvcs_cluster-logging-uninstall">
<title>Deleting logging PVCs</title>
<simpara>To keep persistent volume claims (PVCs) for reuse with other pods, keep the labels or PVC names that you need to reclaim the PVCs.
If you do not want to keep the PVCs, you can delete them. If you want to recover storage space, you can also delete the persistent volumes (PVs).</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have access to the <emphasis role="strong">Administrator</emphasis> perspective of the OpenShift Container Platform web console.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Go to the <emphasis role="strong">Storage</emphasis> &#8594; <emphasis role="strong">Persistent Volume Claims</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Click the options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> next to each PVC, and select <emphasis role="strong">Delete Persistent Volume Claim</emphasis>.</simpara>
</listitem>
</orderedlist>
</section>
<section xml:id="uninstall-loki-operator_cluster-logging-uninstall">
<title>Uninstalling Loki</title>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have access to the <emphasis role="strong">Administrator</emphasis> perspective of the OpenShift Container Platform web console.</simpara>
</listitem>
<listitem>
<simpara>If you have not already removed the Red Hat OpenShift Logging Operator and related resources, you have removed references to LokiStack from the <literal>ClusterLogging</literal> custom resource.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Go to the <emphasis role="strong">Administration</emphasis> &#8594; <emphasis role="strong">Custom Resource Definitions</emphasis> page, and click <emphasis role="strong">LokiStack</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>On the <emphasis role="strong">Custom Resource Definition Details</emphasis> page, click <emphasis role="strong">Instances</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click the options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> next to the instance, and then click <emphasis role="strong">Delete LokiStack</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Go to the <emphasis role="strong">Administration</emphasis> &#8594; <emphasis role="strong">Custom Resource Definitions</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Click the options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> next to <emphasis role="strong">LokiStack</emphasis>, and select <emphasis role="strong">Delete Custom Resource Definition</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Delete the object storage secret.</simpara>
</listitem>
<listitem>
<simpara>Go to the <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Click the options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> next to the Loki Operator, and then click <emphasis role="strong">Uninstall Operator</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Optional: Delete the <literal>openshift-operators-redhat</literal> project.</simpara>
<important>
<simpara>Do not delete the <literal>openshift-operators-redhat</literal> project if other global Operators are installed in this namespace.</simpara>
</important>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Go to the <emphasis role="strong">Home</emphasis> &#8594; <emphasis role="strong">Projects</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Click the options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> next to the <emphasis role="strong">openshift-operators-redhat</emphasis> project, and then click <emphasis role="strong">Delete Project</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Confirm the deletion by typing <literal>openshift-operators-redhat</literal> in the dialog box, and then click <emphasis role="strong">Delete</emphasis>.</simpara>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
</section>
<section xml:id="uninstall-es-operator_cluster-logging-uninstall">
<title>Uninstalling Elasticsearch</title>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have administrator permissions.</simpara>
</listitem>
<listitem>
<simpara>You have access to the <emphasis role="strong">Administrator</emphasis> perspective of the OpenShift Container Platform web console.</simpara>
</listitem>
<listitem>
<simpara>If you have not already removed the Red Hat OpenShift Logging Operator and related resources, you must remove references to Elasticsearch from the <literal>ClusterLogging</literal> custom resource.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Go to the <emphasis role="strong">Administration</emphasis> &#8594; <emphasis role="strong">Custom Resource Definitions</emphasis> page, and click <emphasis role="strong">Elasticsearch</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>On the <emphasis role="strong">Custom Resource Definition Details</emphasis> page, click <emphasis role="strong">Instances</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Click the options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> next to the instance, and then click <emphasis role="strong">Delete Elasticsearch</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Go to the <emphasis role="strong">Administration</emphasis> &#8594; <emphasis role="strong">Custom Resource Definitions</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Click the options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> next to <emphasis role="strong">Elasticsearch</emphasis>, and select <emphasis role="strong">Delete Custom Resource Definition</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Delete the object storage secret.</simpara>
</listitem>
<listitem>
<simpara>Go to the <emphasis role="strong">Operators</emphasis> &#8594; <emphasis role="strong">Installed Operators</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Click the options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> next to the OpenShift Elasticsearch Operator, and then click <emphasis role="strong">Uninstall Operator</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Optional: Delete the <literal>openshift-operators-redhat</literal> project.</simpara>
<important>
<simpara>Do not delete the <literal>openshift-operators-redhat</literal> project if other global Operators are installed in this namespace.</simpara>
</important>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>Go to the <emphasis role="strong">Home</emphasis> &#8594; <emphasis role="strong">Projects</emphasis> page.</simpara>
</listitem>
<listitem>
<simpara>Click the options menu <inlinemediaobject>
<imageobject>
<imagedata fileref="images/kebab.png"/>
</imageobject>
<textobject><phrase>kebab</phrase></textobject>
</inlinemediaobject> next to the <emphasis role="strong">openshift-operators-redhat</emphasis> project, and then click <emphasis role="strong">Delete Project</emphasis>.</simpara>
</listitem>
<listitem>
<simpara>Confirm the deletion by typing <literal>openshift-operators-redhat</literal> in the dialog box, and then click <emphasis role="strong">Delete</emphasis>.</simpara>
</listitem>
</orderedlist>
</listitem>
</orderedlist>
</section>
<section xml:id="olm-deleting-operator-from-a-cluster-using-cli_cluster-logging-uninstall">
<title>Deleting Operators from a cluster using the CLI</title>
<simpara>Cluster administrators can delete installed Operators from a selected namespace by using the CLI.</simpara>
<itemizedlist>
<title>Prerequisites</title>
<listitem>
<simpara>You have access to an OpenShift Container Platform cluster using an account with
<literal>cluster-admin</literal> permissions.</simpara>
</listitem>
<listitem>
<simpara>The OpenShift CLI (<literal>oc</literal>) is installed on your workstation.</simpara>
</listitem>
</itemizedlist>
<orderedlist numeration="arabic">
<title>Procedure</title>
<listitem>
<simpara>Ensure the latest version of the subscribed operator (for example, <literal>serverless-operator</literal>) is identified in the <literal>currentCSV</literal> field.</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc get subscription.operators.coreos.com serverless-operator -n openshift-serverless -o yaml | grep currentCSV</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">  currentCSV: serverless-operator.v1.28.0</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Delete the subscription (for example, <literal>serverless-operator</literal>):</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc delete subscription.operators.coreos.com serverless-operator -n openshift-serverless</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">subscription.operators.coreos.com "serverless-operator" deleted</programlisting>
</para>
</formalpara>
</listitem>
<listitem>
<simpara>Delete the CSV for the Operator in the target namespace using the <literal>currentCSV</literal> value from the previous step:</simpara>
<programlisting language="terminal" linenumbering="unnumbered">$ oc delete clusterserviceversion serverless-operator.v1.28.0 -n openshift-serverless</programlisting>
<formalpara>
<title>Example output</title>
<para>
<programlisting language="terminal" linenumbering="unnumbered">clusterserviceversion.operators.coreos.com "serverless-operator.v1.28.0" deleted</programlisting>
</para>
</formalpara>
</listitem>
</orderedlist>
<itemizedlist role="_additional-resources">
<title>Additional resources</title>
<listitem>
<simpara><link xlink:href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.14/html-single/storage/#reclaim-manual_understanding-persistent-storage">Reclaiming a persistent volume manually</link></simpara>
</listitem>
</itemizedlist>
</section>
</chapter>
<chapter xml:id="cluster-logging-exported-fields">
<title>Log Record Fields</title>

<simpara>The following fields can be present in log records exported by the logging. Although log records are typically formatted as JSON objects, the same data model can be applied to other encodings.</simpara>
<simpara>To search these fields from Elasticsearch and Kibana, use the full dotted field name when searching. For example, with an Elasticsearch <emphasis role="strong">/_search URL</emphasis>, to look for a Kubernetes pod name, use <literal>/_search/q=kubernetes.pod_name:name-of-my-pod</literal>.</simpara>
<simpara xml:id="cluster-logging-exported-fields-top-level-fields_cluster-logging-exported-fields">The top level fields may be present in every record.</simpara>
<bridgehead xml:id="_message" renderas="sect1">message</bridgehead>
<simpara>The original log entry text, UTF-8 encoded. This field may be absent or empty if a non-empty <literal>structured</literal> field is present. See the description of <literal>structured</literal> for more.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>text</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>HAPPY</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead xml:id="_structured" renderas="sect1">structured</bridgehead>
<simpara>Original log entry as a structured object. This field may be present if the forwarder was configured to parse structured JSON logs. If the original log entry was a valid structured log, this field will contain an equivalent JSON structure. Otherwise this field will be empty or absent, and the <literal>message</literal> field will contain the original log message. The <literal>structured</literal> field can have any subfields that are included in the log message, there are no restrictions defined here.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>group</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara>map[message:starting fluentd worker pid=21631 ppid=21618 worker=0 pid:21631 ppid:21618 worker:0]</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead xml:id="_timestamp" renderas="sect1">@timestamp</bridgehead>
<simpara>A UTC value that marks when the log payload was created or, if the creation time is not known, when the log payload was first collected. The “@” prefix denotes a field that is reserved for a particular use. By default, most tools look for “@timestamp” with ElasticSearch.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>date</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>2015-01-24 14:06:05.071000000 Z</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead xml:id="_hostname" renderas="sect1">hostname</bridgehead>
<simpara>The name of the host where this log message originated. In a Kubernetes cluster, this is the same as <literal>kubernetes.host</literal>.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead xml:id="_ipaddr4" renderas="sect1">ipaddr4</bridgehead>
<simpara>The IPv4 address of the source server. Can be an array.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>ip</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead xml:id="_ipaddr6" renderas="sect1">ipaddr6</bridgehead>
<simpara>The IPv6 address of the source server, if available. Can be an array.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>ip</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead xml:id="_level" renderas="sect1">level</bridgehead>
<simpara>The logging level from various sources, including <literal>rsyslog(severitytext property)</literal>, a Python logging module, and others.</simpara>
<simpara>The following values come from <link xlink:href="http://sourceware.org/git/?p=glibc.git;a=blob;f=misc/sys/syslog.h;h=ee01478c4b19a954426a96448577c5a76e6647c0;hb=HEAD#l74"><literal>syslog.h</literal></link>, and are preceded by their <link xlink:href="http://sourceware.org/git/?p=glibc.git;a=blob;f=misc/sys/syslog.h;h=ee01478c4b19a954426a96448577c5a76e6647c0;hb=HEAD#l51">numeric equivalents</link>:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>0</literal> = <literal>emerg</literal>, system is unusable.</simpara>
</listitem>
<listitem>
<simpara><literal>1</literal> = <literal>alert</literal>, action must be taken immediately.</simpara>
</listitem>
<listitem>
<simpara><literal>2</literal> = <literal>crit</literal>, critical conditions.</simpara>
</listitem>
<listitem>
<simpara><literal>3</literal> = <literal>err</literal>, error conditions.</simpara>
</listitem>
<listitem>
<simpara><literal>4</literal> = <literal>warn</literal>, warning conditions.</simpara>
</listitem>
<listitem>
<simpara><literal>5</literal> = <literal>notice</literal>, normal but significant condition.</simpara>
</listitem>
<listitem>
<simpara><literal>6</literal> = <literal>info</literal>, informational.</simpara>
</listitem>
<listitem>
<simpara><literal>7</literal> = <literal>debug</literal>, debug-level messages.</simpara>
</listitem>
</itemizedlist>
<simpara>The two following values are not part of <literal>syslog.h</literal> but are widely used:</simpara>
<itemizedlist>
<listitem>
<simpara><literal>8</literal> = <literal>trace</literal>, trace-level messages, which are more verbose than <literal>debug</literal> messages.</simpara>
</listitem>
<listitem>
<simpara><literal>9</literal> = <literal>unknown</literal>, when the logging system gets a value it doesn&#8217;t recognize.</simpara>
</listitem>
</itemizedlist>
<simpara>Map the log levels or priorities of other logging systems to their nearest match in the preceding list. For example, from <link xlink:href="https://docs.python.org/2.7/library/logging.html#logging-levels">python logging</link>, you can match <literal>CRITICAL</literal> with <literal>crit</literal>, <literal>ERROR</literal> with <literal>err</literal>, and so on.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>info</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead xml:id="_pid" renderas="sect1">pid</bridgehead>
<simpara>The process ID of the logging entity, if available.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead xml:id="_service" renderas="sect1">service</bridgehead>
<simpara>The name of the service associated with the logging entity, if available. For example, syslog&#8217;s <literal>APP-NAME</literal> and rsyslog&#8217;s <literal>programname</literal> properties are mapped to the service field.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</chapter>
<chapter xml:id="_tags">
<title>tags</title>
<simpara>Optional. An operator-defined list of tags placed on each log by the collector or normalizer. The payload can be a string with whitespace-delimited string tokens or a JSON list of string tokens.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>text</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead xml:id="_file" renderas="sect1">file</bridgehead>
<simpara>The path to the log file from which the collector reads this log entry. Normally, this is a path in the <literal>/var/log</literal> file system of a cluster node.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>text</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead xml:id="_offset" renderas="sect1">offset</bridgehead>
<simpara>The offset value. Can represent bytes to the start of the log line in the file (zero- or one-based), or log line numbers (zero- or one-based), so long as the values are strictly monotonically increasing in the context of a single log file. The values are allowed to wrap, representing a new version of the log file (rotation).</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>long</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</chapter>
<chapter xml:id="cluster-logging-exported-fields-kubernetes_cluster-logging-exported-fields">
<title>kubernetes</title>
<simpara>The namespace for Kubernetes-specific metadata</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>group</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<section xml:id="_kubernetes-pod_name">
<title>kubernetes.pod_name</title>
<simpara>The name of the pod</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-pod_id">
<title>kubernetes.pod_id</title>
<simpara>The Kubernetes ID of the pod</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-namespace_name">
<title>kubernetes.namespace_name</title>
<simpara>The name of the namespace in Kubernetes</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-namespace_id">
<title>kubernetes.namespace_id</title>
<simpara>The ID of the namespace in Kubernetes</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-host">
<title>kubernetes.host</title>
<simpara>The Kubernetes node name</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-container_name">
<title>kubernetes.container_name</title>
<simpara>The name of the container in Kubernetes</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-annotations">
<title>kubernetes.annotations</title>
<simpara>Annotations associated with the Kubernetes object</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>group</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-labels">
<title>kubernetes.labels</title>
<simpara>Labels present on the original Kubernetes Pod</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>group</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-event">
<title>kubernetes.event</title>
<simpara>The Kubernetes event obtained from the Kubernetes master API. This event description loosely follows <literal>type Event</literal> in <link xlink:href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#event-v1-core">Event v1 core</link>.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>group</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<section xml:id="_kubernetes-event-verb">
<title>kubernetes.event.verb</title>
<simpara>The type of event, <literal>ADDED</literal>, <literal>MODIFIED</literal>, or <literal>DELETED</literal></simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>ADDED</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-event-metadata">
<title>kubernetes.event.metadata</title>
<simpara>Information related to the location and time of the event creation</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>group</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<section xml:id="_kubernetes-event-metadata-name">
<title>kubernetes.event.metadata.name</title>
<simpara>The name of the object that triggered the event creation</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>java-mainclass-1.14d888a4cfc24890</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-event-metadata-namespace">
<title>kubernetes.event.metadata.namespace</title>
<simpara>The name of the namespace where the event originally occurred. Note that it differs from <literal>kubernetes.namespace_name</literal>, which is the namespace where the <literal>eventrouter</literal> application is deployed.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>default</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-event-metadata-selflink">
<title>kubernetes.event.metadata.selfLink</title>
<simpara>A link to the event</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>/api/v1/namespaces/javaj/events/java-mainclass-1.14d888a4cfc24890</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-event-metadata-uid">
<title>kubernetes.event.metadata.uid</title>
<simpara>The unique ID of the event</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>d828ac69-7b58-11e7-9cf5-5254002f560c</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-event-metadata-resourceversion">
<title>kubernetes.event.metadata.resourceVersion</title>
<simpara>A string that identifies the server&#8217;s internal version of the event. Clients can use this string to determine when objects have changed.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>integer</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>311987</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
<section xml:id="_kubernetes-event-involvedobject">
<title>kubernetes.event.involvedObject</title>
<simpara>The object that the event is about.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>group</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<section xml:id="_kubernetes-event-involvedobject-kind">
<title>kubernetes.event.involvedObject.kind</title>
<simpara>The type of object</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>ReplicationController</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-event-involvedobject-namespace">
<title>kubernetes.event.involvedObject.namespace</title>
<simpara>The namespace name of the involved object. Note that it may differ from <literal>kubernetes.namespace_name</literal>, which is the namespace where the <literal>eventrouter</literal> application is deployed.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>default</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-event-involvedobject-name">
<title>kubernetes.event.involvedObject.name</title>
<simpara>The name of the object that triggered the event</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>java-mainclass-1</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-event-involvedobject-uid">
<title>kubernetes.event.involvedObject.uid</title>
<simpara>The unique ID of the object</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>e6bff941-76a8-11e7-8193-5254002f560c</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-event-involvedobject-apiversion">
<title>kubernetes.event.involvedObject.apiVersion</title>
<simpara>The version of kubernetes master API</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>v1</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-event-involvedobject-resourceversion">
<title>kubernetes.event.involvedObject.resourceVersion</title>
<simpara>A string that identifies the server&#8217;s internal version of the pod that triggered the event. Clients can use this string to determine when objects have changed.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>308882</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
<section xml:id="_kubernetes-event-reason">
<title>kubernetes.event.reason</title>
<simpara>A short machine-understandable string that gives the reason for generating this event</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>SuccessfulCreate</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-event-source_component">
<title>kubernetes.event.source_component</title>
<simpara>The component that reported this event</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>replication-controller</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-event-firsttimestamp">
<title>kubernetes.event.firstTimestamp</title>
<simpara>The time at which the event was first recorded</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>date</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>2017-08-07 10:11:57.000000000 Z</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-event-count">
<title>kubernetes.event.count</title>
<simpara>The number of times this event has occurred</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>integer</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>1</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section xml:id="_kubernetes-event-type">
<title>kubernetes.event.type</title>
<simpara>The type of event, <literal>Normal</literal> or <literal>Warning</literal>. New types could be added in the future.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>keyword</simpara>
</entry>
</row>
<row>
<entry>
<simpara>Example value</simpara>
</entry>
<entry>
<simpara><literal>Normal</literal></simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</chapter>
<chapter xml:id="_openshift">
<title>OpenShift</title>
<simpara>The namespace for openshift-logging specific metadata</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>group</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<section xml:id="_openshift-labels">
<title>openshift.labels</title>
<simpara>Labels added by the Cluster Log Forwarder configuration</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0">
<tgroup cols="2">
<colspec colwidth="15*"/>
<colspec colwidth="85*"/>
<tbody valign="top">
<row>
<entry>
<simpara>Data type</simpara>
</entry>
<entry>
<simpara>group</simpara>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</chapter>
<chapter xml:id="_api-reference">
<title>API reference</title>
<section xml:id="logging-5-6-reference">
<title>5.6 Logging API reference</title>

<section xml:id="logging-5-6-api-ref">
<title>Logging 5.6 API reference</title>
<section xml:id="_clusterlogforwarder">
<title>ClusterLogForwarder</title>
<simpara>ClusterLogForwarder is an API to configure forwarding logs.</simpara>
<simpara>You configure forwarding by specifying a list of <literal>pipelines</literal>,
which forward from a set of named inputs to a set of named outputs.</simpara>
<simpara>There are built-in input names for common log categories, and you can
define custom inputs to do additional filtering.</simpara>
<simpara>There is a built-in output name for the default openshift log store, but
you can define your own outputs with a URL and other connection information
to forward logs to other stores or processors, inside or outside the cluster.</simpara>
<simpara>For more details see the documentation on the API fields.</simpara>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>spec</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>Specification of the desired behavior of ClusterLogForwarder</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>status</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>Status of the ClusterLogForwarder</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<section xml:id="_-spec">
<title>.spec</title>
<section xml:id="_description">
<title>Description</title>
<simpara>ClusterLogForwarderSpec defines how logs should be forwarded to remote targets.</simpara>
<section xml:id="_type">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>inputs</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Inputs are named filters for log messages to be forwarded.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>outputDefaults</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> DEPRECATED OutputDefaults specify forwarder config explicitly for the default store.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>outputs</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Outputs are named destinations for log messages.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>pipelines</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara>Pipelines forward the messages selected by a set of inputs to a set of outputs.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-inputs">
<title>.spec.inputs[]</title>
<section xml:id="_description-2">
<title>Description</title>
<simpara>InputSpec defines a selector of log messages.</simpara>
<section xml:id="_type-2">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>application</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Application, if present, enables named set of <literal>application</literal> logs that</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>name</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara>Name used to refer to the input of a <literal>pipeline</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-inputs-application">
<title>.spec.inputs[].application</title>
<section xml:id="_description-3">
<title>Description</title>
<simpara>Application log selector.
All conditions in the selector must be satisfied (logical AND) to select logs.</simpara>
<section xml:id="_type-3">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>namespaces</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Namespaces from which to collect application logs.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>selector</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Selector for logs from pods with matching labels.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-inputs-application-namespaces">
<title>.spec.inputs[].application.namespaces[]</title>
<section xml:id="_description-4">
<title>Description</title>
<section xml:id="_type-4">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-inputs-application-selector">
<title>.spec.inputs[].application.selector</title>
<section xml:id="_description-5">
<title>Description</title>
<simpara>A label selector is a label query over a set of resources.</simpara>
<section xml:id="_type-5">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>matchLabels</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-inputs-application-selector-matchlabels">
<title>.spec.inputs[].application.selector.matchLabels</title>
<section xml:id="_description-6">
<title>Description</title>
<section xml:id="_type-6">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-outputdefaults">
<title>.spec.outputDefaults</title>
<section xml:id="_description-7">
<title>Description</title>
<section xml:id="_type-7">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>elasticsearch</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Elasticsearch OutputSpec default values</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-outputdefaults-elasticsearch">
<title>.spec.outputDefaults.elasticsearch</title>
<section xml:id="_description-8">
<title>Description</title>
<simpara>ElasticsearchStructuredSpec is spec related to structured log changes to determine the elasticsearch index</simpara>
<section xml:id="_type-8">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>enableStructuredContainerLogs</simpara></entry>
<entry align="left" valign="top"><simpara>bool</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> EnableStructuredContainerLogs enables multi-container structured logs to allow</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>structuredTypeKey</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> StructuredTypeKey specifies the metadata key to be used as name of elasticsearch index</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>structuredTypeName</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> StructuredTypeName specifies the name of elasticsearch schema</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-outputs">
<title>.spec.outputs[]</title>
<section xml:id="_description-9">
<title>Description</title>
<simpara>Output defines a destination for log messages.</simpara>
<section xml:id="_type-9">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>syslog</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>fluentdForward</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>elasticsearch</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>kafka</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>cloudwatch</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>loki</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>googleCloudLogging</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>splunk</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>name</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara>Name used to refer to the output from a <literal>pipeline</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>secret</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Secret for authentication.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>tls</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>TLS contains settings for controlling options on TLS client connections.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>type</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara>Type of output plugin.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>url</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> URL to send log records to.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-outputs-secret">
<title>.spec.outputs[].secret</title>
<section xml:id="_description-10">
<title>Description</title>
<simpara>OutputSecretSpec is a secret reference containing name only, no namespace.</simpara>
<section xml:id="_type-10">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>name</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara>Name of a secret in the namespace configured for log forwarder secrets.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-outputs-tls">
<title>.spec.outputs[].tls</title>
<section xml:id="_description-11">
<title>Description</title>
<simpara>OutputTLSSpec contains options for TLS connections that are agnostic to the output type.</simpara>
<section xml:id="_type-11">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>insecureSkipVerify</simpara></entry>
<entry align="left" valign="top"><simpara>bool</simpara></entry>
<entry align="left" valign="top"><simpara>If InsecureSkipVerify is true, then the TLS client will be configured to ignore errors with certificates.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-pipelines">
<title>.spec.pipelines[]</title>
<section xml:id="_description-12">
<title>Description</title>
<simpara>PipelinesSpec link a set of inputs to a set of outputs.</simpara>
<section xml:id="_type-12">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>detectMultilineErrors</simpara></entry>
<entry align="left" valign="top"><simpara>bool</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> DetectMultilineErrors enables multiline error detection of container logs</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>inputRefs</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara>InputRefs lists the names (<literal>input.name</literal>) of inputs to this pipeline.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>labels</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Labels applied to log records passing through this pipeline.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>name</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Name is optional, but must be unique in the <literal>pipelines</literal> list if provided.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>outputRefs</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara>OutputRefs lists the names (<literal>output.name</literal>) of outputs from this pipeline.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>parse</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Parse enables parsing of log entries into structured logs</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-pipelines-inputrefs">
<title>.spec.pipelines[].inputRefs[]</title>
<section xml:id="_description-13">
<title>Description</title>
<section xml:id="_type-13">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-pipelines-labels">
<title>.spec.pipelines[].labels</title>
<section xml:id="_description-14">
<title>Description</title>
<section xml:id="_type-14">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-pipelines-outputrefs">
<title>.spec.pipelines[].outputRefs[]</title>
<section xml:id="_description-15">
<title>Description</title>
<section xml:id="_type-15">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-status">
<title>.status</title>
<section xml:id="_description-16">
<title>Description</title>
<simpara>ClusterLogForwarderStatus defines the observed state of ClusterLogForwarder</simpara>
<section xml:id="_type-16">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>conditions</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>Conditions of the log forwarder.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>inputs</simpara></entry>
<entry align="left" valign="top"><simpara>Conditions</simpara></entry>
<entry align="left" valign="top"><simpara>Inputs maps input name to condition of the input.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>outputs</simpara></entry>
<entry align="left" valign="top"><simpara>Conditions</simpara></entry>
<entry align="left" valign="top"><simpara>Outputs maps output name to condition of the output.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>pipelines</simpara></entry>
<entry align="left" valign="top"><simpara>Conditions</simpara></entry>
<entry align="left" valign="top"><simpara>Pipelines maps pipeline name to condition of the pipeline.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-status-conditions">
<title>.status.conditions</title>
<section xml:id="_description-17">
<title>Description</title>
<section xml:id="_type-17">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-status-inputs">
<title>.status.inputs</title>
<section xml:id="_description-18">
<title>Description</title>
<section xml:id="_type-18">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>Conditions</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-status-outputs">
<title>.status.outputs</title>
<section xml:id="_description-19">
<title>Description</title>
<section xml:id="_type-19">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>Conditions</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-status-pipelines">
<title>.status.pipelines</title>
<section xml:id="_description-20">
<title>Description</title>
<section xml:id="_type-20">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>Conditions== ClusterLogging
A Red Hat OpenShift Logging instance. ClusterLogging is the Schema for the clusterloggings API</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>spec</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>Specification of the desired behavior of ClusterLogging</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>status</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>Status defines the observed state of ClusterLogging</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-2">
<title>.spec</title>
<section xml:id="_description-21">
<title>Description</title>
<simpara>ClusterLoggingSpec defines the desired state of ClusterLogging</simpara>
<section xml:id="_type-21">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>collection</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>Specification of the Collection component for the cluster</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>curation</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(DEPRECATED)</emphasis> <emphasis role="strong">(optional)</emphasis> Deprecated. Specification of the Curation component for the cluster</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>forwarder</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(DEPRECATED)</emphasis> <emphasis role="strong">(optional)</emphasis> Deprecated. Specification for Forwarder component for the cluster</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>logStore</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Specification of the Log Storage component for the cluster</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>managementState</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Indicator if the resource is &#39;Managed&#39; or &#39;Unmanaged&#39; by the operator</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>visualization</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Specification of the Visualization component for the cluster</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-collection">
<title>.spec.collection</title>
<section xml:id="_description-22">
<title>Description</title>
<simpara>This is the struct that will contain information pertinent to Log and event collection</simpara>
<section xml:id="_type-22">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>resources</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> The resource requirements for the collector</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>nodeSelector</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Define which Nodes the Pods are scheduled on.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>tolerations</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Define the tolerations the Pods will accept</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>fluentd</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Fluentd represents the configuration for forwarders of type fluentd.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>logs</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(DEPRECATED)</emphasis> <emphasis role="strong">(optional)</emphasis> Deprecated. Specification of Log Collection for the cluster</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>type</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> The type of Log Collection to configure</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-collection-fluentd">
<title>.spec.collection.fluentd</title>
<section xml:id="_description-23">
<title>Description</title>
<simpara>FluentdForwarderSpec represents the configuration for forwarders of type fluentd.</simpara>
<section xml:id="_type-23">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>buffer</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>inFile</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-collection-fluentd-buffer">
<title>.spec.collection.fluentd.buffer</title>
<section xml:id="_description-24">
<title>Description</title>
<simpara>FluentdBufferSpec represents a subset of fluentd buffer parameters to tune
the buffer configuration for all fluentd outputs. It supports a subset of
parameters to configure buffer and queue sizing, flush operations and retry
flushing.</simpara>
<simpara>For general parameters refer to:
<link xlink:href="https://docs.fluentd.org/configuration/buffer-section#buffering-parameters">https://docs.fluentd.org/configuration/buffer-section#buffering-parameters</link></simpara>
<simpara>For flush parameters refer to:
<link xlink:href="https://docs.fluentd.org/configuration/buffer-section#flushing-parameters">https://docs.fluentd.org/configuration/buffer-section#flushing-parameters</link></simpara>
<simpara>For retry parameters refer to:
<link xlink:href="https://docs.fluentd.org/configuration/buffer-section#retries-parameters">https://docs.fluentd.org/configuration/buffer-section#retries-parameters</link></simpara>
<section xml:id="_type-24">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>chunkLimitSize</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> ChunkLimitSize represents the maximum size of each chunk. Events will be</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>flushInterval</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> FlushInterval represents the time duration to wait between two consecutive flush</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>flushMode</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> FlushMode represents the mode of the flushing thread to write chunks. The mode</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>flushThreadCount</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> FlushThreadCount reprents the number of threads used by the fluentd buffer</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>overflowAction</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> OverflowAction represents the action for the fluentd buffer plugin to</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>retryMaxInterval</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> RetryMaxInterval represents the maximum time interval for exponential backoff</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>retryTimeout</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> RetryTimeout represents the maximum time interval to attempt retries before giving up</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>retryType</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> RetryType represents the type of retrying flush operations. Flush operations can</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>retryWait</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> RetryWait represents the time duration between two consecutive retries to flush</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>totalLimitSize</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> TotalLimitSize represents the threshold of node space allowed per fluentd</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-collection-fluentd-infile">
<title>.spec.collection.fluentd.inFile</title>
<section xml:id="_description-25">
<title>Description</title>
<simpara>FluentdInFileSpec represents a subset of fluentd in-tail plugin parameters
to tune the configuration for all fluentd in-tail inputs.</simpara>
<simpara>For general parameters refer to:
<link xlink:href="https://docs.fluentd.org/input/tail#parameters">https://docs.fluentd.org/input/tail#parameters</link></simpara>
<section xml:id="_type-25">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>readLinesLimit</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> ReadLinesLimit represents the number of lines to read with each I/O operation</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-collection-logs">
<title>.spec.collection.logs</title>
<section xml:id="_description-26">
<title>Description</title>
<section xml:id="_type-26">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>fluentd</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>Specification of the Fluentd Log Collection component</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>type</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara>The type of Log Collection to configure</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-collection-logs-fluentd">
<title>.spec.collection.logs.fluentd</title>
<section xml:id="_description-27">
<title>Description</title>
<simpara>CollectorSpec is spec to define scheduling and resources for a collector</simpara>
<section xml:id="_type-27">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>nodeSelector</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Define which Nodes the Pods are scheduled on.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>resources</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> The resource requirements for the collector</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>tolerations</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Define the tolerations the Pods will accept</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-collection-logs-fluentd-nodeselector">
<title>.spec.collection.logs.fluentd.nodeSelector</title>
<section xml:id="_description-28">
<title>Description</title>
<section xml:id="_type-28">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-collection-logs-fluentd-resources">
<title>.spec.collection.logs.fluentd.resources</title>
<section xml:id="_description-29">
<title>Description</title>
<section xml:id="_type-29">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>limits</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Limits describes the maximum amount of compute resources allowed.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>requests</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Requests describes the minimum amount of compute resources required.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-collection-logs-fluentd-resources-limits">
<title>.spec.collection.logs.fluentd.resources.limits</title>
<section xml:id="_description-30">
<title>Description</title>
<section xml:id="_type-30">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-collection-logs-fluentd-resources-requests">
<title>.spec.collection.logs.fluentd.resources.requests</title>
<section xml:id="_description-31">
<title>Description</title>
<section xml:id="_type-31">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-collection-logs-fluentd-tolerations">
<title>.spec.collection.logs.fluentd.tolerations[]</title>
<section xml:id="_description-32">
<title>Description</title>
<section xml:id="_type-32">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>effect</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Effect indicates the taint effect to match. Empty means match all taint effects.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>key</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Key is the taint key that the toleration applies to. Empty means match all taint keys.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>operator</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Operator represents a key&#39;s relationship to the value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>tolerationSeconds</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> TolerationSeconds represents the period of time the toleration (which must be</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>value</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Value is the taint value the toleration matches to.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-collection-logs-fluentd-tolerations-tolerationseconds">
<title>.spec.collection.logs.fluentd.tolerations[].tolerationSeconds</title>
<section xml:id="_description-33">
<title>Description</title>
<section xml:id="_type-33">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>int</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-curation">
<title>.spec.curation</title>
<section xml:id="_description-34">
<title>Description</title>
<simpara>This is the struct that will contain information pertinent to Log curation (Curator)</simpara>
<section xml:id="_type-34">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>curator</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>The specification of curation to configure</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>type</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara>The kind of curation to configure</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-curation-curator">
<title>.spec.curation.curator</title>
<section xml:id="_description-35">
<title>Description</title>
<section xml:id="_type-35">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>nodeSelector</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>Define which Nodes the Pods are scheduled on.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>resources</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> The resource requirements for Curator</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>schedule</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara>The cron schedule that the Curator job is run. Defaults to &#34;30 3 * * *&#34;</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>tolerations</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-curation-curator-nodeselector">
<title>.spec.curation.curator.nodeSelector</title>
<section xml:id="_description-36">
<title>Description</title>
<section xml:id="_type-36">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-curation-curator-resources">
<title>.spec.curation.curator.resources</title>
<section xml:id="_description-37">
<title>Description</title>
<section xml:id="_type-37">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>limits</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Limits describes the maximum amount of compute resources allowed.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>requests</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Requests describes the minimum amount of compute resources required.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-curation-curator-resources-limits">
<title>.spec.curation.curator.resources.limits</title>
<section xml:id="_description-38">
<title>Description</title>
<section xml:id="_type-38">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-curation-curator-resources-requests">
<title>.spec.curation.curator.resources.requests</title>
<section xml:id="_description-39">
<title>Description</title>
<section xml:id="_type-39">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-curation-curator-tolerations">
<title>.spec.curation.curator.tolerations[]</title>
<section xml:id="_description-40">
<title>Description</title>
<section xml:id="_type-40">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>effect</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Effect indicates the taint effect to match. Empty means match all taint effects.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>key</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Key is the taint key that the toleration applies to. Empty means match all taint keys.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>operator</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Operator represents a key&#39;s relationship to the value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>tolerationSeconds</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> TolerationSeconds represents the period of time the toleration (which must be</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>value</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Value is the taint value the toleration matches to.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-curation-curator-tolerations-tolerationseconds">
<title>.spec.curation.curator.tolerations[].tolerationSeconds</title>
<section xml:id="_description-41">
<title>Description</title>
<section xml:id="_type-41">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>int</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-forwarder">
<title>.spec.forwarder</title>
<section xml:id="_description-42">
<title>Description</title>
<simpara>ForwarderSpec contains global tuning parameters for specific forwarder implementations.
This field is not required for general use, it allows performance tuning by users
familiar with the underlying forwarder technology.
Currently supported: <literal>fluentd</literal>.</simpara>
<section xml:id="_type-42">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>fluentd</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-forwarder-fluentd">
<title>.spec.forwarder.fluentd</title>
<section xml:id="_description-43">
<title>Description</title>
<simpara>FluentdForwarderSpec represents the configuration for forwarders of type fluentd.</simpara>
<section xml:id="_type-43">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>buffer</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>inFile</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-forwarder-fluentd-buffer">
<title>.spec.forwarder.fluentd.buffer</title>
<section xml:id="_description-44">
<title>Description</title>
<simpara>FluentdBufferSpec represents a subset of fluentd buffer parameters to tune
the buffer configuration for all fluentd outputs. It supports a subset of
parameters to configure buffer and queue sizing, flush operations and retry
flushing.</simpara>
<simpara>For general parameters refer to:
<link xlink:href="https://docs.fluentd.org/configuration/buffer-section#buffering-parameters">https://docs.fluentd.org/configuration/buffer-section#buffering-parameters</link></simpara>
<simpara>For flush parameters refer to:
<link xlink:href="https://docs.fluentd.org/configuration/buffer-section#flushing-parameters">https://docs.fluentd.org/configuration/buffer-section#flushing-parameters</link></simpara>
<simpara>For retry parameters refer to:
<link xlink:href="https://docs.fluentd.org/configuration/buffer-section#retries-parameters">https://docs.fluentd.org/configuration/buffer-section#retries-parameters</link></simpara>
<section xml:id="_type-44">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>chunkLimitSize</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> ChunkLimitSize represents the maximum size of each chunk. Events will be</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>flushInterval</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> FlushInterval represents the time duration to wait between two consecutive flush</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>flushMode</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> FlushMode represents the mode of the flushing thread to write chunks. The mode</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>flushThreadCount</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> FlushThreadCount reprents the number of threads used by the fluentd buffer</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>overflowAction</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> OverflowAction represents the action for the fluentd buffer plugin to</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>retryMaxInterval</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> RetryMaxInterval represents the maximum time interval for exponential backoff</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>retryTimeout</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> RetryTimeout represents the maximum time interval to attempt retries before giving up</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>retryType</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> RetryType represents the type of retrying flush operations. Flush operations can</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>retryWait</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> RetryWait represents the time duration between two consecutive retries to flush</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>totalLimitSize</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> TotalLimitSize represents the threshold of node space allowed per fluentd</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-forwarder-fluentd-infile">
<title>.spec.forwarder.fluentd.inFile</title>
<section xml:id="_description-45">
<title>Description</title>
<simpara>FluentdInFileSpec represents a subset of fluentd in-tail plugin parameters
to tune the configuration for all fluentd in-tail inputs.</simpara>
<simpara>For general parameters refer to:
<link xlink:href="https://docs.fluentd.org/input/tail#parameters">https://docs.fluentd.org/input/tail#parameters</link></simpara>
<section xml:id="_type-45">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>readLinesLimit</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> ReadLinesLimit represents the number of lines to read with each I/O operation</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore">
<title>.spec.logStore</title>
<section xml:id="_description-46">
<title>Description</title>
<simpara>The LogStoreSpec contains information about how logs are stored.</simpara>
<section xml:id="_type-46">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>elasticsearch</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>Specification of the Elasticsearch Log Store component</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>lokistack</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>LokiStack contains information about which LokiStack to use for log storage if Type is set to LogStoreTypeLokiStack.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>retentionPolicy</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Retention policy defines the maximum age for an index after which it should be deleted</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>type</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara>The Type of Log Storage to configure. The operator currently supports either using ElasticSearch</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch">
<title>.spec.logStore.elasticsearch</title>
<section xml:id="_description-47">
<title>Description</title>
<section xml:id="_type-47">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>nodeCount</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara>Number of nodes to deploy for Elasticsearch</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>nodeSelector</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>Define which Nodes the Pods are scheduled on.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>proxy</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>Specification of the Elasticsearch Proxy component</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>redundancyPolicy</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>resources</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> The resource requirements for Elasticsearch</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>storage</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> The storage specification for Elasticsearch data nodes</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>tolerations</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch-nodeselector">
<title>.spec.logStore.elasticsearch.nodeSelector</title>
<section xml:id="_description-48">
<title>Description</title>
<section xml:id="_type-48">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch-proxy">
<title>.spec.logStore.elasticsearch.proxy</title>
<section xml:id="_description-49">
<title>Description</title>
<section xml:id="_type-49">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>resources</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch-proxy-resources">
<title>.spec.logStore.elasticsearch.proxy.resources</title>
<section xml:id="_description-50">
<title>Description</title>
<section xml:id="_type-50">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>limits</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Limits describes the maximum amount of compute resources allowed.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>requests</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Requests describes the minimum amount of compute resources required.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch-proxy-resources-limits">
<title>.spec.logStore.elasticsearch.proxy.resources.limits</title>
<section xml:id="_description-51">
<title>Description</title>
<section xml:id="_type-51">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch-proxy-resources-requests">
<title>.spec.logStore.elasticsearch.proxy.resources.requests</title>
<section xml:id="_description-52">
<title>Description</title>
<section xml:id="_type-52">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch-resources">
<title>.spec.logStore.elasticsearch.resources</title>
<section xml:id="_description-53">
<title>Description</title>
<section xml:id="_type-53">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>limits</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Limits describes the maximum amount of compute resources allowed.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>requests</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Requests describes the minimum amount of compute resources required.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch-resources-limits">
<title>.spec.logStore.elasticsearch.resources.limits</title>
<section xml:id="_description-54">
<title>Description</title>
<section xml:id="_type-54">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch-resources-requests">
<title>.spec.logStore.elasticsearch.resources.requests</title>
<section xml:id="_description-55">
<title>Description</title>
<section xml:id="_type-55">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch-storage">
<title>.spec.logStore.elasticsearch.storage</title>
<section xml:id="_description-56">
<title>Description</title>
<section xml:id="_type-56">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>size</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>The max storage capacity for the node to provision.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>storageClassName</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> The name of the storage class to use with creating the node&#39;s PVC.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch-storage-size">
<title>.spec.logStore.elasticsearch.storage.size</title>
<section xml:id="_description-57">
<title>Description</title>
<section xml:id="_type-57">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Format</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara>Change Format at will. See the comment for Canonicalize for</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>d</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>d is the quantity in inf.Dec form if d.Dec != nil</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>i</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara>i is the quantity in int64 scaled form, if d.Dec == nil</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>s</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara>s is the generated value of this quantity to avoid recalculation</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch-storage-size-d">
<title>.spec.logStore.elasticsearch.storage.size.d</title>
<section xml:id="_description-58">
<title>Description</title>
<section xml:id="_type-58">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Dec</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch-storage-size-d-dec">
<title>.spec.logStore.elasticsearch.storage.size.d.Dec</title>
<section xml:id="_description-59">
<title>Description</title>
<section xml:id="_type-59">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>scale</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>unscaled</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch-storage-size-d-dec-unscaled">
<title>.spec.logStore.elasticsearch.storage.size.d.Dec.unscaled</title>
<section xml:id="_description-60">
<title>Description</title>
<section xml:id="_type-60">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>abs</simpara></entry>
<entry align="left" valign="top"><simpara>Word</simpara></entry>
<entry align="left" valign="top"><simpara>sign</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>neg</simpara></entry>
<entry align="left" valign="top"><simpara>bool</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch-storage-size-d-dec-unscaled-abs">
<title>.spec.logStore.elasticsearch.storage.size.d.Dec.unscaled.abs</title>
<section xml:id="_description-61">
<title>Description</title>
<section xml:id="_type-61">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>Word</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch-storage-size-i">
<title>.spec.logStore.elasticsearch.storage.size.i</title>
<section xml:id="_description-62">
<title>Description</title>
<section xml:id="_type-62">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>int</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>scale</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>value</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch-tolerations">
<title>.spec.logStore.elasticsearch.tolerations[]</title>
<section xml:id="_description-63">
<title>Description</title>
<section xml:id="_type-63">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>effect</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Effect indicates the taint effect to match. Empty means match all taint effects.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>key</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Key is the taint key that the toleration applies to. Empty means match all taint keys.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>operator</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Operator represents a key&#39;s relationship to the value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>tolerationSeconds</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> TolerationSeconds represents the period of time the toleration (which must be</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>value</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Value is the taint value the toleration matches to.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-elasticsearch-tolerations-tolerationseconds">
<title>.spec.logStore.elasticsearch.tolerations[].tolerationSeconds</title>
<section xml:id="_description-64">
<title>Description</title>
<section xml:id="_type-64">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>int</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-lokistack">
<title>.spec.logStore.lokistack</title>
<section xml:id="_description-65">
<title>Description</title>
<simpara>LokiStackStoreSpec is used to set up cluster-logging to use a LokiStack as logging storage.
It points to an existing LokiStack in the same namespace.</simpara>
<section xml:id="_type-65">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>name</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara>Name of the LokiStack resource.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-retentionpolicy">
<title>.spec.logStore.retentionPolicy</title>
<section xml:id="_description-66">
<title>Description</title>
<section xml:id="_type-66">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>application</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>audit</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>infra</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-retentionpolicy-application">
<title>.spec.logStore.retentionPolicy.application</title>
<section xml:id="_description-67">
<title>Description</title>
<section xml:id="_type-67">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>diskThresholdPercent</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> The threshold percentage of ES disk usage that when reached, old indices should be deleted (e.g. 75)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>maxAge</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>namespaceSpec</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> The per namespace specification to delete documents older than a given minimum age</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>pruneNamespacesInterval</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> How often to run a new prune-namespaces job</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-retentionpolicy-application-namespacespec">
<title>.spec.logStore.retentionPolicy.application.namespaceSpec[]</title>
<section xml:id="_description-68">
<title>Description</title>
<section xml:id="_type-68">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>minAge</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Delete the records matching the namespaces which are older than this MinAge (e.g. 1d)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>namespace</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara>Target Namespace to delete logs older than MinAge (defaults to 7d)</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-retentionpolicy-audit">
<title>.spec.logStore.retentionPolicy.audit</title>
<section xml:id="_description-69">
<title>Description</title>
<section xml:id="_type-69">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>diskThresholdPercent</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> The threshold percentage of ES disk usage that when reached, old indices should be deleted (e.g. 75)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>maxAge</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>namespaceSpec</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> The per namespace specification to delete documents older than a given minimum age</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>pruneNamespacesInterval</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> How often to run a new prune-namespaces job</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-retentionpolicy-audit-namespacespec">
<title>.spec.logStore.retentionPolicy.audit.namespaceSpec[]</title>
<section xml:id="_description-70">
<title>Description</title>
<section xml:id="_type-70">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>minAge</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Delete the records matching the namespaces which are older than this MinAge (e.g. 1d)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>namespace</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara>Target Namespace to delete logs older than MinAge (defaults to 7d)</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-retentionpolicy-infra">
<title>.spec.logStore.retentionPolicy.infra</title>
<section xml:id="_description-71">
<title>Description</title>
<section xml:id="_type-71">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>diskThresholdPercent</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> The threshold percentage of ES disk usage that when reached, old indices should be deleted (e.g. 75)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>maxAge</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>namespaceSpec</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> The per namespace specification to delete documents older than a given minimum age</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>pruneNamespacesInterval</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> How often to run a new prune-namespaces job</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-logstore-retentionpolicy-infra-namespacespec">
<title>.spec.logStore.retentionPolicy.infra.namespaceSpec[]</title>
<section xml:id="_description-72">
<title>Description</title>
<section xml:id="_type-72">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>minAge</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Delete the records matching the namespaces which are older than this MinAge (e.g. 1d)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>namespace</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara>Target Namespace to delete logs older than MinAge (defaults to 7d)</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-visualization">
<title>.spec.visualization</title>
<section xml:id="_description-73">
<title>Description</title>
<simpara>This is the struct that will contain information pertinent to Log visualization (Kibana)</simpara>
<section xml:id="_type-73">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>kibana</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>Specification of the Kibana Visualization component</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>type</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara>The type of Visualization to configure</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-visualization-kibana">
<title>.spec.visualization.kibana</title>
<section xml:id="_description-74">
<title>Description</title>
<section xml:id="_type-74">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>nodeSelector</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>Define which Nodes the Pods are scheduled on.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>proxy</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara>Specification of the Kibana Proxy component</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>replicas</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara>Number of instances to deploy for a Kibana deployment</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>resources</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> The resource requirements for Kibana</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>tolerations</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-visualization-kibana-nodeselector">
<title>.spec.visualization.kibana.nodeSelector</title>
<section xml:id="_description-75">
<title>Description</title>
<section xml:id="_type-75">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-visualization-kibana-proxy">
<title>.spec.visualization.kibana.proxy</title>
<section xml:id="_description-76">
<title>Description</title>
<section xml:id="_type-76">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>resources</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-visualization-kibana-proxy-resources">
<title>.spec.visualization.kibana.proxy.resources</title>
<section xml:id="_description-77">
<title>Description</title>
<section xml:id="_type-77">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>limits</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Limits describes the maximum amount of compute resources allowed.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>requests</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Requests describes the minimum amount of compute resources required.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-visualization-kibana-proxy-resources-limits">
<title>.spec.visualization.kibana.proxy.resources.limits</title>
<section xml:id="_description-78">
<title>Description</title>
<section xml:id="_type-78">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-visualization-kibana-proxy-resources-requests">
<title>.spec.visualization.kibana.proxy.resources.requests</title>
<section xml:id="_description-79">
<title>Description</title>
<section xml:id="_type-79">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-visualization-kibana-replicas">
<title>.spec.visualization.kibana.replicas</title>
<section xml:id="_description-80">
<title>Description</title>
<section xml:id="_type-80">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>int</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-visualization-kibana-resources">
<title>.spec.visualization.kibana.resources</title>
<section xml:id="_description-81">
<title>Description</title>
<section xml:id="_type-81">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>limits</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Limits describes the maximum amount of compute resources allowed.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>requests</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Requests describes the minimum amount of compute resources required.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-visualization-kibana-resources-limits">
<title>.spec.visualization.kibana.resources.limits</title>
<section xml:id="_description-82">
<title>Description</title>
<section xml:id="_type-82">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-visualization-kibana-resources-requests">
<title>.spec.visualization.kibana.resources.requests</title>
<section xml:id="_description-83">
<title>Description</title>
<section xml:id="_type-83">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-spec-visualization-kibana-tolerations">
<title>.spec.visualization.kibana.tolerations[]</title>
<section xml:id="_description-84">
<title>Description</title>
<section xml:id="_type-84">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>effect</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Effect indicates the taint effect to match. Empty means match all taint effects.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>key</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Key is the taint key that the toleration applies to. Empty means match all taint keys.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>operator</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Operator represents a key&#39;s relationship to the value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>tolerationSeconds</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> TolerationSeconds represents the period of time the toleration (which must be</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>value</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> Value is the taint value the toleration matches to.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-spec-visualization-kibana-tolerations-tolerationseconds">
<title>.spec.visualization.kibana.tolerations[].tolerationSeconds</title>
<section xml:id="_description-85">
<title>Description</title>
<section xml:id="_type-85">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>int</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-status-2">
<title>.status</title>
<section xml:id="_description-86">
<title>Description</title>
<simpara>ClusterLoggingStatus defines the observed state of ClusterLogging</simpara>
<section xml:id="_type-86">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>collection</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>conditions</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>curation</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>logStore</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>visualization</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-status-collection">
<title>.status.collection</title>
<section xml:id="_description-87">
<title>Description</title>
<section xml:id="_type-87">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>logs</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-status-collection-logs">
<title>.status.collection.logs</title>
<section xml:id="_description-88">
<title>Description</title>
<section xml:id="_type-88">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>fluentdStatus</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-status-collection-logs-fluentdstatus">
<title>.status.collection.logs.fluentdStatus</title>
<section xml:id="_description-89">
<title>Description</title>
<section xml:id="_type-89">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>clusterCondition</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>daemonSet</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>nodes</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>pods</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-status-collection-logs-fluentdstatus-clustercondition">
<title>.status.collection.logs.fluentdStatus.clusterCondition</title>
<section xml:id="_description-90">
<title>Description</title>
<simpara><literal>operator-sdk generate crds</literal> does not allow map-of-slice, must use a named type.</simpara>
<section xml:id="_type-90">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-status-collection-logs-fluentdstatus-nodes">
<title>.status.collection.logs.fluentdStatus.nodes</title>
<section xml:id="_description-91">
<title>Description</title>
<section xml:id="_type-91">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-status-conditions-2">
<title>.status.conditions</title>
<section xml:id="_description-92">
<title>Description</title>
<section xml:id="_type-92">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-status-curation">
<title>.status.curation</title>
<section xml:id="_description-93">
<title>Description</title>
<section xml:id="_type-93">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>curatorStatus</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-status-curation-curatorstatus">
<title>.status.curation.curatorStatus[]</title>
<section xml:id="_description-94">
<title>Description</title>
<section xml:id="_type-94">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>clusterCondition</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>cronJobs</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>schedules</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>suspended</simpara></entry>
<entry align="left" valign="top"><simpara>bool</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-status-curation-curatorstatus-clustercondition">
<title>.status.curation.curatorStatus[].clusterCondition</title>
<section xml:id="_description-95">
<title>Description</title>
<simpara><literal>operator-sdk generate crds</literal> does not allow map-of-slice, must use a named type.</simpara>
<section xml:id="_type-95">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-status-logstore">
<title>.status.logStore</title>
<section xml:id="_description-96">
<title>Description</title>
<section xml:id="_type-96">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>elasticsearchStatus</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-status-logstore-elasticsearchstatus">
<title>.status.logStore.elasticsearchStatus[]</title>
<section xml:id="_description-97">
<title>Description</title>
<section xml:id="_type-97">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>cluster</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>clusterConditions</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>clusterHealth</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>clusterName</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>deployments</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>nodeConditions</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>nodeCount</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>pods</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>replicaSets</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>shardAllocationEnabled</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>statefulSets</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-status-logstore-elasticsearchstatus-cluster">
<title>.status.logStore.elasticsearchStatus[].cluster</title>
<section xml:id="_description-98">
<title>Description</title>
<section xml:id="_type-98">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>activePrimaryShards</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara>The number of Active Primary Shards for the Elasticsearch Cluster</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>activeShards</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara>The number of Active Shards for the Elasticsearch Cluster</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>initializingShards</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara>The number of Initializing Shards for the Elasticsearch Cluster</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>numDataNodes</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara>The number of Data Nodes for the Elasticsearch Cluster</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>numNodes</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara>The number of Nodes for the Elasticsearch Cluster</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>pendingTasks</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>relocatingShards</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara>The number of Relocating Shards for the Elasticsearch Cluster</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>status</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara>The current Status of the Elasticsearch Cluster</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>unassignedShards</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara>The number of Unassigned Shards for the Elasticsearch Cluster</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-status-logstore-elasticsearchstatus-clusterconditions">
<title>.status.logStore.elasticsearchStatus[].clusterConditions</title>
<section xml:id="_description-99">
<title>Description</title>
<section xml:id="_type-99">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-status-logstore-elasticsearchstatus-deployments">
<title>.status.logStore.elasticsearchStatus[].deployments[]</title>
<section xml:id="_description-100">
<title>Description</title>
<section xml:id="_type-100">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-status-logstore-elasticsearchstatus-nodeconditions">
<title>.status.logStore.elasticsearchStatus[].nodeConditions</title>
<section xml:id="_description-101">
<title>Description</title>
<section xml:id="_type-101">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-status-logstore-elasticsearchstatus-pods">
<title>.status.logStore.elasticsearchStatus[].pods</title>
<section xml:id="_description-102">
<title>Description</title>
<section xml:id="_type-102">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-status-logstore-elasticsearchstatus-replicasets">
<title>.status.logStore.elasticsearchStatus[].replicaSets[]</title>
<section xml:id="_description-103">
<title>Description</title>
<section xml:id="_type-103">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-status-logstore-elasticsearchstatus-statefulsets">
<title>.status.logStore.elasticsearchStatus[].statefulSets[]</title>
<section xml:id="_description-104">
<title>Description</title>
<section xml:id="_type-104">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-status-visualization">
<title>.status.visualization</title>
<section xml:id="_description-105">
<title>Description</title>
<section xml:id="_type-105">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>kibanaStatus</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-status-visualization-kibanastatus">
<title>.status.visualization.kibanaStatus[]</title>
<section xml:id="_description-106">
<title>Description</title>
<section xml:id="_type-106">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
<informaltable frame="all" rowsep="1" colsep="1">
<tgroup cols="3">
<colspec colname="col_1" colwidth="33.3333*"/>
<colspec colname="col_2" colwidth="33.3333*"/>
<colspec colname="col_3" colwidth="33.3334*"/>
<thead>
<row>
<entry align="left" valign="top">Property</entry>
<entry align="left" valign="top">Type</entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>clusterCondition</simpara></entry>
<entry align="left" valign="top"><simpara>object</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>deployment</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>pods</simpara></entry>
<entry align="left" valign="top"><simpara>string</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis> The status for each of the Kibana pods for the Visualization component</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>replicaSets</simpara></entry>
<entry align="left" valign="top"><simpara>array</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>replicas</simpara></entry>
<entry align="left" valign="top"><simpara>int</simpara></entry>
<entry align="left" valign="top"><simpara><emphasis role="strong">(optional)</emphasis></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</section>
</section>
<section xml:id="_-status-visualization-kibanastatus-clustercondition">
<title>.status.visualization.kibanaStatus[].clusterCondition</title>
<section xml:id="_description-107">
<title>Description</title>
<section xml:id="_type-107">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>object</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
<section xml:id="_-status-visualization-kibanastatus-replicasets">
<title>.status.visualization.kibanaStatus[].replicaSets[]</title>
<section xml:id="_description-108">
<title>Description</title>
<section xml:id="_type-108">
<title>Type</title>
<itemizedlist>
<listitem>
<simpara>array</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</section>
</section>
</section>
</section>
</chapter>
<chapter xml:id="openshift-logging-common-terms">
<title>Glossary</title>

<simpara>This glossary defines common terms that are used in the logging documentation.</simpara>
<variablelist>
<varlistentry>
<term>Annotation</term>
<listitem>
<simpara>You can use annotations to attach metadata to objects.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Red Hat OpenShift Logging Operator</term>
<listitem>
<simpara>The Red Hat OpenShift Logging Operator provides a set of APIs to control the collection and forwarding of application, infrastructure, and audit logs.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Custom resource (CR)</term>
<listitem>
<simpara>A CR is an extension of the Kubernetes API. To configure the logging and log forwarding, you can customize the <literal>ClusterLogging</literal> and the <literal>ClusterLogForwarder</literal> custom resources.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Event router</term>
<listitem>
<simpara>The event router is a pod that watches OpenShift Container Platform events. It collects logs by using the logging.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Fluentd</term>
<listitem>
<simpara>Fluentd is a log collector that resides on each OpenShift Container Platform node. It gathers application, infrastructure, and audit logs and forwards them to different outputs.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Garbage collection</term>
<listitem>
<simpara>Garbage collection is the process of cleaning up cluster resources, such as terminated containers and images that are not referenced by any running pods.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Elasticsearch</term>
<listitem>
<simpara>Elasticsearch is a distributed search and analytics engine. OpenShift Container Platform uses Elasticsearch as a default log store for the logging.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>OpenShift Elasticsearch Operator</term>
<listitem>
<simpara>The OpenShift Elasticsearch Operator is used to run an Elasticsearch cluster on OpenShift Container Platform. The OpenShift Elasticsearch Operator provides self-service for the Elasticsearch cluster operations and is used by the logging.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Indexing</term>
<listitem>
<simpara>Indexing is a data structure technique that is used to quickly locate and access data. Indexing optimizes the performance by minimizing the amount of disk access required when a query is processed.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>JSON logging</term>
<listitem>
<simpara>The Log Forwarding API enables you to parse JSON logs into a structured object and forward them to either the logging managed Elasticsearch or any other third-party system supported by the Log Forwarding API.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Kibana</term>
<listitem>
<simpara>Kibana is a browser-based console interface to query, discover, and visualize your Elasticsearch data through histograms, line graphs, and pie charts.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Kubernetes API server</term>
<listitem>
<simpara>Kubernetes API server validates and configures data for the API objects.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Labels</term>
<listitem>
<simpara>Labels are key-value pairs that you can use to organize and select subsets of objects, such as a pod.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Logging</term>
<listitem>
<simpara>With the logging, you can aggregate application, infrastructure, and audit logs throughout your cluster. You can also store them to a default log store, forward them to third party systems, and query and visualize the stored logs in the default log store.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Logging collector</term>
<listitem>
<simpara>A logging collector collects logs from the cluster, formats them, and forwards them to the log store or third party systems.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Log store</term>
<listitem>
<simpara>A log store is used to store aggregated logs. You can use an internal log store or forward logs to external log stores.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Log visualizer</term>
<listitem>
<simpara>Log visualizer is the user interface (UI) component you can use to view information such as logs, graphs, charts, and other metrics.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Node</term>
<listitem>
<simpara>A node is a worker machine in the OpenShift Container Platform cluster. A node is either a virtual machine (VM) or a physical machine.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Operators</term>
<listitem>
<simpara>Operators are the preferred method of packaging, deploying, and managing a Kubernetes application in an OpenShift Container Platform cluster. An Operator takes human operational knowledge and encodes it into software that is packaged and shared with customers.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Pod</term>
<listitem>
<simpara>A pod is the smallest logical unit in Kubernetes. A pod consists of one or more containers and runs on a worker node.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Role-based access control (RBAC)</term>
<listitem>
<simpara>RBAC is a key security control to ensure that cluster users and workloads have access only to resources required to execute their roles.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Shards</term>
<listitem>
<simpara>Elasticsearch organizes log data from Fluentd into datastores, or indices, then subdivides each index into multiple pieces called shards.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Taint</term>
<listitem>
<simpara>Taints ensure that pods are scheduled onto appropriate nodes. You can apply one or more taints on a node.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Toleration</term>
<listitem>
<simpara>You can apply tolerations to pods. Tolerations allow the scheduler to schedule pods with matching taints.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>Web console</term>
<listitem>
<simpara>A user interface (UI) to manage OpenShift Container Platform.</simpara>
</listitem>
</varlistentry>
</variablelist>
</chapter>
</book>