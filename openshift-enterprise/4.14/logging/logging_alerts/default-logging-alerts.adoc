:_mod-docs-content-type: ASSEMBLY
[id="default-logging-alerts"]
// The {product-title} attribute provides the context-sensitive name of the relevant OpenShift distribution, for example, "OpenShift Container Platform" or "OKD". The {product-version} attribute provides the product version relative to the distribution, for example "4.9".
// {product-title} and {product-version} are parsed when AsciiBinder queries the _distro_map.yml file in relation to the base branch of a pull request.
// See https://github.com/openshift/openshift-docs/blob/main/contributing_to_docs/doc_guidelines.adoc#product-name-and-version for more information on this topic.
// Other common attributes are defined in the following lines:
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:
:imagesdir: images
:prewrap!:
:op-system-first: Red Hat Enterprise Linux CoreOS (RHCOS)
:op-system: RHCOS
:op-system-lowercase: rhcos
:op-system-base: RHEL
:op-system-base-full: Red Hat Enterprise Linux (RHEL)
:op-system-version: 8.x
:tsb-name: Template Service Broker
:kebab: image:kebab.png[title="Options menu"]
:rh-openstack-first: Red Hat OpenStack Platform (RHOSP)
:rh-openstack: RHOSP
:ai-full: Assisted Installer
:ai-version: 2.3
:cluster-manager-first: Red Hat OpenShift Cluster Manager
:cluster-manager: OpenShift Cluster Manager
:cluster-manager-url: link:https://console.redhat.com/openshift[OpenShift Cluster Manager Hybrid Cloud Console]
:cluster-manager-url-pull: link:https://console.redhat.com/openshift/install/pull-secret[pull secret from the Red Hat OpenShift Cluster Manager]
:insights-advisor-url: link:https://console.redhat.com/openshift/insights/advisor/[Insights Advisor]
:hybrid-console: Red Hat Hybrid Cloud Console
:hybrid-console-second: Hybrid Cloud Console
:oadp-first: OpenShift API for Data Protection (OADP)
:oadp-full: OpenShift API for Data Protection
:oc-first: pass:quotes[OpenShift CLI (`oc`)]
:product-registry: OpenShift image registry
:rh-storage-first: Red Hat OpenShift Data Foundation
:rh-storage: OpenShift Data Foundation
:rh-rhacm-first: Red Hat Advanced Cluster Management (RHACM)
:rh-rhacm: RHACM
:rh-rhacm-version: 2.8
:sandboxed-containers-first: OpenShift sandboxed containers
:sandboxed-containers-operator: OpenShift sandboxed containers Operator
:sandboxed-containers-version: 1.3
:sandboxed-containers-version-z: 1.3.3
:sandboxed-containers-legacy-version: 1.3.2
:cert-manager-operator: cert-manager Operator for Red Hat OpenShift
:secondary-scheduler-operator-full: Secondary Scheduler Operator for Red Hat OpenShift
:secondary-scheduler-operator: Secondary Scheduler Operator
// Backup and restore
:velero-domain: velero.io
:velero-version: 1.11
:launch: image:app-launcher.png[title="Application Launcher"]
:mtc-short: MTC
:mtc-full: Migration Toolkit for Containers
:mtc-version: 1.8
:mtc-version-z: 1.8.0
// builds (Valid only in 4.11 and later)
:builds-v2title: Builds for Red Hat OpenShift
:builds-v2shortname: OpenShift Builds v2
:builds-v1shortname: OpenShift Builds v1
//gitops
:gitops-title: Red Hat OpenShift GitOps
:gitops-shortname: GitOps
:gitops-ver: 1.1
:rh-app-icon: image:red-hat-applications-menu-icon.jpg[title="Red Hat applications"]
//pipelines
:pipelines-title: Red Hat OpenShift Pipelines
:pipelines-shortname: OpenShift Pipelines
:pipelines-ver: pipelines-1.12
:pipelines-version-number: 1.12
:tekton-chains: Tekton Chains
:tekton-hub: Tekton Hub
:artifact-hub: Artifact Hub
:pac: Pipelines as Code
//odo
:odo-title: odo
//OpenShift Kubernetes Engine
:oke: OpenShift Kubernetes Engine
//OpenShift Platform Plus
:opp: OpenShift Platform Plus
//openshift virtualization (cnv)
:VirtProductName: OpenShift Virtualization
:VirtVersion: 4.14
:KubeVirtVersion: v0.59.0
:HCOVersion: 4.14.0
:CNVNamespace: openshift-cnv
:CNVOperatorDisplayName: OpenShift Virtualization Operator
:CNVSubscriptionSpecSource: redhat-operators
:CNVSubscriptionSpecName: kubevirt-hyperconverged
:delete: image:delete.png[title="Delete"]
//distributed tracing
:DTProductName: Red Hat OpenShift distributed tracing platform
:DTShortName: distributed tracing platform
:DTProductVersion: 2.9
:JaegerName: Red Hat OpenShift distributed tracing platform (Jaeger)
:JaegerShortName: distributed tracing platform (Jaeger)
:JaegerVersion: 1.47.0
:OTELName: Red Hat OpenShift distributed tracing data collection
:OTELShortName: distributed tracing data collection
:OTELOperator: Red Hat OpenShift distributed tracing data collection Operator
:OTELVersion: 0.81.0
:TempoName: Red Hat OpenShift distributed tracing platform (Tempo)
:TempoShortName: distributed tracing platform (Tempo)
:TempoOperator: Tempo Operator
:TempoVersion: 2.1.1
//logging
:logging-title: logging subsystem for Red Hat OpenShift
:logging-title-uc: Logging subsystem for Red Hat OpenShift
:logging: logging subsystem
:logging-uc: Logging subsystem
//serverless
:ServerlessProductName: OpenShift Serverless
:ServerlessProductShortName: Serverless
:ServerlessOperatorName: OpenShift Serverless Operator
:FunctionsProductName: OpenShift Serverless Functions
//service mesh v2
:product-dedicated: Red Hat OpenShift Dedicated
:product-rosa: Red Hat OpenShift Service on AWS
:SMProductName: Red Hat OpenShift Service Mesh
:SMProductShortName: Service Mesh
:SMProductVersion: 2.4.4
:MaistraVersion: 2.4
//Service Mesh v1
:SMProductVersion1x: 1.1.18.2
//Windows containers
:productwinc: Red Hat OpenShift support for Windows Containers
// Red Hat Quay Container Security Operator
:rhq-cso: Red Hat Quay Container Security Operator
// Red Hat Quay
:quay: Red Hat Quay
:sno: single-node OpenShift
:sno-caps: Single-node OpenShift
//TALO and Redfish events Operators
:cgu-operator-first: Topology Aware Lifecycle Manager (TALM)
:cgu-operator-full: Topology Aware Lifecycle Manager
:cgu-operator: TALM
:redfish-operator: Bare Metal Event Relay
//Formerly known as CodeReady Containers and CodeReady Workspaces
:openshift-local-productname: Red Hat OpenShift Local
:openshift-dev-spaces-productname: Red Hat OpenShift Dev Spaces
// Factory-precaching-cli tool
:factory-prestaging-tool: factory-precaching-cli tool
:factory-prestaging-tool-caps: Factory-precaching-cli tool
:openshift-networking: Red Hat OpenShift Networking
// TODO - this probably needs to be different for OKD
//ifdef::openshift-origin[]
//:openshift-networking: OKD Networking
//endif::[]
// logical volume manager storage
:lvms-first: Logical volume manager storage (LVM Storage)
:lvms: LVM Storage
//Operator SDK version
:osdk_ver: 1.31.0
//Operator SDK version that shipped with the previous OCP 4.x release
:osdk_ver_n1: 1.28.0
//Next-gen (OCP 4.14+) Operator Lifecycle Manager, aka "v1"
:olmv1: OLM 1.0
:olmv1-first: Operator Lifecycle Manager (OLM) 1.0
:ztp-first: GitOps Zero Touch Provisioning (ZTP)
:ztp: GitOps ZTP
:3no: three-node OpenShift
:3no-caps: Three-node OpenShift
:run-once-operator: Run Once Duration Override Operator
// Web terminal
:web-terminal-op: Web Terminal Operator
:devworkspace-op: DevWorkspace Operator
:secrets-store-driver: Secrets Store CSI driver
:secrets-store-operator: Secrets Store CSI Driver Operator
//AWS STS
:sts-first: Security Token Service (STS)
:sts-full: Security Token Service
:sts-short: STS
//Cloud provider names
//AWS
:aws-first: Amazon Web Services (AWS)
:aws-full: Amazon Web Services
:aws-short: AWS
//GCP
:gcp-first: Google Cloud Platform (GCP)
:gcp-full: Google Cloud Platform
:gcp-short: GCP
//alibaba cloud
:alibaba: Alibaba Cloud
// IBM Cloud VPC
:ibmcloudVPCProductName: IBM Cloud VPC
:ibmcloudVPCRegProductName: IBM(R) Cloud VPC
// IBM Cloud
:ibm-cloud-bm: IBM Cloud Bare Metal (Classic)
:ibm-cloud-bm-reg: IBM Cloud(R) Bare Metal (Classic)
// IBM Power
:ibmpowerProductName: IBM Power
:ibmpowerRegProductName: IBM(R) Power
// IBM zSystems
:ibmzProductName: IBM Z
:ibmzRegProductName: IBM(R) Z
:linuxoneProductName: IBM(R) LinuxONE
//Azure
:azure-full: Microsoft Azure
:azure-short: Azure
//vSphere
:vmw-full: VMware vSphere
:vmw-short: vSphere
//Oracle
:oci-first: Oracle(R) Cloud Infrastructure
:oci: OCI
:ocvs-first: Oracle(R) Cloud VMware Solution (OCVS)
:ocvs: OCVS
= Default logging alerts
:context: default-logging-alerts

toc::[]

Logging alerts are installed as part of the Cluster Logging Operator installation. Alerts depend on metrics exported by the log collection and log storage backends. These metrics are enabled if you selected the option to *Enable operator recommended cluster monitoring on this namespace* when installing the Cluster Logging Operator. For more information about installing logging Operators, see xref:../../logging/cluster-logging-deploying#cluster-logging-deploy-console_cluster-logging-deploying[Installing the {logging-title} using the web console].

Default logging alerts are sent to the {product-title} monitoring stack Alertmanager in the `openshift-monitoring` namespace, unless you have disabled the local Alertmanager instance.

:leveloffset: +1

// Module included in the following assemblies:
//
// * monitoring/managing-alerts.adoc
// * logging/logging_alerts/log-storage-alerts.adoc

:_mod-docs-content-type: PROCEDURE
[id="monitoring-accessing-the-alerting-ui_{context}"]
= Accessing the Alerting UI in the Administrator and Developer perspectives

The Alerting UI is accessible through the Administrator perspective and the Developer perspective in the {product-title} web console.

* In the *Administrator* perspective, select *Observe* -> *Alerting*. The three main pages in the Alerting UI in this perspective are the *Alerts*, *Silences*, and *Alerting Rules* pages.

//Next to the title of each of these pages is a link to the Alertmanager interface.

* In the *Developer* perspective, select *Observe* -> *<project_name>* -> *Alerts*. In this perspective, alerts, silences, and alerting rules are all managed from the *Alerts* page. The results shown in the *Alerts* page are specific to the selected project.

[NOTE]
====
In the *Developer* perspective, you can select from core {product-title} and user-defined projects that you have access to in the *Project:* list. However, alerts, silences, and alerting rules relating to core {product-title} projects are not displayed if you are not logged in as a cluster administrator.
====

:leveloffset!:
:leveloffset: +1

// Module included in the following assemblies:
//
// * logging/logging_alerts/default-logging-alerts.adoc

:_mod-docs-content-type: REFERENCE
[id="logging-vector-collector-alerts_{context}"]
= Vector collector alerts

In logging 5.7 and later versions, the following alerts are generated by the Vector collector. You can view these alerts in the {product-title} web console.

.Vector collector alerts
[cols="2,2,2,1",options="header"]
|===
|Alert |Message |Description |Severity

|`CollectorHighErrorRate`
|`<value> of records have resulted in an error by vector <instance>.`
|The number of vector output errors is high, by default more than 10 in the previous 15 minutes.
|Warning

|`CollectorNodeDown`
|`Prometheus could not scrape vector <instance> for more than 10m.`
|Vector is reporting that Prometheus could not scrape a specific Vector instance.
|Critical

|`CollectorVeryHighErrorRate`
|`<value> of records have resulted in an error by vector <instance>.`
|The number of Vector component errors are very high, by default more than 25 in the previous 15 minutes.
|Critical

|`FluentdQueueLengthIncreasing`
|`In the last 1h, fluentd <instance> buffer queue length constantly increased more than 1. Current value is <value>.`
|Fluentd is reporting that the queue size is increasing.
|Warning

|===

:leveloffset!:
:leveloffset: +1

// Module included in the following assemblies:
//
// * logging/logging_alerts/default-logging-alerts.adoc

:_mod-docs-content-type: REFERENCE
[id="logging-fluentd-collector-alerts_{context}"]
= Fluentd collector alerts

The following alerts are generated by the legacy Fluentd log collector. You can view these alerts in the {product-title} web console.

.Fluentd collector alerts
[cols="2,2,2,1",options="header"]
|===
|Alert |Message |Description |Severity

|`FluentDHighErrorRate`
|`<value> of records have resulted in an error by fluentd <instance>.`
|The number of FluentD output errors is high, by default more than 10 in the previous 15 minutes.
|Warning

|`FluentdNodeDown`
|`Prometheus could not scrape fluentd <instance> for more than 10m.`
|Fluentd is reporting that Prometheus could not scrape a specific Fluentd instance.
|Critical

|`FluentdQueueLengthIncreasing`
|`In the last 1h, fluentd <instance> buffer queue length constantly increased more than 1. Current value is <value>.`
|Fluentd is reporting that the queue size is increasing.
|Warning

|`FluentDVeryHighErrorRate`
|`<value> of records have resulted in an error by fluentd <instance>.`
|The number of FluentD output errors is very high, by default more than 25 in the previous 15 minutes.
|Critical

|===

:leveloffset!:
:leveloffset: +1

// Module included in the following assemblies:
//
// * logging/logging_alerts/default-logging-alerts.adoc

:_mod-docs-content-type: REFERENCE
[id="cluster-logging-elasticsearch-rules_{context}"]
= Elasticsearch alerting rules

You can view these alerting rules in the {product-title} web console.

.Alerting rules
[cols="3,6,1",options="header"]
|===
|Alert
|Description
|Severity

|`ElasticsearchClusterNotHealthy`
|The cluster health status has been RED for at least 2 minutes. The cluster does not accept writes, shards may be missing, or the master
 node hasn't been elected yet.
|Critical

|`ElasticsearchClusterNotHealthy`
|The cluster health status has been YELLOW for at least 20 minutes. Some shard replicas are not allocated.
|Warning

|`ElasticsearchDiskSpaceRunningLow`
|The cluster is expected to be out of disk space within the next 6 hours.
|Critical

|`ElasticsearchHighFileDescriptorUsage`
|The cluster is predicted to be out of file descriptors within the next hour.
|Warning

|`ElasticsearchJVMHeapUseHigh`
|The JVM Heap usage on the specified node is high.
|Alert

|`ElasticsearchNodeDiskWatermarkReached`
|The specified node has hit the low watermark due to low free disk space. Shards can not be allocated to this node anymore. You should consider adding more disk space to the node.
|Info

|`ElasticsearchNodeDiskWatermarkReached`
|The specified node has hit the high watermark due to low free disk space. Some shards will be re-allocated to different
nodes if possible. Make sure more disk space is added to the node or drop old indices allocated to this node.
|Warning

|`ElasticsearchNodeDiskWatermarkReached`
|The specified node has hit the flood watermark due to low free disk space. Every index that has a shard allocated on this node is enforced a read-only block. The index block must be manually released when the disk use falls below the high watermark.
|Critical

|`ElasticsearchJVMHeapUseHigh`
|The JVM Heap usage on the specified node is too high.
|Alert

|`ElasticsearchWriteRequestsRejectionJumps`
|Elasticsearch is experiencing an increase in write rejections on the specified node. This node might not be keeping up with the indexing speed.
|Warning

|`AggregatedLoggingSystemCPUHigh`
|The CPU used by the system on the specified node is too high.
|Alert

|`ElasticsearchProcessCPUHigh`
|The CPU used by Elasticsearch on the specified node is too high.
|Alert
|===

:leveloffset!:

[role="_additional-resources"]
[id="additional-resources_default-logging-alerts"]
== Additional resources
* xref:../../monitoring/managing-alerts.adoc#modifying-core-platform-alerting-rules_managing-alerts[Modifying core platform alerting rules]

//# includes=_attributes/common-attributes,modules/monitoring-accessing-the-alerting-ui,modules/logging-vector-collector-alerts,modules/logging-fluentd-collector-alerts,modules/cluster-logging-elasticsearch-rules
